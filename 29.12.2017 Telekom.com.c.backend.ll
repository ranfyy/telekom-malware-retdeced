source_filename = "test"
target datalayout = "e-m:e-p:32:32-f64:32:64-f80:32-n8:16:32-S128"

@cf = internal unnamed_addr global i1 false
@df = internal unnamed_addr global i1 false
@fpu_stat_TOP = internal unnamed_addr global i3 0
@eax = internal unnamed_addr global i32 0
@ecx = internal unnamed_addr global i32 0
@ebx = internal unnamed_addr global i32 0
@esp = internal unnamed_addr global i32 0
@ebp = internal unnamed_addr global i32 0
@esi = internal unnamed_addr global i32 0
@edi = internal unnamed_addr global i32 0
@0 = external global i32
@global_var_48b692.1 = constant [17 x i8] c"mqoesqcbbqlbkwli\00"
@global_var_48b685.2 = constant [13 x i8] c"uodaprfktkdq\00"
@global_var_48b6a3.4 = constant [13 x i8] c"ktggqcttwima\00"
@global_var_48b6b4.5 = constant [12 x i8] c"qtkyilwamea\00"
@global_var_401431.6 = constant i32 96978985
@global_var_48b643.12 = constant [13 x i8] c"cernel32.dll\00"
@global_var_48b634.13 = constant [15 x i8] c"cirtu_lAllocEx\00"
@global_var_48b639.14 = local_unnamed_addr constant [10 x i8] c"_lAllocEx\00"
@global_var_48b650.15 = constant [13 x i8] c"dzadLibraryA\00"
@global_var_48b628.16 = constant [12 x i8] c"ctdsapi.dll\00"
@global_var_48b65d.17 = local_unnamed_addr constant i32 0
@global_var_40a667.22 = constant i32 890433817
@global_var_40bf40.25 = constant i32 84011024
@global_var_406dd5.3 = constant i16* inttoptr (i32 880869482 to i16*)
@global_var_4019b0.7 = constant i1 true
@global_var_401acf.8 = constant i1 true
@global_var_402357.9 = constant i1 true
@global_var_40c17a.26 = constant i1 true

declare void @__pseudo_call(i32) local_unnamed_addr

declare void @__pseudo_cond_branch(i1, i32) local_unnamed_addr

define i32 @function_401000() local_unnamed_addr {
entry:
  %cf.global-to-local = alloca i1, align 1
  %eax.global-to-local = alloca i32, align 4
  %ebx.global-to-local = alloca i32, align 4
  %ecx.global-to-local = alloca i32, align 4
  %edi.global-to-local = alloca i32, align 4
  %edx.global-to-local = alloca i32, align 4
  %esi.global-to-local = alloca i32, align 4
  store i32 0, i32* %edx.global-to-local, align 4
  %v0_401000 = load i32, i32* @ecx, align 4
  %v1_401000 = inttoptr i32 %v0_401000 to i8*
  %v2_401000 = load i8, i8* %v1_401000, align 1
  %v3_401000 = load i32, i32* %edx.global-to-local, align 4
  %v4_401000 = trunc i32 %v3_401000 to i8
  %v5_401000 = add i8 %v4_401000, %v2_401000
  %v10_401000 = icmp ult i8 %v5_401000, %v2_401000
  store i1 %v10_401000, i1* %cf.global-to-local, align 1
  store i8 %v5_401000, i8* %v1_401000, align 1
  %v0_401002 = load i32, i32* @ecx, align 4
  %v1_401002 = inttoptr i32 %v0_401002 to i32*
  %v2_401002 = load i32, i32* %v1_401002, align 4
  %v3_401002 = load i32, i32* %edx.global-to-local, align 4
  %v4_401002 = load i1, i1* %cf.global-to-local, align 1
  %v5_401002 = zext i1 %v4_401002 to i32
  %v6_401002 = add i32 %v3_401002, %v2_401002
  %v7_401002 = add i32 %v5_401002, %v6_401002
  %v26_401002 = icmp ule i32 %v7_401002, %v2_401002
  %v27_401002 = icmp ult i32 %v6_401002, %v2_401002
  %v28_401002 = select i1 %v4_401002, i1 %v26_401002, i1 %v27_401002
  store i32 %v7_401002, i32* %v1_401002, align 4
  %v0_401004 = load i32, i32* @ecx, align 4
  %v1_401004 = inttoptr i32 %v0_401004 to i32*
  %v2_401004 = load i32, i32* %v1_401004, align 4
  %v3_401004 = load i32, i32* %edx.global-to-local, align 4
  %v5_401004 = zext i1 %v28_401002 to i32
  %v6_401004 = add i32 %v3_401004, %v2_401004
  %v7_401004 = add i32 %v5_401004, %v6_401004
  %v26_401004 = icmp ule i32 %v7_401004, %v2_401004
  %v27_401004 = icmp ult i32 %v6_401004, %v2_401004
  %v28_401004 = select i1 %v28_401002, i1 %v26_401004, i1 %v27_401004
  store i1 %v28_401004, i1* %cf.global-to-local, align 1
  store i32 %v7_401004, i32* %v1_401004, align 4
  %v0_401006 = load i32, i32* @ecx, align 4
  %v1_401006 = inttoptr i32 %v0_401006 to i8*
  %v2_401006 = load i8, i8* %v1_401006, align 1
  %v3_401006 = load i32, i32* %edx.global-to-local, align 4
  %v4_401006 = trunc i32 %v3_401006 to i8
  %v5_401006 = add i8 %v4_401006, %v2_401006
  %v10_401006 = icmp ult i8 %v5_401006, %v2_401006
  store i1 %v10_401006, i1* %cf.global-to-local, align 1
  store i8 %v5_401006, i8* %v1_401006, align 1
  %v0_401008 = load i32, i32* @ecx, align 4
  %v1_401008 = inttoptr i32 %v0_401008 to i32*
  %v2_401008 = load i32, i32* %v1_401008, align 4
  %v3_401008 = load i32, i32* %edx.global-to-local, align 4
  %v4_401008 = load i1, i1* %cf.global-to-local, align 1
  %v5_401008 = zext i1 %v4_401008 to i32
  %v6_401008 = add i32 %v3_401008, %v2_401008
  %v7_401008 = add i32 %v5_401008, %v6_401008
  %v26_401008 = icmp ule i32 %v7_401008, %v2_401008
  %v27_401008 = icmp ult i32 %v6_401008, %v2_401008
  %v28_401008 = select i1 %v4_401008, i1 %v26_401008, i1 %v27_401008
  store i32 %v7_401008, i32* %v1_401008, align 4
  %v0_40100a = load i32, i32* @ecx, align 4
  %v1_40100a = inttoptr i32 %v0_40100a to i32*
  %v2_40100a = load i32, i32* %v1_40100a, align 4
  %v3_40100a = load i32, i32* %edx.global-to-local, align 4
  %v5_40100a = zext i1 %v28_401008 to i32
  %v6_40100a = add i32 %v3_40100a, %v2_40100a
  %v7_40100a = add i32 %v5_40100a, %v6_40100a
  %v26_40100a = icmp ule i32 %v7_40100a, %v2_40100a
  %v27_40100a = icmp ult i32 %v6_40100a, %v2_40100a
  %v28_40100a = select i1 %v28_401008, i1 %v26_40100a, i1 %v27_40100a
  store i1 %v28_40100a, i1* %cf.global-to-local, align 1
  store i32 %v7_40100a, i32* %v1_40100a, align 4
  %v0_40100c = load i32, i32* @ecx, align 4
  %v1_40100c = inttoptr i32 %v0_40100c to i8*
  %v2_40100c = load i8, i8* %v1_40100c, align 1
  %v3_40100c = load i32, i32* %edx.global-to-local, align 4
  %v4_40100c = trunc i32 %v3_40100c to i8
  %v5_40100c = add i8 %v4_40100c, %v2_40100c
  %v10_40100c = icmp ult i8 %v5_40100c, %v2_40100c
  store i1 %v10_40100c, i1* %cf.global-to-local, align 1
  store i8 %v5_40100c, i8* %v1_40100c, align 1
  %v0_40100e = load i32, i32* @ecx, align 4
  %v1_40100e = inttoptr i32 %v0_40100e to i32*
  %v2_40100e = load i32, i32* %v1_40100e, align 4
  %v3_40100e = load i32, i32* %edx.global-to-local, align 4
  %v4_40100e = load i1, i1* %cf.global-to-local, align 1
  %v5_40100e = zext i1 %v4_40100e to i32
  %v6_40100e = add i32 %v3_40100e, %v2_40100e
  %v7_40100e = add i32 %v5_40100e, %v6_40100e
  %v26_40100e = icmp ule i32 %v7_40100e, %v2_40100e
  %v27_40100e = icmp ult i32 %v6_40100e, %v2_40100e
  %v28_40100e = select i1 %v4_40100e, i1 %v26_40100e, i1 %v27_40100e
  store i32 %v7_40100e, i32* %v1_40100e, align 4
  %v0_401010 = load i32, i32* @ecx, align 4
  %v1_401010 = inttoptr i32 %v0_401010 to i32*
  %v2_401010 = load i32, i32* %v1_401010, align 4
  %v3_401010 = load i32, i32* %edx.global-to-local, align 4
  %v5_401010 = zext i1 %v28_40100e to i32
  %v6_401010 = add i32 %v3_401010, %v2_401010
  %v7_401010 = add i32 %v5_401010, %v6_401010
  %v26_401010 = icmp ule i32 %v7_401010, %v2_401010
  %v27_401010 = icmp ult i32 %v6_401010, %v2_401010
  %v28_401010 = select i1 %v28_40100e, i1 %v26_401010, i1 %v27_401010
  store i1 %v28_401010, i1* %cf.global-to-local, align 1
  store i32 %v7_401010, i32* %v1_401010, align 4
  %v0_401012 = load i32, i32* @ecx, align 4
  %v1_401012 = inttoptr i32 %v0_401012 to i8*
  %v2_401012 = load i8, i8* %v1_401012, align 1
  %v3_401012 = load i32, i32* %edx.global-to-local, align 4
  %v4_401012 = trunc i32 %v3_401012 to i8
  %v5_401012 = add i8 %v4_401012, %v2_401012
  %v10_401012 = icmp ult i8 %v5_401012, %v2_401012
  store i1 %v10_401012, i1* %cf.global-to-local, align 1
  store i8 %v5_401012, i8* %v1_401012, align 1
  %v0_401014 = load i32, i32* @ecx, align 4
  %v1_401014 = inttoptr i32 %v0_401014 to i32*
  %v2_401014 = load i32, i32* %v1_401014, align 4
  %v3_401014 = load i32, i32* %edx.global-to-local, align 4
  %v4_401014 = load i1, i1* %cf.global-to-local, align 1
  %v5_401014 = zext i1 %v4_401014 to i32
  %v6_401014 = add i32 %v3_401014, %v2_401014
  %v7_401014 = add i32 %v5_401014, %v6_401014
  %v26_401014 = icmp ule i32 %v7_401014, %v2_401014
  %v27_401014 = icmp ult i32 %v6_401014, %v2_401014
  %v28_401014 = select i1 %v4_401014, i1 %v26_401014, i1 %v27_401014
  store i32 %v7_401014, i32* %v1_401014, align 4
  %v0_401016 = load i32, i32* @ecx, align 4
  %v1_401016 = inttoptr i32 %v0_401016 to i32*
  %v2_401016 = load i32, i32* %v1_401016, align 4
  %v3_401016 = load i32, i32* %edx.global-to-local, align 4
  %v5_401016 = zext i1 %v28_401014 to i32
  %v6_401016 = add i32 %v3_401016, %v2_401016
  %v7_401016 = add i32 %v5_401016, %v6_401016
  %v26_401016 = icmp ule i32 %v7_401016, %v2_401016
  %v27_401016 = icmp ult i32 %v6_401016, %v2_401016
  %v28_401016 = select i1 %v28_401014, i1 %v26_401016, i1 %v27_401016
  store i1 %v28_401016, i1* %cf.global-to-local, align 1
  store i32 %v7_401016, i32* %v1_401016, align 4
  %v0_401018 = load i32, i32* @ecx, align 4
  %v1_401018 = inttoptr i32 %v0_401018 to i8*
  %v2_401018 = load i8, i8* %v1_401018, align 1
  %v3_401018 = load i32, i32* %edx.global-to-local, align 4
  %v4_401018 = trunc i32 %v3_401018 to i8
  %v5_401018 = add i8 %v4_401018, %v2_401018
  %v10_401018 = icmp ult i8 %v5_401018, %v2_401018
  store i1 %v10_401018, i1* %cf.global-to-local, align 1
  store i8 %v5_401018, i8* %v1_401018, align 1
  %v0_40101a = load i32, i32* @ecx, align 4
  %v1_40101a = inttoptr i32 %v0_40101a to i32*
  %v2_40101a = load i32, i32* %v1_40101a, align 4
  %v3_40101a = load i32, i32* %edx.global-to-local, align 4
  %v4_40101a = load i1, i1* %cf.global-to-local, align 1
  %v5_40101a = zext i1 %v4_40101a to i32
  %v6_40101a = add i32 %v3_40101a, %v2_40101a
  %v7_40101a = add i32 %v5_40101a, %v6_40101a
  %v26_40101a = icmp ule i32 %v7_40101a, %v2_40101a
  %v27_40101a = icmp ult i32 %v6_40101a, %v2_40101a
  %v28_40101a = select i1 %v4_40101a, i1 %v26_40101a, i1 %v27_40101a
  store i32 %v7_40101a, i32* %v1_40101a, align 4
  %v0_40101c = load i32, i32* @ecx, align 4
  %v1_40101c = inttoptr i32 %v0_40101c to i32*
  %v2_40101c = load i32, i32* %v1_40101c, align 4
  %v3_40101c = load i32, i32* %edx.global-to-local, align 4
  %v5_40101c = zext i1 %v28_40101a to i32
  %v6_40101c = add i32 %v3_40101c, %v2_40101c
  %v7_40101c = add i32 %v5_40101c, %v6_40101c
  %v26_40101c = icmp ule i32 %v7_40101c, %v2_40101c
  %v27_40101c = icmp ult i32 %v6_40101c, %v2_40101c
  %v28_40101c = select i1 %v28_40101a, i1 %v26_40101c, i1 %v27_40101c
  store i1 %v28_40101c, i1* %cf.global-to-local, align 1
  store i32 %v7_40101c, i32* %v1_40101c, align 4
  %v0_40101e = load i32, i32* @ecx, align 4
  %v1_40101e = inttoptr i32 %v0_40101e to i8*
  %v2_40101e = load i8, i8* %v1_40101e, align 1
  %v3_40101e = load i32, i32* %edx.global-to-local, align 4
  %v4_40101e = trunc i32 %v3_40101e to i8
  %v5_40101e = add i8 %v4_40101e, %v2_40101e
  %v10_40101e = icmp ult i8 %v5_40101e, %v2_40101e
  store i1 %v10_40101e, i1* %cf.global-to-local, align 1
  store i8 %v5_40101e, i8* %v1_40101e, align 1
  %v0_401020 = load i32, i32* @ecx, align 4
  %v1_401020 = inttoptr i32 %v0_401020 to i32*
  %v2_401020 = load i32, i32* %v1_401020, align 4
  %v3_401020 = load i32, i32* %edx.global-to-local, align 4
  %v4_401020 = load i1, i1* %cf.global-to-local, align 1
  %v5_401020 = zext i1 %v4_401020 to i32
  %v6_401020 = add i32 %v3_401020, %v2_401020
  %v7_401020 = add i32 %v5_401020, %v6_401020
  %v26_401020 = icmp ule i32 %v7_401020, %v2_401020
  %v27_401020 = icmp ult i32 %v6_401020, %v2_401020
  %v28_401020 = select i1 %v4_401020, i1 %v26_401020, i1 %v27_401020
  store i32 %v7_401020, i32* %v1_401020, align 4
  %v0_401022 = load i32, i32* @ecx, align 4
  %v1_401022 = inttoptr i32 %v0_401022 to i32*
  %v2_401022 = load i32, i32* %v1_401022, align 4
  %v3_401022 = load i32, i32* %edx.global-to-local, align 4
  %v5_401022 = zext i1 %v28_401020 to i32
  %v6_401022 = add i32 %v3_401022, %v2_401022
  %v7_401022 = add i32 %v5_401022, %v6_401022
  %v26_401022 = icmp ule i32 %v7_401022, %v2_401022
  %v27_401022 = icmp ult i32 %v6_401022, %v2_401022
  %v28_401022 = select i1 %v28_401020, i1 %v26_401022, i1 %v27_401022
  store i1 %v28_401022, i1* %cf.global-to-local, align 1
  store i32 %v7_401022, i32* %v1_401022, align 4
  %v0_401024 = load i32, i32* @ecx, align 4
  %v1_401024 = inttoptr i32 %v0_401024 to i8*
  %v2_401024 = load i8, i8* %v1_401024, align 1
  %v3_401024 = load i32, i32* %edx.global-to-local, align 4
  %v4_401024 = trunc i32 %v3_401024 to i8
  %v5_401024 = add i8 %v4_401024, %v2_401024
  %v10_401024 = icmp ult i8 %v5_401024, %v2_401024
  store i1 %v10_401024, i1* %cf.global-to-local, align 1
  store i8 %v5_401024, i8* %v1_401024, align 1
  %v0_401026 = load i32, i32* @ecx, align 4
  %v1_401026 = inttoptr i32 %v0_401026 to i32*
  %v2_401026 = load i32, i32* %v1_401026, align 4
  %v3_401026 = load i32, i32* %edx.global-to-local, align 4
  %v4_401026 = load i1, i1* %cf.global-to-local, align 1
  %v5_401026 = zext i1 %v4_401026 to i32
  %v6_401026 = add i32 %v3_401026, %v2_401026
  %v7_401026 = add i32 %v5_401026, %v6_401026
  %v26_401026 = icmp ule i32 %v7_401026, %v2_401026
  %v27_401026 = icmp ult i32 %v6_401026, %v2_401026
  %v28_401026 = select i1 %v4_401026, i1 %v26_401026, i1 %v27_401026
  store i32 %v7_401026, i32* %v1_401026, align 4
  %v0_401028 = load i32, i32* @ecx, align 4
  %v1_401028 = inttoptr i32 %v0_401028 to i32*
  %v2_401028 = load i32, i32* %v1_401028, align 4
  %v3_401028 = load i32, i32* %edx.global-to-local, align 4
  %v5_401028 = zext i1 %v28_401026 to i32
  %v6_401028 = add i32 %v3_401028, %v2_401028
  %v7_401028 = add i32 %v5_401028, %v6_401028
  %v26_401028 = icmp ule i32 %v7_401028, %v2_401028
  %v27_401028 = icmp ult i32 %v6_401028, %v2_401028
  %v28_401028 = select i1 %v28_401026, i1 %v26_401028, i1 %v27_401028
  store i1 %v28_401028, i1* %cf.global-to-local, align 1
  store i32 %v7_401028, i32* %v1_401028, align 4
  %v0_40102a = load i32, i32* @ecx, align 4
  %v1_40102a = inttoptr i32 %v0_40102a to i8*
  %v2_40102a = load i8, i8* %v1_40102a, align 1
  %v3_40102a = load i32, i32* %edx.global-to-local, align 4
  %v4_40102a = trunc i32 %v3_40102a to i8
  %v5_40102a = add i8 %v4_40102a, %v2_40102a
  %v10_40102a = icmp ult i8 %v5_40102a, %v2_40102a
  store i1 %v10_40102a, i1* %cf.global-to-local, align 1
  store i8 %v5_40102a, i8* %v1_40102a, align 1
  %v0_40102c = load i32, i32* @ecx, align 4
  %v1_40102c = inttoptr i32 %v0_40102c to i32*
  %v2_40102c = load i32, i32* %v1_40102c, align 4
  %v3_40102c = load i32, i32* %edx.global-to-local, align 4
  %v4_40102c = load i1, i1* %cf.global-to-local, align 1
  %v5_40102c = zext i1 %v4_40102c to i32
  %v6_40102c = add i32 %v3_40102c, %v2_40102c
  %v7_40102c = add i32 %v5_40102c, %v6_40102c
  %v26_40102c = icmp ule i32 %v7_40102c, %v2_40102c
  %v27_40102c = icmp ult i32 %v6_40102c, %v2_40102c
  %v28_40102c = select i1 %v4_40102c, i1 %v26_40102c, i1 %v27_40102c
  store i32 %v7_40102c, i32* %v1_40102c, align 4
  %v0_40102e = load i32, i32* @ecx, align 4
  %v1_40102e = inttoptr i32 %v0_40102e to i32*
  %v2_40102e = load i32, i32* %v1_40102e, align 4
  %v3_40102e = load i32, i32* %edx.global-to-local, align 4
  %v5_40102e = zext i1 %v28_40102c to i32
  %v6_40102e = add i32 %v3_40102e, %v2_40102e
  %v7_40102e = add i32 %v5_40102e, %v6_40102e
  %v26_40102e = icmp ule i32 %v7_40102e, %v2_40102e
  %v27_40102e = icmp ult i32 %v6_40102e, %v2_40102e
  %v28_40102e = select i1 %v28_40102c, i1 %v26_40102e, i1 %v27_40102e
  store i1 %v28_40102e, i1* %cf.global-to-local, align 1
  store i32 %v7_40102e, i32* %v1_40102e, align 4
  %v0_401030 = load i32, i32* @ecx, align 4
  %v1_401030 = inttoptr i32 %v0_401030 to i8*
  %v2_401030 = load i8, i8* %v1_401030, align 1
  %v3_401030 = load i32, i32* %edx.global-to-local, align 4
  %v4_401030 = trunc i32 %v3_401030 to i8
  %v5_401030 = add i8 %v4_401030, %v2_401030
  %v10_401030 = icmp ult i8 %v5_401030, %v2_401030
  store i1 %v10_401030, i1* %cf.global-to-local, align 1
  store i8 %v5_401030, i8* %v1_401030, align 1
  %v0_401032 = load i32, i32* @ecx, align 4
  %v1_401032 = inttoptr i32 %v0_401032 to i32*
  %v2_401032 = load i32, i32* %v1_401032, align 4
  %v3_401032 = load i32, i32* %edx.global-to-local, align 4
  %v4_401032 = load i1, i1* %cf.global-to-local, align 1
  %v5_401032 = zext i1 %v4_401032 to i32
  %v6_401032 = add i32 %v3_401032, %v2_401032
  %v7_401032 = add i32 %v5_401032, %v6_401032
  %v26_401032 = icmp ule i32 %v7_401032, %v2_401032
  %v27_401032 = icmp ult i32 %v6_401032, %v2_401032
  %v28_401032 = select i1 %v4_401032, i1 %v26_401032, i1 %v27_401032
  store i32 %v7_401032, i32* %v1_401032, align 4
  %v0_401034 = load i32, i32* @ecx, align 4
  %v1_401034 = inttoptr i32 %v0_401034 to i32*
  %v2_401034 = load i32, i32* %v1_401034, align 4
  %v3_401034 = load i32, i32* %edx.global-to-local, align 4
  %v5_401034 = zext i1 %v28_401032 to i32
  %v6_401034 = add i32 %v3_401034, %v2_401034
  %v7_401034 = add i32 %v5_401034, %v6_401034
  %v26_401034 = icmp ule i32 %v7_401034, %v2_401034
  %v27_401034 = icmp ult i32 %v6_401034, %v2_401034
  %v28_401034 = select i1 %v28_401032, i1 %v26_401034, i1 %v27_401034
  store i1 %v28_401034, i1* %cf.global-to-local, align 1
  store i32 %v7_401034, i32* %v1_401034, align 4
  %v0_401036 = load i32, i32* @ecx, align 4
  %v1_401036 = inttoptr i32 %v0_401036 to i8*
  %v2_401036 = load i8, i8* %v1_401036, align 1
  %v3_401036 = load i32, i32* %edx.global-to-local, align 4
  %v4_401036 = trunc i32 %v3_401036 to i8
  %v5_401036 = add i8 %v4_401036, %v2_401036
  %v10_401036 = icmp ult i8 %v5_401036, %v2_401036
  store i1 %v10_401036, i1* %cf.global-to-local, align 1
  store i8 %v5_401036, i8* %v1_401036, align 1
  %v0_401038 = load i32, i32* @ecx, align 4
  %v1_401038 = inttoptr i32 %v0_401038 to i32*
  %v2_401038 = load i32, i32* %v1_401038, align 4
  %v3_401038 = load i32, i32* %edx.global-to-local, align 4
  %v4_401038 = load i1, i1* %cf.global-to-local, align 1
  %v5_401038 = zext i1 %v4_401038 to i32
  %v6_401038 = add i32 %v3_401038, %v2_401038
  %v7_401038 = add i32 %v5_401038, %v6_401038
  %v26_401038 = icmp ule i32 %v7_401038, %v2_401038
  %v27_401038 = icmp ult i32 %v6_401038, %v2_401038
  %v28_401038 = select i1 %v4_401038, i1 %v26_401038, i1 %v27_401038
  store i32 %v7_401038, i32* %v1_401038, align 4
  %v0_40103a = load i32, i32* @ecx, align 4
  %v1_40103a = inttoptr i32 %v0_40103a to i32*
  %v2_40103a = load i32, i32* %v1_40103a, align 4
  %v3_40103a = load i32, i32* %edx.global-to-local, align 4
  %v5_40103a = zext i1 %v28_401038 to i32
  %v6_40103a = add i32 %v3_40103a, %v2_40103a
  %v7_40103a = add i32 %v5_40103a, %v6_40103a
  %v26_40103a = icmp ule i32 %v7_40103a, %v2_40103a
  %v27_40103a = icmp ult i32 %v6_40103a, %v2_40103a
  %v28_40103a = select i1 %v28_401038, i1 %v26_40103a, i1 %v27_40103a
  store i1 %v28_40103a, i1* %cf.global-to-local, align 1
  store i32 %v7_40103a, i32* %v1_40103a, align 4
  %v0_40103c = load i32, i32* @ecx, align 4
  %v1_40103c = inttoptr i32 %v0_40103c to i8*
  %v2_40103c = load i8, i8* %v1_40103c, align 1
  %v3_40103c = load i32, i32* %edx.global-to-local, align 4
  %v4_40103c = trunc i32 %v3_40103c to i8
  %v5_40103c = add i8 %v4_40103c, %v2_40103c
  %v10_40103c = icmp ult i8 %v5_40103c, %v2_40103c
  store i1 %v10_40103c, i1* %cf.global-to-local, align 1
  store i8 %v5_40103c, i8* %v1_40103c, align 1
  %v0_40103e = load i32, i32* @ecx, align 4
  %v1_40103e = inttoptr i32 %v0_40103e to i32*
  %v2_40103e = load i32, i32* %v1_40103e, align 4
  %v3_40103e = load i32, i32* %edx.global-to-local, align 4
  %v4_40103e = load i1, i1* %cf.global-to-local, align 1
  %v5_40103e = zext i1 %v4_40103e to i32
  %v6_40103e = add i32 %v3_40103e, %v2_40103e
  %v7_40103e = add i32 %v5_40103e, %v6_40103e
  %v26_40103e = icmp ule i32 %v7_40103e, %v2_40103e
  %v27_40103e = icmp ult i32 %v6_40103e, %v2_40103e
  %v28_40103e = select i1 %v4_40103e, i1 %v26_40103e, i1 %v27_40103e
  store i32 %v7_40103e, i32* %v1_40103e, align 4
  %v0_401040 = load i32, i32* @ecx, align 4
  %v1_401040 = inttoptr i32 %v0_401040 to i32*
  %v2_401040 = load i32, i32* %v1_401040, align 4
  %v3_401040 = load i32, i32* %edx.global-to-local, align 4
  %v5_401040 = zext i1 %v28_40103e to i32
  %v6_401040 = add i32 %v3_401040, %v2_401040
  %v7_401040 = add i32 %v5_401040, %v6_401040
  %v26_401040 = icmp ule i32 %v7_401040, %v2_401040
  %v27_401040 = icmp ult i32 %v6_401040, %v2_401040
  %v28_401040 = select i1 %v28_40103e, i1 %v26_401040, i1 %v27_401040
  store i1 %v28_401040, i1* %cf.global-to-local, align 1
  store i32 %v7_401040, i32* %v1_401040, align 4
  %v0_401042 = load i32, i32* @ecx, align 4
  %v1_401042 = inttoptr i32 %v0_401042 to i8*
  %v2_401042 = load i8, i8* %v1_401042, align 1
  %v3_401042 = load i32, i32* %edx.global-to-local, align 4
  %v4_401042 = trunc i32 %v3_401042 to i8
  %v5_401042 = add i8 %v4_401042, %v2_401042
  %v10_401042 = icmp ult i8 %v5_401042, %v2_401042
  store i1 %v10_401042, i1* %cf.global-to-local, align 1
  store i8 %v5_401042, i8* %v1_401042, align 1
  %v0_401044 = load i32, i32* @ecx, align 4
  %v1_401044 = inttoptr i32 %v0_401044 to i32*
  %v2_401044 = load i32, i32* %v1_401044, align 4
  %v3_401044 = load i32, i32* %edx.global-to-local, align 4
  %v4_401044 = load i1, i1* %cf.global-to-local, align 1
  %v5_401044 = zext i1 %v4_401044 to i32
  %v6_401044 = add i32 %v3_401044, %v2_401044
  %v7_401044 = add i32 %v5_401044, %v6_401044
  %v26_401044 = icmp ule i32 %v7_401044, %v2_401044
  %v27_401044 = icmp ult i32 %v6_401044, %v2_401044
  %v28_401044 = select i1 %v4_401044, i1 %v26_401044, i1 %v27_401044
  store i32 %v7_401044, i32* %v1_401044, align 4
  %v0_401046 = load i32, i32* @ecx, align 4
  %v1_401046 = inttoptr i32 %v0_401046 to i32*
  %v2_401046 = load i32, i32* %v1_401046, align 4
  %v3_401046 = load i32, i32* %edx.global-to-local, align 4
  %v5_401046 = zext i1 %v28_401044 to i32
  %v6_401046 = add i32 %v3_401046, %v2_401046
  %v7_401046 = add i32 %v5_401046, %v6_401046
  %v26_401046 = icmp ule i32 %v7_401046, %v2_401046
  %v27_401046 = icmp ult i32 %v6_401046, %v2_401046
  %v28_401046 = select i1 %v28_401044, i1 %v26_401046, i1 %v27_401046
  store i1 %v28_401046, i1* %cf.global-to-local, align 1
  store i32 %v7_401046, i32* %v1_401046, align 4
  %v0_401048 = load i32, i32* @ecx, align 4
  %v1_401048 = inttoptr i32 %v0_401048 to i8*
  %v2_401048 = load i8, i8* %v1_401048, align 1
  %v3_401048 = load i32, i32* %edx.global-to-local, align 4
  %v4_401048 = trunc i32 %v3_401048 to i8
  %v5_401048 = add i8 %v4_401048, %v2_401048
  %v10_401048 = icmp ult i8 %v5_401048, %v2_401048
  store i1 %v10_401048, i1* %cf.global-to-local, align 1
  store i8 %v5_401048, i8* %v1_401048, align 1
  %v0_40104a = load i32, i32* @ecx, align 4
  %v1_40104a = inttoptr i32 %v0_40104a to i32*
  %v2_40104a = load i32, i32* %v1_40104a, align 4
  %v3_40104a = load i32, i32* %edx.global-to-local, align 4
  %v4_40104a = load i1, i1* %cf.global-to-local, align 1
  %v5_40104a = zext i1 %v4_40104a to i32
  %v6_40104a = add i32 %v3_40104a, %v2_40104a
  %v7_40104a = add i32 %v5_40104a, %v6_40104a
  %v26_40104a = icmp ule i32 %v7_40104a, %v2_40104a
  %v27_40104a = icmp ult i32 %v6_40104a, %v2_40104a
  %v28_40104a = select i1 %v4_40104a, i1 %v26_40104a, i1 %v27_40104a
  store i32 %v7_40104a, i32* %v1_40104a, align 4
  %v0_40104c = load i32, i32* @ecx, align 4
  %v1_40104c = inttoptr i32 %v0_40104c to i32*
  %v2_40104c = load i32, i32* %v1_40104c, align 4
  %v3_40104c = load i32, i32* %edx.global-to-local, align 4
  %v5_40104c = zext i1 %v28_40104a to i32
  %v6_40104c = add i32 %v3_40104c, %v2_40104c
  %v7_40104c = add i32 %v5_40104c, %v6_40104c
  %v26_40104c = icmp ule i32 %v7_40104c, %v2_40104c
  %v27_40104c = icmp ult i32 %v6_40104c, %v2_40104c
  %v28_40104c = select i1 %v28_40104a, i1 %v26_40104c, i1 %v27_40104c
  store i1 %v28_40104c, i1* %cf.global-to-local, align 1
  store i32 %v7_40104c, i32* %v1_40104c, align 4
  %v0_40104e = load i32, i32* @ecx, align 4
  %v1_40104e = inttoptr i32 %v0_40104e to i8*
  %v2_40104e = load i8, i8* %v1_40104e, align 1
  %v3_40104e = load i32, i32* %edx.global-to-local, align 4
  %v4_40104e = trunc i32 %v3_40104e to i8
  %v5_40104e = add i8 %v4_40104e, %v2_40104e
  %v10_40104e = icmp ult i8 %v5_40104e, %v2_40104e
  store i1 %v10_40104e, i1* %cf.global-to-local, align 1
  store i8 %v5_40104e, i8* %v1_40104e, align 1
  %v0_401050 = load i32, i32* @ecx, align 4
  %v1_401050 = inttoptr i32 %v0_401050 to i32*
  %v2_401050 = load i32, i32* %v1_401050, align 4
  %v3_401050 = load i32, i32* %edx.global-to-local, align 4
  %v4_401050 = load i1, i1* %cf.global-to-local, align 1
  %v5_401050 = zext i1 %v4_401050 to i32
  %v6_401050 = add i32 %v3_401050, %v2_401050
  %v7_401050 = add i32 %v5_401050, %v6_401050
  %v26_401050 = icmp ule i32 %v7_401050, %v2_401050
  %v27_401050 = icmp ult i32 %v6_401050, %v2_401050
  %v28_401050 = select i1 %v4_401050, i1 %v26_401050, i1 %v27_401050
  store i32 %v7_401050, i32* %v1_401050, align 4
  %v0_401052 = load i32, i32* @ecx, align 4
  %v1_401052 = inttoptr i32 %v0_401052 to i32*
  %v2_401052 = load i32, i32* %v1_401052, align 4
  %v3_401052 = load i32, i32* %edx.global-to-local, align 4
  %v5_401052 = zext i1 %v28_401050 to i32
  %v6_401052 = add i32 %v3_401052, %v2_401052
  %v7_401052 = add i32 %v5_401052, %v6_401052
  %v26_401052 = icmp ule i32 %v7_401052, %v2_401052
  %v27_401052 = icmp ult i32 %v6_401052, %v2_401052
  %v28_401052 = select i1 %v28_401050, i1 %v26_401052, i1 %v27_401052
  store i1 %v28_401052, i1* %cf.global-to-local, align 1
  store i32 %v7_401052, i32* %v1_401052, align 4
  %v0_401054 = load i32, i32* @ecx, align 4
  %v1_401054 = inttoptr i32 %v0_401054 to i8*
  %v2_401054 = load i8, i8* %v1_401054, align 1
  %v3_401054 = load i32, i32* %edx.global-to-local, align 4
  %v4_401054 = trunc i32 %v3_401054 to i8
  %v5_401054 = add i8 %v4_401054, %v2_401054
  %v10_401054 = icmp ult i8 %v5_401054, %v2_401054
  store i1 %v10_401054, i1* %cf.global-to-local, align 1
  store i8 %v5_401054, i8* %v1_401054, align 1
  %v0_401056 = load i32, i32* @ecx, align 4
  %v1_401056 = inttoptr i32 %v0_401056 to i32*
  %v2_401056 = load i32, i32* %v1_401056, align 4
  %v3_401056 = load i32, i32* %edx.global-to-local, align 4
  %v4_401056 = load i1, i1* %cf.global-to-local, align 1
  %v5_401056 = zext i1 %v4_401056 to i32
  %v6_401056 = add i32 %v3_401056, %v2_401056
  %v7_401056 = add i32 %v5_401056, %v6_401056
  %v26_401056 = icmp ule i32 %v7_401056, %v2_401056
  %v27_401056 = icmp ult i32 %v6_401056, %v2_401056
  %v28_401056 = select i1 %v4_401056, i1 %v26_401056, i1 %v27_401056
  store i32 %v7_401056, i32* %v1_401056, align 4
  %v0_401058 = load i32, i32* @ecx, align 4
  %v1_401058 = inttoptr i32 %v0_401058 to i32*
  %v2_401058 = load i32, i32* %v1_401058, align 4
  %v3_401058 = load i32, i32* %edx.global-to-local, align 4
  %v5_401058 = zext i1 %v28_401056 to i32
  %v6_401058 = add i32 %v3_401058, %v2_401058
  %v7_401058 = add i32 %v5_401058, %v6_401058
  %v26_401058 = icmp ule i32 %v7_401058, %v2_401058
  %v27_401058 = icmp ult i32 %v6_401058, %v2_401058
  %v28_401058 = select i1 %v28_401056, i1 %v26_401058, i1 %v27_401058
  store i1 %v28_401058, i1* %cf.global-to-local, align 1
  store i32 %v7_401058, i32* %v1_401058, align 4
  %v0_40105a = load i32, i32* @ecx, align 4
  %v1_40105a = inttoptr i32 %v0_40105a to i8*
  %v2_40105a = load i8, i8* %v1_40105a, align 1
  %v3_40105a = load i32, i32* %edx.global-to-local, align 4
  %v4_40105a = trunc i32 %v3_40105a to i8
  %v5_40105a = add i8 %v4_40105a, %v2_40105a
  %v10_40105a = icmp ult i8 %v5_40105a, %v2_40105a
  store i1 %v10_40105a, i1* %cf.global-to-local, align 1
  store i8 %v5_40105a, i8* %v1_40105a, align 1
  %v0_40105c = load i32, i32* @ecx, align 4
  %v1_40105c = inttoptr i32 %v0_40105c to i32*
  %v2_40105c = load i32, i32* %v1_40105c, align 4
  %v3_40105c = load i32, i32* %edx.global-to-local, align 4
  %v4_40105c = load i1, i1* %cf.global-to-local, align 1
  %v5_40105c = zext i1 %v4_40105c to i32
  %v6_40105c = add i32 %v3_40105c, %v2_40105c
  %v7_40105c = add i32 %v5_40105c, %v6_40105c
  %v26_40105c = icmp ule i32 %v7_40105c, %v2_40105c
  %v27_40105c = icmp ult i32 %v6_40105c, %v2_40105c
  %v28_40105c = select i1 %v4_40105c, i1 %v26_40105c, i1 %v27_40105c
  store i32 %v7_40105c, i32* %v1_40105c, align 4
  %v0_40105e = load i32, i32* @ecx, align 4
  %v1_40105e = inttoptr i32 %v0_40105e to i32*
  %v2_40105e = load i32, i32* %v1_40105e, align 4
  %v3_40105e = load i32, i32* %edx.global-to-local, align 4
  %v5_40105e = zext i1 %v28_40105c to i32
  %v6_40105e = add i32 %v3_40105e, %v2_40105e
  %v7_40105e = add i32 %v5_40105e, %v6_40105e
  %v26_40105e = icmp ule i32 %v7_40105e, %v2_40105e
  %v27_40105e = icmp ult i32 %v6_40105e, %v2_40105e
  %v28_40105e = select i1 %v28_40105c, i1 %v26_40105e, i1 %v27_40105e
  store i1 %v28_40105e, i1* %cf.global-to-local, align 1
  store i32 %v7_40105e, i32* %v1_40105e, align 4
  %v0_401060 = load i32, i32* @ecx, align 4
  %v1_401060 = inttoptr i32 %v0_401060 to i8*
  %v2_401060 = load i8, i8* %v1_401060, align 1
  %v3_401060 = load i32, i32* %edx.global-to-local, align 4
  %v4_401060 = trunc i32 %v3_401060 to i8
  %v5_401060 = add i8 %v4_401060, %v2_401060
  %v10_401060 = icmp ult i8 %v5_401060, %v2_401060
  store i1 %v10_401060, i1* %cf.global-to-local, align 1
  store i8 %v5_401060, i8* %v1_401060, align 1
  %v0_401062 = load i32, i32* @ecx, align 4
  %v1_401062 = inttoptr i32 %v0_401062 to i32*
  %v2_401062 = load i32, i32* %v1_401062, align 4
  %v3_401062 = load i32, i32* %edx.global-to-local, align 4
  %v4_401062 = load i1, i1* %cf.global-to-local, align 1
  %v5_401062 = zext i1 %v4_401062 to i32
  %v6_401062 = add i32 %v3_401062, %v2_401062
  %v7_401062 = add i32 %v5_401062, %v6_401062
  %v26_401062 = icmp ule i32 %v7_401062, %v2_401062
  %v27_401062 = icmp ult i32 %v6_401062, %v2_401062
  %v28_401062 = select i1 %v4_401062, i1 %v26_401062, i1 %v27_401062
  store i32 %v7_401062, i32* %v1_401062, align 4
  %v0_401064 = load i32, i32* @ecx, align 4
  %v1_401064 = inttoptr i32 %v0_401064 to i32*
  %v2_401064 = load i32, i32* %v1_401064, align 4
  %v3_401064 = load i32, i32* %edx.global-to-local, align 4
  %v5_401064 = zext i1 %v28_401062 to i32
  %v6_401064 = add i32 %v3_401064, %v2_401064
  %v7_401064 = add i32 %v5_401064, %v6_401064
  %v26_401064 = icmp ule i32 %v7_401064, %v2_401064
  %v27_401064 = icmp ult i32 %v6_401064, %v2_401064
  %v28_401064 = select i1 %v28_401062, i1 %v26_401064, i1 %v27_401064
  store i1 %v28_401064, i1* %cf.global-to-local, align 1
  store i32 %v7_401064, i32* %v1_401064, align 4
  %v0_401066 = load i32, i32* @ecx, align 4
  %v1_401066 = inttoptr i32 %v0_401066 to i8*
  %v2_401066 = load i8, i8* %v1_401066, align 1
  %v3_401066 = load i32, i32* %edx.global-to-local, align 4
  %v4_401066 = trunc i32 %v3_401066 to i8
  %v5_401066 = add i8 %v4_401066, %v2_401066
  %v10_401066 = icmp ult i8 %v5_401066, %v2_401066
  store i1 %v10_401066, i1* %cf.global-to-local, align 1
  store i8 %v5_401066, i8* %v1_401066, align 1
  %v0_401068 = load i32, i32* @ecx, align 4
  %v1_401068 = inttoptr i32 %v0_401068 to i32*
  %v2_401068 = load i32, i32* %v1_401068, align 4
  %v3_401068 = load i32, i32* %edx.global-to-local, align 4
  %v4_401068 = load i1, i1* %cf.global-to-local, align 1
  %v5_401068 = zext i1 %v4_401068 to i32
  %v6_401068 = add i32 %v3_401068, %v2_401068
  %v7_401068 = add i32 %v5_401068, %v6_401068
  %v26_401068 = icmp ule i32 %v7_401068, %v2_401068
  %v27_401068 = icmp ult i32 %v6_401068, %v2_401068
  %v28_401068 = select i1 %v4_401068, i1 %v26_401068, i1 %v27_401068
  store i32 %v7_401068, i32* %v1_401068, align 4
  %v0_40106a = load i32, i32* @ecx, align 4
  %v1_40106a = inttoptr i32 %v0_40106a to i32*
  %v2_40106a = load i32, i32* %v1_40106a, align 4
  %v3_40106a = load i32, i32* %edx.global-to-local, align 4
  %v5_40106a = zext i1 %v28_401068 to i32
  %v6_40106a = add i32 %v3_40106a, %v2_40106a
  %v7_40106a = add i32 %v5_40106a, %v6_40106a
  %v26_40106a = icmp ule i32 %v7_40106a, %v2_40106a
  %v27_40106a = icmp ult i32 %v6_40106a, %v2_40106a
  %v28_40106a = select i1 %v28_401068, i1 %v26_40106a, i1 %v27_40106a
  store i1 %v28_40106a, i1* %cf.global-to-local, align 1
  store i32 %v7_40106a, i32* %v1_40106a, align 4
  %v0_40106c = load i32, i32* @ecx, align 4
  %v1_40106c = inttoptr i32 %v0_40106c to i8*
  %v2_40106c = load i8, i8* %v1_40106c, align 1
  %v3_40106c = load i32, i32* %edx.global-to-local, align 4
  %v4_40106c = trunc i32 %v3_40106c to i8
  %v5_40106c = add i8 %v4_40106c, %v2_40106c
  %v10_40106c = icmp ult i8 %v5_40106c, %v2_40106c
  store i1 %v10_40106c, i1* %cf.global-to-local, align 1
  store i8 %v5_40106c, i8* %v1_40106c, align 1
  %v0_40106e = load i32, i32* @ecx, align 4
  %v1_40106e = inttoptr i32 %v0_40106e to i32*
  %v2_40106e = load i32, i32* %v1_40106e, align 4
  %v3_40106e = load i32, i32* %edx.global-to-local, align 4
  %v4_40106e = load i1, i1* %cf.global-to-local, align 1
  %v5_40106e = zext i1 %v4_40106e to i32
  %v6_40106e = add i32 %v3_40106e, %v2_40106e
  %v7_40106e = add i32 %v5_40106e, %v6_40106e
  %v26_40106e = icmp ule i32 %v7_40106e, %v2_40106e
  %v27_40106e = icmp ult i32 %v6_40106e, %v2_40106e
  %v28_40106e = select i1 %v4_40106e, i1 %v26_40106e, i1 %v27_40106e
  store i32 %v7_40106e, i32* %v1_40106e, align 4
  %v0_401070 = load i32, i32* @ecx, align 4
  %v1_401070 = inttoptr i32 %v0_401070 to i32*
  %v2_401070 = load i32, i32* %v1_401070, align 4
  %v3_401070 = load i32, i32* %edx.global-to-local, align 4
  %v5_401070 = zext i1 %v28_40106e to i32
  %v6_401070 = add i32 %v3_401070, %v2_401070
  %v7_401070 = add i32 %v5_401070, %v6_401070
  %v26_401070 = icmp ule i32 %v7_401070, %v2_401070
  %v27_401070 = icmp ult i32 %v6_401070, %v2_401070
  %v28_401070 = select i1 %v28_40106e, i1 %v26_401070, i1 %v27_401070
  store i1 %v28_401070, i1* %cf.global-to-local, align 1
  store i32 %v7_401070, i32* %v1_401070, align 4
  %v0_401072 = load i32, i32* @ecx, align 4
  %v1_401072 = inttoptr i32 %v0_401072 to i8*
  %v2_401072 = load i8, i8* %v1_401072, align 1
  %v3_401072 = load i32, i32* %edx.global-to-local, align 4
  %v4_401072 = trunc i32 %v3_401072 to i8
  %v5_401072 = add i8 %v4_401072, %v2_401072
  %v10_401072 = icmp ult i8 %v5_401072, %v2_401072
  store i1 %v10_401072, i1* %cf.global-to-local, align 1
  store i8 %v5_401072, i8* %v1_401072, align 1
  %v0_401074 = load i32, i32* @ecx, align 4
  %v1_401074 = inttoptr i32 %v0_401074 to i32*
  %v2_401074 = load i32, i32* %v1_401074, align 4
  %v3_401074 = load i32, i32* %edx.global-to-local, align 4
  %v4_401074 = load i1, i1* %cf.global-to-local, align 1
  %v5_401074 = zext i1 %v4_401074 to i32
  %v6_401074 = add i32 %v3_401074, %v2_401074
  %v7_401074 = add i32 %v5_401074, %v6_401074
  %v26_401074 = icmp ule i32 %v7_401074, %v2_401074
  %v27_401074 = icmp ult i32 %v6_401074, %v2_401074
  %v28_401074 = select i1 %v4_401074, i1 %v26_401074, i1 %v27_401074
  store i32 %v7_401074, i32* %v1_401074, align 4
  %v0_401076 = load i32, i32* @ecx, align 4
  %v1_401076 = inttoptr i32 %v0_401076 to i32*
  %v2_401076 = load i32, i32* %v1_401076, align 4
  %v3_401076 = load i32, i32* %edx.global-to-local, align 4
  %v5_401076 = zext i1 %v28_401074 to i32
  %v6_401076 = add i32 %v3_401076, %v2_401076
  %v7_401076 = add i32 %v5_401076, %v6_401076
  %v26_401076 = icmp ule i32 %v7_401076, %v2_401076
  %v27_401076 = icmp ult i32 %v6_401076, %v2_401076
  %v28_401076 = select i1 %v28_401074, i1 %v26_401076, i1 %v27_401076
  store i1 %v28_401076, i1* %cf.global-to-local, align 1
  store i32 %v7_401076, i32* %v1_401076, align 4
  %v0_401078 = load i32, i32* @ecx, align 4
  %v1_401078 = inttoptr i32 %v0_401078 to i8*
  %v2_401078 = load i8, i8* %v1_401078, align 1
  %v3_401078 = load i32, i32* %edx.global-to-local, align 4
  %v4_401078 = trunc i32 %v3_401078 to i8
  %v5_401078 = add i8 %v4_401078, %v2_401078
  %v10_401078 = icmp ult i8 %v5_401078, %v2_401078
  store i1 %v10_401078, i1* %cf.global-to-local, align 1
  store i8 %v5_401078, i8* %v1_401078, align 1
  %v0_40107a = load i32, i32* @ecx, align 4
  %v1_40107a = inttoptr i32 %v0_40107a to i32*
  %v2_40107a = load i32, i32* %v1_40107a, align 4
  %v3_40107a = load i32, i32* %edx.global-to-local, align 4
  %v4_40107a = load i1, i1* %cf.global-to-local, align 1
  %v5_40107a = zext i1 %v4_40107a to i32
  %v6_40107a = add i32 %v3_40107a, %v2_40107a
  %v7_40107a = add i32 %v5_40107a, %v6_40107a
  %v26_40107a = icmp ule i32 %v7_40107a, %v2_40107a
  %v27_40107a = icmp ult i32 %v6_40107a, %v2_40107a
  %v28_40107a = select i1 %v4_40107a, i1 %v26_40107a, i1 %v27_40107a
  store i32 %v7_40107a, i32* %v1_40107a, align 4
  %v0_40107c = load i32, i32* @ecx, align 4
  %v1_40107c = inttoptr i32 %v0_40107c to i32*
  %v2_40107c = load i32, i32* %v1_40107c, align 4
  %v3_40107c = load i32, i32* %edx.global-to-local, align 4
  %v5_40107c = zext i1 %v28_40107a to i32
  %v6_40107c = add i32 %v3_40107c, %v2_40107c
  %v7_40107c = add i32 %v5_40107c, %v6_40107c
  %v26_40107c = icmp ule i32 %v7_40107c, %v2_40107c
  %v27_40107c = icmp ult i32 %v6_40107c, %v2_40107c
  %v28_40107c = select i1 %v28_40107a, i1 %v26_40107c, i1 %v27_40107c
  store i1 %v28_40107c, i1* %cf.global-to-local, align 1
  store i32 %v7_40107c, i32* %v1_40107c, align 4
  %v0_40107e = load i32, i32* @ecx, align 4
  %v1_40107e = inttoptr i32 %v0_40107e to i8*
  %v2_40107e = load i8, i8* %v1_40107e, align 1
  %v3_40107e = load i32, i32* %edx.global-to-local, align 4
  %v4_40107e = trunc i32 %v3_40107e to i8
  %v5_40107e = add i8 %v4_40107e, %v2_40107e
  %v10_40107e = icmp ult i8 %v5_40107e, %v2_40107e
  store i1 %v10_40107e, i1* %cf.global-to-local, align 1
  store i8 %v5_40107e, i8* %v1_40107e, align 1
  %v0_401080 = load i32, i32* @ecx, align 4
  %v1_401080 = inttoptr i32 %v0_401080 to i32*
  %v2_401080 = load i32, i32* %v1_401080, align 4
  %v3_401080 = load i32, i32* %edx.global-to-local, align 4
  %v4_401080 = load i1, i1* %cf.global-to-local, align 1
  %v5_401080 = zext i1 %v4_401080 to i32
  %v6_401080 = add i32 %v3_401080, %v2_401080
  %v7_401080 = add i32 %v5_401080, %v6_401080
  %v26_401080 = icmp ule i32 %v7_401080, %v2_401080
  %v27_401080 = icmp ult i32 %v6_401080, %v2_401080
  %v28_401080 = select i1 %v4_401080, i1 %v26_401080, i1 %v27_401080
  store i32 %v7_401080, i32* %v1_401080, align 4
  %v0_401082 = load i32, i32* @ecx, align 4
  %v1_401082 = inttoptr i32 %v0_401082 to i32*
  %v2_401082 = load i32, i32* %v1_401082, align 4
  %v3_401082 = load i32, i32* %edx.global-to-local, align 4
  %v5_401082 = zext i1 %v28_401080 to i32
  %v6_401082 = add i32 %v3_401082, %v2_401082
  %v7_401082 = add i32 %v5_401082, %v6_401082
  %v26_401082 = icmp ule i32 %v7_401082, %v2_401082
  %v27_401082 = icmp ult i32 %v6_401082, %v2_401082
  %v28_401082 = select i1 %v28_401080, i1 %v26_401082, i1 %v27_401082
  store i1 %v28_401082, i1* %cf.global-to-local, align 1
  store i32 %v7_401082, i32* %v1_401082, align 4
  %v0_401084 = load i32, i32* @ecx, align 4
  %v1_401084 = inttoptr i32 %v0_401084 to i8*
  %v2_401084 = load i8, i8* %v1_401084, align 1
  %v3_401084 = load i32, i32* %edx.global-to-local, align 4
  %v4_401084 = trunc i32 %v3_401084 to i8
  %v5_401084 = add i8 %v4_401084, %v2_401084
  %v10_401084 = icmp ult i8 %v5_401084, %v2_401084
  store i1 %v10_401084, i1* %cf.global-to-local, align 1
  store i8 %v5_401084, i8* %v1_401084, align 1
  %v0_401086 = load i32, i32* @ecx, align 4
  %v1_401086 = inttoptr i32 %v0_401086 to i32*
  %v2_401086 = load i32, i32* %v1_401086, align 4
  %v3_401086 = load i32, i32* %edx.global-to-local, align 4
  %v4_401086 = load i1, i1* %cf.global-to-local, align 1
  %v5_401086 = zext i1 %v4_401086 to i32
  %v6_401086 = add i32 %v3_401086, %v2_401086
  %v7_401086 = add i32 %v5_401086, %v6_401086
  %v26_401086 = icmp ule i32 %v7_401086, %v2_401086
  %v27_401086 = icmp ult i32 %v6_401086, %v2_401086
  %v28_401086 = select i1 %v4_401086, i1 %v26_401086, i1 %v27_401086
  store i32 %v7_401086, i32* %v1_401086, align 4
  %v0_401088 = load i32, i32* @ecx, align 4
  %v1_401088 = inttoptr i32 %v0_401088 to i32*
  %v2_401088 = load i32, i32* %v1_401088, align 4
  %v3_401088 = load i32, i32* %edx.global-to-local, align 4
  %v5_401088 = zext i1 %v28_401086 to i32
  %v6_401088 = add i32 %v3_401088, %v2_401088
  %v7_401088 = add i32 %v5_401088, %v6_401088
  %v26_401088 = icmp ule i32 %v7_401088, %v2_401088
  %v27_401088 = icmp ult i32 %v6_401088, %v2_401088
  %v28_401088 = select i1 %v28_401086, i1 %v26_401088, i1 %v27_401088
  store i1 %v28_401088, i1* %cf.global-to-local, align 1
  store i32 %v7_401088, i32* %v1_401088, align 4
  %v0_40108a = load i32, i32* @ecx, align 4
  %v1_40108a = inttoptr i32 %v0_40108a to i8*
  %v2_40108a = load i8, i8* %v1_40108a, align 1
  %v3_40108a = load i32, i32* %edx.global-to-local, align 4
  %v4_40108a = trunc i32 %v3_40108a to i8
  %v5_40108a = add i8 %v4_40108a, %v2_40108a
  %v10_40108a = icmp ult i8 %v5_40108a, %v2_40108a
  store i1 %v10_40108a, i1* %cf.global-to-local, align 1
  store i8 %v5_40108a, i8* %v1_40108a, align 1
  %v0_40108c = load i32, i32* @ecx, align 4
  %v1_40108c = inttoptr i32 %v0_40108c to i32*
  %v2_40108c = load i32, i32* %v1_40108c, align 4
  %v3_40108c = load i32, i32* %edx.global-to-local, align 4
  %v4_40108c = load i1, i1* %cf.global-to-local, align 1
  %v5_40108c = zext i1 %v4_40108c to i32
  %v6_40108c = add i32 %v3_40108c, %v2_40108c
  %v7_40108c = add i32 %v5_40108c, %v6_40108c
  %v26_40108c = icmp ule i32 %v7_40108c, %v2_40108c
  %v27_40108c = icmp ult i32 %v6_40108c, %v2_40108c
  %v28_40108c = select i1 %v4_40108c, i1 %v26_40108c, i1 %v27_40108c
  store i32 %v7_40108c, i32* %v1_40108c, align 4
  %v0_40108e = load i32, i32* @ecx, align 4
  %v1_40108e = inttoptr i32 %v0_40108e to i32*
  %v2_40108e = load i32, i32* %v1_40108e, align 4
  %v3_40108e = load i32, i32* %edx.global-to-local, align 4
  %v5_40108e = zext i1 %v28_40108c to i32
  %v6_40108e = add i32 %v3_40108e, %v2_40108e
  %v7_40108e = add i32 %v5_40108e, %v6_40108e
  %v26_40108e = icmp ule i32 %v7_40108e, %v2_40108e
  %v27_40108e = icmp ult i32 %v6_40108e, %v2_40108e
  %v28_40108e = select i1 %v28_40108c, i1 %v26_40108e, i1 %v27_40108e
  store i1 %v28_40108e, i1* %cf.global-to-local, align 1
  store i32 %v7_40108e, i32* %v1_40108e, align 4
  %v0_401090 = load i32, i32* @ecx, align 4
  %v1_401090 = inttoptr i32 %v0_401090 to i8*
  %v2_401090 = load i8, i8* %v1_401090, align 1
  %v3_401090 = load i32, i32* %edx.global-to-local, align 4
  %v4_401090 = trunc i32 %v3_401090 to i8
  %v5_401090 = add i8 %v4_401090, %v2_401090
  %v10_401090 = icmp ult i8 %v5_401090, %v2_401090
  store i1 %v10_401090, i1* %cf.global-to-local, align 1
  store i8 %v5_401090, i8* %v1_401090, align 1
  %v0_401092 = load i32, i32* @ecx, align 4
  %v1_401092 = inttoptr i32 %v0_401092 to i32*
  %v2_401092 = load i32, i32* %v1_401092, align 4
  %v3_401092 = load i32, i32* %edx.global-to-local, align 4
  %v4_401092 = load i1, i1* %cf.global-to-local, align 1
  %v5_401092 = zext i1 %v4_401092 to i32
  %v6_401092 = add i32 %v3_401092, %v2_401092
  %v7_401092 = add i32 %v5_401092, %v6_401092
  %v26_401092 = icmp ule i32 %v7_401092, %v2_401092
  %v27_401092 = icmp ult i32 %v6_401092, %v2_401092
  %v28_401092 = select i1 %v4_401092, i1 %v26_401092, i1 %v27_401092
  store i32 %v7_401092, i32* %v1_401092, align 4
  %v0_401094 = load i32, i32* @ecx, align 4
  %v1_401094 = inttoptr i32 %v0_401094 to i32*
  %v2_401094 = load i32, i32* %v1_401094, align 4
  %v3_401094 = load i32, i32* %edx.global-to-local, align 4
  %v5_401094 = zext i1 %v28_401092 to i32
  %v6_401094 = add i32 %v3_401094, %v2_401094
  %v7_401094 = add i32 %v5_401094, %v6_401094
  %v26_401094 = icmp ule i32 %v7_401094, %v2_401094
  %v27_401094 = icmp ult i32 %v6_401094, %v2_401094
  %v28_401094 = select i1 %v28_401092, i1 %v26_401094, i1 %v27_401094
  store i1 %v28_401094, i1* %cf.global-to-local, align 1
  store i32 %v7_401094, i32* %v1_401094, align 4
  %v0_401096 = load i32, i32* @ecx, align 4
  %v1_401096 = inttoptr i32 %v0_401096 to i8*
  %v2_401096 = load i8, i8* %v1_401096, align 1
  %v3_401096 = load i32, i32* %edx.global-to-local, align 4
  %v4_401096 = trunc i32 %v3_401096 to i8
  %v5_401096 = add i8 %v4_401096, %v2_401096
  %v10_401096 = icmp ult i8 %v5_401096, %v2_401096
  store i1 %v10_401096, i1* %cf.global-to-local, align 1
  store i8 %v5_401096, i8* %v1_401096, align 1
  %v0_401098 = load i32, i32* @ecx, align 4
  %v1_401098 = inttoptr i32 %v0_401098 to i32*
  %v2_401098 = load i32, i32* %v1_401098, align 4
  %v3_401098 = load i32, i32* %edx.global-to-local, align 4
  %v4_401098 = load i1, i1* %cf.global-to-local, align 1
  %v5_401098 = zext i1 %v4_401098 to i32
  %v6_401098 = add i32 %v3_401098, %v2_401098
  %v7_401098 = add i32 %v5_401098, %v6_401098
  %v26_401098 = icmp ule i32 %v7_401098, %v2_401098
  %v27_401098 = icmp ult i32 %v6_401098, %v2_401098
  %v28_401098 = select i1 %v4_401098, i1 %v26_401098, i1 %v27_401098
  store i32 %v7_401098, i32* %v1_401098, align 4
  %v0_40109a = load i32, i32* @ecx, align 4
  %v1_40109a = inttoptr i32 %v0_40109a to i32*
  %v2_40109a = load i32, i32* %v1_40109a, align 4
  %v3_40109a = load i32, i32* %edx.global-to-local, align 4
  %v5_40109a = zext i1 %v28_401098 to i32
  %v6_40109a = add i32 %v3_40109a, %v2_40109a
  %v7_40109a = add i32 %v5_40109a, %v6_40109a
  %v26_40109a = icmp ule i32 %v7_40109a, %v2_40109a
  %v27_40109a = icmp ult i32 %v6_40109a, %v2_40109a
  %v28_40109a = select i1 %v28_401098, i1 %v26_40109a, i1 %v27_40109a
  store i1 %v28_40109a, i1* %cf.global-to-local, align 1
  store i32 %v7_40109a, i32* %v1_40109a, align 4
  %v0_40109c = load i32, i32* @ecx, align 4
  %v1_40109c = inttoptr i32 %v0_40109c to i8*
  %v2_40109c = load i8, i8* %v1_40109c, align 1
  %v3_40109c = load i32, i32* %edx.global-to-local, align 4
  %v4_40109c = trunc i32 %v3_40109c to i8
  %v5_40109c = add i8 %v4_40109c, %v2_40109c
  %v10_40109c = icmp ult i8 %v5_40109c, %v2_40109c
  store i1 %v10_40109c, i1* %cf.global-to-local, align 1
  store i8 %v5_40109c, i8* %v1_40109c, align 1
  %v0_40109e = load i32, i32* @ecx, align 4
  %v1_40109e = inttoptr i32 %v0_40109e to i32*
  %v2_40109e = load i32, i32* %v1_40109e, align 4
  %v3_40109e = load i32, i32* %edx.global-to-local, align 4
  %v4_40109e = load i1, i1* %cf.global-to-local, align 1
  %v5_40109e = zext i1 %v4_40109e to i32
  %v6_40109e = add i32 %v3_40109e, %v2_40109e
  %v7_40109e = add i32 %v5_40109e, %v6_40109e
  %v26_40109e = icmp ule i32 %v7_40109e, %v2_40109e
  %v27_40109e = icmp ult i32 %v6_40109e, %v2_40109e
  %v28_40109e = select i1 %v4_40109e, i1 %v26_40109e, i1 %v27_40109e
  store i32 %v7_40109e, i32* %v1_40109e, align 4
  %v0_4010a0 = load i32, i32* @ecx, align 4
  %v1_4010a0 = inttoptr i32 %v0_4010a0 to i32*
  %v2_4010a0 = load i32, i32* %v1_4010a0, align 4
  %v3_4010a0 = load i32, i32* %edx.global-to-local, align 4
  %v5_4010a0 = zext i1 %v28_40109e to i32
  %v6_4010a0 = add i32 %v3_4010a0, %v2_4010a0
  %v7_4010a0 = add i32 %v5_4010a0, %v6_4010a0
  %v26_4010a0 = icmp ule i32 %v7_4010a0, %v2_4010a0
  %v27_4010a0 = icmp ult i32 %v6_4010a0, %v2_4010a0
  %v28_4010a0 = select i1 %v28_40109e, i1 %v26_4010a0, i1 %v27_4010a0
  store i1 %v28_4010a0, i1* %cf.global-to-local, align 1
  store i32 %v7_4010a0, i32* %v1_4010a0, align 4
  %v0_4010a2 = load i32, i32* @ecx, align 4
  %v1_4010a2 = inttoptr i32 %v0_4010a2 to i8*
  %v2_4010a2 = load i8, i8* %v1_4010a2, align 1
  %v3_4010a2 = load i32, i32* %edx.global-to-local, align 4
  %v4_4010a2 = trunc i32 %v3_4010a2 to i8
  %v5_4010a2 = add i8 %v4_4010a2, %v2_4010a2
  %v10_4010a2 = icmp ult i8 %v5_4010a2, %v2_4010a2
  store i1 %v10_4010a2, i1* %cf.global-to-local, align 1
  store i8 %v5_4010a2, i8* %v1_4010a2, align 1
  %v0_4010a4 = load i32, i32* @ecx, align 4
  %v1_4010a4 = inttoptr i32 %v0_4010a4 to i32*
  %v2_4010a4 = load i32, i32* %v1_4010a4, align 4
  %v3_4010a4 = load i32, i32* %edx.global-to-local, align 4
  %v4_4010a4 = load i1, i1* %cf.global-to-local, align 1
  %v5_4010a4 = zext i1 %v4_4010a4 to i32
  %v6_4010a4 = add i32 %v3_4010a4, %v2_4010a4
  %v7_4010a4 = add i32 %v5_4010a4, %v6_4010a4
  %v26_4010a4 = icmp ule i32 %v7_4010a4, %v2_4010a4
  %v27_4010a4 = icmp ult i32 %v6_4010a4, %v2_4010a4
  %v28_4010a4 = select i1 %v4_4010a4, i1 %v26_4010a4, i1 %v27_4010a4
  store i32 %v7_4010a4, i32* %v1_4010a4, align 4
  %v0_4010a6 = load i32, i32* @ecx, align 4
  %v1_4010a6 = inttoptr i32 %v0_4010a6 to i32*
  %v2_4010a6 = load i32, i32* %v1_4010a6, align 4
  %v3_4010a6 = load i32, i32* %edx.global-to-local, align 4
  %v5_4010a6 = zext i1 %v28_4010a4 to i32
  %v6_4010a6 = add i32 %v3_4010a6, %v2_4010a6
  %v7_4010a6 = add i32 %v5_4010a6, %v6_4010a6
  %v26_4010a6 = icmp ule i32 %v7_4010a6, %v2_4010a6
  %v27_4010a6 = icmp ult i32 %v6_4010a6, %v2_4010a6
  %v28_4010a6 = select i1 %v28_4010a4, i1 %v26_4010a6, i1 %v27_4010a6
  store i1 %v28_4010a6, i1* %cf.global-to-local, align 1
  store i32 %v7_4010a6, i32* %v1_4010a6, align 4
  %v0_4010a8 = load i32, i32* @ecx, align 4
  %v1_4010a8 = inttoptr i32 %v0_4010a8 to i8*
  %v2_4010a8 = load i8, i8* %v1_4010a8, align 1
  %v3_4010a8 = load i32, i32* %edx.global-to-local, align 4
  %v4_4010a8 = trunc i32 %v3_4010a8 to i8
  %v5_4010a8 = add i8 %v4_4010a8, %v2_4010a8
  %v10_4010a8 = icmp ult i8 %v5_4010a8, %v2_4010a8
  store i1 %v10_4010a8, i1* %cf.global-to-local, align 1
  store i8 %v5_4010a8, i8* %v1_4010a8, align 1
  %v0_4010aa = load i32, i32* @ecx, align 4
  %v1_4010aa = inttoptr i32 %v0_4010aa to i32*
  %v2_4010aa = load i32, i32* %v1_4010aa, align 4
  %v3_4010aa = load i32, i32* %edx.global-to-local, align 4
  %v4_4010aa = load i1, i1* %cf.global-to-local, align 1
  %v5_4010aa = zext i1 %v4_4010aa to i32
  %v6_4010aa = add i32 %v3_4010aa, %v2_4010aa
  %v7_4010aa = add i32 %v5_4010aa, %v6_4010aa
  %v26_4010aa = icmp ule i32 %v7_4010aa, %v2_4010aa
  %v27_4010aa = icmp ult i32 %v6_4010aa, %v2_4010aa
  %v28_4010aa = select i1 %v4_4010aa, i1 %v26_4010aa, i1 %v27_4010aa
  store i32 %v7_4010aa, i32* %v1_4010aa, align 4
  %v0_4010ac = load i32, i32* @ecx, align 4
  %v1_4010ac = inttoptr i32 %v0_4010ac to i32*
  %v2_4010ac = load i32, i32* %v1_4010ac, align 4
  %v3_4010ac = load i32, i32* %edx.global-to-local, align 4
  %v5_4010ac = zext i1 %v28_4010aa to i32
  %v6_4010ac = add i32 %v3_4010ac, %v2_4010ac
  %v7_4010ac = add i32 %v5_4010ac, %v6_4010ac
  %v26_4010ac = icmp ule i32 %v7_4010ac, %v2_4010ac
  %v27_4010ac = icmp ult i32 %v6_4010ac, %v2_4010ac
  %v28_4010ac = select i1 %v28_4010aa, i1 %v26_4010ac, i1 %v27_4010ac
  store i1 %v28_4010ac, i1* %cf.global-to-local, align 1
  store i32 %v7_4010ac, i32* %v1_4010ac, align 4
  %v0_4010ae = load i32, i32* @ecx, align 4
  %v1_4010ae = inttoptr i32 %v0_4010ae to i8*
  %v2_4010ae = load i8, i8* %v1_4010ae, align 1
  %v3_4010ae = load i32, i32* %edx.global-to-local, align 4
  %v4_4010ae = trunc i32 %v3_4010ae to i8
  %v5_4010ae = add i8 %v4_4010ae, %v2_4010ae
  %v10_4010ae = icmp ult i8 %v5_4010ae, %v2_4010ae
  store i1 %v10_4010ae, i1* %cf.global-to-local, align 1
  store i8 %v5_4010ae, i8* %v1_4010ae, align 1
  %v0_4010b0 = load i32, i32* @ecx, align 4
  %v1_4010b0 = inttoptr i32 %v0_4010b0 to i32*
  %v2_4010b0 = load i32, i32* %v1_4010b0, align 4
  %v3_4010b0 = load i32, i32* %edx.global-to-local, align 4
  %v4_4010b0 = load i1, i1* %cf.global-to-local, align 1
  %v5_4010b0 = zext i1 %v4_4010b0 to i32
  %v6_4010b0 = add i32 %v3_4010b0, %v2_4010b0
  %v7_4010b0 = add i32 %v5_4010b0, %v6_4010b0
  %v26_4010b0 = icmp ule i32 %v7_4010b0, %v2_4010b0
  %v27_4010b0 = icmp ult i32 %v6_4010b0, %v2_4010b0
  %v28_4010b0 = select i1 %v4_4010b0, i1 %v26_4010b0, i1 %v27_4010b0
  store i32 %v7_4010b0, i32* %v1_4010b0, align 4
  %v0_4010b2 = load i32, i32* @ecx, align 4
  %v1_4010b2 = inttoptr i32 %v0_4010b2 to i32*
  %v2_4010b2 = load i32, i32* %v1_4010b2, align 4
  %v3_4010b2 = load i32, i32* %edx.global-to-local, align 4
  %v5_4010b2 = zext i1 %v28_4010b0 to i32
  %v6_4010b2 = add i32 %v3_4010b2, %v2_4010b2
  %v7_4010b2 = add i32 %v5_4010b2, %v6_4010b2
  %v26_4010b2 = icmp ule i32 %v7_4010b2, %v2_4010b2
  %v27_4010b2 = icmp ult i32 %v6_4010b2, %v2_4010b2
  %v28_4010b2 = select i1 %v28_4010b0, i1 %v26_4010b2, i1 %v27_4010b2
  store i1 %v28_4010b2, i1* %cf.global-to-local, align 1
  store i32 %v7_4010b2, i32* %v1_4010b2, align 4
  %v0_4010b4 = load i32, i32* @ecx, align 4
  %v1_4010b4 = inttoptr i32 %v0_4010b4 to i8*
  %v2_4010b4 = load i8, i8* %v1_4010b4, align 1
  %v3_4010b4 = load i32, i32* %edx.global-to-local, align 4
  %v4_4010b4 = trunc i32 %v3_4010b4 to i8
  %v5_4010b4 = add i8 %v4_4010b4, %v2_4010b4
  %v10_4010b4 = icmp ult i8 %v5_4010b4, %v2_4010b4
  store i1 %v10_4010b4, i1* %cf.global-to-local, align 1
  store i8 %v5_4010b4, i8* %v1_4010b4, align 1
  %v0_4010b6 = load i32, i32* @ecx, align 4
  %v1_4010b6 = inttoptr i32 %v0_4010b6 to i32*
  %v2_4010b6 = load i32, i32* %v1_4010b6, align 4
  %v3_4010b6 = load i32, i32* %edx.global-to-local, align 4
  %v4_4010b6 = load i1, i1* %cf.global-to-local, align 1
  %v5_4010b6 = zext i1 %v4_4010b6 to i32
  %v6_4010b6 = add i32 %v3_4010b6, %v2_4010b6
  %v7_4010b6 = add i32 %v5_4010b6, %v6_4010b6
  %v26_4010b6 = icmp ule i32 %v7_4010b6, %v2_4010b6
  %v27_4010b6 = icmp ult i32 %v6_4010b6, %v2_4010b6
  %v28_4010b6 = select i1 %v4_4010b6, i1 %v26_4010b6, i1 %v27_4010b6
  store i32 %v7_4010b6, i32* %v1_4010b6, align 4
  %v0_4010b8 = load i32, i32* @ecx, align 4
  %v1_4010b8 = inttoptr i32 %v0_4010b8 to i32*
  %v2_4010b8 = load i32, i32* %v1_4010b8, align 4
  %v3_4010b8 = load i32, i32* %edx.global-to-local, align 4
  %v5_4010b8 = zext i1 %v28_4010b6 to i32
  %v6_4010b8 = add i32 %v3_4010b8, %v2_4010b8
  %v7_4010b8 = add i32 %v5_4010b8, %v6_4010b8
  %v26_4010b8 = icmp ule i32 %v7_4010b8, %v2_4010b8
  %v27_4010b8 = icmp ult i32 %v6_4010b8, %v2_4010b8
  %v28_4010b8 = select i1 %v28_4010b6, i1 %v26_4010b8, i1 %v27_4010b8
  store i1 %v28_4010b8, i1* %cf.global-to-local, align 1
  store i32 %v7_4010b8, i32* %v1_4010b8, align 4
  %v0_4010ba = load i32, i32* @ecx, align 4
  %v1_4010ba = inttoptr i32 %v0_4010ba to i8*
  %v2_4010ba = load i8, i8* %v1_4010ba, align 1
  %v3_4010ba = load i32, i32* %edx.global-to-local, align 4
  %v4_4010ba = trunc i32 %v3_4010ba to i8
  %v5_4010ba = add i8 %v4_4010ba, %v2_4010ba
  %v10_4010ba = icmp ult i8 %v5_4010ba, %v2_4010ba
  store i1 %v10_4010ba, i1* %cf.global-to-local, align 1
  store i8 %v5_4010ba, i8* %v1_4010ba, align 1
  %v0_4010bc = load i32, i32* @ecx, align 4
  %v1_4010bc = inttoptr i32 %v0_4010bc to i32*
  %v2_4010bc = load i32, i32* %v1_4010bc, align 4
  %v3_4010bc = load i32, i32* %edx.global-to-local, align 4
  %v4_4010bc = load i1, i1* %cf.global-to-local, align 1
  %v5_4010bc = zext i1 %v4_4010bc to i32
  %v6_4010bc = add i32 %v3_4010bc, %v2_4010bc
  %v7_4010bc = add i32 %v5_4010bc, %v6_4010bc
  %v26_4010bc = icmp ule i32 %v7_4010bc, %v2_4010bc
  %v27_4010bc = icmp ult i32 %v6_4010bc, %v2_4010bc
  %v28_4010bc = select i1 %v4_4010bc, i1 %v26_4010bc, i1 %v27_4010bc
  store i32 %v7_4010bc, i32* %v1_4010bc, align 4
  %v0_4010be = load i32, i32* @ecx, align 4
  %v1_4010be = inttoptr i32 %v0_4010be to i32*
  %v2_4010be = load i32, i32* %v1_4010be, align 4
  %v3_4010be = load i32, i32* %edx.global-to-local, align 4
  %v5_4010be = zext i1 %v28_4010bc to i32
  %v6_4010be = add i32 %v3_4010be, %v2_4010be
  %v7_4010be = add i32 %v5_4010be, %v6_4010be
  %v26_4010be = icmp ule i32 %v7_4010be, %v2_4010be
  %v27_4010be = icmp ult i32 %v6_4010be, %v2_4010be
  %v28_4010be = select i1 %v28_4010bc, i1 %v26_4010be, i1 %v27_4010be
  store i1 %v28_4010be, i1* %cf.global-to-local, align 1
  store i32 %v7_4010be, i32* %v1_4010be, align 4
  %v0_4010c0 = load i32, i32* @ecx, align 4
  %v1_4010c0 = inttoptr i32 %v0_4010c0 to i8*
  %v2_4010c0 = load i8, i8* %v1_4010c0, align 1
  %v3_4010c0 = load i32, i32* %edx.global-to-local, align 4
  %v4_4010c0 = trunc i32 %v3_4010c0 to i8
  %v5_4010c0 = add i8 %v4_4010c0, %v2_4010c0
  %v10_4010c0 = icmp ult i8 %v5_4010c0, %v2_4010c0
  store i1 %v10_4010c0, i1* %cf.global-to-local, align 1
  store i8 %v5_4010c0, i8* %v1_4010c0, align 1
  %v0_4010c2 = load i32, i32* @ecx, align 4
  %v1_4010c2 = inttoptr i32 %v0_4010c2 to i32*
  %v2_4010c2 = load i32, i32* %v1_4010c2, align 4
  %v3_4010c2 = load i32, i32* %edx.global-to-local, align 4
  %v4_4010c2 = load i1, i1* %cf.global-to-local, align 1
  %v5_4010c2 = zext i1 %v4_4010c2 to i32
  %v6_4010c2 = add i32 %v3_4010c2, %v2_4010c2
  %v7_4010c2 = add i32 %v5_4010c2, %v6_4010c2
  %v26_4010c2 = icmp ule i32 %v7_4010c2, %v2_4010c2
  %v27_4010c2 = icmp ult i32 %v6_4010c2, %v2_4010c2
  %v28_4010c2 = select i1 %v4_4010c2, i1 %v26_4010c2, i1 %v27_4010c2
  store i32 %v7_4010c2, i32* %v1_4010c2, align 4
  %v0_4010c4 = load i32, i32* @ecx, align 4
  %v1_4010c4 = inttoptr i32 %v0_4010c4 to i32*
  %v2_4010c4 = load i32, i32* %v1_4010c4, align 4
  %v3_4010c4 = load i32, i32* %edx.global-to-local, align 4
  %v5_4010c4 = zext i1 %v28_4010c2 to i32
  %v6_4010c4 = add i32 %v3_4010c4, %v2_4010c4
  %v7_4010c4 = add i32 %v5_4010c4, %v6_4010c4
  %v26_4010c4 = icmp ule i32 %v7_4010c4, %v2_4010c4
  %v27_4010c4 = icmp ult i32 %v6_4010c4, %v2_4010c4
  %v28_4010c4 = select i1 %v28_4010c2, i1 %v26_4010c4, i1 %v27_4010c4
  store i1 %v28_4010c4, i1* %cf.global-to-local, align 1
  store i32 %v7_4010c4, i32* %v1_4010c4, align 4
  %v0_4010c6 = load i32, i32* @ecx, align 4
  %v1_4010c6 = inttoptr i32 %v0_4010c6 to i8*
  %v2_4010c6 = load i8, i8* %v1_4010c6, align 1
  %v3_4010c6 = load i32, i32* %edx.global-to-local, align 4
  %v4_4010c6 = trunc i32 %v3_4010c6 to i8
  %v5_4010c6 = add i8 %v4_4010c6, %v2_4010c6
  %v10_4010c6 = icmp ult i8 %v5_4010c6, %v2_4010c6
  store i1 %v10_4010c6, i1* %cf.global-to-local, align 1
  store i8 %v5_4010c6, i8* %v1_4010c6, align 1
  %v0_4010c8 = load i32, i32* @ecx, align 4
  %v1_4010c8 = inttoptr i32 %v0_4010c8 to i32*
  %v2_4010c8 = load i32, i32* %v1_4010c8, align 4
  %v3_4010c8 = load i32, i32* %edx.global-to-local, align 4
  %v4_4010c8 = load i1, i1* %cf.global-to-local, align 1
  %v5_4010c8 = zext i1 %v4_4010c8 to i32
  %v6_4010c8 = add i32 %v3_4010c8, %v2_4010c8
  %v7_4010c8 = add i32 %v5_4010c8, %v6_4010c8
  %v26_4010c8 = icmp ule i32 %v7_4010c8, %v2_4010c8
  %v27_4010c8 = icmp ult i32 %v6_4010c8, %v2_4010c8
  %v28_4010c8 = select i1 %v4_4010c8, i1 %v26_4010c8, i1 %v27_4010c8
  store i32 %v7_4010c8, i32* %v1_4010c8, align 4
  %v0_4010ca = load i32, i32* @ecx, align 4
  %v1_4010ca = inttoptr i32 %v0_4010ca to i32*
  %v2_4010ca = load i32, i32* %v1_4010ca, align 4
  %v3_4010ca = load i32, i32* %edx.global-to-local, align 4
  %v5_4010ca = zext i1 %v28_4010c8 to i32
  %v6_4010ca = add i32 %v3_4010ca, %v2_4010ca
  %v7_4010ca = add i32 %v5_4010ca, %v6_4010ca
  %v26_4010ca = icmp ule i32 %v7_4010ca, %v2_4010ca
  %v27_4010ca = icmp ult i32 %v6_4010ca, %v2_4010ca
  %v28_4010ca = select i1 %v28_4010c8, i1 %v26_4010ca, i1 %v27_4010ca
  store i1 %v28_4010ca, i1* %cf.global-to-local, align 1
  store i32 %v7_4010ca, i32* %v1_4010ca, align 4
  %v0_4010cc = load i32, i32* @ecx, align 4
  %v1_4010cc = inttoptr i32 %v0_4010cc to i8*
  %v2_4010cc = load i8, i8* %v1_4010cc, align 1
  %v3_4010cc = load i32, i32* %edx.global-to-local, align 4
  %v4_4010cc = trunc i32 %v3_4010cc to i8
  %v5_4010cc = add i8 %v4_4010cc, %v2_4010cc
  %v10_4010cc = icmp ult i8 %v5_4010cc, %v2_4010cc
  store i1 %v10_4010cc, i1* %cf.global-to-local, align 1
  store i8 %v5_4010cc, i8* %v1_4010cc, align 1
  %v0_4010ce = load i32, i32* @ecx, align 4
  %v1_4010ce = inttoptr i32 %v0_4010ce to i32*
  %v2_4010ce = load i32, i32* %v1_4010ce, align 4
  %v3_4010ce = load i32, i32* %edx.global-to-local, align 4
  %v4_4010ce = load i1, i1* %cf.global-to-local, align 1
  %v5_4010ce = zext i1 %v4_4010ce to i32
  %v6_4010ce = add i32 %v3_4010ce, %v2_4010ce
  %v7_4010ce = add i32 %v5_4010ce, %v6_4010ce
  %v26_4010ce = icmp ule i32 %v7_4010ce, %v2_4010ce
  %v27_4010ce = icmp ult i32 %v6_4010ce, %v2_4010ce
  %v28_4010ce = select i1 %v4_4010ce, i1 %v26_4010ce, i1 %v27_4010ce
  store i32 %v7_4010ce, i32* %v1_4010ce, align 4
  %v0_4010d0 = load i32, i32* @ecx, align 4
  %v1_4010d0 = inttoptr i32 %v0_4010d0 to i32*
  %v2_4010d0 = load i32, i32* %v1_4010d0, align 4
  %v3_4010d0 = load i32, i32* %edx.global-to-local, align 4
  %v5_4010d0 = zext i1 %v28_4010ce to i32
  %v6_4010d0 = add i32 %v3_4010d0, %v2_4010d0
  %v7_4010d0 = add i32 %v5_4010d0, %v6_4010d0
  %v26_4010d0 = icmp ule i32 %v7_4010d0, %v2_4010d0
  %v27_4010d0 = icmp ult i32 %v6_4010d0, %v2_4010d0
  %v28_4010d0 = select i1 %v28_4010ce, i1 %v26_4010d0, i1 %v27_4010d0
  store i1 %v28_4010d0, i1* %cf.global-to-local, align 1
  store i32 %v7_4010d0, i32* %v1_4010d0, align 4
  %v0_4010d2 = load i32, i32* @ecx, align 4
  %v1_4010d2 = inttoptr i32 %v0_4010d2 to i8*
  %v2_4010d2 = load i8, i8* %v1_4010d2, align 1
  %v3_4010d2 = load i32, i32* %edx.global-to-local, align 4
  %v4_4010d2 = trunc i32 %v3_4010d2 to i8
  %v5_4010d2 = add i8 %v4_4010d2, %v2_4010d2
  %v10_4010d2 = icmp ult i8 %v5_4010d2, %v2_4010d2
  store i1 %v10_4010d2, i1* %cf.global-to-local, align 1
  store i8 %v5_4010d2, i8* %v1_4010d2, align 1
  %v0_4010d4 = load i32, i32* @ecx, align 4
  %v1_4010d4 = inttoptr i32 %v0_4010d4 to i32*
  %v2_4010d4 = load i32, i32* %v1_4010d4, align 4
  %v3_4010d4 = load i32, i32* %edx.global-to-local, align 4
  %v4_4010d4 = load i1, i1* %cf.global-to-local, align 1
  %v5_4010d4 = zext i1 %v4_4010d4 to i32
  %v6_4010d4 = add i32 %v3_4010d4, %v2_4010d4
  %v7_4010d4 = add i32 %v5_4010d4, %v6_4010d4
  %v26_4010d4 = icmp ule i32 %v7_4010d4, %v2_4010d4
  %v27_4010d4 = icmp ult i32 %v6_4010d4, %v2_4010d4
  %v28_4010d4 = select i1 %v4_4010d4, i1 %v26_4010d4, i1 %v27_4010d4
  store i32 %v7_4010d4, i32* %v1_4010d4, align 4
  %v0_4010d6 = load i32, i32* @ecx, align 4
  %v1_4010d6 = inttoptr i32 %v0_4010d6 to i32*
  %v2_4010d6 = load i32, i32* %v1_4010d6, align 4
  %v3_4010d6 = load i32, i32* %edx.global-to-local, align 4
  %v5_4010d6 = zext i1 %v28_4010d4 to i32
  %v6_4010d6 = add i32 %v3_4010d6, %v2_4010d6
  %v7_4010d6 = add i32 %v5_4010d6, %v6_4010d6
  %v26_4010d6 = icmp ule i32 %v7_4010d6, %v2_4010d6
  %v27_4010d6 = icmp ult i32 %v6_4010d6, %v2_4010d6
  %v28_4010d6 = select i1 %v28_4010d4, i1 %v26_4010d6, i1 %v27_4010d6
  store i1 %v28_4010d6, i1* %cf.global-to-local, align 1
  store i32 %v7_4010d6, i32* %v1_4010d6, align 4
  %v0_4010d8 = load i32, i32* @ecx, align 4
  %v1_4010d8 = inttoptr i32 %v0_4010d8 to i8*
  %v2_4010d8 = load i8, i8* %v1_4010d8, align 1
  %v3_4010d8 = load i32, i32* %edx.global-to-local, align 4
  %v4_4010d8 = trunc i32 %v3_4010d8 to i8
  %v5_4010d8 = add i8 %v4_4010d8, %v2_4010d8
  %v10_4010d8 = icmp ult i8 %v5_4010d8, %v2_4010d8
  store i1 %v10_4010d8, i1* %cf.global-to-local, align 1
  store i8 %v5_4010d8, i8* %v1_4010d8, align 1
  %v0_4010da = load i32, i32* @ecx, align 4
  %v1_4010da = inttoptr i32 %v0_4010da to i32*
  %v2_4010da = load i32, i32* %v1_4010da, align 4
  %v3_4010da = load i32, i32* %edx.global-to-local, align 4
  %v4_4010da = load i1, i1* %cf.global-to-local, align 1
  %v5_4010da = zext i1 %v4_4010da to i32
  %v6_4010da = add i32 %v3_4010da, %v2_4010da
  %v7_4010da = add i32 %v5_4010da, %v6_4010da
  %v26_4010da = icmp ule i32 %v7_4010da, %v2_4010da
  %v27_4010da = icmp ult i32 %v6_4010da, %v2_4010da
  %v28_4010da = select i1 %v4_4010da, i1 %v26_4010da, i1 %v27_4010da
  store i32 %v7_4010da, i32* %v1_4010da, align 4
  %v0_4010dc = load i32, i32* @ecx, align 4
  %v1_4010dc = inttoptr i32 %v0_4010dc to i32*
  %v2_4010dc = load i32, i32* %v1_4010dc, align 4
  %v3_4010dc = load i32, i32* %edx.global-to-local, align 4
  %v5_4010dc = zext i1 %v28_4010da to i32
  %v6_4010dc = add i32 %v3_4010dc, %v2_4010dc
  %v7_4010dc = add i32 %v5_4010dc, %v6_4010dc
  %v26_4010dc = icmp ule i32 %v7_4010dc, %v2_4010dc
  %v27_4010dc = icmp ult i32 %v6_4010dc, %v2_4010dc
  %v28_4010dc = select i1 %v28_4010da, i1 %v26_4010dc, i1 %v27_4010dc
  store i1 %v28_4010dc, i1* %cf.global-to-local, align 1
  store i32 %v7_4010dc, i32* %v1_4010dc, align 4
  %v0_4010de = load i32, i32* @ecx, align 4
  %v1_4010de = inttoptr i32 %v0_4010de to i8*
  %v2_4010de = load i8, i8* %v1_4010de, align 1
  %v3_4010de = load i32, i32* %edx.global-to-local, align 4
  %v4_4010de = trunc i32 %v3_4010de to i8
  %v5_4010de = add i8 %v4_4010de, %v2_4010de
  %v10_4010de = icmp ult i8 %v5_4010de, %v2_4010de
  store i1 %v10_4010de, i1* %cf.global-to-local, align 1
  store i8 %v5_4010de, i8* %v1_4010de, align 1
  %v0_4010e0 = load i32, i32* @ecx, align 4
  %v1_4010e0 = inttoptr i32 %v0_4010e0 to i32*
  %v2_4010e0 = load i32, i32* %v1_4010e0, align 4
  %v3_4010e0 = load i32, i32* %edx.global-to-local, align 4
  %v4_4010e0 = load i1, i1* %cf.global-to-local, align 1
  %v5_4010e0 = zext i1 %v4_4010e0 to i32
  %v6_4010e0 = add i32 %v3_4010e0, %v2_4010e0
  %v7_4010e0 = add i32 %v5_4010e0, %v6_4010e0
  %v26_4010e0 = icmp ule i32 %v7_4010e0, %v2_4010e0
  %v27_4010e0 = icmp ult i32 %v6_4010e0, %v2_4010e0
  %v28_4010e0 = select i1 %v4_4010e0, i1 %v26_4010e0, i1 %v27_4010e0
  store i32 %v7_4010e0, i32* %v1_4010e0, align 4
  %v0_4010e2 = load i32, i32* @ecx, align 4
  %v1_4010e2 = inttoptr i32 %v0_4010e2 to i32*
  %v2_4010e2 = load i32, i32* %v1_4010e2, align 4
  %v3_4010e2 = load i32, i32* %edx.global-to-local, align 4
  %v5_4010e2 = zext i1 %v28_4010e0 to i32
  %v6_4010e2 = add i32 %v3_4010e2, %v2_4010e2
  %v7_4010e2 = add i32 %v5_4010e2, %v6_4010e2
  %v26_4010e2 = icmp ule i32 %v7_4010e2, %v2_4010e2
  %v27_4010e2 = icmp ult i32 %v6_4010e2, %v2_4010e2
  %v28_4010e2 = select i1 %v28_4010e0, i1 %v26_4010e2, i1 %v27_4010e2
  store i1 %v28_4010e2, i1* %cf.global-to-local, align 1
  store i32 %v7_4010e2, i32* %v1_4010e2, align 4
  %v0_4010e4 = load i32, i32* @ecx, align 4
  %v1_4010e4 = inttoptr i32 %v0_4010e4 to i8*
  %v2_4010e4 = load i8, i8* %v1_4010e4, align 1
  %v3_4010e4 = load i32, i32* %edx.global-to-local, align 4
  %v4_4010e4 = trunc i32 %v3_4010e4 to i8
  %v5_4010e4 = add i8 %v4_4010e4, %v2_4010e4
  %v10_4010e4 = icmp ult i8 %v5_4010e4, %v2_4010e4
  store i1 %v10_4010e4, i1* %cf.global-to-local, align 1
  store i8 %v5_4010e4, i8* %v1_4010e4, align 1
  %v0_4010e6 = load i32, i32* @ecx, align 4
  %v1_4010e6 = inttoptr i32 %v0_4010e6 to i32*
  %v2_4010e6 = load i32, i32* %v1_4010e6, align 4
  %v3_4010e6 = load i32, i32* %edx.global-to-local, align 4
  %v4_4010e6 = load i1, i1* %cf.global-to-local, align 1
  %v5_4010e6 = zext i1 %v4_4010e6 to i32
  %v6_4010e6 = add i32 %v3_4010e6, %v2_4010e6
  %v7_4010e6 = add i32 %v5_4010e6, %v6_4010e6
  %v26_4010e6 = icmp ule i32 %v7_4010e6, %v2_4010e6
  %v27_4010e6 = icmp ult i32 %v6_4010e6, %v2_4010e6
  %v28_4010e6 = select i1 %v4_4010e6, i1 %v26_4010e6, i1 %v27_4010e6
  store i32 %v7_4010e6, i32* %v1_4010e6, align 4
  %v0_4010e8 = load i32, i32* @ecx, align 4
  %v1_4010e8 = inttoptr i32 %v0_4010e8 to i32*
  %v2_4010e8 = load i32, i32* %v1_4010e8, align 4
  %v3_4010e8 = load i32, i32* %edx.global-to-local, align 4
  %v5_4010e8 = zext i1 %v28_4010e6 to i32
  %v6_4010e8 = add i32 %v3_4010e8, %v2_4010e8
  %v7_4010e8 = add i32 %v5_4010e8, %v6_4010e8
  %v26_4010e8 = icmp ule i32 %v7_4010e8, %v2_4010e8
  %v27_4010e8 = icmp ult i32 %v6_4010e8, %v2_4010e8
  %v28_4010e8 = select i1 %v28_4010e6, i1 %v26_4010e8, i1 %v27_4010e8
  store i1 %v28_4010e8, i1* %cf.global-to-local, align 1
  store i32 %v7_4010e8, i32* %v1_4010e8, align 4
  %v0_4010ea = load i32, i32* @ecx, align 4
  %v1_4010ea = inttoptr i32 %v0_4010ea to i8*
  %v2_4010ea = load i8, i8* %v1_4010ea, align 1
  %v3_4010ea = load i32, i32* %edx.global-to-local, align 4
  %v4_4010ea = trunc i32 %v3_4010ea to i8
  %v5_4010ea = add i8 %v4_4010ea, %v2_4010ea
  %v10_4010ea = icmp ult i8 %v5_4010ea, %v2_4010ea
  store i1 %v10_4010ea, i1* %cf.global-to-local, align 1
  store i8 %v5_4010ea, i8* %v1_4010ea, align 1
  %v0_4010ec = load i32, i32* @ecx, align 4
  %v1_4010ec = inttoptr i32 %v0_4010ec to i32*
  %v2_4010ec = load i32, i32* %v1_4010ec, align 4
  %v3_4010ec = load i32, i32* %edx.global-to-local, align 4
  %v4_4010ec = load i1, i1* %cf.global-to-local, align 1
  %v5_4010ec = zext i1 %v4_4010ec to i32
  %v6_4010ec = add i32 %v3_4010ec, %v2_4010ec
  %v7_4010ec = add i32 %v5_4010ec, %v6_4010ec
  %v26_4010ec = icmp ule i32 %v7_4010ec, %v2_4010ec
  %v27_4010ec = icmp ult i32 %v6_4010ec, %v2_4010ec
  %v28_4010ec = select i1 %v4_4010ec, i1 %v26_4010ec, i1 %v27_4010ec
  store i32 %v7_4010ec, i32* %v1_4010ec, align 4
  %v0_4010ee = load i32, i32* @ecx, align 4
  %v1_4010ee = inttoptr i32 %v0_4010ee to i32*
  %v2_4010ee = load i32, i32* %v1_4010ee, align 4
  %v3_4010ee = load i32, i32* %edx.global-to-local, align 4
  %v5_4010ee = zext i1 %v28_4010ec to i32
  %v6_4010ee = add i32 %v3_4010ee, %v2_4010ee
  %v7_4010ee = add i32 %v5_4010ee, %v6_4010ee
  %v26_4010ee = icmp ule i32 %v7_4010ee, %v2_4010ee
  %v27_4010ee = icmp ult i32 %v6_4010ee, %v2_4010ee
  %v28_4010ee = select i1 %v28_4010ec, i1 %v26_4010ee, i1 %v27_4010ee
  store i1 %v28_4010ee, i1* %cf.global-to-local, align 1
  store i32 %v7_4010ee, i32* %v1_4010ee, align 4
  %v0_4010f0 = load i32, i32* @ecx, align 4
  %v1_4010f0 = inttoptr i32 %v0_4010f0 to i8*
  %v2_4010f0 = load i8, i8* %v1_4010f0, align 1
  %v3_4010f0 = load i32, i32* %edx.global-to-local, align 4
  %v4_4010f0 = trunc i32 %v3_4010f0 to i8
  %v5_4010f0 = add i8 %v4_4010f0, %v2_4010f0
  %v10_4010f0 = icmp ult i8 %v5_4010f0, %v2_4010f0
  store i1 %v10_4010f0, i1* %cf.global-to-local, align 1
  store i8 %v5_4010f0, i8* %v1_4010f0, align 1
  %v0_4010f2 = load i32, i32* @ecx, align 4
  %v1_4010f2 = inttoptr i32 %v0_4010f2 to i32*
  %v2_4010f2 = load i32, i32* %v1_4010f2, align 4
  %v3_4010f2 = load i32, i32* %edx.global-to-local, align 4
  %v4_4010f2 = load i1, i1* %cf.global-to-local, align 1
  %v5_4010f2 = zext i1 %v4_4010f2 to i32
  %v6_4010f2 = add i32 %v3_4010f2, %v2_4010f2
  %v7_4010f2 = add i32 %v5_4010f2, %v6_4010f2
  %v26_4010f2 = icmp ule i32 %v7_4010f2, %v2_4010f2
  %v27_4010f2 = icmp ult i32 %v6_4010f2, %v2_4010f2
  %v28_4010f2 = select i1 %v4_4010f2, i1 %v26_4010f2, i1 %v27_4010f2
  store i32 %v7_4010f2, i32* %v1_4010f2, align 4
  %v0_4010f4 = load i32, i32* @ecx, align 4
  %v1_4010f4 = inttoptr i32 %v0_4010f4 to i32*
  %v2_4010f4 = load i32, i32* %v1_4010f4, align 4
  %v3_4010f4 = load i32, i32* %edx.global-to-local, align 4
  %v5_4010f4 = zext i1 %v28_4010f2 to i32
  %v6_4010f4 = add i32 %v3_4010f4, %v2_4010f4
  %v7_4010f4 = add i32 %v5_4010f4, %v6_4010f4
  %v26_4010f4 = icmp ule i32 %v7_4010f4, %v2_4010f4
  %v27_4010f4 = icmp ult i32 %v6_4010f4, %v2_4010f4
  %v28_4010f4 = select i1 %v28_4010f2, i1 %v26_4010f4, i1 %v27_4010f4
  store i1 %v28_4010f4, i1* %cf.global-to-local, align 1
  store i32 %v7_4010f4, i32* %v1_4010f4, align 4
  %v0_4010f6 = load i32, i32* @ecx, align 4
  %v1_4010f6 = inttoptr i32 %v0_4010f6 to i8*
  %v2_4010f6 = load i8, i8* %v1_4010f6, align 1
  %v3_4010f6 = load i32, i32* %edx.global-to-local, align 4
  %v4_4010f6 = trunc i32 %v3_4010f6 to i8
  %v5_4010f6 = add i8 %v4_4010f6, %v2_4010f6
  store i8 %v5_4010f6, i8* %v1_4010f6, align 1
  %v0_4010f8 = load i32, i32* @ebx, align 4
  %v1_4010f8 = add i32 %v0_4010f8, -30
  store i32 %v1_4010f8, i32* %ebx.global-to-local, align 4
  %v0_4010fb = load i32, i32* inttoptr (i32 4763853 to i32*), align 4
  %v1_4010fb = load i32, i32* @edi, align 4
  %v2_4010fb = sub i32 %v0_4010fb, %v1_4010fb
  store i32 %v2_4010fb, i32* inttoptr (i32 4763853 to i32*), align 4
  %v1_401106 = load i32, i32* @esi, align 4
  %v2_401106 = add i32 %v1_401106, 1
  store i32 %v2_401106, i32* %ecx.global-to-local, align 4
  %v0_401108 = load i32, i32* inttoptr (i32 4763807 to i32*), align 4
  %v1_401108 = and i32 %v0_401108, 221
  store i32 %v1_401108, i32* inttoptr (i32 4763807 to i32*), align 4
  %v0_401112 = load i32, i32* %ebx.global-to-local, align 4
  %v1_401112 = xor i32 %v0_401112, -88
  store i32 %v1_401112, i32* %ebx.global-to-local, align 4
  %v0_401115 = load i32, i32* inttoptr (i32 4763863 to i32*), align 4
  %v2_401115 = or i32 %v0_401115, %v1_401112
  store i32 %v2_401115, i32* inttoptr (i32 4763863 to i32*), align 4
  store i32 64, i32* inttoptr (i32 4764072 to i32*), align 8
  %v0_401125 = load i32, i32* @edi, align 4
  %v1_401125 = xor i32 %v0_401125, 25
  store i32 %v1_401125, i32* %edi.global-to-local, align 4
  %v0_401128 = load i32, i32* inttoptr (i32 4763788 to i32*), align 4
  %v1_401128 = xor i32 %v0_401128, 60
  store i32 %v1_401128, i32* inttoptr (i32 4763788 to i32*), align 4
  %v0_40112f = load i32, i32* inttoptr (i32 4763902 to i32*), align 4
  %v3_40112f = add i32 %v0_40112f, -224
  store i32 %v3_40112f, i32* inttoptr (i32 4763902 to i32*), align 4
  %v0_401139 = load i32, i32* @esi, align 4
  %v2_401139 = mul i32 %v0_401139, 2
  %v7_401139 = icmp ult i32 %v2_401139, %v0_401139
  store i32 %v2_401139, i32* %esi.global-to-local, align 4
  %v0_40113b = load i32, i32* %ebx.global-to-local, align 4
  %v1_40113b = load i32, i32* inttoptr (i32 4763759 to i32*), align 4
  %v3_40113b = zext i1 %v7_401139 to i32
  %v4_40113b = add i32 %v1_40113b, %v0_40113b
  %v5_40113b = add i32 %v4_40113b, %v3_40113b
  store i32 %v5_40113b, i32* %ebx.global-to-local, align 4
  %v0_401141 = load i32, i32* inttoptr (i32 4763793 to i32*), align 4
  %v1_401141 = and i32 %v0_401141, 121
  store i32 %v1_401141, i32* inttoptr (i32 4763793 to i32*), align 4
  %v0_401148 = load i32, i32* @eax, align 4
  %v1_401148 = load i32, i32* inttoptr (i32 4763867 to i32*), align 4
  %v2_401148 = or i32 %v1_401148, %v0_401148
  store i32 %v2_401148, i32* %eax.global-to-local, align 4
  store i1 false, i1* %cf.global-to-local, align 1
  %v8_401160 = call i1 @SetEnvironmentVariableW(i16* bitcast ([13 x i8]* @global_var_48b685.2 to i16*), i16* bitcast ([17 x i8]* @global_var_48b692.1 to i16*))
  %v9_401160 = sext i1 %v8_401160 to i32
  store i32 %v9_401160, i32* %eax.global-to-local, align 4
  %v0_401166 = load i32, i32* %ebx.global-to-local, align 4
  %v1_401166 = load i32, i32* inttoptr (i32 4763872 to i32*), align 32
  %v2_401166 = load i1, i1* %cf.global-to-local, align 1
  %v3_401166 = zext i1 %v2_401166 to i32
  %v4_401166 = add i32 %v1_401166, %v0_401166
  %v5_401166 = add i32 %v3_401166, %v4_401166
  %v24_401166 = icmp ule i32 %v5_401166, %v0_401166
  %v25_401166 = icmp ult i32 %v4_401166, %v0_401166
  %v26_401166 = select i1 %v2_401166, i1 %v24_401166, i1 %v25_401166
  store i32 %v5_401166, i32* %ebx.global-to-local, align 4
  %v0_40116c = load i32, i32* inttoptr (i32 4763742 to i32*), align 4
  %v2_40116c = zext i1 %v26_401166 to i32
  %v3_40116c = add i32 %v0_40116c, -25
  %v4_40116c = add i32 %v3_40116c, %v2_40116c
  store i32 %v4_40116c, i32* inttoptr (i32 4763742 to i32*), align 4
  %v0_401173 = load i32, i32* %esi.global-to-local, align 4
  %v1_401173 = load i32, i32* inttoptr (i32 4763901 to i32*), align 4
  %v2_401173 = or i32 %v1_401173, %v0_401173
  store i32 %v2_401173, i32* %esi.global-to-local, align 4
  %v4_401179 = add i32 %v2_401173, %v9_401160
  %v25_401179 = icmp ult i32 %v4_401179, %v9_401160
  store i32 %v4_401179, i32* %eax.global-to-local, align 4
  store i32 1, i32* %ecx.global-to-local, align 4
  %v1_401180 = load i32, i32* inttoptr (i32 4764106 to i32*), align 4
  %v3_401180 = zext i1 %v25_401179 to i32
  %v4_401180 = add i32 %v1_401180, 1
  %v5_401180 = add i32 %v4_401180, %v3_401180
  %v24_401180 = icmp ult i32 %v5_401180, 2
  %v25_401180 = icmp eq i32 %v4_401180, 0
  %v26_401180 = select i1 %v25_401179, i1 %v24_401180, i1 %v25_401180
  store i32 %v5_401180, i32* %ecx.global-to-local, align 4
  %v0_401186 = load i32, i32* inttoptr (i32 4763816 to i32*), align 8
  %v3_401186 = select i1 %v26_401180, i32 234, i32 233
  %v4_401186 = add i32 %v3_401186, %v0_401186
  %v21_401186 = icmp ule i32 %v4_401186, %v0_401186
  %v22_401186 = icmp ugt i32 %v0_401186, -234
  %v23_401186 = select i1 %v26_401180, i1 %v21_401186, i1 %v22_401186
  store i32 %v4_401186, i32* inttoptr (i32 4763816 to i32*), align 8
  %v0_401190 = load i32, i32* inttoptr (i32 4763916 to i32*), align 4
  %v3_401190 = select i1 %v23_401186, i32 218, i32 217
  %v4_401190 = add i32 %v3_401190, %v0_401190
  store i32 %v4_401190, i32* inttoptr (i32 4763916 to i32*), align 4
  %v0_40119a = load i32, i32* %ebx.global-to-local, align 4
  %v1_40119a = load i32, i32* inttoptr (i32 4763668 to i32*), align 4
  %v2_40119a = or i32 %v1_40119a, %v0_40119a
  %v5_40119a = trunc i32 %v2_40119a to i8
  %v0_4011a0 = load i32, i32* %edi.global-to-local, align 4
  %v1_4011a0 = load i32, i32* %eax.global-to-local, align 4
  %v4_4011a0 = sub i32 %v0_4011a0, %v1_4011a0
  store i32 %v4_4011a0, i32* %edi.global-to-local, align 4
  %v2_4011a2 = load i32, i32* %ecx.global-to-local, align 4
  %v3_4011a2 = udiv i32 %v2_4011a2, 256
  %v4_4011a2 = trunc i32 %v3_4011a2 to i8
  %v5_4011a2 = add i8 %v4_4011a2, %v5_40119a
  %v10_4011a2 = icmp ult i8 %v5_4011a2, %v5_40119a
  %v20_4011a2 = zext i8 %v5_4011a2 to i32
  %v22_4011a2 = and i32 %v2_40119a, -256
  %v23_4011a2 = or i32 %v20_4011a2, %v22_4011a2
  store i32 %v23_4011a2, i32* %ebx.global-to-local, align 4
  %v0_4011a4 = load i32, i32* inttoptr (i32 4763949 to i32*), align 4
  %v2_4011a4 = zext i1 %v10_4011a2 to i32
  %v3_4011a4 = add i32 %v0_4011a4, -204
  %v4_4011a4 = add i32 %v3_4011a4, %v2_4011a4
  store i32 %v4_4011a4, i32* inttoptr (i32 4763949 to i32*), align 4
  store i32 7, i32* %edx.global-to-local, align 4
  %v0_4011b6 = load i32, i32* inttoptr (i32 4763761 to i32*), align 4
  %v1_4011b6 = load i32, i32* %ecx.global-to-local, align 4
  %v2_4011b6 = or i32 %v1_4011b6, %v0_4011b6
  store i32 %v2_4011b6, i32* inttoptr (i32 4763761 to i32*), align 4
  %v0_4011bc = load i32, i32* %esi.global-to-local, align 4
  %v1_4011bc = load i32, i32* inttoptr (i32 4764045 to i32*), align 4
  %v2_4011bc = sub i32 %v0_4011bc, %v1_4011bc
  store i32 %v2_4011bc, i32* %esi.global-to-local, align 4
  %v0_4011c2 = load i32, i32* inttoptr (i32 4763835 to i32*), align 4
  %v1_4011c2 = load i32, i32* %ecx.global-to-local, align 4
  %v2_4011c2 = add i32 %v1_4011c2, %v0_4011c2
  store i32 %v2_4011c2, i32* inttoptr (i32 4763835 to i32*), align 4
  %v0_4011c8 = load i32, i32* inttoptr (i32 4763700 to i32*), align 4
  %v1_4011c8 = load i32, i32* %edx.global-to-local, align 4
  %v2_4011c8 = and i32 %v1_4011c8, %v0_4011c8
  store i32 %v2_4011c8, i32* inttoptr (i32 4763700 to i32*), align 4
  %v0_4011ce = load i32, i32* %ecx.global-to-local, align 4
  %v1_4011ce = load i32, i32* inttoptr (i32 4763909 to i32*), align 4
  %v4_4011ce = add i32 %v1_4011ce, %v0_4011ce
  %v25_4011ce = icmp ult i32 %v4_4011ce, %v0_4011ce
  store i1 %v25_4011ce, i1* %cf.global-to-local, align 1
  store i32 %v4_4011ce, i32* %ecx.global-to-local, align 4
  %v0_4011d4 = load i8, i8* inttoptr (i32 4763759 to i8*), align 1
  %v1_4011d4 = add i8 %v0_4011d4, 68
  store i8 %v1_4011d4, i8* inttoptr (i32 4763759 to i8*), align 1
  store i32 0, i32* %edi.global-to-local, align 4
  %v0_4011dd = load i32, i32* %edx.global-to-local, align 4
  store i1 false, i1* %cf.global-to-local, align 1
  %v42_4011dd = and i32 %v0_4011dd, -65281
  store i32 %v42_4011dd, i32* %edx.global-to-local, align 4
  call void @__pseudo_call(i32 4198887)
  %v0_4011e7 = load i32, i32* inttoptr (i32 4763766 to i32*), align 4
  %v1_4011e7 = load i32, i32* %edx.global-to-local, align 4
  %v2_4011e7 = sub i32 %v0_4011e7, %v1_4011e7
  %v7_4011e7 = icmp ult i32 %v0_4011e7, %v1_4011e7
  store i32 %v2_4011e7, i32* inttoptr (i32 4763766 to i32*), align 4
  %v0_4011ed = load i32, i32* %ebx.global-to-local, align 4
  %v1_4011ed = load i32, i32* %esi.global-to-local, align 4
  %v3_4011ed = zext i1 %v7_4011e7 to i32
  %v4_4011ed = sub i32 %v0_4011ed, %v1_4011ed
  %v5_4011ed = add i32 %v4_4011ed, %v3_4011ed
  %v16_4011ed = sub i32 %v4_4011ed, %v3_4011ed
  %v17_4011ed = icmp ult i32 %v0_4011ed, %v16_4011ed
  %v18_4011ed = icmp ne i32 %v1_4011ed, -1
  %v19_4011ed = or i1 %v18_4011ed, %v17_4011ed
  %v20_4011ed = icmp ult i32 %v0_4011ed, %v1_4011ed
  %v21_4011ed = select i1 %v7_4011e7, i1 %v19_4011ed, i1 %v20_4011ed
  store i32 %v5_4011ed, i32* %ebx.global-to-local, align 4
  %v2_4011ef = zext i1 %v21_4011ed to i32
  %v3_4011ef = add i32 %v1_4011ed, 28
  %v4_4011ef = add i32 %v3_4011ef, %v2_4011ef
  store i32 %v4_4011ef, i32* %esi.global-to-local, align 4
  %v0_4011f2 = load i32, i32* inttoptr (i32 4763670 to i32*), align 4
  %v1_4011f2 = or i32 %v0_4011f2, 215
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v1_4011f2, i32* inttoptr (i32 4763670 to i32*), align 4
  %v0_4011fc = load i8, i8* inttoptr (i32 4763908 to i8*), align 4
  %v1_4011fc = load i32, i32* %ebx.global-to-local, align 4
  %v2_4011fc = trunc i32 %v1_4011fc to i8
  %v3_4011fc = sub i8 %v0_4011fc, %v2_4011fc
  store i8 %v3_4011fc, i8* inttoptr (i32 4763908 to i8*), align 4
  %v0_401202 = load i32, i32* %edi.global-to-local, align 4
  %v1_401202 = load i32, i32* inttoptr (i32 4763653 to i32*), align 4
  %v2_401202 = sub i32 %v0_401202, %v1_401202
  store i32 %v2_401202, i32* %edi.global-to-local, align 4
  %v0_401208 = load i32, i32* inttoptr (i32 4763799 to i32*), align 4
  %v1_401208 = and i32 %v0_401208, 237
  store i32 %v1_401208, i32* inttoptr (i32 4763799 to i32*), align 4
  %v0_401212 = load i32, i32* %edx.global-to-local, align 4
  %v1_401212 = load i32, i32* %eax.global-to-local, align 4
  %v4_401212 = sub i32 %v0_401212, %v1_401212
  %v20_401212 = icmp ult i32 %v0_401212, %v1_401212
  store i32 %v4_401212, i32* %edx.global-to-local, align 4
  %v2_401214 = zext i1 %v20_401212 to i32
  %v1_401216 = load i32, i32* %edi.global-to-local, align 4
  %v2_401216 = sub i32 %v2_401214, %v1_401216
  %v7_401216 = icmp ult i32 %v2_401214, %v1_401216
  store i32 %v2_401216, i32* %ebx.global-to-local, align 4
  %v0_401218 = load i32, i32* inttoptr (i32 4763910 to i32*), align 4
  %v2_401218 = zext i1 %v7_401216 to i32
  %v3_401218 = add i32 %v0_401218, -176
  %v4_401218 = add i32 %v3_401218, %v2_401218
  store i32 %v4_401218, i32* inttoptr (i32 4763910 to i32*), align 4
  store i32 219, i32* inttoptr (i32 4763835 to i32*), align 4
  %v0_40122c = load i32, i32* %eax.global-to-local, align 4
  %v1_40122c = xor i32 %v0_40122c, -84
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v1_40122c, i32* %eax.global-to-local, align 4
  store i32 232, i32* inttoptr (i32 4764121 to i32*), align 4
  %v1_401239 = inttoptr i32 %v1_40122c to i8*
  %v2_401239 = load i8, i8* %v1_401239, align 1
  %v4_401239 = trunc i32 %v1_40122c to i8
  %v5_401239 = add i8 %v4_401239, %v2_401239
  %v10_401239 = icmp ult i8 %v5_401239, %v2_401239
  store i1 %v10_401239, i1* %cf.global-to-local, align 1
  store i8 %v5_401239, i8* %v1_401239, align 1
  %v0_40123b = load i32, i32* %esi.global-to-local, align 4
  %v2_40123b = load i1, i1* %cf.global-to-local, align 1
  %v3_40123b = zext i1 %v2_40123b to i32
  %v4_40123b = mul i32 %v0_40123b, 2
  %v5_40123b = or i32 %v3_40123b, %v4_40123b
  %v24_40123b = icmp ule i32 %v5_40123b, %v0_40123b
  %v25_40123b = icmp ult i32 %v4_40123b, %v0_40123b
  %v26_40123b = select i1 %v2_40123b, i1 %v24_40123b, i1 %v25_40123b
  store i32 %v5_40123b, i32* %esi.global-to-local, align 4
  %v0_40123d = load i32, i32* %eax.global-to-local, align 4
  %v1_40123d = load i32, i32* %edi.global-to-local, align 4
  %v3_40123d = zext i1 %v26_40123b to i32
  %v4_40123d = add i32 %v1_40123d, %v0_40123d
  %v5_40123d = add i32 %v3_40123d, %v4_40123d
  %v24_40123d = icmp ule i32 %v5_40123d, %v0_40123d
  %v25_40123d = icmp ult i32 %v4_40123d, %v0_40123d
  %v26_40123d = select i1 %v26_40123b, i1 %v24_40123d, i1 %v25_40123d
  store i32 %v5_40123d, i32* %eax.global-to-local, align 4
  %v0_40123f = load i32, i32* inttoptr (i32 4763989 to i32*), align 4
  %v3_40123f = zext i1 %v26_40123d to i32
  %v4_40123f = sub i32 %v0_40123f, %v5_40123b
  %v5_40123f = add i32 %v3_40123f, %v4_40123f
  %v16_40123f = sub i32 %v4_40123f, %v3_40123f
  %v17_40123f = icmp ult i32 %v0_40123f, %v16_40123f
  %v18_40123f = icmp ne i32 %v5_40123b, -1
  %v19_40123f = or i1 %v18_40123f, %v17_40123f
  %v20_40123f = icmp ult i32 %v0_40123f, %v5_40123b
  %v21_40123f = select i1 %v26_40123d, i1 %v19_40123f, i1 %v20_40123f
  store i1 %v21_40123f, i1* %cf.global-to-local, align 1
  store i32 %v5_40123f, i32* inttoptr (i32 4763989 to i32*), align 4
  %v0_401245 = load i8, i8* inttoptr (i32 4763891 to i8*), align 1
  %v1_401245 = add i8 %v0_401245, -24
  store i8 %v1_401245, i8* inttoptr (i32 4763891 to i8*), align 1
  %v0_40124c = load i32, i32* inttoptr (i32 4764063 to i32*), align 4
  %v1_40124c = and i32 %v0_40124c, 81
  store i32 %v1_40124c, i32* inttoptr (i32 4764063 to i32*), align 4
  %v0_401253 = load i32, i32* inttoptr (i32 4764131 to i32*), align 4
  %v3_401253 = add i32 %v0_401253, 237
  store i32 %v3_401253, i32* inttoptr (i32 4764131 to i32*), align 4
  %v0_40125d = load i32, i32* %ebx.global-to-local, align 4
  %v1_40125d = load i32, i32* %edi.global-to-local, align 4
  %v2_40125d = sub i32 %v0_40125d, %v1_40125d
  store i32 %v2_40125d, i32* %ebx.global-to-local, align 4
  %v0_40125f = load i32, i32* %ecx.global-to-local, align 4
  %v1_40125f = and i32 %v0_40125f, -65281
  %v20_401261 = or i32 %v1_40125f, 17920
  store i32 %v20_401261, i32* %ecx.global-to-local, align 4
  %v0_401264 = load i32, i32* inttoptr (i32 4764138 to i32*), align 4
  %v3_401264 = add i32 %v0_401264, -96
  %v11_401264 = icmp ult i32 %v0_401264, 96
  store i32 %v3_401264, i32* inttoptr (i32 4764138 to i32*), align 4
  %v0_40126b = load i32, i32* %ebx.global-to-local, align 4
  %v1_40126b = udiv i32 %v0_40126b, 256
  %v2_40126b = trunc i32 %v1_40126b to i8
  %v3_40126b = load i32, i32* %eax.global-to-local, align 4
  %v4_40126b = udiv i32 %v3_40126b, 256
  %v5_40126b = trunc i32 %v4_40126b to i8
  %v7_40126b = zext i1 %v11_401264 to i8
  %v8_40126b = add i8 %v5_40126b, %v2_40126b
  %v9_40126b = add i8 %v8_40126b, %v7_40126b
  %v27_40126b = icmp ule i8 %v9_40126b, %v2_40126b
  %v28_40126b = icmp ult i8 %v8_40126b, %v2_40126b
  %v29_40126b = select i1 %v11_401264, i1 %v27_40126b, i1 %v28_40126b
  %v30_40126b = zext i8 %v9_40126b to i32
  %v32_40126b = mul nuw nsw i32 %v30_40126b, 256
  %v33_40126b = and i32 %v0_40126b, -65281
  %v34_40126b = or i32 %v32_40126b, %v33_40126b
  store i32 %v34_40126b, i32* %ebx.global-to-local, align 4
  %v2_40126d = zext i1 %v29_40126b to i32
  %v3_40126d = add i32 %v3_40126b, 4
  %v4_40126d = add i32 %v3_40126d, %v2_40126d
  store i32 %v4_40126d, i32* %eax.global-to-local, align 4
  %v0_401270 = load i32, i32* inttoptr (i32 4763742 to i32*), align 4
  %v1_401270 = and i32 %v0_401270, 7
  store i32 %v1_401270, i32* inttoptr (i32 4763742 to i32*), align 4
  %v0_401277 = load i32, i32* %ecx.global-to-local, align 4
  %v1_401277 = xor i32 %v0_401277, -8
  store i32 %v1_401277, i32* %ecx.global-to-local, align 4
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 1048576, i32* %eax.global-to-local, align 4
  %v10_401293 = call i32* @OpenJobObjectW(i32 1048576, i1 false, i16* bitcast ([13 x i8]* @global_var_48b6a3.4 to i16*))
  %v11_401293 = ptrtoint i32* %v10_401293 to i32
  store i32 %v11_401293, i32* %eax.global-to-local, align 4
  %sext = mul i32 %v11_401293, 16777216
  store i1 false, i1* %cf.global-to-local, align 1
  %v2_401299 = icmp eq i32 %sext, 0
  %v1_40129b = icmp eq i1 %v2_401299, false
  call void @__pseudo_cond_branch(i1 %v1_40129b, i32 4210422)
  store i32 67, i32* %edx.global-to-local, align 4
  %v1_4012b1 = load i32, i32* %edi.global-to-local, align 4
  %v2_4012b1 = add i32 %v1_4012b1, 1
  store i32 %v2_4012b1, i32* %ecx.global-to-local, align 4
  %v0_4012b3 = load i32, i32* inttoptr (i32 4763943 to i32*), align 4
  %v1_4012b3 = load i32, i32* %ebx.global-to-local, align 4
  %v2_4012b3 = add i32 %v1_4012b3, %v0_4012b3
  %v7_4012b3 = icmp ult i32 %v2_4012b3, %v0_4012b3
  store i32 %v2_4012b3, i32* inttoptr (i32 4763943 to i32*), align 4
  %v0_4012b9 = load i32, i32* %esi.global-to-local, align 4
  %v1_4012b9 = load i32, i32* inttoptr (i32 4763884 to i32*), align 4
  %v3_4012b9 = zext i1 %v7_4012b3 to i32
  %v4_4012b9 = add i32 %v1_4012b9, %v0_4012b9
  %v5_4012b9 = add i32 %v4_4012b9, %v3_4012b9
  store i32 %v5_4012b9, i32* %esi.global-to-local, align 4
  %v0_4012bf = load i32, i32* inttoptr (i32 4763919 to i32*), align 4
  %v1_4012bf = load i32, i32* %edi.global-to-local, align 4
  %v2_4012bf = xor i32 %v1_4012bf, %v0_4012bf
  store i32 %v2_4012bf, i32* inttoptr (i32 4763919 to i32*), align 4
  %v1_4012c5 = load i32, i32* inttoptr (i32 4763785 to i32*), align 4
  %v4_4012c5 = add i32 %v1_4012c5, %v1_4012bf
  %v25_4012c5 = icmp ult i32 %v4_4012c5, %v1_4012bf
  store i32 %v4_4012c5, i32* %edi.global-to-local, align 4
  %v0_4012cb = load i32, i32* inttoptr (i32 4763886 to i32*), align 4
  %v3_4012cb = zext i1 %v25_4012c5 to i32
  %v4_4012cb = add i32 %v0_4012cb, %v4_4012c5
  %v5_4012cb = add i32 %v4_4012cb, %v3_4012cb
  store i32 %v5_4012cb, i32* inttoptr (i32 4763886 to i32*), align 4
  %v0_4012d1 = load i32, i32* inttoptr (i32 4764055 to i32*), align 4
  %v1_4012d1 = and i32 %v0_4012d1, 42
  store i32 %v1_4012d1, i32* inttoptr (i32 4764055 to i32*), align 4
  %v0_4012d8 = load i32, i32* inttoptr (i32 4764052 to i32*), align 4
  %v1_4012d8 = load i32, i32* %ebx.global-to-local, align 4
  %v2_4012d8 = add i32 %v1_4012d8, %v0_4012d8
  %v7_4012d8 = icmp ult i32 %v2_4012d8, %v0_4012d8
  store i32 %v2_4012d8, i32* inttoptr (i32 4764052 to i32*), align 4
  %v3_4012de = load i32, i32* %edx.global-to-local, align 4
  %v6_4012de = zext i1 %v7_4012d8 to i32
  %v7_4012de = add i32 %v3_4012de, %v11_401293
  %v8_4012de = add i32 %v7_4012de, %v6_4012de
  %v29_4012de = and i32 %v8_4012de, 255
  %v31_4012de = sdiv i32 %sext, 16777216
  %v32_4012de = and i32 %v31_4012de, -256
  %v33_4012de = or i32 %v29_4012de, %v32_4012de
  store i32 %v33_4012de, i32* %eax.global-to-local, align 4
  %v0_4012e0 = load i32, i32* inttoptr (i32 4763808 to i32*), align 32
  %v1_4012e0 = load i32, i32* %edi.global-to-local, align 4
  %v2_4012e0 = add i32 %v1_4012e0, %v0_4012e0
  store i32 %v2_4012e0, i32* inttoptr (i32 4763808 to i32*), align 32
  %v0_4012e6 = load i32, i32* inttoptr (i32 4763925 to i32*), align 4
  %v1_4012e6 = and i32 %v0_4012e6, 30
  store i32 %v1_4012e6, i32* inttoptr (i32 4763925 to i32*), align 4
  %v0_4012ed = load i32, i32* %edx.global-to-local, align 4
  %v1_4012ed = load i32, i32* %ebx.global-to-local, align 4
  %v2_4012ed = add i32 %v1_4012ed, %v0_4012ed
  store i32 %v2_4012ed, i32* %edx.global-to-local, align 4
  %v0_4012ef = load i32, i32* %edi.global-to-local, align 4
  %v1_4012ef = load i32, i32* %esi.global-to-local, align 4
  %v2_4012ef = xor i32 %v1_4012ef, %v0_4012ef
  store i32 %v2_4012ef, i32* %edi.global-to-local, align 4
  %v0_4012f1 = load i32, i32* inttoptr (i32 4764018 to i32*), align 4
  %v4_4012f1 = add i32 %v0_4012f1, %v2_4012ed
  store i32 %v4_4012f1, i32* inttoptr (i32 4764018 to i32*), align 4
  %v0_4012f7 = load i32, i32* inttoptr (i32 4763943 to i32*), align 4
  %v1_4012f7 = load i32, i32* %ebx.global-to-local, align 4
  %v2_4012f7 = or i32 %v1_4012f7, %v0_4012f7
  store i32 %v2_4012f7, i32* inttoptr (i32 4763943 to i32*), align 4
  %v0_4012fd = load i32, i32* %edx.global-to-local, align 4
  %v1_4012fd = add i32 %v0_4012fd, -85
  store i32 %v1_4012fd, i32* %edx.global-to-local, align 4
  %v0_401300 = load i32, i32* inttoptr (i32 4764014 to i32*), align 4
  %v1_401300 = load i32, i32* %eax.global-to-local, align 4
  %v2_401300 = or i32 %v1_401300, %v0_401300
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v2_401300, i32* inttoptr (i32 4764014 to i32*), align 4
  %v0_401306 = load i32, i32* %ecx.global-to-local, align 4
  %v1_401306 = udiv i32 %v0_401306, 256
  %v2_401306 = trunc i32 %v1_401306 to i8
  %v3_401306 = load i8, i8* inttoptr (i32 4763975 to i8*), align 1
  %v6_401306 = add i8 %v2_401306, %v3_401306
  %v26_401306 = icmp ult i8 %v6_401306, %v2_401306
  store i1 %v26_401306, i1* %cf.global-to-local, align 1
  %v28_401306 = zext i8 %v6_401306 to i32
  %v30_401306 = mul nuw nsw i32 %v28_401306, 256
  %v31_401306 = and i32 %v0_401306, -65281
  %v32_401306 = or i32 %v30_401306, %v31_401306
  store i32 %v32_401306, i32* %ecx.global-to-local, align 4
  call void @__pseudo_call(i32 0)
  %v0_401314 = load i8, i8* inttoptr (i32 4764073 to i8*), align 1
  %v1_401314 = load i32, i32* %edx.global-to-local, align 4
  %v2_401314 = udiv i32 %v1_401314, 256
  %v3_401314 = trunc i32 %v2_401314 to i8
  %v4_401314 = add i8 %v3_401314, %v0_401314
  store i8 %v4_401314, i8* inttoptr (i32 4764073 to i8*), align 1
  %v0_40131a = load i32, i32* %ebx.global-to-local, align 4
  %v1_40131a = add i32 %v0_40131a, 118
  store i32 %v1_40131a, i32* %ebx.global-to-local, align 4
  %v0_40131d = load i32, i32* inttoptr (i32 4764154 to i32*), align 4
  %v1_40131d = load i32, i32* %ecx.global-to-local, align 4
  %v2_40131d = and i32 %v1_40131d, %v0_40131d
  store i32 %v2_40131d, i32* inttoptr (i32 4764154 to i32*), align 4
  %v1_401323 = add i32 %v0_40131a, 235
  %v5_401323 = icmp ugt i32 %v1_40131a, -118
  store i32 %v1_401323, i32* %ebx.global-to-local, align 4
  %v1_401326 = load i32, i32* inttoptr (i32 4763793 to i32*), align 4
  %v3_401326 = zext i1 %v5_401323 to i32
  %v4_401326 = add i32 %v1_401326, %v1_401323
  %v5_401326 = add i32 %v4_401326, %v3_401326
  %v24_401326 = icmp ule i32 %v5_401326, %v1_401323
  %v25_401326 = icmp ult i32 %v4_401326, %v1_401323
  %v26_401326 = select i1 %v5_401323, i1 %v24_401326, i1 %v25_401326
  store i32 %v5_401326, i32* %ebx.global-to-local, align 4
  %v0_40132c = load i32, i32* inttoptr (i32 4764030 to i32*), align 4
  %v3_40132c = select i1 %v26_401326, i32 160, i32 159
  %v4_40132c = add i32 %v3_40132c, %v0_40132c
  store i32 %v4_40132c, i32* inttoptr (i32 4764030 to i32*), align 4
  %v0_401336 = load i32, i32* %edi.global-to-local, align 4
  %v1_401336 = add i32 %v0_401336, -48
  store i32 %v1_401336, i32* %edi.global-to-local, align 4
  %v0_401339 = load i32, i32* inttoptr (i32 4763964 to i32*), align 4
  %v2_401339 = or i32 %v0_401339, %v1_401336
  store i32 %v2_401339, i32* inttoptr (i32 4763964 to i32*), align 4
  %v1_40133f = load i32, i32* inttoptr (i32 4763986 to i32*), align 4
  %v4_40133f = add i32 %v1_40133f, %v1_401336
  store i32 %v4_40133f, i32* %edi.global-to-local, align 4
  %v0_401345 = load i32, i32* %edx.global-to-local, align 4
  %v1_401345 = load i32, i32* inttoptr (i32 4763838 to i32*), align 4
  %v2_401345 = sub i32 %v0_401345, %v1_401345
  %v7_401345 = icmp ult i32 %v0_401345, %v1_401345
  %v1_40134b = load i32, i32* %esi.global-to-local, align 4
  %v3_40134b = zext i1 %v7_401345 to i32
  %v4_40134b = add i32 %v2_401345, %v1_40134b
  %v5_40134b = add i32 %v4_40134b, %v3_40134b
  store i32 %v5_40134b, i32* %edx.global-to-local, align 4
  %v0_40134d = load i32, i32* inttoptr (i32 4763808 to i32*), align 32
  %v1_40134d = load i32, i32* %ecx.global-to-local, align 4
  %v2_40134d = add i32 %v1_40134d, %v0_40134d
  store i32 %v2_40134d, i32* inttoptr (i32 4763808 to i32*), align 32
  %v2_401353 = add i32 %v1_40134d, %v5_40134b
  %v7_401353 = icmp ult i32 %v2_401353, %v5_40134b
  store i32 %v2_401353, i32* %edx.global-to-local, align 4
  %v0_401355 = load i32, i32* %esi.global-to-local, align 4
  %v1_401355 = load i32, i32* %ebx.global-to-local, align 4
  %v3_401355 = zext i1 %v7_401353 to i32
  %v4_401355 = add i32 %v1_401355, %v0_401355
  %v5_401355 = add i32 %v4_401355, %v3_401355
  store i32 %v5_401355, i32* %esi.global-to-local, align 4
  %v0_401357 = load i32, i32* %eax.global-to-local, align 4
  %v1_401357 = or i32 %v0_401357, -74
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v1_401357, i32* %eax.global-to-local, align 4
  %v1_40135a = udiv i32 %v1_401355, 256
  %v2_40135a = trunc i32 %v1_40135a to i8
  %v3_40135a = load i8, i8* inttoptr (i32 4763751 to i8*), align 1
  %v6_40135a = add i8 %v3_40135a, %v2_40135a
  %v28_40135a = zext i8 %v6_40135a to i32
  %v30_40135a = mul nuw nsw i32 %v28_40135a, 256
  %v31_40135a = and i32 %v1_401355, -65281
  %v32_40135a = or i32 %v30_40135a, %v31_40135a
  store i32 %v32_40135a, i32* %ebx.global-to-local, align 4
  %v0_401360 = load i32, i32* inttoptr (i32 4764068 to i32*), align 4
  %v1_401360 = or i32 %v0_401360, 109
  store i32 %v1_401360, i32* inttoptr (i32 4764068 to i32*), align 4
  store i32 245, i32* inttoptr (i32 4763734 to i32*), align 4
  %v1_401371 = trunc i32 %v1_401355 to i8
  %v2_401371 = add i32 %v1_401355, 159
  %v5_401371 = icmp ugt i8 %v1_401371, 96
  store i1 %v5_401371, i1* %cf.global-to-local, align 1
  %v15_401371 = and i32 %v2_401371, 255
  %v17_401371 = and i32 %v32_40135a, -256
  %v18_401371 = or i32 %v15_401371, %v17_401371
  store i32 %v18_401371, i32* %ebx.global-to-local, align 4
  %v0_401374 = load i32, i32* %eax.global-to-local, align 4
  %v1_401374 = inttoptr i32 %v0_401374 to i8*
  %v2_401374 = load i8, i8* %v1_401374, align 1
  %v4_401374 = trunc i32 %v0_401374 to i8
  %v5_401374 = add i8 %v4_401374, %v2_401374
  %v10_401374 = icmp ult i8 %v5_401374, %v2_401374
  store i1 %v10_401374, i1* %cf.global-to-local, align 1
  store i8 %v5_401374, i8* %v1_401374, align 1
  %v0_401376 = load i32, i32* %eax.global-to-local, align 4
  %v1_401376 = inttoptr i32 %v0_401376 to i8*
  %v2_401376 = load i8, i8* %v1_401376, align 1
  %v4_401376 = trunc i32 %v0_401376 to i8
  %v5_401376 = add i8 %v4_401376, %v2_401376
  %v10_401376 = icmp ult i8 %v5_401376, %v2_401376
  store i1 %v10_401376, i1* %cf.global-to-local, align 1
  store i8 %v5_401376, i8* %v1_401376, align 1
  %v0_401378 = load i32, i32* %eax.global-to-local, align 4
  %v1_401378 = inttoptr i32 %v0_401378 to i8*
  %v2_401378 = load i8, i8* %v1_401378, align 1
  %v4_401378 = trunc i32 %v0_401378 to i8
  %v5_401378 = add i8 %v4_401378, %v2_401378
  %v10_401378 = icmp ult i8 %v5_401378, %v2_401378
  store i1 %v10_401378, i1* %cf.global-to-local, align 1
  store i8 %v5_401378, i8* %v1_401378, align 1
  %v0_40137a = load i32, i32* %eax.global-to-local, align 4
  %v1_40137a = inttoptr i32 %v0_40137a to i8*
  %v2_40137a = load i8, i8* %v1_40137a, align 1
  %v4_40137a = trunc i32 %v0_40137a to i8
  %v5_40137a = add i8 %v4_40137a, %v2_40137a
  %v10_40137a = icmp ult i8 %v5_40137a, %v2_40137a
  store i1 %v10_40137a, i1* %cf.global-to-local, align 1
  store i8 %v5_40137a, i8* %v1_40137a, align 1
  %v0_40137c = load i32, i32* %eax.global-to-local, align 4
  %v1_40137c = inttoptr i32 %v0_40137c to i8*
  %v2_40137c = load i8, i8* %v1_40137c, align 1
  %v4_40137c = trunc i32 %v0_40137c to i8
  %v5_40137c = add i8 %v4_40137c, %v2_40137c
  store i8 %v5_40137c, i8* %v1_40137c, align 1
  %v0_40137e = load i32, i32* inttoptr (i32 4763949 to i32*), align 4
  %v1_40137e = xor i32 %v0_40137e, 13
  store i32 %v1_40137e, i32* inttoptr (i32 4763949 to i32*), align 4
  store i32 0, i32* %esi.global-to-local, align 4
  %v1_401387 = load i32, i32* inttoptr (i32 4763961 to i32*), align 4
  %v2_401387 = sub i32 0, %v1_401387
  %v7_401387 = icmp ne i32 %v1_401387, 0
  store i32 %v2_401387, i32* %esi.global-to-local, align 4
  %v0_40138d = load i32, i32* inttoptr (i32 4764128 to i32*), align 32
  %v1_40138d = load i32, i32* %eax.global-to-local, align 4
  %v3_40138d = zext i1 %v7_401387 to i32
  %v4_40138d = add i32 %v3_40138d, %v0_40138d
  %v5_40138d = add i32 %v4_40138d, %v1_40138d
  store i32 %v5_40138d, i32* inttoptr (i32 4764128 to i32*), align 32
  %v1_401398 = load i32, i32* %esi.global-to-local, align 4
  %v2_401398 = add i32 %v1_401398, 1
  %v7_401398 = icmp eq i32 %v2_401398, 0
  %v0_40139a = load i32, i32* %eax.global-to-local, align 4
  %v1_40139a = load i32, i32* %ebx.global-to-local, align 4
  %v3_40139a = zext i1 %v7_401398 to i32
  %v4_40139a = add i32 %v1_40139a, %v0_40139a
  %v5_40139a = add i32 %v4_40139a, %v3_40139a
  store i32 %v5_40139a, i32* %eax.global-to-local, align 4
  %v4_40139c = sub i32 %v2_401398, %v1_40139a
  %v20_40139c = and i32 %v4_40139c, 255
  %v22_40139c = and i32 %v2_401398, -256
  %v23_40139c = or i32 %v20_40139c, %v22_40139c
  store i32 %v23_40139c, i32* %edx.global-to-local, align 4
  %v0_40139e = load i32, i32* inttoptr (i32 4763920 to i32*), align 16
  %v2_40139e = add i32 %v0_40139e, %v1_401398
  %v7_40139e = icmp ult i32 %v2_40139e, %v0_40139e
  store i32 %v2_40139e, i32* inttoptr (i32 4763920 to i32*), align 16
  %v0_4013a4 = load i32, i32* inttoptr (i32 4763870 to i32*), align 4
  %v3_4013a4 = zext i1 %v7_40139e to i32
  %v4_4013a4 = add i32 %v23_40139c, %v0_4013a4
  %v5_4013a4 = add i32 %v4_4013a4, %v3_4013a4
  store i32 %v5_4013a4, i32* inttoptr (i32 4763870 to i32*), align 4
  %v0_4013aa = load i32, i32* inttoptr (i32 4763959 to i32*), align 4
  %v1_4013aa = load i32, i32* %esi.global-to-local, align 4
  %v2_4013aa = and i32 %v1_4013aa, %v0_4013aa
  store i32 %v2_4013aa, i32* inttoptr (i32 4763959 to i32*), align 4
  %v0_4013b0 = load i32, i32* %ebx.global-to-local, align 4
  %v1_4013b0 = load i32, i32* %edi.global-to-local, align 4
  %v2_4013b0 = sub i32 %v0_4013b0, %v1_4013b0
  %tmp285 = mul i32 %v2_4013b0, 2
  %v23_4013b2 = and i32 %tmp285, 65024
  %v24_4013b2 = and i32 %v2_4013b0, -65281
  %v25_4013b2 = or i32 %v23_4013b2, %v24_4013b2
  store i32 %v25_4013b2, i32* %ebx.global-to-local, align 4
  %v0_4013b4 = load i32, i32* %edx.global-to-local, align 4
  %v1_4013b4 = add i32 %v0_4013b4, -121
  %v5_4013b4 = icmp ugt i32 %v0_4013b4, 120
  store i1 %v5_4013b4, i1* %cf.global-to-local, align 1
  store i32 %v1_4013b4, i32* %edx.global-to-local, align 4
  %v1_4013b7 = trunc i32 %v2_4013b0 to i8
  %v2_4013b7 = load i8, i8* inttoptr (i32 4763746 to i8*), align 2
  %v4_4013b7 = zext i1 %v5_4013b4 to i8
  %v5_4013b7 = add i8 %v4_4013b7, %v1_4013b7
  %v6_4013b7 = add i8 %v5_4013b7, %v2_4013b7
  %v27_4013b7 = zext i8 %v6_4013b7 to i32
  %v29_4013b7 = and i32 %v25_4013b2, -512
  %v30_4013b7 = or i32 %v27_4013b7, %v29_4013b7
  store i32 %v30_4013b7, i32* %ebx.global-to-local, align 4
  %v0_4013bd = load i32, i32* inttoptr (i32 4763907 to i32*), align 4
  %v1_4013bd = load i32, i32* %esi.global-to-local, align 4
  %v2_4013bd = xor i32 %v1_4013bd, %v0_4013bd
  store i32 %v2_4013bd, i32* inttoptr (i32 4763907 to i32*), align 4
  %v1_4013c3 = add i32 %v30_4013b7, 9
  store i32 %v1_4013c3, i32* %ebx.global-to-local, align 4
  %v0_4013c6 = load i32, i32* inttoptr (i32 4763747 to i32*), align 4
  %v1_4013c6 = or i32 %v0_4013c6, 22
  store i32 %v1_4013c6, i32* inttoptr (i32 4763747 to i32*), align 4
  store i32 11, i32* %eax.global-to-local, align 4
  store i1 false, i1* %cf.global-to-local, align 1
  %v7_4013e4 = call i1 @IsBadStringPtrA(i8* getelementptr inbounds ([12 x i8], [12 x i8]* @global_var_48b6b4.5, i32 0, i32 0), i32 11)
  %v8_4013e4 = sext i1 %v7_4013e4 to i32
  store i32 %v8_4013e4, i32* %eax.global-to-local, align 4
  store i1 false, i1* %cf.global-to-local, align 1
  %v1_4013ea = icmp eq i1 %v7_4013e4, false
  %v1_4013ec = icmp eq i1 %v1_4013ea, false
  call void @__pseudo_cond_branch(i1 %v1_4013ec, i32 4220637)
  %v0_4013f2 = load i32, i32* inttoptr (i32 4764052 to i32*), align 4
  %v1_4013f2 = load i1, i1* %cf.global-to-local, align 1
  %v2_4013f2 = zext i1 %v1_4013f2 to i32
  %v3_4013f2 = add i32 %v0_4013f2, -176
  %v4_4013f2 = add i32 %v3_4013f2, %v2_4013f2
  %v11_4013f2 = icmp ult i32 %v0_4013f2, 176
  %v12_4013f2 = or i1 %v11_4013f2, %v1_4013f2
  store i1 %v12_4013f2, i1* %cf.global-to-local, align 1
  store i32 %v4_4013f2, i32* inttoptr (i32 4764052 to i32*), align 4
  %v0_4013fc = load i8, i8* inttoptr (i32 4763819 to i8*), align 1
  %v1_4013fc = add i8 %v0_4013fc, -124
  store i8 %v1_4013fc, i8* inttoptr (i32 4763819 to i8*), align 1
  %v0_401403 = load i32, i32* %ecx.global-to-local, align 4
  %v1_401403 = and i32 %v0_401403, -256
  %v2_401405 = load i32, i32* %ebx.global-to-local, align 4
  %v3_401405 = udiv i32 %v2_401405, 256
  %v5_401405 = add nuw nsw i32 %v3_401405, 1
  %v20_401405 = and i32 %v5_401405, 255
  %v23_401405 = or i32 %v20_401405, %v1_401403
  store i32 %v23_401405, i32* %ecx.global-to-local, align 4
  %v1_401407 = load i32, i32* inttoptr (i32 4763821 to i32*), align 4
  %v2_401407 = or i32 %v1_401407, %v8_4013e4
  %v1_40140d = load i32, i32* %esi.global-to-local, align 4
  %v2_40140d = sub i32 %v2_401407, %v1_40140d
  store i32 %v2_40140d, i32* %eax.global-to-local, align 4
  %v0_40140f = load i32, i32* inttoptr (i32 4763731 to i32*), align 4
  %v1_40140f = xor i32 %v0_40140f, 59
  store i32 %v1_40140f, i32* inttoptr (i32 4763731 to i32*), align 4
  %v1_401416 = load i32, i32* %ecx.global-to-local, align 4
  %v2_401416 = add i32 %v1_401416, %v1_40140d
  store i32 %v2_401416, i32* %esi.global-to-local, align 4
  store i32 -98, i32* %edx.global-to-local, align 4
  %v0_401420 = load i32, i32* %eax.global-to-local, align 4
  %v1_401420 = add i32 %v0_401420, -66
  store i32 %v1_401420, i32* %eax.global-to-local, align 4
  %v0_401423 = load i32, i32* %ebx.global-to-local, align 4
  %v1_401423 = load i32, i32* inttoptr (i32 4763692 to i32*), align 4
  %v2_401423 = or i32 %v1_401423, %v0_401423
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v2_401423, i32* %ebx.global-to-local, align 4
  call void @__pseudo_call(i32 ptrtoint (i32* @global_var_401431.6 to i32))
  %v0_401431 = load i32, i32* %eax.global-to-local, align 4
  %v1_401431 = load i32, i32* %ecx.global-to-local, align 4
  %v2_401431 = sub i32 %v0_401431, %v1_401431
  store i32 %v2_401431, i32* %eax.global-to-local, align 4
  store i32 146, i32* inttoptr (i32 4763681 to i32*), align 4
  %v0_40143d = load i32, i32* %edx.global-to-local, align 4
  %v1_40143d = add i32 %v0_40143d, 25
  %v5_40143d = icmp ugt i32 %v0_40143d, -26
  store i32 %v1_40143d, i32* %edx.global-to-local, align 4
  %v0_401440 = load i32, i32* inttoptr (i32 4763919 to i32*), align 4
  %v2_401440 = zext i1 %v5_40143d to i32
  %v3_401440 = add i32 %v0_401440, -134
  %v4_401440 = add i32 %v3_401440, %v2_401440
  %v12_401440 = icmp ult i32 %v0_401440, 134
  %v13_401440 = or i1 %v5_40143d, %v12_401440
  store i32 %v4_401440, i32* inttoptr (i32 4763919 to i32*), align 4
  %v0_40144a = load i32, i32* %edi.global-to-local, align 4
  %v1_40144a = load i32, i32* %eax.global-to-local, align 4
  %v3_40144a = zext i1 %v13_401440 to i32
  %v4_40144a = sub i32 %v0_40144a, %v1_40144a
  %v5_40144a = add i32 %v4_40144a, %v3_40144a
  %v1_40144c = load i32, i32* %edx.global-to-local, align 4
  %v2_40144c = add i32 %v5_40144a, %v1_40144c
  store i32 %v2_40144c, i32* %edi.global-to-local, align 4
  %v0_40144e = load i32, i32* %ecx.global-to-local, align 4
  %v1_40144e = add i32 %v0_40144e, 86
  %v5_40144e = icmp ugt i32 %v0_40144e, -87
  store i32 %v1_40144e, i32* %ecx.global-to-local, align 4
  %v0_401451 = load i32, i32* %esi.global-to-local, align 4
  %v1_401451 = load i32, i32* inttoptr (i32 4764152 to i32*), align 8
  %v3_401451 = zext i1 %v5_40144e to i32
  %v4_401451 = add i32 %v1_401451, %v0_401451
  %v5_401451 = add i32 %v4_401451, %v3_401451
  %v24_401451 = icmp ule i32 %v5_401451, %v0_401451
  %v25_401451 = icmp ult i32 %v4_401451, %v0_401451
  %v26_401451 = select i1 %v5_40144e, i1 %v24_401451, i1 %v25_401451
  store i1 %v26_401451, i1* %cf.global-to-local, align 1
  store i32 %v5_401451, i32* %esi.global-to-local, align 4
  %v1_401457 = udiv i32 %v1_40144a, 256
  %v2_401457 = trunc i32 %v1_401457 to i8
  %v3_401457 = load i8, i8* inttoptr (i32 4763810 to i8*), align 2
  %v5_401457 = zext i1 %v26_401451 to i8
  %v6_401457 = add i8 %v2_401457, %v3_401457
  %v7_401457 = add i8 %v6_401457, %v5_401457
  %v28_401457 = zext i8 %v7_401457 to i32
  %v30_401457 = mul nuw nsw i32 %v28_401457, 256
  %v31_401457 = and i32 %v1_40144a, -65281
  %v32_401457 = or i32 %v30_401457, %v31_401457
  store i32 %v32_401457, i32* %eax.global-to-local, align 4
  %v1_40145d = xor i32 %v1_40144e, -118
  store i32 %v1_40145d, i32* %ecx.global-to-local, align 4
  %v4_401460 = add i32 %v2_40144c, %v5_401451
  %v25_401460 = icmp ult i32 %v4_401460, %v5_401451
  store i1 %v25_401460, i1* %cf.global-to-local, align 1
  store i32 %v4_401460, i32* %esi.global-to-local, align 4
  %v1_401462 = trunc i32 %v1_40144a to i8
  %v2_401462 = load i8, i8* inttoptr (i32 4764023 to i8*), align 1
  %v4_401462 = zext i1 %v25_401460 to i8
  %v5_401462 = add i8 %v2_401462, %v1_401462
  %v6_401462 = add i8 %v5_401462, %v4_401462
  %v27_401462 = zext i8 %v6_401462 to i32
  %v29_401462 = and i32 %v32_401457, -256
  %v30_401462 = or i32 %v27_401462, %v29_401462
  store i32 %v30_401462, i32* %eax.global-to-local, align 4
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 0, i32* %esi.global-to-local, align 4
  store i32 125, i32* inttoptr (i32 4763844 to i32*), align 4
  %v1_401474 = udiv i32 %v30_401462, 256
  %v2_401474 = trunc i32 %v1_401474 to i8
  %v3_401474 = load i8, i8* inttoptr (i32 4764073 to i8*), align 1
  %v6_401474 = add i8 %v2_401474, %v3_401474
  %v26_401474 = icmp ult i8 %v6_401474, %v2_401474
  store i1 %v26_401474, i1* %cf.global-to-local, align 1
  %v28_401474 = zext i8 %v6_401474 to i32
  %v30_401474 = mul nuw nsw i32 %v28_401474, 256
  %v31_401474 = and i32 %v30_401462, -65281
  %v32_401474 = or i32 %v30_401474, %v31_401474
  store i32 %v32_401474, i32* %eax.global-to-local, align 4
  %v1_40147a = inttoptr i32 %v32_401474 to i8*
  %v2_40147a = load i8, i8* %v1_40147a, align 1
  %v5_40147a = add i8 %v2_40147a, %v6_401462
  %v10_40147a = icmp ult i8 %v5_40147a, %v2_40147a
  store i1 %v10_40147a, i1* %cf.global-to-local, align 1
  store i8 %v5_40147a, i8* %v1_40147a, align 1
  %v0_40147c = load i32, i32* %eax.global-to-local, align 4
  %v1_40147c = inttoptr i32 %v0_40147c to i8*
  %v2_40147c = load i8, i8* %v1_40147c, align 1
  %v4_40147c = trunc i32 %v0_40147c to i8
  %v5_40147c = add i8 %v4_40147c, %v2_40147c
  %v10_40147c = icmp ult i8 %v5_40147c, %v2_40147c
  store i1 %v10_40147c, i1* %cf.global-to-local, align 1
  store i8 %v5_40147c, i8* %v1_40147c, align 1
  %v0_40147e = load i32, i32* %eax.global-to-local, align 4
  %v1_40147e = inttoptr i32 %v0_40147e to i8*
  %v2_40147e = load i8, i8* %v1_40147e, align 1
  %v4_40147e = trunc i32 %v0_40147e to i8
  %v5_40147e = add i8 %v4_40147e, %v2_40147e
  %v10_40147e = icmp ult i8 %v5_40147e, %v2_40147e
  store i1 %v10_40147e, i1* %cf.global-to-local, align 1
  store i8 %v5_40147e, i8* %v1_40147e, align 1
  %v0_401480 = load i32, i32* %eax.global-to-local, align 4
  %v1_401480 = inttoptr i32 %v0_401480 to i8*
  %v2_401480 = load i8, i8* %v1_401480, align 1
  %v4_401480 = trunc i32 %v0_401480 to i8
  %v5_401480 = add i8 %v4_401480, %v2_401480
  %v10_401480 = icmp ult i8 %v5_401480, %v2_401480
  store i1 %v10_401480, i1* %cf.global-to-local, align 1
  store i8 %v5_401480, i8* %v1_401480, align 1
  %v0_401482 = load i32, i32* %eax.global-to-local, align 4
  %v1_401482 = inttoptr i32 %v0_401482 to i8*
  %v2_401482 = load i8, i8* %v1_401482, align 1
  %v4_401482 = trunc i32 %v0_401482 to i8
  %v5_401482 = add i8 %v4_401482, %v2_401482
  %v10_401482 = icmp ult i8 %v5_401482, %v2_401482
  store i1 %v10_401482, i1* %cf.global-to-local, align 1
  store i8 %v5_401482, i8* %v1_401482, align 1
  %v0_401484 = load i32, i32* %eax.global-to-local, align 4
  %v1_401484 = inttoptr i32 %v0_401484 to i8*
  %v2_401484 = load i8, i8* %v1_401484, align 1
  %v4_401484 = trunc i32 %v0_401484 to i8
  %v5_401484 = add i8 %v4_401484, %v2_401484
  %v10_401484 = icmp ult i8 %v5_401484, %v2_401484
  store i1 %v10_401484, i1* %cf.global-to-local, align 1
  store i8 %v5_401484, i8* %v1_401484, align 1
  %v0_401486 = load i32, i32* %edx.global-to-local, align 4
  %v1_401486 = add i32 %v0_401486, 1
  %v2_401486 = inttoptr i32 %v1_401486 to i8*
  %v3_401486 = load i8, i8* %v2_401486, align 1
  %v4_401486 = load i32, i32* %ebx.global-to-local, align 4
  %v5_401486 = udiv i32 %v4_401486, 256
  %v6_401486 = trunc i32 %v5_401486 to i8
  %v7_401486 = add i8 %v6_401486, %v3_401486
  store i8 %v7_401486, i8* %v2_401486, align 1
  %v0_40148c = load i32, i32* %edx.global-to-local, align 4
  %v1_40148c = add i32 %v0_40148c, -12
  %v5_40148c = icmp ugt i32 %v0_40148c, 11
  store i1 %v5_40148c, i1* %cf.global-to-local, align 1
  store i32 %v1_40148c, i32* %edx.global-to-local, align 4
  %v1_40148f = udiv i32 %v1_40148c, 256
  %v2_40148f = trunc i32 %v1_40148f to i8
  %v3_40148f = load i8, i8* inttoptr (i32 4764074 to i8*), align 2
  %v5_40148f = zext i1 %v5_40148c to i8
  %v6_40148f = add i8 %v2_40148f, %v5_40148f
  %v7_40148f = add i8 %v6_40148f, %v3_40148f
  %v28_40148f = zext i8 %v7_40148f to i32
  %v30_40148f = mul nuw nsw i32 %v28_40148f, 256
  %v31_40148f = and i32 %v1_40148c, -65281
  %v32_40148f = or i32 %v30_40148f, %v31_40148f
  store i32 %v32_40148f, i32* %edx.global-to-local, align 4
  %v0_401495 = load i32, i32* %esi.global-to-local, align 4
  %v1_401495 = load i32, i32* inttoptr (i32 4764126 to i32*), align 4
  %v2_401495 = or i32 %v1_401495, %v0_401495
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v2_401495, i32* %esi.global-to-local, align 4
  %v0_40149b = load i8, i8* inttoptr (i32 4764157 to i8*), align 1
  %v1_40149b = load i32, i32* %eax.global-to-local, align 4
  %v2_40149b = trunc i32 %v1_40149b to i8
  %v3_40149b = and i8 %v2_40149b, %v0_40149b
  store i8 %v3_40149b, i8* inttoptr (i32 4764157 to i8*), align 1
  %v1_4014a1 = load i32, i32* %edx.global-to-local, align 4
  %v2_4014a1 = xor i32 %v1_4014a1, %v1_40149b
  store i32 %v2_4014a1, i32* %eax.global-to-local, align 4
  %v0_4014a3 = load i32, i32* inttoptr (i32 4764053 to i32*), align 4
  %v1_4014a3 = load i32, i32* %ebx.global-to-local, align 4
  %v2_4014a3 = add i32 %v1_4014a3, %v0_4014a3
  %v7_4014a3 = icmp ult i32 %v2_4014a3, %v0_4014a3
  store i32 %v2_4014a3, i32* inttoptr (i32 4764053 to i32*), align 4
  %v1_4014a9 = udiv i32 %v1_4014a3, 256
  %v3_4014a9 = load i32, i32* %eax.global-to-local, align 4
  %v4_4014a9 = udiv i32 %v3_4014a9, 256
  %v7_4014a9 = zext i1 %v7_4014a3 to i32
  %v8_4014a9 = add nuw nsw i32 %v7_4014a9, %v1_4014a9
  %v9_4014a9 = sub nsw i32 %v8_4014a9, %v4_4014a9
  %v39_4014a9 = mul i32 %v9_4014a9, 256
  %v41_4014a9 = and i32 %v39_4014a9, 65280
  %v42_4014a9 = and i32 %v1_4014a3, -65281
  %v43_4014a9 = or i32 %v41_4014a9, %v42_4014a9
  store i32 %v43_4014a9, i32* %ebx.global-to-local, align 4
  %v0_4014ab = load i32, i32* inttoptr (i32 4763821 to i32*), align 4
  %v1_4014ab = and i32 %v0_4014ab, 108
  store i32 %v1_4014ab, i32* inttoptr (i32 4763821 to i32*), align 4
  %v0_4014b2 = load i32, i32* inttoptr (i32 4764117 to i32*), align 4
  %v3_4014b2 = add i32 %v0_4014b2, -160
  %v11_4014b2 = icmp ult i32 %v0_4014b2, 160
  store i32 %v3_4014b2, i32* inttoptr (i32 4764117 to i32*), align 4
  %v2_4014bc = zext i1 %v11_4014b2 to i32
  %v0_4014be = load i32, i32* %eax.global-to-local, align 4
  %v2_4014be = add i32 %v0_4014be, %v2_4014bc
  store i32 %v2_4014be, i32* %eax.global-to-local, align 4
  store i32 %v2_4014bc, i32* %edx.global-to-local, align 4
  %v0_4014c3 = load i32, i32* inttoptr (i32 4763923 to i32*), align 4
  %v1_4014c3 = load i32, i32* %ebx.global-to-local, align 4
  %v2_4014c3 = and i32 %v1_4014c3, %v0_4014c3
  store i32 %v2_4014c3, i32* inttoptr (i32 4763923 to i32*), align 4
  %v0_4014c9 = load i32, i32* %edi.global-to-local, align 4
  %v1_4014c9 = load i32, i32* inttoptr (i32 4763666 to i32*), align 4
  %v4_4014c9 = add i32 %v1_4014c9, %v0_4014c9
  %v25_4014c9 = icmp ult i32 %v4_4014c9, %v0_4014c9
  store i32 %v4_4014c9, i32* %edi.global-to-local, align 4
  %v0_4014cf = load i32, i32* inttoptr (i32 4763968 to i32*), align 64
  %v3_4014cf = select i1 %v25_4014c9, i32 115, i32 114
  %v4_4014cf = add i32 %v3_4014cf, %v0_4014cf
  store i32 %v4_4014cf, i32* inttoptr (i32 4763968 to i32*), align 64
  %v0_4014d6 = load i32, i32* inttoptr (i32 4764014 to i32*), align 4
  %v1_4014d6 = load i32, i32* %esi.global-to-local, align 4
  %v2_4014d6 = add i32 %v1_4014d6, %v0_4014d6
  store i32 %v2_4014d6, i32* inttoptr (i32 4764014 to i32*), align 4
  %v0_4014dc = load i32, i32* inttoptr (i32 4764123 to i32*), align 4
  %v1_4014dc = or i32 %v0_4014dc, 228
  store i32 %v1_4014dc, i32* inttoptr (i32 4764123 to i32*), align 4
  store i1 false, i1* %cf.global-to-local, align 1
  %v8_4014f8 = call i1 @SetEnvironmentVariableW(i16* bitcast ([13 x i8]* @global_var_48b685.2 to i16*), i16* bitcast ([17 x i8]* @global_var_48b692.1 to i16*))
  %v9_4014f8 = sext i1 %v8_4014f8 to i32
  store i32 %v9_4014f8, i32* %eax.global-to-local, align 4
  %v3_4014fe = load i8, i8* inttoptr (i32 4764142 to i8*), align 2
  store i1 false, i1* %cf.global-to-local, align 1
  %tmp286 = zext i8 %v3_4014fe to i32
  %v14_4014fe = select i1 %v8_4014f8, i32 -1, i32 %tmp286
  store i32 %v14_4014fe, i32* %eax.global-to-local, align 4
  %v0_401504 = load i8, i8* inttoptr (i32 4764115 to i8*), align 1
  %v1_401504 = add i8 %v0_401504, -111
  store i8 %v1_401504, i8* inttoptr (i32 4764115 to i8*), align 1
  %v1_401510 = load i32, i32* %ebx.global-to-local, align 4
  %v2_401510 = add i32 %v1_401510, 1
  %v7_401510 = icmp eq i32 %v2_401510, 0
  store i32 %v2_401510, i32* %ecx.global-to-local, align 4
  %v1_401512 = load i32, i32* inttoptr (i32 4764029 to i32*), align 4
  %v3_401512 = zext i1 %v7_401510 to i32
  %v4_401512 = add i32 %v1_401512, %v1_401510
  %v5_401512 = add i32 %v4_401512, %v3_401512
  store i32 %v5_401512, i32* %ebx.global-to-local, align 4
  %v0_401518 = load i32, i32* inttoptr (i32 4763767 to i32*), align 4
  %v2_401518 = sub i32 %v0_401518, %v2_401510
  store i32 %v2_401518, i32* inttoptr (i32 4763767 to i32*), align 4
  %v0_40151e = load i32, i32* %esi.global-to-local, align 4
  %v2_40151e = xor i32 %v5_401512, %v0_40151e
  store i32 %v2_40151e, i32* %esi.global-to-local, align 4
  %v0_401520 = load i32, i32* inttoptr (i32 4763827 to i32*), align 4
  %v1_401520 = xor i32 %v0_401520, 141
  store i32 %v1_401520, i32* inttoptr (i32 4763827 to i32*), align 4
  %v0_40152a = load i32, i32* inttoptr (i32 4764007 to i32*), align 4
  %v3_40152a = add i32 %v0_40152a, 2
  store i32 %v3_40152a, i32* inttoptr (i32 4764007 to i32*), align 4
  %v0_401531 = load i32, i32* inttoptr (i32 4764059 to i32*), align 4
  %v1_401531 = load i32, i32* %edi.global-to-local, align 4
  %v2_401531 = and i32 %v1_401531, %v0_401531
  store i32 %v2_401531, i32* inttoptr (i32 4764059 to i32*), align 4
  %v1_401537 = and i32 %v1_401531, 103
  store i32 %v1_401537, i32* %edi.global-to-local, align 4
  %v0_40153a = load i32, i32* %esi.global-to-local, align 4
  %v1_40153a = or i32 %v0_40153a, 101
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v1_40153a, i32* %esi.global-to-local, align 4
  call void @__pseudo_call(i32 4199749)
  %v0_401545 = load i32, i32* inttoptr (i32 4763656 to i32*), align 8
  %v1_401545 = and i32 %v0_401545, 105
  store i32 %v1_401545, i32* inttoptr (i32 4763656 to i32*), align 8
  %v0_40154c = load i32, i32* %eax.global-to-local, align 4
  %v1_40154c = add i32 %v0_40154c, 32
  %v9_40154c = trunc i32 %v1_40154c to i8
  %v13_40154c = inttoptr i32 %v1_40154c to i8*
  store i32 %v1_40154c, i32* %eax.global-to-local, align 4
  %v0_40154f = load i32, i32* %esi.global-to-local, align 4
  %v1_40154f = add i32 %v0_40154f, 28
  %v5_40154f = icmp ult i32 %v0_40154f, -28
  store i32 %v1_40154f, i32* %esi.global-to-local, align 4
  %v0_401552 = load i32, i32* %ecx.global-to-local, align 4
  %v2_401552 = zext i1 %v5_40154f to i32
  %v3_401552 = add i32 %v0_401552, -65
  %v4_401552 = add i32 %v3_401552, %v2_401552
  store i32 %v4_401552, i32* %ecx.global-to-local, align 4
  %v2_40155a = add i32 %v4_401552, 1
  %v7_40155a = icmp eq i32 %v2_40155a, 0
  store i32 %v2_40155a, i32* %edx.global-to-local, align 4
  %v0_40155c = load i32, i32* %edi.global-to-local, align 4
  %v1_40155c = load i32, i32* inttoptr (i32 4763668 to i32*), align 4
  %v3_40155c = zext i1 %v7_40155a to i32
  %v4_40155c = add i32 %v1_40155c, %v0_40155c
  %v5_40155c = add i32 %v3_40155c, %v4_40155c
  %v24_40155c = icmp ule i32 %v5_40155c, %v0_40155c
  %v25_40155c = icmp ult i32 %v4_40155c, %v0_40155c
  %v26_40155c = select i1 %v7_40155a, i1 %v24_40155c, i1 %v25_40155c
  store i32 %v5_40155c, i32* %edi.global-to-local, align 4
  %v0_401562 = load i32, i32* %ebx.global-to-local, align 4
  %v3_401562 = zext i1 %v26_40155c to i32
  %v4_401562 = add i32 %v0_401562, %v5_40155c
  %v5_401562 = add i32 %v4_401562, %v3_401562
  store i32 %v5_401562, i32* %ebx.global-to-local, align 4
  %v0_401564 = load i32, i32* inttoptr (i32 4763742 to i32*), align 4
  %v3_401564 = xor i32 %v0_401564, %v1_40154c
  store i32 %v3_401564, i32* inttoptr (i32 4763742 to i32*), align 4
  %v0_40156a = load i32, i32* %ecx.global-to-local, align 4
  %v1_40156a = or i32 %v0_40156a, -42
  store i32 %v1_40156a, i32* %ecx.global-to-local, align 4
  %v0_40156d = load i32, i32* inttoptr (i32 4763834 to i32*), align 4
  %v3_40156d = add i32 %v0_40156d, 147
  %v22_40156d = icmp ugt i32 %v0_40156d, -148
  store i1 %v22_40156d, i1* %cf.global-to-local, align 1
  store i32 %v3_40156d, i32* inttoptr (i32 4763834 to i32*), align 4
  %v0_401577 = load i32, i32* %edx.global-to-local, align 4
  %v1_401577 = trunc i32 %v0_401577 to i8
  %v2_401577 = load i8, i8* inttoptr (i32 4763753 to i8*), align 1
  %v4_401577 = zext i1 %v22_40156d to i8
  %v5_401577 = add i8 %v1_401577, %v2_401577
  %v6_401577 = add i8 %v5_401577, %v4_401577
  %v24_401577 = icmp ule i8 %v6_401577, %v1_401577
  %v25_401577 = icmp ult i8 %v5_401577, %v1_401577
  %v26_401577 = select i1 %v22_40156d, i1 %v24_401577, i1 %v25_401577
  store i1 %v26_401577, i1* %cf.global-to-local, align 1
  %v27_401577 = zext i8 %v6_401577 to i32
  %v29_401577 = and i32 %v0_401577, -256
  %v30_401577 = or i32 %v27_401577, %v29_401577
  store i32 %v30_401577, i32* %edx.global-to-local, align 4
  %v3_40157d = load i8, i8* %v13_40154c, align 1
  %factor = mul i8 %v9_40154c, 2
  %v7_40157f = add i8 %v3_40157d, %factor
  %v7_401581 = add i8 %v7_40157f, %v9_40154c
  %v12_401581 = icmp ult i8 %v7_401581, %v7_40157f
  store i1 %v12_401581, i1* %cf.global-to-local, align 1
  store i8 %v7_401581, i8* %v13_40154c, align 1
  %v0_401583 = load i32, i32* %ecx.global-to-local, align 4
  %v1_401583 = inttoptr i32 %v0_401583 to i8*
  %v2_401583 = load i8, i8* %v1_401583, align 1
  %v6_401583 = add i8 %v2_401583, %v9_40154c
  %v11_401583 = icmp ult i8 %v6_401583, %v2_401583
  store i1 %v11_401583, i1* %cf.global-to-local, align 1
  store i8 %v6_401583, i8* %v1_401583, align 1
  ret i32 %v1_40154c

; uselistorder directives
  uselistorder i8 %v2_401583, { 1, 0 }
  uselistorder i8 %v7_40157f, { 1, 0 }
  uselistorder i8 %v6_401577, { 1, 0 }
  uselistorder i8 %v5_401577, { 1, 0 }
  uselistorder i1 %v22_40156d, { 1, 2, 0 }
  uselistorder i32 %v5_40155c, { 0, 2, 1 }
  uselistorder i32 %v4_40155c, { 1, 0 }
  uselistorder i32 %v0_40155c, { 1, 2, 0 }
  uselistorder i1 %v7_40155a, { 1, 0 }
  uselistorder i32 %v2_40155a, { 1, 0 }
  uselistorder i32 %v0_40154f, { 1, 0 }
  uselistorder i32 %v1_40154c, { 1, 0, 4, 2, 3 }
  uselistorder i32 %v2_401510, { 0, 2, 1 }
  uselistorder i32 %v0_4014c9, { 1, 0 }
  uselistorder i32 %v0_4014b2, { 1, 0 }
  uselistorder i32 %v0_4014a3, { 1, 0 }
  uselistorder i32 %v1_40148c, { 1, 0, 2 }
  uselistorder i8 %v2_401484, { 1, 0 }
  uselistorder i8 %v2_401482, { 1, 0 }
  uselistorder i8 %v2_401480, { 1, 0 }
  uselistorder i8 %v2_40147e, { 1, 0 }
  uselistorder i8 %v2_40147c, { 1, 0 }
  uselistorder i8 %v2_40147a, { 1, 0 }
  uselistorder i8 %v2_401474, { 1, 0 }
  uselistorder i1 %v25_401460, { 1, 0 }
  uselistorder i32 %v5_401451, { 1, 0, 3, 2 }
  uselistorder i32 %v4_401451, { 1, 0 }
  uselistorder i32 %v0_401451, { 1, 2, 0 }
  uselistorder i1 %v5_40144e, { 1, 0 }
  uselistorder i32 %v1_40144a, { 2, 1, 0, 3 }
  uselistorder i32 %v0_401440, { 1, 0 }
  uselistorder i32 %v0_4013f2, { 1, 0 }
  uselistorder i32 %v2_4013b0, { 1, 2, 0 }
  uselistorder i32 %v0_40139e, { 1, 0 }
  uselistorder i32 %v1_40139a, { 1, 0 }
  uselistorder i32 %v2_401398, { 1, 0, 2 }
  uselistorder i8 %v2_40137a, { 1, 0 }
  uselistorder i8 %v2_401378, { 1, 0 }
  uselistorder i8 %v2_401376, { 1, 0 }
  uselistorder i8 %v2_401374, { 1, 0 }
  uselistorder i32 %v1_401355, { 0, 1, 4, 2, 3 }
  uselistorder i32 %v1_401345, { 1, 0 }
  uselistorder i32 %v0_401345, { 1, 0 }
  uselistorder i32 %v5_401326, { 1, 0 }
  uselistorder i32 %v4_401326, { 1, 0 }
  uselistorder i1 %v5_401323, { 1, 0 }
  uselistorder i32 %v1_401323, { 2, 1, 0, 3 }
  uselistorder i8 %v2_401306, { 1, 0 }
  uselistorder i32 %v0_401306, { 1, 0 }
  uselistorder i32 %v0_4012d8, { 1, 0 }
  uselistorder i32 %v0_4012b3, { 1, 0 }
  uselistorder i32 %sext, { 1, 0 }
  uselistorder i32 %v11_401293, { 1, 0, 2 }
  uselistorder i8 %v9_40126b, { 1, 0 }
  uselistorder i8 %v8_40126b, { 1, 0 }
  uselistorder i32 %v3_40126b, { 1, 0 }
  uselistorder i8 %v2_40126b, { 1, 2, 0 }
  uselistorder i32 %v0_40126b, { 1, 0 }
  uselistorder i1 %v11_401264, { 1, 0 }
  uselistorder i32 %v0_401264, { 1, 0 }
  uselistorder i32 %v4_40123f, { 1, 0 }
  uselistorder i32 %v3_40123f, { 1, 0 }
  uselistorder i32 %v5_40123d, { 1, 0 }
  uselistorder i32 %v4_40123d, { 1, 0 }
  uselistorder i32 %v0_40123d, { 1, 2, 0 }
  uselistorder i1 %v26_40123b, { 1, 0 }
  uselistorder i32 %v5_40123b, { 1, 2, 0, 4, 3 }
  uselistorder i32 %v0_40123b, { 1, 2, 0 }
  uselistorder i8 %v2_401239, { 1, 0 }
  uselistorder i32 %v1_40122c, { 1, 0, 2 }
  uselistorder i32 %v2_401214, { 1, 0 }
  uselistorder i32 %v4_4011ed, { 1, 0 }
  uselistorder i32 %v3_4011ed, { 1, 0 }
  uselistorder i32 %v1_4011ed, { 0, 2, 1, 3 }
  uselistorder i1 %v7_4011e7, { 1, 0 }
  uselistorder i32 %v0_4011ce, { 1, 0 }
  uselistorder i8 %v5_40119a, { 1, 0 }
  uselistorder i32 %v4_401186, { 1, 0 }
  uselistorder i32 %v0_401186, { 1, 2, 0 }
  uselistorder i1 %v26_401180, { 1, 0 }
  uselistorder i32 %v5_401180, { 1, 0 }
  uselistorder i32 %v4_401180, { 1, 0 }
  uselistorder i32 %v5_401166, { 1, 0 }
  uselistorder i32 %v4_401166, { 1, 0 }
  uselistorder i32 %v0_401166, { 1, 2, 0 }
  uselistorder i32 %v9_401160, { 1, 0, 2 }
  uselistorder i32 %v0_401139, { 1, 0 }
  uselistorder i32 %v7_4010f4, { 1, 0 }
  uselistorder i32 %v6_4010f4, { 1, 0 }
  uselistorder i32 %v2_4010f4, { 1, 2, 0 }
  uselistorder i1 %v28_4010f2, { 1, 0 }
  uselistorder i32 %v7_4010f2, { 1, 0 }
  uselistorder i32 %v6_4010f2, { 1, 0 }
  uselistorder i32 %v2_4010f2, { 1, 2, 0 }
  uselistorder i8 %v2_4010f0, { 1, 0 }
  uselistorder i32 %v7_4010ee, { 1, 0 }
  uselistorder i32 %v6_4010ee, { 1, 0 }
  uselistorder i32 %v2_4010ee, { 1, 2, 0 }
  uselistorder i1 %v28_4010ec, { 1, 0 }
  uselistorder i32 %v7_4010ec, { 1, 0 }
  uselistorder i32 %v6_4010ec, { 1, 0 }
  uselistorder i32 %v2_4010ec, { 1, 2, 0 }
  uselistorder i8 %v2_4010ea, { 1, 0 }
  uselistorder i32 %v7_4010e8, { 1, 0 }
  uselistorder i32 %v6_4010e8, { 1, 0 }
  uselistorder i32 %v2_4010e8, { 1, 2, 0 }
  uselistorder i1 %v28_4010e6, { 1, 0 }
  uselistorder i32 %v7_4010e6, { 1, 0 }
  uselistorder i32 %v6_4010e6, { 1, 0 }
  uselistorder i32 %v2_4010e6, { 1, 2, 0 }
  uselistorder i8 %v2_4010e4, { 1, 0 }
  uselistorder i32 %v7_4010e2, { 1, 0 }
  uselistorder i32 %v6_4010e2, { 1, 0 }
  uselistorder i32 %v2_4010e2, { 1, 2, 0 }
  uselistorder i1 %v28_4010e0, { 1, 0 }
  uselistorder i32 %v7_4010e0, { 1, 0 }
  uselistorder i32 %v6_4010e0, { 1, 0 }
  uselistorder i32 %v2_4010e0, { 1, 2, 0 }
  uselistorder i8 %v2_4010de, { 1, 0 }
  uselistorder i32 %v7_4010dc, { 1, 0 }
  uselistorder i32 %v6_4010dc, { 1, 0 }
  uselistorder i32 %v2_4010dc, { 1, 2, 0 }
  uselistorder i1 %v28_4010da, { 1, 0 }
  uselistorder i32 %v7_4010da, { 1, 0 }
  uselistorder i32 %v6_4010da, { 1, 0 }
  uselistorder i32 %v2_4010da, { 1, 2, 0 }
  uselistorder i8 %v2_4010d8, { 1, 0 }
  uselistorder i32 %v7_4010d6, { 1, 0 }
  uselistorder i32 %v6_4010d6, { 1, 0 }
  uselistorder i32 %v2_4010d6, { 1, 2, 0 }
  uselistorder i1 %v28_4010d4, { 1, 0 }
  uselistorder i32 %v7_4010d4, { 1, 0 }
  uselistorder i32 %v6_4010d4, { 1, 0 }
  uselistorder i32 %v2_4010d4, { 1, 2, 0 }
  uselistorder i8 %v2_4010d2, { 1, 0 }
  uselistorder i32 %v7_4010d0, { 1, 0 }
  uselistorder i32 %v6_4010d0, { 1, 0 }
  uselistorder i32 %v2_4010d0, { 1, 2, 0 }
  uselistorder i1 %v28_4010ce, { 1, 0 }
  uselistorder i32 %v7_4010ce, { 1, 0 }
  uselistorder i32 %v6_4010ce, { 1, 0 }
  uselistorder i32 %v2_4010ce, { 1, 2, 0 }
  uselistorder i8 %v2_4010cc, { 1, 0 }
  uselistorder i32 %v7_4010ca, { 1, 0 }
  uselistorder i32 %v6_4010ca, { 1, 0 }
  uselistorder i32 %v2_4010ca, { 1, 2, 0 }
  uselistorder i1 %v28_4010c8, { 1, 0 }
  uselistorder i32 %v7_4010c8, { 1, 0 }
  uselistorder i32 %v6_4010c8, { 1, 0 }
  uselistorder i32 %v2_4010c8, { 1, 2, 0 }
  uselistorder i8 %v2_4010c6, { 1, 0 }
  uselistorder i32 %v7_4010c4, { 1, 0 }
  uselistorder i32 %v6_4010c4, { 1, 0 }
  uselistorder i32 %v2_4010c4, { 1, 2, 0 }
  uselistorder i1 %v28_4010c2, { 1, 0 }
  uselistorder i32 %v7_4010c2, { 1, 0 }
  uselistorder i32 %v6_4010c2, { 1, 0 }
  uselistorder i32 %v2_4010c2, { 1, 2, 0 }
  uselistorder i8 %v2_4010c0, { 1, 0 }
  uselistorder i32 %v7_4010be, { 1, 0 }
  uselistorder i32 %v6_4010be, { 1, 0 }
  uselistorder i32 %v2_4010be, { 1, 2, 0 }
  uselistorder i1 %v28_4010bc, { 1, 0 }
  uselistorder i32 %v7_4010bc, { 1, 0 }
  uselistorder i32 %v6_4010bc, { 1, 0 }
  uselistorder i32 %v2_4010bc, { 1, 2, 0 }
  uselistorder i8 %v2_4010ba, { 1, 0 }
  uselistorder i32 %v7_4010b8, { 1, 0 }
  uselistorder i32 %v6_4010b8, { 1, 0 }
  uselistorder i32 %v2_4010b8, { 1, 2, 0 }
  uselistorder i1 %v28_4010b6, { 1, 0 }
  uselistorder i32 %v7_4010b6, { 1, 0 }
  uselistorder i32 %v6_4010b6, { 1, 0 }
  uselistorder i32 %v2_4010b6, { 1, 2, 0 }
  uselistorder i8 %v2_4010b4, { 1, 0 }
  uselistorder i32 %v7_4010b2, { 1, 0 }
  uselistorder i32 %v6_4010b2, { 1, 0 }
  uselistorder i32 %v2_4010b2, { 1, 2, 0 }
  uselistorder i1 %v28_4010b0, { 1, 0 }
  uselistorder i32 %v7_4010b0, { 1, 0 }
  uselistorder i32 %v6_4010b0, { 1, 0 }
  uselistorder i32 %v2_4010b0, { 1, 2, 0 }
  uselistorder i8 %v2_4010ae, { 1, 0 }
  uselistorder i32 %v7_4010ac, { 1, 0 }
  uselistorder i32 %v6_4010ac, { 1, 0 }
  uselistorder i32 %v2_4010ac, { 1, 2, 0 }
  uselistorder i1 %v28_4010aa, { 1, 0 }
  uselistorder i32 %v7_4010aa, { 1, 0 }
  uselistorder i32 %v6_4010aa, { 1, 0 }
  uselistorder i32 %v2_4010aa, { 1, 2, 0 }
  uselistorder i8 %v2_4010a8, { 1, 0 }
  uselistorder i32 %v7_4010a6, { 1, 0 }
  uselistorder i32 %v6_4010a6, { 1, 0 }
  uselistorder i32 %v2_4010a6, { 1, 2, 0 }
  uselistorder i1 %v28_4010a4, { 1, 0 }
  uselistorder i32 %v7_4010a4, { 1, 0 }
  uselistorder i32 %v6_4010a4, { 1, 0 }
  uselistorder i32 %v2_4010a4, { 1, 2, 0 }
  uselistorder i8 %v2_4010a2, { 1, 0 }
  uselistorder i32 %v7_4010a0, { 1, 0 }
  uselistorder i32 %v6_4010a0, { 1, 0 }
  uselistorder i32 %v2_4010a0, { 1, 2, 0 }
  uselistorder i1 %v28_40109e, { 1, 0 }
  uselistorder i32 %v7_40109e, { 1, 0 }
  uselistorder i32 %v6_40109e, { 1, 0 }
  uselistorder i32 %v2_40109e, { 1, 2, 0 }
  uselistorder i8 %v2_40109c, { 1, 0 }
  uselistorder i32 %v7_40109a, { 1, 0 }
  uselistorder i32 %v6_40109a, { 1, 0 }
  uselistorder i32 %v2_40109a, { 1, 2, 0 }
  uselistorder i1 %v28_401098, { 1, 0 }
  uselistorder i32 %v7_401098, { 1, 0 }
  uselistorder i32 %v6_401098, { 1, 0 }
  uselistorder i32 %v2_401098, { 1, 2, 0 }
  uselistorder i8 %v2_401096, { 1, 0 }
  uselistorder i32 %v7_401094, { 1, 0 }
  uselistorder i32 %v6_401094, { 1, 0 }
  uselistorder i32 %v2_401094, { 1, 2, 0 }
  uselistorder i1 %v28_401092, { 1, 0 }
  uselistorder i32 %v7_401092, { 1, 0 }
  uselistorder i32 %v6_401092, { 1, 0 }
  uselistorder i32 %v2_401092, { 1, 2, 0 }
  uselistorder i8 %v2_401090, { 1, 0 }
  uselistorder i32 %v7_40108e, { 1, 0 }
  uselistorder i32 %v6_40108e, { 1, 0 }
  uselistorder i32 %v2_40108e, { 1, 2, 0 }
  uselistorder i1 %v28_40108c, { 1, 0 }
  uselistorder i32 %v7_40108c, { 1, 0 }
  uselistorder i32 %v6_40108c, { 1, 0 }
  uselistorder i32 %v2_40108c, { 1, 2, 0 }
  uselistorder i8 %v2_40108a, { 1, 0 }
  uselistorder i32 %v7_401088, { 1, 0 }
  uselistorder i32 %v6_401088, { 1, 0 }
  uselistorder i32 %v2_401088, { 1, 2, 0 }
  uselistorder i1 %v28_401086, { 1, 0 }
  uselistorder i32 %v7_401086, { 1, 0 }
  uselistorder i32 %v6_401086, { 1, 0 }
  uselistorder i32 %v2_401086, { 1, 2, 0 }
  uselistorder i8 %v2_401084, { 1, 0 }
  uselistorder i32 %v7_401082, { 1, 0 }
  uselistorder i32 %v6_401082, { 1, 0 }
  uselistorder i32 %v2_401082, { 1, 2, 0 }
  uselistorder i1 %v28_401080, { 1, 0 }
  uselistorder i32 %v7_401080, { 1, 0 }
  uselistorder i32 %v6_401080, { 1, 0 }
  uselistorder i32 %v2_401080, { 1, 2, 0 }
  uselistorder i8 %v2_40107e, { 1, 0 }
  uselistorder i32 %v7_40107c, { 1, 0 }
  uselistorder i32 %v6_40107c, { 1, 0 }
  uselistorder i32 %v2_40107c, { 1, 2, 0 }
  uselistorder i1 %v28_40107a, { 1, 0 }
  uselistorder i32 %v7_40107a, { 1, 0 }
  uselistorder i32 %v6_40107a, { 1, 0 }
  uselistorder i32 %v2_40107a, { 1, 2, 0 }
  uselistorder i8 %v2_401078, { 1, 0 }
  uselistorder i32 %v7_401076, { 1, 0 }
  uselistorder i32 %v6_401076, { 1, 0 }
  uselistorder i32 %v2_401076, { 1, 2, 0 }
  uselistorder i1 %v28_401074, { 1, 0 }
  uselistorder i32 %v7_401074, { 1, 0 }
  uselistorder i32 %v6_401074, { 1, 0 }
  uselistorder i32 %v2_401074, { 1, 2, 0 }
  uselistorder i8 %v2_401072, { 1, 0 }
  uselistorder i32 %v7_401070, { 1, 0 }
  uselistorder i32 %v6_401070, { 1, 0 }
  uselistorder i32 %v2_401070, { 1, 2, 0 }
  uselistorder i1 %v28_40106e, { 1, 0 }
  uselistorder i32 %v7_40106e, { 1, 0 }
  uselistorder i32 %v6_40106e, { 1, 0 }
  uselistorder i32 %v2_40106e, { 1, 2, 0 }
  uselistorder i8 %v2_40106c, { 1, 0 }
  uselistorder i32 %v7_40106a, { 1, 0 }
  uselistorder i32 %v6_40106a, { 1, 0 }
  uselistorder i32 %v2_40106a, { 1, 2, 0 }
  uselistorder i1 %v28_401068, { 1, 0 }
  uselistorder i32 %v7_401068, { 1, 0 }
  uselistorder i32 %v6_401068, { 1, 0 }
  uselistorder i32 %v2_401068, { 1, 2, 0 }
  uselistorder i8 %v2_401066, { 1, 0 }
  uselistorder i32 %v7_401064, { 1, 0 }
  uselistorder i32 %v6_401064, { 1, 0 }
  uselistorder i32 %v2_401064, { 1, 2, 0 }
  uselistorder i1 %v28_401062, { 1, 0 }
  uselistorder i32 %v7_401062, { 1, 0 }
  uselistorder i32 %v6_401062, { 1, 0 }
  uselistorder i32 %v2_401062, { 1, 2, 0 }
  uselistorder i8 %v2_401060, { 1, 0 }
  uselistorder i32 %v7_40105e, { 1, 0 }
  uselistorder i32 %v6_40105e, { 1, 0 }
  uselistorder i32 %v2_40105e, { 1, 2, 0 }
  uselistorder i1 %v28_40105c, { 1, 0 }
  uselistorder i32 %v7_40105c, { 1, 0 }
  uselistorder i32 %v6_40105c, { 1, 0 }
  uselistorder i32 %v2_40105c, { 1, 2, 0 }
  uselistorder i8 %v2_40105a, { 1, 0 }
  uselistorder i32 %v7_401058, { 1, 0 }
  uselistorder i32 %v6_401058, { 1, 0 }
  uselistorder i32 %v2_401058, { 1, 2, 0 }
  uselistorder i1 %v28_401056, { 1, 0 }
  uselistorder i32 %v7_401056, { 1, 0 }
  uselistorder i32 %v6_401056, { 1, 0 }
  uselistorder i32 %v2_401056, { 1, 2, 0 }
  uselistorder i8 %v2_401054, { 1, 0 }
  uselistorder i32 %v7_401052, { 1, 0 }
  uselistorder i32 %v6_401052, { 1, 0 }
  uselistorder i32 %v2_401052, { 1, 2, 0 }
  uselistorder i1 %v28_401050, { 1, 0 }
  uselistorder i32 %v7_401050, { 1, 0 }
  uselistorder i32 %v6_401050, { 1, 0 }
  uselistorder i32 %v2_401050, { 1, 2, 0 }
  uselistorder i8 %v2_40104e, { 1, 0 }
  uselistorder i32 %v7_40104c, { 1, 0 }
  uselistorder i32 %v6_40104c, { 1, 0 }
  uselistorder i32 %v2_40104c, { 1, 2, 0 }
  uselistorder i1 %v28_40104a, { 1, 0 }
  uselistorder i32 %v7_40104a, { 1, 0 }
  uselistorder i32 %v6_40104a, { 1, 0 }
  uselistorder i32 %v2_40104a, { 1, 2, 0 }
  uselistorder i8 %v2_401048, { 1, 0 }
  uselistorder i32 %v7_401046, { 1, 0 }
  uselistorder i32 %v6_401046, { 1, 0 }
  uselistorder i32 %v2_401046, { 1, 2, 0 }
  uselistorder i1 %v28_401044, { 1, 0 }
  uselistorder i32 %v7_401044, { 1, 0 }
  uselistorder i32 %v6_401044, { 1, 0 }
  uselistorder i32 %v2_401044, { 1, 2, 0 }
  uselistorder i8 %v2_401042, { 1, 0 }
  uselistorder i32 %v7_401040, { 1, 0 }
  uselistorder i32 %v6_401040, { 1, 0 }
  uselistorder i32 %v2_401040, { 1, 2, 0 }
  uselistorder i1 %v28_40103e, { 1, 0 }
  uselistorder i32 %v7_40103e, { 1, 0 }
  uselistorder i32 %v6_40103e, { 1, 0 }
  uselistorder i32 %v2_40103e, { 1, 2, 0 }
  uselistorder i8 %v2_40103c, { 1, 0 }
  uselistorder i32 %v7_40103a, { 1, 0 }
  uselistorder i32 %v6_40103a, { 1, 0 }
  uselistorder i32 %v2_40103a, { 1, 2, 0 }
  uselistorder i1 %v28_401038, { 1, 0 }
  uselistorder i32 %v7_401038, { 1, 0 }
  uselistorder i32 %v6_401038, { 1, 0 }
  uselistorder i32 %v2_401038, { 1, 2, 0 }
  uselistorder i8 %v2_401036, { 1, 0 }
  uselistorder i32 %v7_401034, { 1, 0 }
  uselistorder i32 %v6_401034, { 1, 0 }
  uselistorder i32 %v2_401034, { 1, 2, 0 }
  uselistorder i1 %v28_401032, { 1, 0 }
  uselistorder i32 %v7_401032, { 1, 0 }
  uselistorder i32 %v6_401032, { 1, 0 }
  uselistorder i32 %v2_401032, { 1, 2, 0 }
  uselistorder i8 %v2_401030, { 1, 0 }
  uselistorder i32 %v7_40102e, { 1, 0 }
  uselistorder i32 %v6_40102e, { 1, 0 }
  uselistorder i32 %v2_40102e, { 1, 2, 0 }
  uselistorder i1 %v28_40102c, { 1, 0 }
  uselistorder i32 %v7_40102c, { 1, 0 }
  uselistorder i32 %v6_40102c, { 1, 0 }
  uselistorder i32 %v2_40102c, { 1, 2, 0 }
  uselistorder i8 %v2_40102a, { 1, 0 }
  uselistorder i32 %v7_401028, { 1, 0 }
  uselistorder i32 %v6_401028, { 1, 0 }
  uselistorder i32 %v2_401028, { 1, 2, 0 }
  uselistorder i1 %v28_401026, { 1, 0 }
  uselistorder i32 %v7_401026, { 1, 0 }
  uselistorder i32 %v6_401026, { 1, 0 }
  uselistorder i32 %v2_401026, { 1, 2, 0 }
  uselistorder i8 %v2_401024, { 1, 0 }
  uselistorder i32 %v7_401022, { 1, 0 }
  uselistorder i32 %v6_401022, { 1, 0 }
  uselistorder i32 %v2_401022, { 1, 2, 0 }
  uselistorder i1 %v28_401020, { 1, 0 }
  uselistorder i32 %v7_401020, { 1, 0 }
  uselistorder i32 %v6_401020, { 1, 0 }
  uselistorder i32 %v2_401020, { 1, 2, 0 }
  uselistorder i8 %v2_40101e, { 1, 0 }
  uselistorder i32 %v7_40101c, { 1, 0 }
  uselistorder i32 %v6_40101c, { 1, 0 }
  uselistorder i32 %v2_40101c, { 1, 2, 0 }
  uselistorder i1 %v28_40101a, { 1, 0 }
  uselistorder i32 %v7_40101a, { 1, 0 }
  uselistorder i32 %v6_40101a, { 1, 0 }
  uselistorder i32 %v2_40101a, { 1, 2, 0 }
  uselistorder i8 %v2_401018, { 1, 0 }
  uselistorder i32 %v7_401016, { 1, 0 }
  uselistorder i32 %v6_401016, { 1, 0 }
  uselistorder i32 %v2_401016, { 1, 2, 0 }
  uselistorder i1 %v28_401014, { 1, 0 }
  uselistorder i32 %v7_401014, { 1, 0 }
  uselistorder i32 %v6_401014, { 1, 0 }
  uselistorder i32 %v2_401014, { 1, 2, 0 }
  uselistorder i8 %v2_401012, { 1, 0 }
  uselistorder i32 %v7_401010, { 1, 0 }
  uselistorder i32 %v6_401010, { 1, 0 }
  uselistorder i32 %v2_401010, { 1, 2, 0 }
  uselistorder i1 %v28_40100e, { 1, 0 }
  uselistorder i32 %v7_40100e, { 1, 0 }
  uselistorder i32 %v6_40100e, { 1, 0 }
  uselistorder i32 %v2_40100e, { 1, 2, 0 }
  uselistorder i8 %v2_40100c, { 1, 0 }
  uselistorder i32 %v7_40100a, { 1, 0 }
  uselistorder i32 %v6_40100a, { 1, 0 }
  uselistorder i32 %v2_40100a, { 1, 2, 0 }
  uselistorder i1 %v28_401008, { 1, 0 }
  uselistorder i32 %v7_401008, { 1, 0 }
  uselistorder i32 %v6_401008, { 1, 0 }
  uselistorder i32 %v2_401008, { 1, 2, 0 }
  uselistorder i8 %v2_401006, { 1, 0 }
  uselistorder i32 %v7_401004, { 1, 0 }
  uselistorder i32 %v6_401004, { 1, 0 }
  uselistorder i32 %v2_401004, { 1, 2, 0 }
  uselistorder i1 %v28_401002, { 1, 0 }
  uselistorder i32 %v7_401002, { 1, 0 }
  uselistorder i32 %v6_401002, { 1, 0 }
  uselistorder i32 %v2_401002, { 1, 2, 0 }
  uselistorder i8 %v2_401000, { 1, 0 }
  uselistorder i32* %edx.global-to-local, { 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124 }
  uselistorder i32* %ecx.global-to-local, { 0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 25, 27, 28, 29 }
  uselistorder i32* %ebx.global-to-local, { 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43 }
  uselistorder i32* %eax.global-to-local, { 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49 }
  uselistorder i32 160, { 1, 0 }
}

define i32 @function_4016d3() local_unnamed_addr {
dec_label_pc_4016d3:
  %cf.global-to-local = alloca i1, align 1
  %eax.global-to-local = alloca i32, align 4
  %ebx.global-to-local = alloca i32, align 4
  %ecx.global-to-local = alloca i32, align 4
  %edi.global-to-local = alloca i32, align 4
  %edx.global-to-local = alloca i32, align 4
  %esi.global-to-local = alloca i32, align 4
  %v0_4016d3 = load i32, i32* @eax, align 4
  %v1_4016d3 = load i32, i32* inttoptr (i32 4764063 to i32*), align 4
  %v2_4016d3 = load i1, i1* @cf, align 1
  %v3_4016d3 = zext i1 %v2_4016d3 to i32
  %v4_4016d3 = add i32 %v1_4016d3, %v0_4016d3
  %v5_4016d3 = add i32 %v3_4016d3, %v4_4016d3
  %v24_4016d3 = icmp ule i32 %v5_4016d3, %v0_4016d3
  %v25_4016d3 = icmp ult i32 %v4_4016d3, %v0_4016d3
  %v26_4016d3 = select i1 %v2_4016d3, i1 %v24_4016d3, i1 %v25_4016d3
  store i32 %v5_4016d3, i32* %eax.global-to-local, align 4
  store i32 1, i32* %edx.global-to-local, align 4
  %v1_4016de = load i32, i32* inttoptr (i32 4763857 to i32*), align 4
  %v3_4016de = zext i1 %v26_4016d3 to i32
  %v4_4016de = add i32 %v1_4016de, 1
  %v5_4016de = add i32 %v4_4016de, %v3_4016de
  store i32 %v5_4016de, i32* %edx.global-to-local, align 4
  store i32 232, i32* inttoptr (i32 4764142 to i32*), align 4
  %v1_4016ee = load i32, i32* @esi, align 4
  %v2_4016ee = sub i32 %v5_4016de, %v1_4016ee
  %v7_4016ee = icmp ult i32 %v5_4016de, %v1_4016ee
  store i32 %v2_4016ee, i32* %edx.global-to-local, align 4
  %v0_4016f0 = load i32, i32* inttoptr (i32 4764011 to i32*), align 4
  %v2_4016f0 = zext i1 %v7_4016ee to i32
  %v3_4016f0 = add i32 %v0_4016f0, 177
  %v4_4016f0 = add i32 %v3_4016f0, %v2_4016f0
  %v21_4016f0 = icmp ule i32 %v4_4016f0, %v0_4016f0
  %v22_4016f0 = icmp ugt i32 %v0_4016f0, -178
  %v23_4016f0 = select i1 %v7_4016ee, i1 %v21_4016f0, i1 %v22_4016f0
  store i1 %v23_4016f0, i1* %cf.global-to-local, align 1
  store i32 %v4_4016f0, i32* inttoptr (i32 4764011 to i32*), align 4
  %v0_4016fa = load i32, i32* %eax.global-to-local, align 4
  %v1_4016fa = trunc i32 %v0_4016fa to i8
  %v2_4016fa = load i8, i8* inttoptr (i32 4763831 to i8*), align 1
  %v3_4016fa = sub i8 %v1_4016fa, %v2_4016fa
  %v8_4016fa = icmp ult i8 %v1_4016fa, %v2_4016fa
  store i1 %v8_4016fa, i1* %cf.global-to-local, align 1
  %v18_4016fa = zext i8 %v3_4016fa to i32
  %v20_4016fa = and i32 %v0_4016fa, -256
  %v21_4016fa = or i32 %v18_4016fa, %v20_4016fa
  store i32 %v21_4016fa, i32* %eax.global-to-local, align 4
  %v0_401700 = load i8, i8* inttoptr (i32 4763665 to i8*), align 1
  %v1_401700 = add i8 %v0_401700, -65
  store i8 %v1_401700, i8* inttoptr (i32 4763665 to i8*), align 1
  %v2_40170c = add i32 %v21_4016fa, 1
  %v7_40170c = icmp eq i32 %v2_40170c, 0
  store i1 %v7_40170c, i1* %cf.global-to-local, align 1
  store i32 %v2_40170c, i32* %ecx.global-to-local, align 4
  %v0_40170e = load i8, i8* inttoptr (i32 4763656 to i8*), align 8
  %v1_40170e = load i32, i32* @ebx, align 4
  %v2_40170e = trunc i32 %v1_40170e to i8
  %v3_40170e = add i8 %v2_40170e, %v0_40170e
  %v8_40170e = icmp ult i8 %v3_40170e, %v0_40170e
  store i1 %v8_40170e, i1* %cf.global-to-local, align 1
  store i8 %v3_40170e, i8* inttoptr (i32 4763656 to i8*), align 8
  %v0_401714 = load i32, i32* @ebx, align 4
  %v2_401714 = zext i1 %v8_40170e to i32
  %v3_401714 = add i32 %v0_401714, 50
  %v4_401714 = add i32 %v3_401714, %v2_401714
  store i32 %v4_401714, i32* %ebx.global-to-local, align 4
  %v0_401717 = load i32, i32* inttoptr (i32 4764103 to i32*), align 4
  %v1_401717 = and i32 %v0_401717, 31
  store i32 %v1_401717, i32* inttoptr (i32 4764103 to i32*), align 4
  store i1 false, i1* %cf.global-to-local, align 1
  %v8_401730 = call i1 @SetEnvironmentVariableW(i16* bitcast ([13 x i8]* @global_var_48b685.2 to i16*), i16* bitcast ([17 x i8]* @global_var_48b692.1 to i16*))
  %v9_401730 = sext i1 %v8_401730 to i32
  store i32 %v9_401730, i32* %eax.global-to-local, align 4
  %v0_401736 = load i32, i32* @edi, align 4
  %v2_401736 = load i1, i1* %cf.global-to-local, align 1
  %v3_401736 = zext i1 %v2_401736 to i32
  %v4_401736 = add i32 %v0_401736, %v9_401730
  %v5_401736 = add i32 %v4_401736, %v3_401736
  store i32 %v5_401736, i32* %edi.global-to-local, align 4
  store i32 48, i32* inttoptr (i32 4763828 to i32*), align 4
  %v0_401742 = load i32, i32* @esi, align 4
  %v1_401742 = xor i32 %v0_401742, 21
  store i32 %v1_401742, i32* %esi.global-to-local, align 4
  %v0_401745 = load i32, i32* inttoptr (i32 4764082 to i32*), align 4
  %v1_401745 = load i32, i32* %ebx.global-to-local, align 4
  %v4_401745 = add i32 %v1_401745, %v0_401745
  store i32 %v4_401745, i32* inttoptr (i32 4764082 to i32*), align 4
  %v1_40174b = load i32, i32* inttoptr (i32 4763700 to i32*), align 4
  %v2_40174b = sub i32 %v1_401742, %v1_40174b
  %v7_40174b = icmp ult i32 %v1_401742, %v1_40174b
  store i32 %v2_40174b, i32* %esi.global-to-local, align 4
  store i32 1, i32* %edx.global-to-local, align 4
  %v1_401756 = load i32, i32* inttoptr (i32 4763802 to i32*), align 4
  %v4_401756 = select i1 %v7_40174b, i32 2, i32 1
  %v5_401756 = add i32 %v4_401756, %v1_401756
  %v2_40175c = sub i32 %v5_401756, %v9_401730
  %v7_40175c = icmp ult i32 %v5_401756, %v9_401730
  store i32 %v2_40175c, i32* %edx.global-to-local, align 4
  %v1_40175e = load i32, i32* inttoptr (i32 4764150 to i32*), align 4
  %v3_40175e = zext i1 %v7_40175c to i32
  %v4_40175e = add i32 %v1_40175e, %v9_401730
  %v5_40175e = add i32 %v4_40175e, %v3_40175e
  store i32 %v5_40175e, i32* %eax.global-to-local, align 4
  %v1_401764 = load i32, i32* inttoptr (i32 4763768 to i32*), align 8
  store i32 0, i32* %edx.global-to-local, align 4
  %v2_401764 = add i32 %v2_40174b, -39
  %v1_40176c = sub i32 %v2_401764, %v1_401764
  store i32 %v1_40176c, i32* %esi.global-to-local, align 4
  %v1_40176f = or i32 %v5_40175e, 52
  store i32 %v1_40176f, i32* %eax.global-to-local, align 4
  %v0_401772 = load i32, i32* inttoptr (i32 4763675 to i32*), align 4
  %v1_401772 = or i32 %v0_401772, 41
  store i32 %v1_401772, i32* inttoptr (i32 4763675 to i32*), align 4
  %v0_401779 = load i32, i32* %ecx.global-to-local, align 4
  %v1_401779 = and i32 %v0_401779, -256
  %v2_401779 = or i32 %v1_401779, 1
  store i32 %v2_401779, i32* %ecx.global-to-local, align 4
  %v0_40177d = load i32, i32* %ebx.global-to-local, align 4
  %v1_40177d = load i32, i32* inttoptr (i32 4763764 to i32*), align 4
  %v4_40177d = add i32 %v1_40177d, %v0_40177d
  %v25_40177d = icmp ult i32 %v4_40177d, %v0_40177d
  store i1 %v25_40177d, i1* %cf.global-to-local, align 1
  store i32 %v4_40177d, i32* %ebx.global-to-local, align 4
  call void @__pseudo_call(i32 4200331)
  %v0_40178b = load i32, i32* inttoptr (i32 4764076 to i32*), align 4
  %v1_40178b = load i1, i1* %cf.global-to-local, align 1
  %v2_40178b = zext i1 %v1_40178b to i32
  %v3_40178b = add i32 %v0_40178b, 118
  %v4_40178b = add i32 %v3_40178b, %v2_40178b
  store i32 %v4_40178b, i32* inttoptr (i32 4764076 to i32*), align 4
  store i32 0, i32* %edx.global-to-local, align 4
  %v0_401795 = load i32, i32* %edi.global-to-local, align 4
  %v1_401795 = load i32, i32* %ecx.global-to-local, align 4
  %v2_401795 = add i32 %v1_401795, %v0_401795
  %v7_401795 = icmp ult i32 %v2_401795, %v0_401795
  store i32 %v2_401795, i32* %edi.global-to-local, align 4
  %v0_401797 = load i32, i32* %esi.global-to-local, align 4
  %v3_401797 = zext i1 %v7_401795 to i32
  %v4_401797 = add i32 %v0_401797, %v2_401795
  %v5_401797 = add i32 %v3_401797, %v4_401797
  %v24_401797 = icmp ule i32 %v5_401797, %v0_401797
  %v25_401797 = icmp ult i32 %v4_401797, %v0_401797
  %v26_401797 = select i1 %v7_401795, i1 %v24_401797, i1 %v25_401797
  store i32 %v5_401797, i32* %esi.global-to-local, align 4
  %v0_401799 = load i32, i32* inttoptr (i32 4764024 to i32*), align 8
  %v3_401799 = select i1 %v26_401797, i32 60, i32 59
  %v4_401799 = add i32 %v3_401799, %v0_401799
  store i32 %v4_401799, i32* inttoptr (i32 4764024 to i32*), align 8
  %v0_4017a0 = load i32, i32* inttoptr (i32 4763807 to i32*), align 4
  %v1_4017a0 = or i32 %v0_4017a0, 238
  store i32 %v1_4017a0, i32* inttoptr (i32 4763807 to i32*), align 4
  %v0_4017aa = load i32, i32* %esi.global-to-local, align 4
  %v1_4017aa = add i32 %v0_4017aa, -10
  store i32 %v1_4017aa, i32* %esi.global-to-local, align 4
  %v0_4017ad = load i32, i32* inttoptr (i32 4763721 to i32*), align 4
  %v1_4017ad = load i32, i32* %eax.global-to-local, align 4
  %v2_4017ad = and i32 %v1_4017ad, %v0_4017ad
  store i32 %v2_4017ad, i32* inttoptr (i32 4763721 to i32*), align 4
  %v0_4017b3 = load i32, i32* %edx.global-to-local, align 4
  %v1_4017b3 = load i32, i32* inttoptr (i32 4763954 to i32*), align 4
  %v4_4017b3 = add i32 %v1_4017b3, %v0_4017b3
  %v25_4017b3 = icmp ult i32 %v4_4017b3, %v0_4017b3
  store i32 %v4_4017b3, i32* %edx.global-to-local, align 4
  %v0_4017b9 = load i32, i32* %eax.global-to-local, align 4
  %v2_4017b9 = zext i1 %v25_4017b3 to i32
  %v3_4017b9 = add i32 %v0_4017b9, -97
  %v4_4017b9 = add i32 %v3_4017b9, %v2_4017b9
  %v22_4017b9 = trunc i32 %v4_4017b9 to i8
  store i32 %v4_4017b9, i32* %eax.global-to-local, align 4
  %v0_4017bc = load i32, i32* %ecx.global-to-local, align 4
  %v1_4017bc = load i32, i32* inttoptr (i32 4763921 to i32*), align 4
  %v2_4017bc = sub i32 %v0_4017bc, %v1_4017bc
  store i32 %v2_4017bc, i32* %ecx.global-to-local, align 4
  %v1_4017c2 = add i32 %v4_4017b3, -54
  %v5_4017c2 = icmp ugt i32 %v4_4017b3, 53
  store i1 %v5_4017c2, i1* %cf.global-to-local, align 1
  store i32 %v1_4017c2, i32* %edx.global-to-local, align 4
  %v1_4017c5 = inttoptr i32 %v4_4017b9 to i8*
  %v2_4017c5 = load i8, i8* %v1_4017c5, align 1
  %v5_4017c5 = add i8 %v2_4017c5, %v22_4017b9
  %v10_4017c5 = icmp ult i8 %v5_4017c5, %v2_4017c5
  store i1 %v10_4017c5, i1* %cf.global-to-local, align 1
  store i8 %v5_4017c5, i8* %v1_4017c5, align 1
  %v0_4017c7 = load i32, i32* %ecx.global-to-local, align 4
  %v1_4017c7 = inttoptr i32 %v0_4017c7 to i8*
  %v2_4017c7 = load i8, i8* %v1_4017c7, align 1
  %v3_4017c7 = load i32, i32* %eax.global-to-local, align 4
  %v4_4017c7 = udiv i32 %v3_4017c7, 256
  %v5_4017c7 = trunc i32 %v4_4017c7 to i8
  %v6_4017c7 = add i8 %v5_4017c7, %v2_4017c7
  store i8 %v6_4017c7, i8* %v1_4017c7, align 1
  %v0_4017c9 = load i32, i32* %eax.global-to-local, align 4
  %v1_4017c9 = add i32 %v0_4017c9, 4763980
  store i32 %v1_4017c9, i32* %eax.global-to-local, align 4
  %v0_4017ce = load i32, i32* %esi.global-to-local, align 4
  %v1_4017ce = load i32, i32* inttoptr (i32 4763940 to i32*), align 4
  %v2_4017ce = sub i32 %v0_4017ce, %v1_4017ce
  store i32 %v2_4017ce, i32* %esi.global-to-local, align 4
  %v0_4017d4 = load i32, i32* %ecx.global-to-local, align 4
  %v1_4017d4 = and i32 %v0_4017d4, -256
  %v18_4017d6 = or i32 %v1_4017d4, 53
  store i32 %v18_4017d6, i32* %ecx.global-to-local, align 4
  %v0_4017d9 = load i32, i32* inttoptr (i32 4763700 to i32*), align 4
  %v3_4017d9 = add i32 %v0_4017d9, 161
  store i32 %v3_4017d9, i32* inttoptr (i32 4763700 to i32*), align 4
  %v0_4017e3 = load i32, i32* inttoptr (i32 4764063 to i32*), align 4
  %v1_4017e3 = or i32 %v0_4017e3, 167
  store i32 %v1_4017e3, i32* inttoptr (i32 4764063 to i32*), align 4
  %v0_4017ed = load i32, i32* inttoptr (i32 4764031 to i32*), align 4
  %v1_4017ed = xor i32 %v0_4017ed, 103
  store i32 %v1_4017ed, i32* inttoptr (i32 4764031 to i32*), align 4
  %v0_4017f4 = load i32, i32* %esi.global-to-local, align 4
  %v3_4017f4 = add i32 %v0_4017f4, 110
  %v12_4017f4 = icmp ult i32 %v0_4017f4, -110
  store i32 %v3_4017f4, i32* %esi.global-to-local, align 4
  %v0_4017f7 = load i32, i32* inttoptr (i32 4763871 to i32*), align 4
  %v2_4017f7 = zext i1 %v12_4017f4 to i32
  %v3_4017f7 = add i32 %v0_4017f7, 13
  %v4_4017f7 = add i32 %v3_4017f7, %v2_4017f7
  store i32 %v4_4017f7, i32* inttoptr (i32 4763871 to i32*), align 4
  %v1_4017fe = add i32 %v0_4017f4, 156
  store i32 %v1_4017fe, i32* %esi.global-to-local, align 4
  %v0_401801 = load i32, i32* %ebx.global-to-local, align 4
  %v1_401801 = add i32 %v0_401801, 125
  store i32 %v1_401801, i32* %ebx.global-to-local, align 4
  store i1 false, i1* %cf.global-to-local, align 1
  %v8_401816 = call i1 @SetEnvironmentVariableW(i16* bitcast ([13 x i8]* @global_var_48b685.2 to i16*), i16* bitcast ([17 x i8]* @global_var_48b692.1 to i16*))
  %v9_401816 = sext i1 %v8_401816 to i32
  store i32 %v9_401816, i32* %eax.global-to-local, align 4
  %v0_40181c = load i32, i32* inttoptr (i32 4764125 to i32*), align 4
  %v1_40181c = load i32, i32* %edi.global-to-local, align 4
  %v2_40181c = and i32 %v1_40181c, %v0_40181c
  store i32 %v2_40181c, i32* inttoptr (i32 4764125 to i32*), align 4
  store i32 32, i32* %edx.global-to-local, align 4
  %v0_40182a = load i32, i32* inttoptr (i32 4763894 to i32*), align 4
  %v2_40182a = select i1 %v8_401816, i32 %v0_40182a, i32 0
  store i32 %v2_40182a, i32* inttoptr (i32 4763894 to i32*), align 4
  %v0_401830 = load i32, i32* %esi.global-to-local, align 4
  %v2_401830 = xor i32 %v0_401830, %v9_401816
  store i32 %v2_401830, i32* %esi.global-to-local, align 4
  %v0_401832 = load i32, i32* %ebx.global-to-local, align 4
  %v3_401832 = add i32 %v0_401832, 5
  store i32 %v3_401832, i32* %ebx.global-to-local, align 4
  %v0_401835 = load i32, i32* %edx.global-to-local, align 4
  %v1_401835 = xor i32 %v0_401835, 61
  store i32 %v1_401835, i32* %edx.global-to-local, align 4
  %v0_401838 = load i32, i32* inttoptr (i32 4763731 to i32*), align 4
  %v4_401838 = add i32 %v0_401838, %v1_401835
  %v25_401838 = icmp ult i32 %v4_401838, %v0_401838
  store i32 %v4_401838, i32* inttoptr (i32 4763731 to i32*), align 4
  %v0_40183e = load i32, i32* inttoptr (i32 4764098 to i32*), align 4
  %v2_40183e = zext i1 %v25_401838 to i32
  %v3_40183e = add i32 %v0_40183e, -137
  %v4_40183e = add i32 %v3_40183e, %v2_40183e
  store i32 %v4_40183e, i32* inttoptr (i32 4764098 to i32*), align 4
  store i32 -1, i32* %ecx.global-to-local, align 4
  %v0_401850 = load i32, i32* inttoptr (i32 4763951 to i32*), align 4
  %v4_401850 = add i32 %v0_401850, -1
  %v25_401850 = icmp ne i32 %v0_401850, 0
  store i32 %v4_401850, i32* inttoptr (i32 4763951 to i32*), align 4
  store i32 114, i32* inttoptr (i32 4764045 to i32*), align 4
  %v2_401860 = zext i1 %v25_401850 to i32
  %v3_401860 = add nsw i32 %v9_401816, 16
  %v4_401860 = add nsw i32 %v3_401860, %v2_401860
  %v0_401863 = load i32, i32* %edi.global-to-local, align 4
  %v2_401863 = xor i32 %v0_401863, %v4_401860
  store i32 %v2_401863, i32* %edi.global-to-local, align 4
  %v1_401865 = add nsw i32 %v4_401860, -106
  store i32 %v1_401865, i32* %eax.global-to-local, align 4
  %v0_401868 = load i32, i32* %ebx.global-to-local, align 4
  %v1_401868 = udiv i32 %v0_401868, 256
  %v2_401868 = trunc i32 %v1_401868 to i8
  %v3_401868 = load i32, i32* %ecx.global-to-local, align 4
  %v4_401868 = udiv i32 %v3_401868, 256
  %v5_401868 = trunc i32 %v4_401868 to i8
  %v6_401868 = add i8 %v5_401868, %v2_401868
  %v11_401868 = icmp ult i8 %v6_401868, %v2_401868
  %v21_401868 = zext i8 %v6_401868 to i32
  %v23_401868 = mul nuw nsw i32 %v21_401868, 256
  %v24_401868 = and i32 %v0_401868, -65281
  %v25_401868 = or i32 %v23_401868, %v24_401868
  store i32 %v25_401868, i32* %ebx.global-to-local, align 4
  %v0_40186a = load i32, i32* inttoptr (i32 4763989 to i32*), align 4
  %v2_40186a = zext i1 %v11_401868 to i32
  %v3_40186a = add i32 %v0_40186a, 60
  %v4_40186a = add i32 %v3_40186a, %v2_40186a
  %v21_40186a = icmp ule i32 %v4_40186a, %v0_40186a
  %v22_40186a = icmp ugt i32 %v0_40186a, -61
  %v23_40186a = select i1 %v11_401868, i1 %v21_40186a, i1 %v22_40186a
  store i1 %v23_40186a, i1* %cf.global-to-local, align 1
  store i32 %v4_40186a, i32* inttoptr (i32 4763989 to i32*), align 4
  call void @__pseudo_call(i32 4200569)
  %v0_401879 = load i32, i32* inttoptr (i32 4763955 to i32*), align 4
  %v1_401879 = load i32, i32* %edx.global-to-local, align 4
  %v2_401879 = sub i32 %v0_401879, %v1_401879
  store i32 %v2_401879, i32* inttoptr (i32 4763955 to i32*), align 4
  %v0_40187f = load i32, i32* %ecx.global-to-local, align 4
  %v1_40187f = load i32, i32* %edi.global-to-local, align 4
  %v2_40187f = add i32 %v1_40187f, %v0_40187f
  %v7_40187f = icmp ult i32 %v2_40187f, %v0_40187f
  store i32 %v2_40187f, i32* %ecx.global-to-local, align 4
  %v1_401881 = load i32, i32* inttoptr (i32 4764112 to i32*), align 16
  %v3_401881 = zext i1 %v7_40187f to i32
  %v4_401881 = add i32 %v1_401881, %v2_40187f
  %v5_401881 = add i32 %v3_401881, %v4_401881
  %v24_401881 = icmp ule i32 %v5_401881, %v2_40187f
  %v25_401881 = icmp ult i32 %v4_401881, %v2_40187f
  %v26_401881 = select i1 %v7_40187f, i1 %v24_401881, i1 %v25_401881
  store i32 %v5_401881, i32* %ecx.global-to-local, align 4
  %v0_401887 = load i32, i32* %eax.global-to-local, align 4
  %v1_401887 = load i32, i32* %esi.global-to-local, align 4
  %v3_401887 = zext i1 %v26_401881 to i32
  %v4_401887 = sub i32 %v0_401887, %v1_401887
  %v5_401887 = add i32 %v4_401887, %v3_401887
  store i32 %v5_401887, i32* %eax.global-to-local, align 4
  %v0_401889 = load i32, i32* %ebx.global-to-local, align 4
  %v1_401889 = or i32 %v0_401889, -29
  store i32 %v1_401889, i32* %ebx.global-to-local, align 4
  %v0_40188c = load i32, i32* inttoptr (i32 4763976 to i32*), align 8
  %v3_40188c = add i32 %v0_40188c, -65
  store i32 %v3_40188c, i32* inttoptr (i32 4763976 to i32*), align 8
  store i32 0, i32* %edi.global-to-local, align 4
  %v0_401895 = load i32, i32* inttoptr (i32 4764013 to i32*), align 4
  %v1_401895 = load i32, i32* %esi.global-to-local, align 4
  %v4_401895 = add i32 %v1_401895, %v0_401895
  %v25_401895 = icmp ult i32 %v4_401895, %v0_401895
  store i32 %v4_401895, i32* inttoptr (i32 4764013 to i32*), align 4
  %v0_40189b = load i32, i32* inttoptr (i32 4763895 to i32*), align 4
  %v1_40189b = load i32, i32* %edi.global-to-local, align 4
  %v3_40189b = zext i1 %v25_401895 to i32
  %v4_40189b = sub i32 %v0_40189b, %v1_40189b
  %v5_40189b = add i32 %v4_40189b, %v3_40189b
  store i32 %v5_40189b, i32* inttoptr (i32 4763895 to i32*), align 4
  %v0_4018a1 = load i32, i32* inttoptr (i32 4764140 to i32*), align 4
  %v1_4018a1 = load i32, i32* %edx.global-to-local, align 4
  %v2_4018a1 = and i32 %v1_4018a1, %v0_4018a1
  store i32 %v2_4018a1, i32* inttoptr (i32 4764140 to i32*), align 4
  %v0_4018a7 = load i32, i32* inttoptr (i32 4764116 to i32*), align 4
  %v3_4018a7 = add i32 %v0_4018a7, 77
  %v22_4018a7 = icmp ugt i32 %v0_4018a7, -78
  store i32 %v3_4018a7, i32* inttoptr (i32 4764116 to i32*), align 4
  %v0_4018ae = load i32, i32* %ecx.global-to-local, align 4
  %v1_4018ae = load i32, i32* inttoptr (i32 4764133 to i32*), align 4
  %v3_4018ae = zext i1 %v22_4018a7 to i32
  %v4_4018ae = add i32 %v1_4018ae, %v0_4018ae
  %v5_4018ae = add i32 %v4_4018ae, %v3_4018ae
  %v24_4018ae = icmp ule i32 %v5_4018ae, %v0_4018ae
  %v25_4018ae = icmp ult i32 %v4_4018ae, %v0_4018ae
  %v26_4018ae = select i1 %v22_4018a7, i1 %v24_4018ae, i1 %v25_4018ae
  %v1_4018b4 = load i32, i32* %edx.global-to-local, align 4
  %v3_4018b4 = zext i1 %v26_4018ae to i32
  %v4_4018b4 = add i32 %v5_4018ae, %v1_4018b4
  %v5_4018b4 = add i32 %v4_4018b4, %v3_4018b4
  %v2_4018b6 = mul i32 %v5_4018b4, 2
  %v7_4018b6 = icmp ult i32 %v2_4018b6, %v5_4018b4
  store i32 %v2_4018b6, i32* %ecx.global-to-local, align 4
  %v0_4018b8 = load i32, i32* inttoptr (i32 4763770 to i32*), align 4
  %v3_4018b8 = zext i1 %v7_4018b6 to i32
  %v4_4018b8 = add i32 %v2_4018b6, %v0_4018b8
  %v5_4018b8 = add i32 %v3_4018b8, %v4_4018b8
  %v24_4018b8 = icmp ule i32 %v5_4018b8, %v0_4018b8
  %v25_4018b8 = icmp ult i32 %v4_4018b8, %v0_4018b8
  %v26_4018b8 = select i1 %v7_4018b6, i1 %v24_4018b8, i1 %v25_4018b8
  store i32 %v5_4018b8, i32* inttoptr (i32 4763770 to i32*), align 4
  %v0_4018be = load i32, i32* %edi.global-to-local, align 4
  %v2_4018be = zext i1 %v26_4018b8 to i32
  %v3_4018be = add i32 %v0_4018be, 82
  %v4_4018be = add i32 %v3_4018be, %v2_4018be
  %v12_4018be = icmp ult i32 %v0_4018be, -82
  %v13_4018be = or i1 %v12_4018be, %v26_4018b8
  store i32 %v4_4018be, i32* %edi.global-to-local, align 4
  %v0_4018c1 = load i32, i32* %edx.global-to-local, align 4
  %v2_4018c1 = zext i1 %v13_4018be to i32
  %v3_4018c1 = add i32 %v0_4018c1, 46
  %v4_4018c1 = add i32 %v3_4018c1, %v2_4018c1
  store i32 %v4_4018c1, i32* %edx.global-to-local, align 4
  %v0_4018c4 = load i32, i32* %ebx.global-to-local, align 4
  %v1_4018c4 = or i32 %v0_4018c4, -128
  store i32 %v1_4018c4, i32* %ebx.global-to-local, align 4
  %v0_4018c7 = load i32, i32* inttoptr (i32 4763762 to i32*), align 4
  %v1_4018c7 = and i32 %v0_4018c7, 227
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v1_4018c7, i32* inttoptr (i32 4763762 to i32*), align 4
  %v0_4018d1 = load i32, i32* %eax.global-to-local, align 4
  %v1_4018d1 = inttoptr i32 %v0_4018d1 to i8*
  %v2_4018d1 = load i8, i8* %v1_4018d1, align 1
  %v4_4018d1 = trunc i32 %v0_4018d1 to i8
  %v5_4018d1 = add i8 %v4_4018d1, %v2_4018d1
  %v10_4018d1 = icmp ult i8 %v5_4018d1, %v2_4018d1
  store i1 %v10_4018d1, i1* %cf.global-to-local, align 1
  store i8 %v5_4018d1, i8* %v1_4018d1, align 1
  %v0_4018d3 = load i32, i32* %eax.global-to-local, align 4
  %v1_4018d3 = inttoptr i32 %v0_4018d3 to i8*
  %v2_4018d3 = load i8, i8* %v1_4018d3, align 1
  %v4_4018d3 = trunc i32 %v0_4018d3 to i8
  %v5_4018d3 = add i8 %v4_4018d3, %v2_4018d3
  %v10_4018d3 = icmp ult i8 %v5_4018d3, %v2_4018d3
  store i1 %v10_4018d3, i1* %cf.global-to-local, align 1
  store i8 %v5_4018d3, i8* %v1_4018d3, align 1
  %v0_4018d5 = load i32, i32* %eax.global-to-local, align 4
  %v1_4018d5 = inttoptr i32 %v0_4018d5 to i8*
  %v2_4018d5 = load i8, i8* %v1_4018d5, align 1
  %v4_4018d5 = trunc i32 %v0_4018d5 to i8
  %v5_4018d5 = add i8 %v4_4018d5, %v2_4018d5
  %v10_4018d5 = icmp ult i8 %v5_4018d5, %v2_4018d5
  store i1 %v10_4018d5, i1* %cf.global-to-local, align 1
  store i8 %v5_4018d5, i8* %v1_4018d5, align 1
  %v0_4018d7 = load i32, i32* %eax.global-to-local, align 4
  %v1_4018d7 = inttoptr i32 %v0_4018d7 to i8*
  %v2_4018d7 = load i8, i8* %v1_4018d7, align 1
  %v4_4018d7 = trunc i32 %v0_4018d7 to i8
  %v5_4018d7 = add i8 %v4_4018d7, %v2_4018d7
  %v10_4018d7 = icmp ult i8 %v5_4018d7, %v2_4018d7
  store i1 %v10_4018d7, i1* %cf.global-to-local, align 1
  store i8 %v5_4018d7, i8* %v1_4018d7, align 1
  %v0_4018d9 = load i32, i32* %eax.global-to-local, align 4
  %v1_4018d9 = inttoptr i32 %v0_4018d9 to i8*
  %v2_4018d9 = load i8, i8* %v1_4018d9, align 1
  %v4_4018d9 = trunc i32 %v0_4018d9 to i8
  %v5_4018d9 = add i8 %v4_4018d9, %v2_4018d9
  store i8 %v5_4018d9, i8* %v1_4018d9, align 1
  %v0_4018db = load i32, i32* %edi.global-to-local, align 4
  %v1_4018db = add i32 %v0_4018db, 50
  store i32 %v1_4018db, i32* %edi.global-to-local, align 4
  %v0_4018de = load i32, i32* inttoptr (i32 4763815 to i32*), align 4
  %v1_4018de = xor i32 %v0_4018de, 93
  store i32 %v1_4018de, i32* inttoptr (i32 4763815 to i32*), align 4
  %v0_4018e5 = load i32, i32* inttoptr (i32 4763729 to i32*), align 4
  %v1_4018e5 = load i32, i32* %esi.global-to-local, align 4
  %v2_4018e5 = add i32 %v1_4018e5, %v0_4018e5
  %v7_4018e5 = icmp ult i32 %v2_4018e5, %v0_4018e5
  store i32 %v2_4018e5, i32* inttoptr (i32 4763729 to i32*), align 4
  %v0_4018eb = load i32, i32* %ebx.global-to-local, align 4
  %v1_4018eb = load i32, i32* inttoptr (i32 4764049 to i32*), align 4
  %v3_4018eb = zext i1 %v7_4018e5 to i32
  %v4_4018eb = add i32 %v1_4018eb, %v0_4018eb
  %v5_4018eb = add i32 %v4_4018eb, %v3_4018eb
  %v24_4018eb = icmp ule i32 %v5_4018eb, %v0_4018eb
  %v25_4018eb = icmp ult i32 %v4_4018eb, %v0_4018eb
  %v26_4018eb = select i1 %v7_4018e5, i1 %v24_4018eb, i1 %v25_4018eb
  store i32 %v5_4018eb, i32* %ebx.global-to-local, align 4
  %v0_4018f1 = load i32, i32* inttoptr (i32 4764053 to i32*), align 4
  %v1_4018f1 = load i32, i32* %eax.global-to-local, align 4
  %v3_4018f1 = zext i1 %v26_4018eb to i32
  %v4_4018f1 = add i32 %v1_4018f1, %v0_4018f1
  %v5_4018f1 = add i32 %v4_4018f1, %v3_4018f1
  store i32 %v5_4018f1, i32* inttoptr (i32 4764053 to i32*), align 4
  %v0_4018f7 = load i32, i32* inttoptr (i32 4764028 to i32*), align 4
  %v1_4018f7 = load i32, i32* %ebx.global-to-local, align 4
  %v2_4018f7 = add i32 %v1_4018f7, %v0_4018f7
  store i32 %v2_4018f7, i32* inttoptr (i32 4764028 to i32*), align 4
  %v0_4018fd = load i32, i32* %edi.global-to-local, align 4
  %v1_4018fd = load i32, i32* %esi.global-to-local, align 4
  %v2_4018fd = sub i32 %v0_4018fd, %v1_4018fd
  %v7_4018fd = icmp ult i32 %v0_4018fd, %v1_4018fd
  store i1 %v7_4018fd, i1* %cf.global-to-local, align 1
  store i32 %v2_4018fd, i32* %edi.global-to-local, align 4
  %v0_4018ff = load i8, i8* inttoptr (i32 4763962 to i8*), align 2
  %v1_4018ff = load i32, i32* %ebx.global-to-local, align 4
  %v2_4018ff = trunc i32 %v1_4018ff to i8
  %v3_4018ff = sub i8 %v0_4018ff, %v2_4018ff
  store i8 %v3_4018ff, i8* inttoptr (i32 4763962 to i8*), align 2
  store i32 -58, i32* %edx.global-to-local, align 4
  %v1_401912 = load i32, i32* %esi.global-to-local, align 4
  %v2_401912 = add i32 %v1_401912, 1
  store i32 %v2_401912, i32* %ecx.global-to-local, align 4
  store i32 156, i32* inttoptr (i32 4763984 to i32*), align 16
  %v0_40191e = load i32, i32* %edi.global-to-local, align 4
  %v1_40191e = load i32, i32* inttoptr (i32 4764097 to i32*), align 4
  %v2_40191e = sub i32 %v0_40191e, %v1_40191e
  %v7_40191e = icmp ult i32 %v0_40191e, %v1_40191e
  store i1 %v7_40191e, i1* %cf.global-to-local, align 1
  store i32 %v2_40191e, i32* %edi.global-to-local, align 4
  %v0_401924 = load i8, i8* inttoptr (i32 4763882 to i8*), align 2
  %v1_401924 = add i8 %v0_401924, -108
  %v5_401924 = icmp ult i8 %v0_401924, 108
  store i1 %v5_401924, i1* %cf.global-to-local, align 1
  store i8 %v1_401924, i8* inttoptr (i32 4763882 to i8*), align 2
  %v0_40192b = load i32, i32* %esi.global-to-local, align 4
  %v1_40192b = load i32, i32* %edi.global-to-local, align 4
  %v3_40192b = zext i1 %v5_401924 to i32
  %v4_40192b = sub i32 %v0_40192b, %v1_40192b
  %v5_40192b = add i32 %v4_40192b, %v3_40192b
  store i32 %v5_40192b, i32* %esi.global-to-local, align 4
  %v0_401930 = load i32, i32* %ecx.global-to-local, align 4
  %v1_401930 = add i32 %v0_401930, -62
  store i32 %v1_401930, i32* %ecx.global-to-local, align 4
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 0, i32* %ebx.global-to-local, align 4
  %v0_401935 = load i8, i8* inttoptr (i32 4763801 to i8*), align 1
  %v1_401935 = add i8 %v0_401935, 69
  store i8 %v1_401935, i8* inttoptr (i32 4763801 to i8*), align 1
  %v0_40193c = load i32, i32* %edx.global-to-local, align 4
  %v1_40193c = load i32, i32* inttoptr (i32 4764098 to i32*), align 4
  %v2_40193c = sub i32 %v0_40193c, %v1_40193c
  store i32 %v2_40193c, i32* %edx.global-to-local, align 4
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 1048576, i32* %eax.global-to-local, align 4
  %v10_40195b = call i32* @OpenJobObjectW(i32 1048576, i1 false, i16* bitcast ([13 x i8]* @global_var_48b6a3.4 to i16*))
  %v11_40195b = ptrtoint i32* %v10_40195b to i32
  store i32 %v11_40195b, i32* %eax.global-to-local, align 4
  store i1 false, i1* %cf.global-to-local, align 1
  %v1_401961 = icmp eq i32* %v10_40195b, null
  %v1_401964 = icmp eq i1 %v1_401961, false
  call void @__pseudo_cond_branch(i1 %v1_401964, i32 4220978)
  %v0_40196a = load i32, i32* inttoptr (i32 4764037 to i32*), align 4
  %v1_40196a = load i32, i32* %ebx.global-to-local, align 4
  %v2_40196a = xor i32 %v1_40196a, %v0_40196a
  store i32 %v2_40196a, i32* inttoptr (i32 4764037 to i32*), align 4
  store i32 1, i32* %ecx.global-to-local, align 4
  %v1_401975 = load i32, i32* inttoptr (i32 4764123 to i32*), align 4
  %v4_401975 = add i32 %v1_401975, 1
  store i32 %v4_401975, i32* %ecx.global-to-local, align 4
  %v0_40197b = load i32, i32* %ebx.global-to-local, align 4
  %v2_40197b = mul i32 %v0_40197b, 2
  store i32 %v2_40197b, i32* %ebx.global-to-local, align 4
  %v0_40197d = load i32, i32* inttoptr (i32 4764012 to i32*), align 4
  %v2_40197d = sub i32 %v0_40197d, %v2_40197b
  store i32 %v2_40197d, i32* inttoptr (i32 4764012 to i32*), align 4
  %v0_401983 = load i32, i32* inttoptr (i32 4764068 to i32*), align 4
  %v1_401983 = load i32, i32* %ecx.global-to-local, align 4
  %v2_401983 = sub i32 %v0_401983, %v1_401983
  %v7_401983 = icmp ult i32 %v0_401983, %v1_401983
  store i32 %v2_401983, i32* inttoptr (i32 4764068 to i32*), align 4
  %v2_401989 = zext i1 %v7_401983 to i32
  store i32 %v2_401989, i32* %edi.global-to-local, align 4
  %v2_401990 = add i32 %v1_401983, 1
  %v7_401990 = icmp eq i32 %v2_401990, 0
  store i1 %v7_401990, i1* %cf.global-to-local, align 1
  store i32 %v2_401990, i32* %edx.global-to-local, align 4
  %v0_401992 = load i32, i32* %ebx.global-to-local, align 4
  %v1_401992 = udiv i32 %v0_401992, 256
  %v2_401992 = trunc i32 %v1_401992 to i8
  %v3_401992 = load i8, i8* inttoptr (i32 4763704 to i8*), align 8
  %v5_401992 = zext i1 %v7_401990 to i8
  %v6_401992 = add i8 %v3_401992, %v5_401992
  %v7_401992 = add i8 %v6_401992, %v2_401992
  %v28_401992 = zext i8 %v7_401992 to i32
  %v30_401992 = mul nuw nsw i32 %v28_401992, 256
  %v31_401992 = and i32 %v0_401992, -65281
  %v32_401992 = or i32 %v30_401992, %v31_401992
  store i32 %v32_401992, i32* %ebx.global-to-local, align 4
  %v1_401998 = load i32, i32* inttoptr (i32 4763740 to i32*), align 4
  %v2_401998 = sub i32 %v2_401990, %v1_401998
  %v7_401998 = icmp ult i32 %v2_401990, %v1_401998
  store i1 %v7_401998, i1* %cf.global-to-local, align 1
  store i32 %v2_401998, i32* %edx.global-to-local, align 4
  %v0_40199e = load i8, i8* inttoptr (i32 4764024 to i8*), align 8
  %v1_40199e = add i8 %v0_40199e, -85
  store i8 %v1_40199e, i8* inttoptr (i32 4764024 to i8*), align 8
  %v0_4019a5 = load i32, i32* %esi.global-to-local, align 4
  %v1_4019a5 = add i32 %v0_4019a5, -103
  %v5_4019a5 = icmp ugt i32 %v0_4019a5, 102
  store i1 %v5_4019a5, i1* %cf.global-to-local, align 1
  store i32 %v1_4019a5, i32* %esi.global-to-local, align 4
  call void @__pseudo_call(i32 sext (i1 ptrtoint (i1* @global_var_4019b0.7 to i1) to i32))
  %v1_4019b0 = load i32, i32* %ebx.global-to-local, align 4
  %v2_4019b0 = load i1, i1* %cf.global-to-local, align 1
  %v3_4019b0 = zext i1 %v2_4019b0 to i32
  %v4_4019b0 = add i32 %v1_4019b0, %v11_40195b
  %v5_4019b0 = add i32 %v4_4019b0, %v3_4019b0
  store i32 %v5_4019b0, i32* %eax.global-to-local, align 4
  %v0_4019b2 = load i32, i32* inttoptr (i32 4763852 to i32*), align 4
  %v1_4019b2 = load i32, i32* %edi.global-to-local, align 4
  %v2_4019b2 = sub i32 %v0_4019b2, %v1_4019b2
  store i32 %v2_4019b2, i32* inttoptr (i32 4763852 to i32*), align 4
  %v0_4019b8 = load i32, i32* %edx.global-to-local, align 4
  %v2_4019b8 = mul i32 %v0_4019b8, 2
  %v7_4019b8 = icmp ult i32 %v2_4019b8, %v0_4019b8
  store i1 %v7_4019b8, i1* %cf.global-to-local, align 1
  store i32 %v2_4019b8, i32* %edx.global-to-local, align 4
  %v0_4019ba = load i32, i32* %ecx.global-to-local, align 4
  %v1_4019ba = udiv i32 %v0_4019ba, 256
  %v2_4019ba = trunc i32 %v1_4019ba to i8
  %v3_4019ba = load i8, i8* inttoptr (i32 4764091 to i8*), align 1
  %v5_4019ba = zext i1 %v7_4019b8 to i8
  %v6_4019ba = add i8 %v2_4019ba, %v3_4019ba
  %v7_4019ba = add i8 %v6_4019ba, %v5_4019ba
  %v25_4019ba = icmp ule i8 %v7_4019ba, %v2_4019ba
  %v26_4019ba = icmp ult i8 %v6_4019ba, %v2_4019ba
  %v27_4019ba = select i1 %v7_4019b8, i1 %v25_4019ba, i1 %v26_4019ba
  %v28_4019ba = zext i8 %v7_4019ba to i32
  %v30_4019ba = mul nuw nsw i32 %v28_4019ba, 256
  %v31_4019ba = and i32 %v0_4019ba, -65281
  %v32_4019ba = or i32 %v30_4019ba, %v31_4019ba
  store i32 %v32_4019ba, i32* %ecx.global-to-local, align 4
  %v0_4019c0 = load i32, i32* inttoptr (i32 4763801 to i32*), align 4
  %v2_4019c0 = zext i1 %v27_4019ba to i32
  %v3_4019c0 = add i32 %v0_4019c0, 73
  %v4_4019c0 = add i32 %v3_4019c0, %v2_4019c0
  store i32 %v4_4019c0, i32* inttoptr (i32 4763801 to i32*), align 4
  %v1_4019c7 = or i32 %v0_4019ba, -36
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v1_4019c7, i32* %ecx.global-to-local, align 4
  %v0_4019ca = load i8, i8* inttoptr (i32 4763873 to i8*), align 1
  %v1_4019ca = add i8 %v0_4019ca, 119
  store i8 %v1_4019ca, i8* inttoptr (i32 4763873 to i8*), align 1
  %v0_4019d1 = load i32, i32* inttoptr (i32 4763995 to i32*), align 4
  %v1_4019d1 = load i32, i32* %edx.global-to-local, align 4
  %v2_4019d1 = xor i32 %v1_4019d1, %v0_4019d1
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v2_4019d1, i32* inttoptr (i32 4763995 to i32*), align 4
  %v0_4019d7 = load i32, i32* %ecx.global-to-local, align 4
  %v1_4019d7 = udiv i32 %v0_4019d7, 256
  %v2_4019d7 = trunc i32 %v1_4019d7 to i8
  %v3_4019d7 = load i8, i8* inttoptr (i32 4763901 to i8*), align 1
  %v4_4019d7 = or i8 %v2_4019d7, %v3_4019d7
  %v10_4019d7 = zext i8 %v4_4019d7 to i32
  %v12_4019d7 = mul nuw nsw i32 %v10_4019d7, 256
  %v13_4019d7 = and i32 %v0_4019d7, -65281
  %v14_4019d7 = or i32 %v12_4019d7, %v13_4019d7
  store i32 %v14_4019d7, i32* %ecx.global-to-local, align 4
  %v0_4019dd = load i32, i32* %eax.global-to-local, align 4
  %v1_4019dd = udiv i32 %v0_4019dd, 256
  %v2_4019dd = trunc i32 %v1_4019dd to i8
  %v4_4019dd = trunc i32 %v0_4019d7 to i8
  %v5_4019dd = add i8 %v2_4019dd, %v4_4019dd
  %v10_4019dd = icmp ult i8 %v5_4019dd, %v2_4019dd
  store i1 %v10_4019dd, i1* %cf.global-to-local, align 1
  %v20_4019dd = zext i8 %v5_4019dd to i32
  %v22_4019dd = mul nuw nsw i32 %v20_4019dd, 256
  %v23_4019dd = and i32 %v0_4019dd, -65281
  %v24_4019dd = or i32 %v22_4019dd, %v23_4019dd
  store i32 %v24_4019dd, i32* %eax.global-to-local, align 4
  %v3_4019df = load i8, i8* inttoptr (i32 4764080 to i8*), align 16
  %v5_4019df = zext i1 %v10_4019dd to i8
  %v6_4019df = add i8 %v3_4019df, %v4_4019d7
  %v7_4019df = add i8 %v5_4019df, %v6_4019df
  %v25_4019df = icmp ule i8 %v7_4019df, %v4_4019d7
  %v26_4019df = icmp ult i8 %v6_4019df, %v4_4019d7
  %v27_4019df = select i1 %v10_4019dd, i1 %v25_4019df, i1 %v26_4019df
  store i1 %v27_4019df, i1* %cf.global-to-local, align 1
  %v28_4019df = zext i8 %v7_4019df to i32
  %v30_4019df = mul nuw nsw i32 %v28_4019df, 256
  %v32_4019df = or i32 %v30_4019df, %v13_4019d7
  store i32 %v32_4019df, i32* %ecx.global-to-local, align 4
  %v1_4019e5 = inttoptr i32 %v24_4019dd to i8*
  %v2_4019e5 = load i8, i8* %v1_4019e5, align 1
  %v4_4019e5 = trunc i32 %v0_4019dd to i8
  %v5_4019e5 = add i8 %v2_4019e5, %v4_4019e5
  %v10_4019e5 = icmp ult i8 %v5_4019e5, %v2_4019e5
  store i1 %v10_4019e5, i1* %cf.global-to-local, align 1
  store i8 %v5_4019e5, i8* %v1_4019e5, align 1
  %v0_4019e7 = load i32, i32* %eax.global-to-local, align 4
  %v1_4019e7 = inttoptr i32 %v0_4019e7 to i8*
  %v2_4019e7 = load i8, i8* %v1_4019e7, align 1
  %v4_4019e7 = trunc i32 %v0_4019e7 to i8
  %v5_4019e7 = add i8 %v4_4019e7, %v2_4019e7
  %v10_4019e7 = icmp ult i8 %v5_4019e7, %v2_4019e7
  store i1 %v10_4019e7, i1* %cf.global-to-local, align 1
  store i8 %v5_4019e7, i8* %v1_4019e7, align 1
  %v0_4019e9 = load i32, i32* %eax.global-to-local, align 4
  %v1_4019e9 = inttoptr i32 %v0_4019e9 to i8*
  %v2_4019e9 = load i8, i8* %v1_4019e9, align 1
  %v4_4019e9 = trunc i32 %v0_4019e9 to i8
  %v5_4019e9 = add i8 %v4_4019e9, %v2_4019e9
  %v10_4019e9 = icmp ult i8 %v5_4019e9, %v2_4019e9
  store i1 %v10_4019e9, i1* %cf.global-to-local, align 1
  store i8 %v5_4019e9, i8* %v1_4019e9, align 1
  %v0_4019eb = load i32, i32* %eax.global-to-local, align 4
  %v1_4019eb = inttoptr i32 %v0_4019eb to i8*
  %v2_4019eb = load i8, i8* %v1_4019eb, align 1
  %v4_4019eb = trunc i32 %v0_4019eb to i8
  %v5_4019eb = add i8 %v4_4019eb, %v2_4019eb
  %v10_4019eb = icmp ult i8 %v5_4019eb, %v2_4019eb
  store i1 %v10_4019eb, i1* %cf.global-to-local, align 1
  store i8 %v5_4019eb, i8* %v1_4019eb, align 1
  %v0_4019ed = load i32, i32* %eax.global-to-local, align 4
  %v1_4019ed = inttoptr i32 %v0_4019ed to i8*
  %v2_4019ed = load i8, i8* %v1_4019ed, align 1
  %v4_4019ed = trunc i32 %v0_4019ed to i8
  %v5_4019ed = add i8 %v4_4019ed, %v2_4019ed
  %v10_4019ed = icmp ult i8 %v5_4019ed, %v2_4019ed
  store i1 %v10_4019ed, i1* %cf.global-to-local, align 1
  store i8 %v5_4019ed, i8* %v1_4019ed, align 1
  %v0_4019ef = load i32, i32* %edx.global-to-local, align 4
  %v1_4019ef = add i32 %v0_4019ef, 1
  %v2_4019ef = inttoptr i32 %v1_4019ef to i8*
  %v3_4019ef = load i8, i8* %v2_4019ef, align 1
  %v4_4019ef = load i32, i32* %ebx.global-to-local, align 4
  %v5_4019ef = udiv i32 %v4_4019ef, 256
  %v6_4019ef = trunc i32 %v5_4019ef to i8
  %v7_4019ef = add i8 %v6_4019ef, %v3_4019ef
  store i8 %v7_4019ef, i8* %v2_4019ef, align 1
  %v0_4019f5 = load i32, i32* %edx.global-to-local, align 4
  %v1_4019f5 = load i32, i32* %ebx.global-to-local, align 4
  %v2_4019f5 = add i32 %v1_4019f5, %v0_4019f5
  store i32 %v2_4019f5, i32* %edx.global-to-local, align 4
  %v0_4019f7 = load i32, i32* inttoptr (i32 4763751 to i32*), align 4
  %v1_4019f7 = xor i32 %v0_4019f7, 68
  store i32 %v1_4019f7, i32* inttoptr (i32 4763751 to i32*), align 4
  %v0_4019fe = load i32, i32* inttoptr (i32 4764028 to i32*), align 4
  %v1_4019fe = load i32, i32* %eax.global-to-local, align 4
  %v2_4019fe = sub i32 %v0_4019fe, %v1_4019fe
  %v7_4019fe = icmp ult i32 %v0_4019fe, %v1_4019fe
  store i32 %v2_4019fe, i32* inttoptr (i32 4764028 to i32*), align 4
  %v0_401a04 = load i32, i32* inttoptr (i32 4764144 to i32*), align 16
  %v1_401a04 = load i32, i32* %edx.global-to-local, align 4
  %v3_401a04 = zext i1 %v7_4019fe to i32
  %v4_401a04 = add i32 %v3_401a04, %v0_401a04
  %v5_401a04 = sub i32 %v4_401a04, %v1_401a04
  store i32 %v5_401a04, i32* inttoptr (i32 4764144 to i32*), align 16
  %v1_401a0a = load i32, i32* %ebx.global-to-local, align 4
  %v2_401a0a = xor i32 %v1_401a0a, %v1_401a04
  store i32 %v2_401a0a, i32* %edx.global-to-local, align 4
  store i32 0, i32* %ecx.global-to-local, align 4
  %v0_401a16 = load i32, i32* inttoptr (i32 4763852 to i32*), align 4
  %v1_401a16 = load i32, i32* %edi.global-to-local, align 4
  %v2_401a16 = xor i32 %v1_401a16, %v0_401a16
  store i32 %v2_401a16, i32* inttoptr (i32 4763852 to i32*), align 4
  %v0_401a1c = load i32, i32* inttoptr (i32 4764018 to i32*), align 4
  %v3_401a1c = add i32 %v0_401a1c, 151
  %v22_401a1c = icmp ugt i32 %v0_401a1c, -152
  store i32 %v3_401a1c, i32* inttoptr (i32 4764018 to i32*), align 4
  %v2_401a26 = zext i1 %v22_401a1c to i32
  store i32 %v2_401a26, i32* %edx.global-to-local, align 4
  %v0_401a28 = load i32, i32* inttoptr (i32 4764000 to i32*), align 32
  %v1_401a28 = or i32 %v0_401a28, 180
  store i32 %v1_401a28, i32* inttoptr (i32 4764000 to i32*), align 32
  %v0_401a32 = load i32, i32* %ebx.global-to-local, align 4
  %v1_401a32 = load i32, i32* %esi.global-to-local, align 4
  %v2_401a32 = add i32 %v1_401a32, %v0_401a32
  %v7_401a32 = icmp ult i32 %v2_401a32, %v0_401a32
  store i32 %v2_401a32, i32* %ebx.global-to-local, align 4
  %v0_401a34 = load i32, i32* %edx.global-to-local, align 4
  %v1_401a34 = load i32, i32* inttoptr (i32 4763736 to i32*), align 8
  %v3_401a34 = zext i1 %v7_401a32 to i32
  %v4_401a34 = add i32 %v1_401a34, %v0_401a34
  %v5_401a34 = add i32 %v4_401a34, %v3_401a34
  %v24_401a34 = icmp ule i32 %v5_401a34, %v0_401a34
  %v25_401a34 = icmp ult i32 %v4_401a34, %v0_401a34
  %v26_401a34 = select i1 %v7_401a32, i1 %v24_401a34, i1 %v25_401a34
  store i32 %v5_401a34, i32* %edx.global-to-local, align 4
  %v1_401a3a = udiv i32 %v2_401a32, 256
  %v4_401a3a = zext i1 %v26_401a34 to i32
  %v5_401a3a = add nuw nsw i32 %v1_401a3a, 221
  %v6_401a3a = add nuw nsw i32 %v5_401a3a, %v4_401a3a
  %v27_401a3a = mul i32 %v6_401a3a, 256
  %v29_401a3a = and i32 %v27_401a3a, 65280
  %v30_401a3a = and i32 %v2_401a32, -65281
  %v31_401a3a = or i32 %v29_401a3a, %v30_401a3a
  store i32 %v31_401a3a, i32* %ebx.global-to-local, align 4
  %v0_401a3d = load i32, i32* inttoptr (i32 4763669 to i32*), align 4
  %v2_401a3d = add i32 %v0_401a3d, %v1_401a32
  store i32 %v2_401a3d, i32* inttoptr (i32 4763669 to i32*), align 4
  %v0_401a43 = load i32, i32* inttoptr (i32 4763893 to i32*), align 4
  %v1_401a43 = xor i32 %v0_401a43, 175
  store i32 %v1_401a43, i32* inttoptr (i32 4763893 to i32*), align 4
  %v0_401a4d = load i32, i32* %edi.global-to-local, align 4
  %v1_401a4d = load i32, i32* inttoptr (i32 4763871 to i32*), align 4
  %v4_401a4d = add i32 %v1_401a4d, %v0_401a4d
  store i32 %v4_401a4d, i32* %edi.global-to-local, align 4
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 1048576, i32* %eax.global-to-local, align 4
  %v9_401a6c = call i32* @OpenJobObjectW(i32 1048576, i1 false, i16* bitcast ([13 x i8]* @global_var_48b6a3.4 to i16*))
  %v10_401a6c = ptrtoint i32* %v9_401a6c to i32
  store i32 %v10_401a6c, i32* %eax.global-to-local, align 4
  store i1 false, i1* %cf.global-to-local, align 1
  %v1_401a72 = icmp eq i32* %v9_401a6c, null
  %v1_401a74 = icmp eq i1 %v1_401a72, false
  call void @__pseudo_cond_branch(i1 %v1_401a74, i32 ptrtoint (i16** @global_var_406dd5.3 to i32))
  %v2_401a7a = mul i32 %v10_401a6c, 2
  %v7_401a7a = icmp ult i32 %v2_401a7a, %v10_401a6c
  store i32 %v2_401a7a, i32* %eax.global-to-local, align 4
  %v0_401a7c = load i32, i32* %ebx.global-to-local, align 4
  %v1_401a7c = load i32, i32* %edi.global-to-local, align 4
  %v3_401a7c = zext i1 %v7_401a7a to i32
  %v4_401a7c = sub i32 %v0_401a7c, %v1_401a7c
  %v5_401a7c = add i32 %v4_401a7c, %v3_401a7c
  %v16_401a7c = sub i32 %v4_401a7c, %v3_401a7c
  %v17_401a7c = icmp ult i32 %v0_401a7c, %v16_401a7c
  %v18_401a7c = icmp ne i32 %v1_401a7c, -1
  %v19_401a7c = or i1 %v18_401a7c, %v17_401a7c
  %v20_401a7c = icmp ult i32 %v0_401a7c, %v1_401a7c
  %v21_401a7c = select i1 %v7_401a7a, i1 %v19_401a7c, i1 %v20_401a7c
  store i32 %v5_401a7c, i32* %ebx.global-to-local, align 4
  %v0_401a7e = load i32, i32* inttoptr (i32 4763869 to i32*), align 4
  %v2_401a7e = zext i1 %v21_401a7c to i32
  %v3_401a7e = add i32 %v2_401a7e, %v0_401a7e
  %v18_401a7e = icmp ule i32 %v3_401a7e, %v0_401a7e
  %v19_401a7e = and i1 %v21_401a7c, %v18_401a7e
  store i32 %v3_401a7e, i32* inttoptr (i32 4763869 to i32*), align 4
  %v0_401a85 = load i32, i32* %esi.global-to-local, align 4
  %v1_401a85 = load i32, i32* inttoptr (i32 4764080 to i32*), align 16
  %v3_401a85 = zext i1 %v19_401a7e to i32
  %v4_401a85 = add i32 %v1_401a85, %v0_401a85
  %v5_401a85 = add i32 %v4_401a85, %v3_401a85
  store i32 %v5_401a85, i32* %esi.global-to-local, align 4
  %v0_401a8b = load i32, i32* inttoptr (i32 4763831 to i32*), align 4
  %v1_401a8b = load i32, i32* %edi.global-to-local, align 4
  %v2_401a8b = or i32 %v1_401a8b, %v0_401a8b
  store i32 %v2_401a8b, i32* inttoptr (i32 4763831 to i32*), align 4
  %v0_401a91 = load i32, i32* inttoptr (i32 4763811 to i32*), align 4
  %v3_401a91 = add i32 %v0_401a91, -185
  store i32 %v3_401a91, i32* inttoptr (i32 4763811 to i32*), align 4
  %v0_401a9b = load i32, i32* %ecx.global-to-local, align 4
  %v1_401a9b = and i32 %v0_401a9b, -65281
  %v3_401a9d = load i32, i32* %eax.global-to-local, align 4
  %v4_401a9d = udiv i32 %v3_401a9d, 256
  %v5_401a9d = trunc i32 %v4_401a9d to i8
  %v6_401a9d = add i8 %v5_401a9d, 1
  %v11_401a9d = icmp eq i8 %v6_401a9d, 0
  %v21_401a9d = zext i8 %v6_401a9d to i32
  %v23_401a9d = mul nuw nsw i32 %v21_401a9d, 256
  %v25_401a9d = or i32 %v23_401a9d, %v1_401a9b
  store i32 %v25_401a9d, i32* %ecx.global-to-local, align 4
  %v2_401a9f = zext i1 %v11_401a9d to i32
  %v3_401a9f = add i32 %v3_401a9d, 118
  %v4_401a9f = add i32 %v3_401a9f, %v2_401a9f
  %v12_401a9f = icmp ult i32 %v3_401a9d, -118
  %v13_401a9f = or i1 %v12_401a9f, %v11_401a9d
  store i32 %v4_401a9f, i32* %eax.global-to-local, align 4
  %v0_401aa2 = load i32, i32* %esi.global-to-local, align 4
  %v1_401aa2 = load i32, i32* inttoptr (i32 4764111 to i32*), align 4
  %v3_401aa2 = zext i1 %v13_401a9f to i32
  %v4_401aa2 = add i32 %v1_401aa2, %v0_401aa2
  %v5_401aa2 = add i32 %v4_401aa2, %v3_401aa2
  store i32 %v5_401aa2, i32* %esi.global-to-local, align 4
  %v0_401aa8 = load i32, i32* %ebx.global-to-local, align 4
  %v1_401aa8 = xor i32 %v0_401aa8, 39
  store i32 %v1_401aa8, i32* %ebx.global-to-local, align 4
  store i32 1, i32* %edx.global-to-local, align 4
  %v1_401ab0 = load i32, i32* inttoptr (i32 4764133 to i32*), align 4
  %v4_401ab0 = add i32 %v1_401ab0, 1
  %v16_401ab0 = icmp eq i32 %v4_401ab0, 0
  store i32 %v4_401ab0, i32* %edx.global-to-local, align 4
  %v0_401ab6 = load i32, i32* inttoptr (i32 4764049 to i32*), align 4
  %v3_401ab6 = select i1 %v16_401ab0, i32 134, i32 133
  %v4_401ab6 = add i32 %v3_401ab6, %v0_401ab6
  %v21_401ab6 = icmp ule i32 %v4_401ab6, %v0_401ab6
  %v22_401ab6 = icmp ugt i32 %v0_401ab6, -134
  %v23_401ab6 = select i1 %v16_401ab0, i1 %v21_401ab6, i1 %v22_401ab6
  store i32 %v4_401ab6, i32* inttoptr (i32 4764049 to i32*), align 4
  %v0_401ac0 = load i32, i32* inttoptr (i32 4763726 to i32*), align 4
  %v3_401ac0 = select i1 %v23_401ab6, i32 121, i32 120
  %v4_401ac0 = add i32 %v3_401ac0, %v0_401ac0
  %v21_401ac0 = icmp ule i32 %v4_401ac0, %v0_401ac0
  %v22_401ac0 = icmp ugt i32 %v0_401ac0, -121
  %v23_401ac0 = select i1 %v23_401ab6, i1 %v21_401ac0, i1 %v22_401ac0
  store i1 %v23_401ac0, i1* %cf.global-to-local, align 1
  store i32 %v4_401ac0, i32* inttoptr (i32 4763726 to i32*), align 4
  call void @__pseudo_call(i32 sext (i1 ptrtoint (i1* @global_var_401acf.8 to i1) to i32))
  %v0_401acf = load i32, i32* %eax.global-to-local, align 4
  %v1_401acf = load i32, i32* %edx.global-to-local, align 4
  %v2_401acf = add i32 %v1_401acf, %v0_401acf
  %v7_401acf = icmp ult i32 %v2_401acf, %v0_401acf
  store i1 %v7_401acf, i1* %cf.global-to-local, align 1
  store i32 %v2_401acf, i32* %eax.global-to-local, align 4
  %v0_401ad1 = load i32, i32* %ebx.global-to-local, align 4
  %v1_401ad1 = trunc i32 %v0_401ad1 to i8
  %v2_401ad1 = load i8, i8* inttoptr (i32 4763881 to i8*), align 1
  %v4_401ad1 = zext i1 %v7_401acf to i8
  %v5_401ad1 = add i8 %v1_401ad1, %v2_401ad1
  %v6_401ad1 = add i8 %v5_401ad1, %v4_401ad1
  %v24_401ad1 = icmp ule i8 %v6_401ad1, %v1_401ad1
  %v25_401ad1 = icmp ult i8 %v5_401ad1, %v1_401ad1
  %v26_401ad1 = select i1 %v7_401acf, i1 %v24_401ad1, i1 %v25_401ad1
  %v27_401ad1 = zext i8 %v6_401ad1 to i32
  %v29_401ad1 = and i32 %v0_401ad1, -256
  %v30_401ad1 = or i32 %v27_401ad1, %v29_401ad1
  store i32 %v30_401ad1, i32* %ebx.global-to-local, align 4
  %v3_401ad7 = zext i1 %v26_401ad1 to i32
  %v4_401ad7 = add i32 %v2_401acf, 52
  %v5_401ad7 = add i32 %v4_401ad7, %v3_401ad7
  %v24_401ad7 = and i32 %v5_401ad7, 255
  %v27_401ad7 = and i32 %v2_401acf, -2304
  %v13_401ad9 = or i32 %v27_401ad7, %v24_401ad7
  store i32 %v13_401ad9, i32* %eax.global-to-local, align 4
  %v0_401adc = load i32, i32* inttoptr (i32 4764106 to i32*), align 4
  %v4_401adc = sub i32 %v0_401adc, %v30_401ad1
  store i32 %v4_401adc, i32* inttoptr (i32 4764106 to i32*), align 4
  %v0_401ae2 = load i32, i32* %ecx.global-to-local, align 4
  %v1_401ae2 = or i32 %v0_401ae2, -12
  store i32 %v1_401ae2, i32* %ecx.global-to-local, align 4
  %v0_401ae5 = load i32, i32* %eax.global-to-local, align 4
  %v4_401ae5 = sub i32 %v0_401ae5, %v1_401ae2
  %v20_401ae5 = icmp ult i32 %v0_401ae5, %v1_401ae2
  store i32 %v4_401ae5, i32* %eax.global-to-local, align 4
  %v0_401ae7 = load i32, i32* inttoptr (i32 4763851 to i32*), align 4
  %v1_401ae7 = load i32, i32* %ebx.global-to-local, align 4
  %v3_401ae7 = zext i1 %v20_401ae5 to i32
  %v4_401ae7 = add i32 %v3_401ae7, %v0_401ae7
  %v5_401ae7 = sub i32 %v4_401ae7, %v1_401ae7
  store i32 %v5_401ae7, i32* inttoptr (i32 4763851 to i32*), align 4
  %v0_401aed = load i32, i32* inttoptr (i32 4763840 to i32*), align 64
  %v1_401aed = load i32, i32* %ecx.global-to-local, align 4
  %v2_401aed = add i32 %v1_401aed, %v0_401aed
  %v7_401aed = icmp ult i32 %v2_401aed, %v0_401aed
  store i32 %v2_401aed, i32* inttoptr (i32 4763840 to i32*), align 64
  %v0_401af3 = load i32, i32* %eax.global-to-local, align 4
  %v1_401af3 = load i32, i32* inttoptr (i32 4763959 to i32*), align 4
  %v3_401af3 = zext i1 %v7_401aed to i32
  %v4_401af3 = add i32 %v1_401af3, %v0_401af3
  %v5_401af3 = add i32 %v4_401af3, %v3_401af3
  store i32 %v5_401af3, i32* %eax.global-to-local, align 4
  %v1_401af9 = load i32, i32* inttoptr (i32 4763945 to i32*), align 4
  %v2_401af9 = sub i32 %v5_401af3, %v1_401af9
  %v7_401af9 = icmp ult i32 %v5_401af3, %v1_401af9
  store i1 %v7_401af9, i1* %cf.global-to-local, align 1
  %v14_401af9 = trunc i32 %v2_401af9 to i8
  store i32 %v2_401af9, i32* %eax.global-to-local, align 4
  %v1_401aff = inttoptr i32 %v2_401af9 to i8*
  %v2_401aff = load i8, i8* %v1_401aff, align 1
  %v5_401aff = add i8 %v2_401aff, %v14_401af9
  %v10_401aff = icmp ult i8 %v5_401aff, %v2_401aff
  store i1 %v10_401aff, i1* %cf.global-to-local, align 1
  store i8 %v5_401aff, i8* %v1_401aff, align 1
  %v0_401b01 = load i32, i32* %eax.global-to-local, align 4
  %v1_401b01 = inttoptr i32 %v0_401b01 to i8*
  %v2_401b01 = load i8, i8* %v1_401b01, align 1
  %v4_401b01 = trunc i32 %v0_401b01 to i8
  %v5_401b01 = add i8 %v4_401b01, %v2_401b01
  %v10_401b01 = icmp ult i8 %v5_401b01, %v2_401b01
  store i1 %v10_401b01, i1* %cf.global-to-local, align 1
  store i8 %v5_401b01, i8* %v1_401b01, align 1
  %v0_401b03 = load i32, i32* %eax.global-to-local, align 4
  %v1_401b03 = inttoptr i32 %v0_401b03 to i8*
  %v2_401b03 = load i8, i8* %v1_401b03, align 1
  %v4_401b03 = trunc i32 %v0_401b03 to i8
  %v5_401b03 = add i8 %v4_401b03, %v2_401b03
  %v10_401b03 = icmp ult i8 %v5_401b03, %v2_401b03
  store i1 %v10_401b03, i1* %cf.global-to-local, align 1
  store i8 %v5_401b03, i8* %v1_401b03, align 1
  %v0_401b05 = load i32, i32* %eax.global-to-local, align 4
  %v1_401b05 = inttoptr i32 %v0_401b05 to i8*
  %v2_401b05 = load i8, i8* %v1_401b05, align 1
  %v4_401b05 = trunc i32 %v0_401b05 to i8
  %v5_401b05 = add i8 %v4_401b05, %v2_401b05
  %v10_401b05 = icmp ult i8 %v5_401b05, %v2_401b05
  store i1 %v10_401b05, i1* %cf.global-to-local, align 1
  store i8 %v5_401b05, i8* %v1_401b05, align 1
  %v0_401b07 = load i32, i32* %eax.global-to-local, align 4
  %v1_401b07 = inttoptr i32 %v0_401b07 to i8*
  %v2_401b07 = load i8, i8* %v1_401b07, align 1
  %v4_401b07 = trunc i32 %v0_401b07 to i8
  %v5_401b07 = add i8 %v4_401b07, %v2_401b07
  %v10_401b07 = icmp ult i8 %v5_401b07, %v2_401b07
  store i1 %v10_401b07, i1* %cf.global-to-local, align 1
  store i8 %v5_401b07, i8* %v1_401b07, align 1
  %v0_401b09 = load i32, i32* %eax.global-to-local, align 4
  %v1_401b09 = inttoptr i32 %v0_401b09 to i8*
  %v2_401b09 = load i8, i8* %v1_401b09, align 1
  %v4_401b09 = trunc i32 %v0_401b09 to i8
  %v5_401b09 = add i8 %v4_401b09, %v2_401b09
  %v10_401b09 = icmp ult i8 %v5_401b09, %v2_401b09
  store i1 %v10_401b09, i1* %cf.global-to-local, align 1
  store i8 %v5_401b09, i8* %v1_401b09, align 1
  %v0_401b0b = load i32, i32* %eax.global-to-local, align 4
  %v1_401b0b = inttoptr i32 %v0_401b0b to i8*
  %v2_401b0b = load i8, i8* %v1_401b0b, align 1
  %v4_401b0b = trunc i32 %v0_401b0b to i8
  %v5_401b0b = add i8 %v4_401b0b, %v2_401b0b
  %v10_401b0b = icmp ult i8 %v5_401b0b, %v2_401b0b
  store i1 %v10_401b0b, i1* %cf.global-to-local, align 1
  store i8 %v5_401b0b, i8* %v1_401b0b, align 1
  %v0_401b0d = load i32, i32* %eax.global-to-local, align 4
  %v1_401b0d = inttoptr i32 %v0_401b0d to i8*
  %v2_401b0d = load i8, i8* %v1_401b0d, align 1
  %v4_401b0d = trunc i32 %v0_401b0d to i8
  %v5_401b0d = add i8 %v4_401b0d, %v2_401b0d
  store i8 %v5_401b0d, i8* %v1_401b0d, align 1
  %v0_401b0f = load i32, i32* %edi.global-to-local, align 4
  %v1_401b0f = add i32 %v0_401b0f, -42
  store i32 %v1_401b0f, i32* %edi.global-to-local, align 4
  %v2_401b17 = add i32 %v0_401b0f, -41
  store i32 %v2_401b17, i32* %ecx.global-to-local, align 4
  %v0_401b19 = load i32, i32* inttoptr (i32 4763652 to i32*), align 4
  %v1_401b19 = load i32, i32* %esi.global-to-local, align 4
  %v2_401b19 = sub i32 %v0_401b19, %v1_401b19
  %v7_401b19 = icmp ult i32 %v0_401b19, %v1_401b19
  store i32 %v2_401b19, i32* inttoptr (i32 4763652 to i32*), align 4
  %v0_401b1f = load i32, i32* inttoptr (i32 4763924 to i32*), align 4
  %v2_401b1f = zext i1 %v7_401b19 to i32
  %v3_401b1f = add i32 %v0_401b1f, 241
  %v4_401b1f = add i32 %v3_401b1f, %v2_401b1f
  store i32 %v4_401b1f, i32* inttoptr (i32 4763924 to i32*), align 4
  %v1_401b2e = load i32, i32* %edi.global-to-local, align 4
  %v2_401b2e = add i32 %v1_401b2e, 1
  %v1_401b30 = load i32, i32* %ebx.global-to-local, align 4
  %v2_401b30 = sub i32 %v2_401b2e, %v1_401b30
  store i32 %v2_401b30, i32* %edx.global-to-local, align 4
  %v0_401b32 = load i32, i32* inttoptr (i32 4763931 to i32*), align 4
  %v2_401b32 = or i32 %v0_401b32, %v1_401b30
  store i32 %v2_401b32, i32* inttoptr (i32 4763931 to i32*), align 4
  %v0_401b38 = load i32, i32* %eax.global-to-local, align 4
  %v1_401b38 = load i32, i32* inttoptr (i32 4763709 to i32*), align 4
  %v2_401b38 = or i32 %v1_401b38, %v0_401b38
  %v1_401b3e = xor i32 %v2_401b38, 20
  store i32 %v1_401b3e, i32* %eax.global-to-local, align 4
  %v0_401b43 = load i32, i32* %edi.global-to-local, align 4
  %v4_401b43 = mul i32 %v0_401b43, 2
  store i32 %v4_401b43, i32* %edi.global-to-local, align 4
  %v0_401b45 = load i32, i32* %ebx.global-to-local, align 4
  %v1_401b45 = load i32, i32* %edx.global-to-local, align 4
  %v2_401b45 = add i32 %v1_401b45, %v0_401b45
  %v7_401b45 = icmp ult i32 %v2_401b45, %v0_401b45
  store i32 %v2_401b45, i32* %ebx.global-to-local, align 4
  %v1_401b47 = load i32, i32* %ecx.global-to-local, align 4
  %v3_401b47 = zext i1 %v7_401b45 to i32
  %v4_401b47 = add i32 %v1_401b47, %v1_401b45
  %v5_401b47 = add i32 %v4_401b47, %v3_401b47
  store i32 %v5_401b47, i32* %edx.global-to-local, align 4
  store i32 87, i32* %esi.global-to-local, align 4
  %v0_401b4c = load i32, i32* inttoptr (i32 4764125 to i32*), align 4
  %v2_401b4c = add i32 %v0_401b4c, %v4_401b43
  store i32 %v2_401b4c, i32* inttoptr (i32 4764125 to i32*), align 4
  %v1_401b52 = trunc i32 %v5_401b47 to i8
  %v2_401b52 = add i32 %v5_401b47, 121
  %v6_401b52 = icmp ugt i8 %v1_401b52, -122
  %v15_401b52 = and i32 %v2_401b52, 255
  %v17_401b52 = and i32 %v5_401b47, -256
  %v18_401b52 = or i32 %v15_401b52, %v17_401b52
  store i32 %v18_401b52, i32* %edx.global-to-local, align 4
  %v0_401b55 = load i32, i32* inttoptr (i32 4763852 to i32*), align 4
  %v1_401b55 = load i32, i32* %esi.global-to-local, align 4
  %v3_401b55 = zext i1 %v6_401b52 to i32
  %v4_401b55 = add i32 %v1_401b55, %v0_401b55
  %v5_401b55 = add i32 %v4_401b55, %v3_401b55
  store i32 %v5_401b55, i32* inttoptr (i32 4763852 to i32*), align 4
  store i32 11, i32* %eax.global-to-local, align 4
  store i1 false, i1* %cf.global-to-local, align 1
  %v6_401b6c = call i1 @IsBadStringPtrA(i8* getelementptr inbounds ([12 x i8], [12 x i8]* @global_var_48b6b4.5, i32 0, i32 0), i32 11)
  %v7_401b6c = sext i1 %v6_401b6c to i32
  store i32 %v7_401b6c, i32* %eax.global-to-local, align 4
  store i1 false, i1* %cf.global-to-local, align 1
  %v1_401b72 = icmp eq i1 %v6_401b6c, false
  %v1_401b75 = icmp eq i1 %v1_401b72, false
  call void @__pseudo_cond_branch(i1 %v1_401b75, i32 ptrtoint (i16** @global_var_406dd5.3 to i32))
  %v0_401b7b = load i32, i32* %ebx.global-to-local, align 4
  %v1_401b7b = load i32, i32* %edi.global-to-local, align 4
  %v2_401b7b = add i32 %v1_401b7b, %v0_401b7b
  store i32 %v2_401b7b, i32* %ebx.global-to-local, align 4
  %v2_401b7d = xor i32 %v1_401b7b, %v7_401b6c
  store i32 %v2_401b7d, i32* %eax.global-to-local, align 4
  %v1_401b7f = xor i32 %v1_401b7b, -22
  store i32 %v1_401b7f, i32* %edi.global-to-local, align 4
  store i32 128, i32* inttoptr (i32 4763869 to i32*), align 4
  %v4_401b8c = add i32 %v2_401b7d, %v2_401b7b
  %v25_401b8c = icmp ult i32 %v4_401b8c, %v2_401b7b
  %v0_401b8e = load i32, i32* %esi.global-to-local, align 4
  %v3_401b8e = zext i1 %v25_401b8c to i32
  %v4_401b8e = mul i32 %v0_401b8e, 2
  %v5_401b8e = or i32 %v3_401b8e, %v4_401b8e
  store i32 %v5_401b8e, i32* %esi.global-to-local, align 4
  %v1_401b90 = add i32 %v4_401b8c, 78
  store i32 %v1_401b90, i32* %ebx.global-to-local, align 4
  %v0_401b93 = load i32, i32* %edi.global-to-local, align 4
  %v1_401b93 = or i32 %v0_401b93, 56
  store i32 %v1_401b93, i32* %edi.global-to-local, align 4
  %v0_401b96 = load i32, i32* inttoptr (i32 4763861 to i32*), align 4
  %v1_401b96 = and i32 %v0_401b96, 226
  store i32 %v1_401b96, i32* inttoptr (i32 4763861 to i32*), align 4
  store i32 114, i32* %edx.global-to-local, align 4
  %v0_401ba8 = load i32, i32* %esi.global-to-local, align 4
  %v1_401ba8 = or i32 %v0_401ba8, 39
  store i32 %v1_401ba8, i32* %esi.global-to-local, align 4
  %v1_401bab = load i32, i32* inttoptr (i32 4763888 to i32*), align 16
  %v4_401bab = add i32 %v1_401bab, 114
  %v25_401bab = icmp ugt i32 %v1_401bab, -115
  store i32 %v4_401bab, i32* %edx.global-to-local, align 4
  %v0_401bb1 = load i32, i32* %ebx.global-to-local, align 4
  %v1_401bb1 = load i32, i32* inttoptr (i32 4763838 to i32*), align 4
  %v3_401bb1 = zext i1 %v25_401bab to i32
  %v4_401bb1 = add i32 %v1_401bb1, %v0_401bb1
  %v5_401bb1 = add i32 %v4_401bb1, %v3_401bb1
  %v24_401bb1 = icmp ule i32 %v5_401bb1, %v0_401bb1
  %v25_401bb1 = icmp ult i32 %v4_401bb1, %v0_401bb1
  %v26_401bb1 = select i1 %v25_401bab, i1 %v24_401bb1, i1 %v25_401bb1
  store i1 %v26_401bb1, i1* %cf.global-to-local, align 1
  store i32 %v5_401bb1, i32* %ebx.global-to-local, align 4
  call void @__pseudo_call(i32 4201407)
  %v0_401bbf = load i32, i32* inttoptr (i32 4763777 to i32*), align 4
  %v1_401bbf = xor i32 %v0_401bbf, 142
  store i32 %v1_401bbf, i32* inttoptr (i32 4763777 to i32*), align 4
  %v0_401bc9 = load i32, i32* inttoptr (i32 4763860 to i32*), align 4
  %v1_401bc9 = and i32 %v0_401bc9, 250
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v1_401bc9, i32* inttoptr (i32 4763860 to i32*), align 4
  %v0_401bd3 = load i8, i8* inttoptr (i32 4764158 to i8*), align 2
  %v1_401bd3 = load i32, i32* %ebx.global-to-local, align 4
  %v2_401bd3 = trunc i32 %v1_401bd3 to i8
  %v5_401bd3 = sub i8 %v0_401bd3, %v2_401bd3
  store i8 %v5_401bd3, i8* inttoptr (i32 4764158 to i8*), align 2
  %v0_401bd9 = load i32, i32* %edx.global-to-local, align 4
  %v1_401bd9 = load i32, i32* inttoptr (i32 4763764 to i32*), align 4
  %v2_401bd9 = sub i32 %v0_401bd9, %v1_401bd9
  store i32 %v2_401bd9, i32* %edx.global-to-local, align 4
  %v0_401bdf = load i32, i32* %eax.global-to-local, align 4
  %v1_401bdf = load i32, i32* %ebx.global-to-local, align 4
  %tmp80 = and i32 %v1_401bdf, 65280
  %v13_401bdf = xor i32 %tmp80, %v0_401bdf
  %v3_401be1 = add i32 %v13_401bdf, -13
  %v12_401be1 = icmp ult i32 %v13_401bdf, 13
  store i32 %v3_401be1, i32* %eax.global-to-local, align 4
  %v1_401be4 = load i32, i32* inttoptr (i32 4763875 to i32*), align 4
  %v3_401be4 = zext i1 %v12_401be1 to i32
  %v4_401be4 = add i32 %v1_401be4, %v1_401bdf
  %v5_401be4 = add i32 %v4_401be4, %v3_401be4
  store i32 %v5_401be4, i32* %ebx.global-to-local, align 4
  %v0_401bea = load i32, i32* inttoptr (i32 4763857 to i32*), align 4
  %v1_401bea = load i32, i32* %edi.global-to-local, align 4
  %v2_401bea = and i32 %v1_401bea, %v0_401bea
  store i32 %v2_401bea, i32* inttoptr (i32 4763857 to i32*), align 4
  store i32 103, i32* inttoptr (i32 4764157 to i32*), align 4
  %v0_401bfa = load i32, i32* inttoptr (i32 4763765 to i32*), align 4
  %v1_401bfa = load i32, i32* %ebx.global-to-local, align 4
  %v2_401bfa = add i32 %v1_401bfa, %v0_401bfa
  store i32 %v2_401bfa, i32* inttoptr (i32 4763765 to i32*), align 4
  %v0_401c00 = load i32, i32* %edi.global-to-local, align 4
  %v1_401c00 = load i32, i32* %eax.global-to-local, align 4
  %v2_401c00 = xor i32 %v1_401c00, %v0_401c00
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v2_401c00, i32* %edi.global-to-local, align 4
  %v1_401c02 = inttoptr i32 %v1_401c00 to i8*
  %v2_401c02 = load i8, i8* %v1_401c02, align 1
  %v4_401c02 = trunc i32 %v1_401c00 to i8
  %v5_401c02 = add i8 %v2_401c02, %v4_401c02
  %v10_401c02 = icmp ult i8 %v5_401c02, %v2_401c02
  store i1 %v10_401c02, i1* %cf.global-to-local, align 1
  store i8 %v5_401c02, i8* %v1_401c02, align 1
  %v0_401c04 = load i32, i32* %eax.global-to-local, align 4
  %v1_401c04 = inttoptr i32 %v0_401c04 to i8*
  %v2_401c04 = load i8, i8* %v1_401c04, align 1
  %v4_401c04 = trunc i32 %v0_401c04 to i8
  %v5_401c04 = add i8 %v4_401c04, %v2_401c04
  store i8 %v5_401c04, i8* %v1_401c04, align 1
  %v0_401c06 = load i32, i32* %esi.global-to-local, align 4
  %v1_401c06 = add i32 %v0_401c06, 80
  %v2_401c06 = icmp ult i32 %v0_401c06, -80
  store i32 %v1_401c06, i32* %esi.global-to-local, align 4
  %v0_401c09 = load i32, i32* inttoptr (i32 4763703 to i32*), align 4
  %v2_401c09 = zext i1 %v2_401c06 to i32
  %v3_401c09 = add i32 %v0_401c09, -248
  %v4_401c09 = add i32 %v3_401c09, %v2_401c09
  %v12_401c09 = icmp ult i32 %v0_401c09, 248
  %v13_401c09 = or i1 %v2_401c06, %v12_401c09
  store i1 %v13_401c09, i1* %cf.global-to-local, align 1
  store i32 %v4_401c09, i32* inttoptr (i32 4763703 to i32*), align 4
  %v0_401c13 = load i32, i32* %eax.global-to-local, align 4
  %v1_401c13 = trunc i32 %v0_401c13 to i8
  %v2_401c13 = load i8, i8* inttoptr (i32 4763924 to i8*), align 4
  %v4_401c13 = zext i1 %v13_401c09 to i8
  %v5_401c13 = add i8 %v1_401c13, %v2_401c13
  %v6_401c13 = add i8 %v5_401c13, %v4_401c13
  %v24_401c13 = icmp ule i8 %v6_401c13, %v1_401c13
  %v25_401c13 = icmp ult i8 %v5_401c13, %v1_401c13
  %v26_401c13 = select i1 %v13_401c09, i1 %v24_401c13, i1 %v25_401c13
  %v27_401c13 = zext i8 %v6_401c13 to i32
  %v29_401c13 = and i32 %v0_401c13, -256
  %v30_401c13 = or i32 %v27_401c13, %v29_401c13
  %v1_401c19 = load i32, i32* %esi.global-to-local, align 4
  %v3_401c19 = zext i1 %v26_401c13 to i32
  %v4_401c19 = add i32 %v30_401c13, %v1_401c19
  %v5_401c19 = add i32 %v4_401c19, %v3_401c19
  store i32 %v5_401c19, i32* %eax.global-to-local, align 4
  %v0_401c1b = load i32, i32* inttoptr (i32 4764139 to i32*), align 4
  %v1_401c1b = load i32, i32* %ebx.global-to-local, align 4
  %v2_401c1b = add i32 %v1_401c1b, %v0_401c1b
  %v7_401c1b = icmp ult i32 %v2_401c1b, %v0_401c1b
  store i32 %v2_401c1b, i32* inttoptr (i32 4764139 to i32*), align 4
  store i32 1, i32* %ecx.global-to-local, align 4
  %v1_401c26 = load i32, i32* inttoptr (i32 4763763 to i32*), align 4
  %v3_401c26 = zext i1 %v7_401c1b to i32
  %v4_401c26 = add i32 %v1_401c26, 1
  %v5_401c26 = add i32 %v4_401c26, %v3_401c26
  store i32 %v5_401c26, i32* %ecx.global-to-local, align 4
  %v0_401c2c = load i32, i32* inttoptr (i32 4764080 to i32*), align 16
  %v1_401c2c = and i32 %v0_401c2c, 220
  store i32 %v1_401c2c, i32* inttoptr (i32 4764080 to i32*), align 16
  %v0_401c36 = load i32, i32* %esi.global-to-local, align 4
  %v2_401c36 = xor i32 %v5_401c26, %v0_401c36
  store i32 %v2_401c36, i32* %esi.global-to-local, align 4
  %v0_401c38 = load i32, i32* %ebx.global-to-local, align 4
  %v2_401c38 = xor i32 %v0_401c38, %v2_401c36
  store i32 %v2_401c38, i32* %ebx.global-to-local, align 4
  %v0_401c3a = load i32, i32* inttoptr (i32 4763945 to i32*), align 4
  %v3_401c3a = add i32 %v0_401c3a, 152
  %v22_401c3a = icmp ugt i32 %v0_401c3a, -153
  store i32 %v3_401c3a, i32* inttoptr (i32 4763945 to i32*), align 4
  %v0_401c44 = load i32, i32* %eax.global-to-local, align 4
  %v1_401c44 = load i32, i32* inttoptr (i32 4763720 to i32*), align 8
  %v3_401c44 = zext i1 %v22_401c3a to i32
  %v4_401c44 = add i32 %v3_401c44, %v0_401c44
  %v5_401c44 = add i32 %v4_401c44, %v1_401c44
  %v0_401c4a = load i32, i32* %ebx.global-to-local, align 4
  %v2_401c4a = xor i32 %v5_401c44, %v0_401c4a
  store i32 %v2_401c4a, i32* %ebx.global-to-local, align 4
  %v0_401c4c = load i32, i32* %edi.global-to-local, align 4
  %v1_401c4c = or i32 %v0_401c4c, -118
  store i32 %v1_401c4c, i32* %edi.global-to-local, align 4
  %v1_401c4f = load i32, i32* %ecx.global-to-local, align 4
  %v4_401c4f = add i32 %v1_401c4f, %v5_401c44
  %v18_401c4f = trunc i32 %v4_401c4f to i8
  %v25_401c4f = icmp ult i32 %v4_401c4f, %v5_401c44
  %v3_401c51 = udiv i32 %v2_401c4a, 256
  %v4_401c51 = trunc i32 %v3_401c51 to i8
  %v6_401c51 = zext i1 %v25_401c4f to i8
  %v7_401c51 = add i8 %v18_401c4f, %v4_401c51
  %v8_401c51 = add i8 %v7_401c51, %v6_401c51
  %v26_401c51 = icmp ule i8 %v8_401c51, %v18_401c4f
  %v27_401c51 = icmp ult i8 %v7_401c51, %v18_401c4f
  %v28_401c51 = select i1 %v25_401c4f, i1 %v26_401c51, i1 %v27_401c51
  %v29_401c51 = zext i8 %v8_401c51 to i32
  %v31_401c51 = and i32 %v4_401c4f, -256
  %v32_401c51 = or i32 %v29_401c51, %v31_401c51
  store i32 %v32_401c51, i32* %eax.global-to-local, align 4
  %v1_401c53 = load i32, i32* inttoptr (i32 4763705 to i32*), align 4
  %v3_401c53 = zext i1 %v28_401c51 to i32
  %v4_401c53 = add i32 %v32_401c51, %v1_401c53
  %v5_401c53 = add i32 %v4_401c53, %v3_401c53
  %v1_401c59 = xor i32 %v5_401c53, 19
  store i32 %v1_401c59, i32* %eax.global-to-local, align 4
  %v1_401c5c = trunc i32 %v1_401c4f to i8
  %v3_401c5c = udiv i32 %v1_401c4f, 256
  %v4_401c5c = trunc i32 %v3_401c5c to i8
  %v7_401c5c = add i8 %v4_401c5c, %v1_401c5c
  %v27_401c5c = icmp ult i8 %v7_401c5c, %v1_401c5c
  %v29_401c5c = zext i8 %v7_401c5c to i32
  %v31_401c5c = and i32 %v1_401c4f, -256
  %v32_401c5c = or i32 %v29_401c5c, %v31_401c5c
  store i32 %v32_401c5c, i32* %ecx.global-to-local, align 4
  %v6_401c5e = zext i1 %v27_401c5c to i32
  %v7_401c5e = add i32 %v2_401c4a, %v3_401c5c
  %v8_401c5e = add i32 %v7_401c5e, %v6_401c5e
  %v29_401c5e = and i32 %v8_401c5e, 255
  %v31_401c5e = and i32 %v2_401c4a, -256
  %v32_401c5e = or i32 %v29_401c5e, %v31_401c5e
  store i32 %v32_401c5e, i32* %ebx.global-to-local, align 4
  %v0_401c60 = load i32, i32* inttoptr (i32 4763745 to i32*), align 4
  %v2_401c60 = sub i32 %v0_401c60, %v32_401c5c
  store i32 %v2_401c60, i32* inttoptr (i32 4763745 to i32*), align 4
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 1048576, i32* %eax.global-to-local, align 4
  %v9_401c7f = call i32* @OpenJobObjectW(i32 1048576, i1 false, i16* bitcast ([13 x i8]* @global_var_48b6a3.4 to i16*))
  %v10_401c7f = ptrtoint i32* %v9_401c7f to i32
  store i32 %v10_401c7f, i32* %eax.global-to-local, align 4
  store i1 false, i1* %cf.global-to-local, align 1
  %v1_401c85 = icmp eq i32* %v9_401c7f, null
  %v1_401c87 = icmp eq i1 %v1_401c85, false
  call void @__pseudo_cond_branch(i1 %v1_401c87, i32 ptrtoint (i16** @global_var_406dd5.3 to i32))
  %v1_401c8d = udiv i32 %v10_401c7f, 256
  %v2_401c8d = trunc i32 %v1_401c8d to i8
  %v3_401c8d = load i8, i8* inttoptr (i32 4764058 to i8*), align 2
  %v4_401c8d = load i1, i1* %cf.global-to-local, align 1
  %v5_401c8d = zext i1 %v4_401c8d to i8
  %v6_401c8d = add i8 %v3_401c8d, %v2_401c8d
  %v7_401c8d = add i8 %v6_401c8d, %v5_401c8d
  %v28_401c8d = zext i8 %v7_401c8d to i32
  %v30_401c8d = mul nuw nsw i32 %v28_401c8d, 256
  %v31_401c8d = and i32 %v10_401c7f, -65281
  %v32_401c8d = or i32 %v30_401c8d, %v31_401c8d
  %v0_401c93 = load i32, i32* %edi.global-to-local, align 4
  %v1_401c93 = add i32 %v0_401c93, 35
  %v5_401c93 = icmp ugt i32 %v0_401c93, -36
  store i32 %v1_401c93, i32* %edi.global-to-local, align 4
  %v0_401c96 = load i32, i32* %ebx.global-to-local, align 4
  %v3_401c96 = zext i1 %v5_401c93 to i32
  %v4_401c96 = add i32 %v32_401c8d, %v0_401c96
  %v5_401c96 = add i32 %v4_401c96, %v3_401c96
  %v24_401c96 = icmp ule i32 %v5_401c96, %v0_401c96
  %v25_401c96 = icmp ult i32 %v4_401c96, %v0_401c96
  %v26_401c96 = select i1 %v5_401c93, i1 %v24_401c96, i1 %v25_401c96
  store i32 %v5_401c96, i32* %ebx.global-to-local, align 4
  %v1_401c98 = load i32, i32* %esi.global-to-local, align 4
  %v3_401c98 = zext i1 %v26_401c96 to i32
  %v4_401c98 = sub i32 %v32_401c8d, %v1_401c98
  %v5_401c98 = add i32 %v4_401c98, %v3_401c98
  store i32 %v5_401c98, i32* %eax.global-to-local, align 4
  %v0_401c9a = load i32, i32* inttoptr (i32 4763810 to i32*), align 4
  %v1_401c9a = xor i32 %v0_401c9a, 161
  store i32 %v1_401c9a, i32* inttoptr (i32 4763810 to i32*), align 4
  store i32 1, i32* %ecx.global-to-local, align 4
  %v1_401ca9 = load i32, i32* inttoptr (i32 4764137 to i32*), align 4
  %v4_401ca9 = add i32 %v1_401ca9, 1
  %v2_401caf = mul i32 %v4_401ca9, 2
  %v7_401caf = icmp ult i32 %v2_401caf, %v4_401ca9
  store i1 %v7_401caf, i1* %cf.global-to-local, align 1
  store i32 %v2_401caf, i32* %ecx.global-to-local, align 4
  %v0_401cb1 = load i8, i8* inttoptr (i32 4764031 to i8*), align 1
  %v1_401cb1 = add i8 %v0_401cb1, -31
  %v5_401cb1 = icmp ult i8 %v0_401cb1, 31
  store i1 %v5_401cb1, i1* %cf.global-to-local, align 1
  store i8 %v1_401cb1, i8* inttoptr (i32 4764031 to i8*), align 1
  %v0_401cb8 = load i32, i32* inttoptr (i32 4764007 to i32*), align 4
  %v2_401cb8 = zext i1 %v5_401cb1 to i32
  %v3_401cb8 = add i32 %v0_401cb8, 114
  %v4_401cb8 = add i32 %v3_401cb8, %v2_401cb8
  store i32 %v4_401cb8, i32* inttoptr (i32 4764007 to i32*), align 4
  %v0_401cbf = load i32, i32* %ecx.global-to-local, align 4
  %v1_401cbf = load i32, i32* inttoptr (i32 4764070 to i32*), align 4
  %v2_401cbf = or i32 %v1_401cbf, %v0_401cbf
  store i32 %v2_401cbf, i32* %ecx.global-to-local, align 4
  %v0_401cc5 = load i32, i32* %eax.global-to-local, align 4
  %v1_401cc5 = load i32, i32* inttoptr (i32 4764116 to i32*), align 4
  %v4_401cc5 = add i32 %v1_401cc5, %v0_401cc5
  store i32 %v4_401cc5, i32* %eax.global-to-local, align 4
  %v0_401ccb = load i32, i32* %ebx.global-to-local, align 4
  %v1_401ccb = load i32, i32* inttoptr (i32 4763859 to i32*), align 4
  %v2_401ccb = sub i32 %v0_401ccb, %v1_401ccb
  store i32 %v2_401ccb, i32* %ebx.global-to-local, align 4
  %v0_401cd1 = load i32, i32* inttoptr (i32 4764136 to i32*), align 8
  %v2_401cd1 = sub i32 %v0_401cd1, %v2_401cbf
  store i32 %v2_401cd1, i32* inttoptr (i32 4764136 to i32*), align 8
  %v0_401cd7 = load i32, i32* %esi.global-to-local, align 4
  %v1_401cd7 = load i32, i32* inttoptr (i32 4764029 to i32*), align 4
  %v2_401cd7 = sub i32 %v0_401cd7, %v1_401cd7
  %v7_401cd7 = icmp ult i32 %v0_401cd7, %v1_401cd7
  %v1_401cdd = load i32, i32* %ebx.global-to-local, align 4
  %v3_401cdd = zext i1 %v7_401cd7 to i32
  %v4_401cdd = add i32 %v1_401cdd, %v2_401cd7
  %v5_401cdd = add i32 %v3_401cdd, %v4_401cdd
  %v24_401cdd = icmp ule i32 %v5_401cdd, %v2_401cd7
  %v25_401cdd = icmp ult i32 %v4_401cdd, %v2_401cd7
  %v26_401cdd = select i1 %v7_401cd7, i1 %v24_401cdd, i1 %v25_401cdd
  store i32 %v5_401cdd, i32* %esi.global-to-local, align 4
  %v0_401cdf = load i32, i32* inttoptr (i32 4763930 to i32*), align 4
  %v3_401cdf = zext i1 %v26_401cdd to i32
  %v4_401cdf = add i32 %v0_401cdf, %v1_401cdd
  %v5_401cdf = add i32 %v3_401cdf, %v4_401cdf
  %v24_401cdf = icmp ule i32 %v5_401cdf, %v0_401cdf
  %v25_401cdf = icmp ult i32 %v4_401cdf, %v0_401cdf
  %v26_401cdf = select i1 %v26_401cdd, i1 %v24_401cdf, i1 %v25_401cdf
  store i1 %v26_401cdf, i1* %cf.global-to-local, align 1
  store i32 %v5_401cdf, i32* inttoptr (i32 4763930 to i32*), align 4
  %v0_401ce5 = load i8, i8* inttoptr (i32 4764103 to i8*), align 1
  %v1_401ce5 = add i8 %v0_401ce5, 103
  %v5_401ce5 = icmp ult i8 %v0_401ce5, -103
  store i1 %v5_401ce5, i1* %cf.global-to-local, align 1
  store i8 %v1_401ce5, i8* inttoptr (i32 4764103 to i8*), align 1
  call void @__pseudo_call(i32 0)
  %v0_401cf4 = load i32, i32* %eax.global-to-local, align 4
  %v1_401cf4 = udiv i32 %v0_401cf4, 256
  %v2_401cf4 = trunc i32 %v1_401cf4 to i8
  %v3_401cf4 = load i8, i8* inttoptr (i32 4764154 to i8*), align 2
  %v4_401cf4 = load i1, i1* %cf.global-to-local, align 1
  %v5_401cf4 = zext i1 %v4_401cf4 to i8
  %v6_401cf4 = add i8 %v2_401cf4, %v3_401cf4
  %v7_401cf4 = add i8 %v6_401cf4, %v5_401cf4
  %v25_401cf4 = icmp ule i8 %v7_401cf4, %v2_401cf4
  %v26_401cf4 = icmp ult i8 %v6_401cf4, %v2_401cf4
  %v27_401cf4 = select i1 %v4_401cf4, i1 %v25_401cf4, i1 %v26_401cf4
  %v28_401cf4 = zext i8 %v7_401cf4 to i32
  %v30_401cf4 = mul nuw nsw i32 %v28_401cf4, 256
  %v31_401cf4 = and i32 %v0_401cf4, -65281
  %v32_401cf4 = or i32 %v30_401cf4, %v31_401cf4
  store i32 %v32_401cf4, i32* %eax.global-to-local, align 4
  %v0_401cfa = load i32, i32* inttoptr (i32 4763802 to i32*), align 4
  %v2_401cfa = zext i1 %v27_401cf4 to i32
  %v3_401cfa = add i32 %v0_401cfa, 35
  %v4_401cfa = add i32 %v3_401cfa, %v2_401cfa
  store i32 %v4_401cfa, i32* inttoptr (i32 4763802 to i32*), align 4
  %v0_401d01 = load i32, i32* inttoptr (i32 4763742 to i32*), align 4
  %v1_401d01 = load i32, i32* %edi.global-to-local, align 4
  %v2_401d01 = add i32 %v1_401d01, %v0_401d01
  store i32 %v2_401d01, i32* inttoptr (i32 4763742 to i32*), align 4
  %v0_401d07 = load i32, i32* inttoptr (i32 4764050 to i32*), align 4
  %v1_401d07 = or i32 %v0_401d07, 221
  store i32 %v1_401d07, i32* inttoptr (i32 4764050 to i32*), align 4
  %v2_401d16 = add i32 %v1_401d01, 1
  %v7_401d16 = icmp eq i32 %v2_401d16, 0
  store i1 %v7_401d16, i1* %cf.global-to-local, align 1
  store i32 %v2_401d16, i32* %edx.global-to-local, align 4
  %v0_401d18 = load i8, i8* inttoptr (i32 4763809 to i8*), align 1
  %v1_401d18 = load i32, i32* %eax.global-to-local, align 4
  %v2_401d18 = trunc i32 %v1_401d18 to i8
  %v4_401d18 = zext i1 %v7_401d16 to i8
  %v5_401d18 = add i8 %v4_401d18, %v0_401d18
  %v6_401d18 = sub i8 %v5_401d18, %v2_401d18
  store i8 %v6_401d18, i8* inttoptr (i32 4763809 to i8*), align 1
  %v0_401d1e = load i32, i32* inttoptr (i32 4763767 to i32*), align 4
  %v1_401d1e = xor i32 %v0_401d1e, 9
  store i32 %v1_401d1e, i32* inttoptr (i32 4763767 to i32*), align 4
  %v0_401d25 = load i32, i32* %edx.global-to-local, align 4
  %v9_401d25 = or i32 %v0_401d25, 142
  store i32 %v9_401d25, i32* %edx.global-to-local, align 4
  %v0_401d28 = load i32, i32* inttoptr (i32 4763769 to i32*), align 4
  %v1_401d28 = load i32, i32* %ebx.global-to-local, align 4
  %v2_401d28 = sub i32 %v0_401d28, %v1_401d28
  store i32 %v2_401d28, i32* inttoptr (i32 4763769 to i32*), align 4
  %v1_401d2e = load i32, i32* %eax.global-to-local, align 4
  %v2_401d2e = xor i32 %v1_401d2e, %v9_401d25
  store i32 %v2_401d2e, i32* %edx.global-to-local, align 4
  %v0_401d32 = load i32, i32* %esi.global-to-local, align 4
  %v1_401d32 = load i32, i32* %ebx.global-to-local, align 4
  %v2_401d32 = add i32 %v1_401d32, %v0_401d32
  store i32 %v2_401d32, i32* %esi.global-to-local, align 4
  %v2_401d34 = sub i32 0, %v1_401d2e
  %v7_401d34 = icmp ne i32 %v1_401d2e, 0
  store i32 %v2_401d34, i32* %edi.global-to-local, align 4
  %v3_401d36 = select i1 %v7_401d34, i32 -27, i32 -28
  %v4_401d36 = add i32 %v3_401d36, %v1_401d32
  %v12_401d36 = icmp ult i32 %v1_401d32, 28
  %v13_401d36 = or i1 %v7_401d34, %v12_401d36
  store i32 %v4_401d36, i32* %ebx.global-to-local, align 4
  %v0_401d39 = load i32, i32* %ecx.global-to-local, align 4
  %v1_401d39 = load i32, i32* inttoptr (i32 4763663 to i32*), align 4
  %v3_401d39 = zext i1 %v13_401d36 to i32
  %v4_401d39 = add i32 %v1_401d39, %v0_401d39
  %v5_401d39 = add i32 %v4_401d39, %v3_401d39
  %v24_401d39 = icmp ule i32 %v5_401d39, %v0_401d39
  %v25_401d39 = icmp ult i32 %v4_401d39, %v0_401d39
  %v26_401d39 = select i1 %v13_401d36, i1 %v24_401d39, i1 %v25_401d39
  store i1 %v26_401d39, i1* %cf.global-to-local, align 1
  store i32 %v5_401d39, i32* %ecx.global-to-local, align 4
  %v1_401d3f = inttoptr i32 %v1_401d2e to i8*
  %v2_401d3f = load i8, i8* %v1_401d3f, align 1
  %v4_401d3f = trunc i32 %v1_401d2e to i8
  %v5_401d3f = add i8 %v4_401d3f, %v2_401d3f
  %v10_401d3f = icmp ult i8 %v5_401d3f, %v2_401d3f
  store i1 %v10_401d3f, i1* %cf.global-to-local, align 1
  store i8 %v5_401d3f, i8* %v1_401d3f, align 1
  %v0_401d41 = load i32, i32* %eax.global-to-local, align 4
  %v1_401d41 = inttoptr i32 %v0_401d41 to i8*
  %v2_401d41 = load i8, i8* %v1_401d41, align 1
  %v4_401d41 = trunc i32 %v0_401d41 to i8
  %v5_401d41 = add i8 %v4_401d41, %v2_401d41
  %v10_401d41 = icmp ult i8 %v5_401d41, %v2_401d41
  store i1 %v10_401d41, i1* %cf.global-to-local, align 1
  store i8 %v5_401d41, i8* %v1_401d41, align 1
  %v0_401d43 = load i32, i32* %eax.global-to-local, align 4
  %v1_401d43 = inttoptr i32 %v0_401d43 to i8*
  %v2_401d43 = load i8, i8* %v1_401d43, align 1
  %v4_401d43 = trunc i32 %v0_401d43 to i8
  %v5_401d43 = add i8 %v4_401d43, %v2_401d43
  %v10_401d43 = icmp ult i8 %v5_401d43, %v2_401d43
  store i1 %v10_401d43, i1* %cf.global-to-local, align 1
  store i8 %v5_401d43, i8* %v1_401d43, align 1
  %v0_401d45 = load i32, i32* %eax.global-to-local, align 4
  %v1_401d45 = inttoptr i32 %v0_401d45 to i8*
  %v2_401d45 = load i8, i8* %v1_401d45, align 1
  %v4_401d45 = trunc i32 %v0_401d45 to i8
  %v5_401d45 = add i8 %v4_401d45, %v2_401d45
  %v10_401d45 = icmp ult i8 %v5_401d45, %v2_401d45
  store i1 %v10_401d45, i1* %cf.global-to-local, align 1
  store i8 %v5_401d45, i8* %v1_401d45, align 1
  %v0_401d47 = load i32, i32* %eax.global-to-local, align 4
  %v1_401d47 = inttoptr i32 %v0_401d47 to i8*
  %v2_401d47 = load i8, i8* %v1_401d47, align 1
  %v4_401d47 = trunc i32 %v0_401d47 to i8
  %v5_401d47 = add i8 %v4_401d47, %v2_401d47
  store i8 %v5_401d47, i8* %v1_401d47, align 1
  %v0_401d49 = load i32, i32* inttoptr (i32 4764041 to i32*), align 4
  %v1_401d49 = or i32 %v0_401d49, 130
  store i32 %v1_401d49, i32* inttoptr (i32 4764041 to i32*), align 4
  %v0_401d53 = load i32, i32* inttoptr (i32 4763918 to i32*), align 4
  %v1_401d53 = or i32 %v0_401d53, 17
  store i32 %v1_401d53, i32* inttoptr (i32 4763918 to i32*), align 4
  %v0_401d5a = load i32, i32* inttoptr (i32 4763817 to i32*), align 4
  %v1_401d5a = load i32, i32* %ebx.global-to-local, align 4
  %v4_401d5a = add i32 %v1_401d5a, %v0_401d5a
  %v25_401d5a = icmp ult i32 %v4_401d5a, %v0_401d5a
  store i32 %v4_401d5a, i32* inttoptr (i32 4763817 to i32*), align 4
  %v0_401d60 = load i32, i32* inttoptr (i32 4763892 to i32*), align 4
  %v2_401d60 = zext i1 %v25_401d5a to i32
  %v3_401d60 = add i32 %v0_401d60, -244
  %v4_401d60 = add i32 %v3_401d60, %v2_401d60
  %v12_401d60 = icmp ult i32 %v0_401d60, 244
  %v13_401d60 = or i1 %v25_401d5a, %v12_401d60
  store i32 %v4_401d60, i32* inttoptr (i32 4763892 to i32*), align 4
  %v0_401d6a = load i32, i32* %edi.global-to-local, align 4
  %v1_401d6a = load i32, i32* inttoptr (i32 4763776 to i32*), align 128
  %v3_401d6a = zext i1 %v13_401d60 to i32
  %v4_401d6a = add i32 %v1_401d6a, %v0_401d6a
  %v5_401d6a = add i32 %v4_401d6a, %v3_401d6a
  store i32 %v5_401d6a, i32* %edi.global-to-local, align 4
  %v0_401d70 = load i32, i32* %esi.global-to-local, align 4
  %v1_401d70 = load i32, i32* inttoptr (i32 4764079 to i32*), align 4
  %v2_401d70 = sub i32 %v0_401d70, %v1_401d70
  store i32 %v2_401d70, i32* %esi.global-to-local, align 4
  %v2_401d7b = add i32 %v2_401d70, 1
  store i32 %v2_401d7b, i32* %edx.global-to-local, align 4
  %v0_401d7d = load i32, i32* inttoptr (i32 4764059 to i32*), align 4
  %v1_401d7d = load i32, i32* %eax.global-to-local, align 4
  %v2_401d7d = or i32 %v1_401d7d, %v0_401d7d
  store i32 %v2_401d7d, i32* inttoptr (i32 4764059 to i32*), align 4
  %v1_401d83 = udiv i32 %v2_401d7b, 256
  %v2_401d83 = trunc i32 %v1_401d83 to i8
  %v7_401d83 = icmp ult i8 %v2_401d83, 28
  %v3_401d83 = mul nuw i32 %v1_401d83, 256
  %v16_401d83 = add i32 %v3_401d83, 58368
  %v18_401d83 = and i32 %v16_401d83, 65280
  %v19_401d83 = and i32 %v2_401d7b, -65281
  %v20_401d83 = or i32 %v18_401d83, %v19_401d83
  store i32 %v20_401d83, i32* %edx.global-to-local, align 4
  %v0_401d86 = load i32, i32* inttoptr (i32 4763714 to i32*), align 4
  %v1_401d86 = load i32, i32* %ebx.global-to-local, align 4
  %v3_401d86 = zext i1 %v7_401d83 to i32
  %v4_401d86 = sub i32 %v0_401d86, %v1_401d86
  %v5_401d86 = add i32 %v4_401d86, %v3_401d86
  store i32 %v5_401d86, i32* inttoptr (i32 4763714 to i32*), align 4
  %v0_401d8c = load i32, i32* inttoptr (i32 4763888 to i32*), align 16
  %v1_401d8c = xor i32 %v0_401d8c, 44
  store i32 %v1_401d8c, i32* inttoptr (i32 4763888 to i32*), align 16
  %v0_401d93 = load i32, i32* %edi.global-to-local, align 4
  %v1_401d93 = load i32, i32* inttoptr (i32 4764024 to i32*), align 8
  %v4_401d93 = add i32 %v1_401d93, %v0_401d93
  %v25_401d93 = icmp ult i32 %v4_401d93, %v0_401d93
  store i1 %v25_401d93, i1* %cf.global-to-local, align 1
  store i32 %v4_401d93, i32* %edi.global-to-local, align 4
  store i32 0, i32* %eax.global-to-local, align 4
  %v4_401da1 = call i32* @EncodePointer(i32* null)
  %v5_401da1 = ptrtoint i32* %v4_401da1 to i32
  store i32 %v5_401da1, i32* %eax.global-to-local, align 4
  store i32 1, i32* %edx.global-to-local, align 4
  %v1_401dac = load i32, i32* inttoptr (i32 4763918 to i32*), align 4
  %v2_401dac = load i1, i1* %cf.global-to-local, align 1
  %v3_401dac = zext i1 %v2_401dac to i32
  %v4_401dac = add i32 %v1_401dac, 1
  %v5_401dac = add i32 %v4_401dac, %v3_401dac
  store i32 %v5_401dac, i32* %edx.global-to-local, align 4
  %v0_401db2 = load i32, i32* %ebx.global-to-local, align 4
  %v1_401db2 = load i32, i32* %edi.global-to-local, align 4
  %v2_401db2 = add i32 %v1_401db2, %v0_401db2
  store i32 %v2_401db2, i32* %ebx.global-to-local, align 4
  %v2_401db9 = add i32 %v1_401db2, 1
  %v7_401db9 = icmp eq i32 %v2_401db9, 0
  store i32 %v2_401db9, i32* %ecx.global-to-local, align 4
  %v3_401dbb = zext i1 %v7_401db9 to i32
  %v4_401dbb = add i32 %v5_401dac, %v5_401da1
  %v5_401dbb = add i32 %v4_401dbb, %v3_401dbb
  store i32 %v5_401dbb, i32* %eax.global-to-local, align 4
  %v1_401dbd = load i32, i32* inttoptr (i32 4763805 to i32*), align 4
  %v2_401dbd = sub i32 %v5_401dac, %v1_401dbd
  %v7_401dbd = icmp ult i32 %v5_401dac, %v1_401dbd
  store i1 %v7_401dbd, i1* %cf.global-to-local, align 1
  store i32 %v2_401dbd, i32* %edx.global-to-local, align 4
  %v0_401dc3 = load i8, i8* inttoptr (i32 4763780 to i8*), align 4
  %v1_401dc3 = add i8 %v0_401dc3, -116
  %v5_401dc3 = icmp ult i8 %v0_401dc3, 116
  store i1 %v5_401dc3, i1* %cf.global-to-local, align 1
  store i8 %v1_401dc3, i8* inttoptr (i32 4763780 to i8*), align 4
  %v0_401dca = load i8, i8* inttoptr (i32 4764147 to i8*), align 1
  %v1_401dca = add i8 %v0_401dca, -94
  store i8 %v1_401dca, i8* inttoptr (i32 4764147 to i8*), align 1
  %v0_401dd1 = load i32, i32* %eax.global-to-local, align 4
  %v1_401dd1 = load i32, i32* inttoptr (i32 4764146 to i32*), align 4
  %v2_401dd1 = sub i32 %v0_401dd1, %v1_401dd1
  %v7_401dd1 = icmp ult i32 %v0_401dd1, %v1_401dd1
  store i32 %v2_401dd1, i32* %eax.global-to-local, align 4
  %v0_401dd7 = load i32, i32* %edi.global-to-local, align 4
  %v2_401dd7 = zext i1 %v7_401dd1 to i32
  %v3_401dd7 = add i32 %v0_401dd7, -87
  %v4_401dd7 = add i32 %v3_401dd7, %v2_401dd7
  %v12_401dd7 = icmp ult i32 %v0_401dd7, 87
  %v13_401dd7 = or i1 %v7_401dd1, %v12_401dd7
  store i32 %v4_401dd7, i32* %edi.global-to-local, align 4
  %v1_401dda = load i32, i32* inttoptr (i32 4763900 to i32*), align 4
  %v3_401dda = zext i1 %v13_401dd7 to i32
  %v4_401dda = add i32 %v1_401dda, %v4_401dd7
  %v5_401dda = add i32 %v4_401dda, %v3_401dda
  store i32 %v5_401dda, i32* %edi.global-to-local, align 4
  %v0_401de0 = load i32, i32* inttoptr (i32 4763953 to i32*), align 4
  %v2_401de0 = add i32 %v0_401de0, %v2_401dd1
  %v7_401de0 = icmp ult i32 %v2_401de0, %v0_401de0
  store i32 %v2_401de0, i32* inttoptr (i32 4763953 to i32*), align 4
  %v0_401de6 = load i32, i32* %esi.global-to-local, align 4
  %v1_401de6 = load i32, i32* inttoptr (i32 4763723 to i32*), align 4
  %v3_401de6 = zext i1 %v7_401de0 to i32
  %v4_401de6 = add i32 %v1_401de6, %v0_401de6
  %v5_401de6 = add i32 %v4_401de6, %v3_401de6
  %v24_401de6 = icmp ule i32 %v5_401de6, %v0_401de6
  %v25_401de6 = icmp ult i32 %v4_401de6, %v0_401de6
  %v26_401de6 = select i1 %v7_401de0, i1 %v24_401de6, i1 %v25_401de6
  store i1 %v26_401de6, i1* %cf.global-to-local, align 1
  store i32 %v5_401de6, i32* %esi.global-to-local, align 4
  %v0_401dec = load i8, i8* inttoptr (i32 4764042 to i8*), align 2
  %v1_401dec = load i32, i32* %edx.global-to-local, align 4
  %v2_401dec = trunc i32 %v1_401dec to i8
  %v3_401dec = sub i8 %v0_401dec, %v2_401dec
  store i8 %v3_401dec, i8* inttoptr (i32 4764042 to i8*), align 2
  %v0_401df2 = load i32, i32* inttoptr (i32 4763754 to i32*), align 4
  %v2_401df2 = add i32 %v1_401dec, %v0_401df2
  store i32 %v2_401df2, i32* inttoptr (i32 4763754 to i32*), align 4
  %v0_401df8 = load i32, i32* %esi.global-to-local, align 4
  %v1_401df8 = load i32, i32* inttoptr (i32 4763996 to i32*), align 4
  %v2_401df8 = or i32 %v1_401df8, %v0_401df8
  store i32 %v2_401df8, i32* %esi.global-to-local, align 4
  %v0_401dfe = load i32, i32* %ecx.global-to-local, align 4
  %v1_401dfe = load i32, i32* %ebx.global-to-local, align 4
  %v2_401dfe = add i32 %v1_401dfe, %v0_401dfe
  %v7_401dfe = icmp ult i32 %v2_401dfe, %v0_401dfe
  store i32 %v2_401dfe, i32* %ecx.global-to-local, align 4
  %v0_401e00 = load i32, i32* %edx.global-to-local, align 4
  %v1_401e00 = load i32, i32* inttoptr (i32 4764078 to i32*), align 4
  %v3_401e00 = zext i1 %v7_401dfe to i32
  %v4_401e00 = add i32 %v1_401e00, %v0_401e00
  %v5_401e00 = add i32 %v4_401e00, %v3_401e00
  %v24_401e00 = icmp ule i32 %v5_401e00, %v0_401e00
  %v25_401e00 = icmp ult i32 %v4_401e00, %v0_401e00
  %v26_401e00 = select i1 %v7_401dfe, i1 %v24_401e00, i1 %v25_401e00
  store i1 %v26_401e00, i1* %cf.global-to-local, align 1
  store i32 %v5_401e00, i32* %edx.global-to-local, align 4
  call void @__pseudo_call(i32 4201998)
  %v0_401e0e = load i32, i32* %eax.global-to-local, align 4
  %v1_401e0e45 = add i32 %v0_401e0e, 2304
  %v18_401e0e = and i32 %v1_401e0e45, 65280
  %v19_401e0e = and i32 %v0_401e0e, -65281
  %v20_401e0e = or i32 %v18_401e0e, %v19_401e0e
  %v1_401e11 = load i32, i32* %edx.global-to-local, align 4
  %v2_401e11 = sub i32 %v20_401e0e, %v1_401e11
  store i32 %v2_401e11, i32* %eax.global-to-local, align 4
  %v0_401e13 = load i32, i32* inttoptr (i32 4764088 to i32*), align 8
  %v1_401e13 = load i32, i32* %edi.global-to-local, align 4
  %v2_401e13 = and i32 %v1_401e13, %v0_401e13
  store i32 %v2_401e13, i32* inttoptr (i32 4764088 to i32*), align 8
  %v0_401e19 = load i32, i32* inttoptr (i32 4763922 to i32*), align 4
  %v1_401e19 = load i32, i32* %ebx.global-to-local, align 4
  %v2_401e19 = sub i32 %v0_401e19, %v1_401e19
  store i32 %v2_401e19, i32* inttoptr (i32 4763922 to i32*), align 4
  %v0_401e1f = load i32, i32* inttoptr (i32 4763944 to i32*), align 8
  %v1_401e1f = load i32, i32* %edi.global-to-local, align 4
  %v2_401e1f = add i32 %v1_401e1f, %v0_401e1f
  store i32 %v2_401e1f, i32* inttoptr (i32 4763944 to i32*), align 8
  %v0_401e25 = load i32, i32* %esi.global-to-local, align 4
  %v1_401e25 = add i32 %v0_401e25, -68
  %v5_401e25 = icmp ugt i32 %v0_401e25, 67
  store i32 %v1_401e25, i32* %esi.global-to-local, align 4
  %v0_401e28 = load i32, i32* inttoptr (i32 4763893 to i32*), align 4
  %v2_401e28 = zext i1 %v5_401e25 to i32
  %v3_401e28 = add i32 %v0_401e28, 133
  %v4_401e28 = add i32 %v3_401e28, %v2_401e28
  store i32 %v4_401e28, i32* inttoptr (i32 4763893 to i32*), align 4
  %v0_401e32 = load i32, i32* inttoptr (i32 4763690 to i32*), align 4
  %v1_401e32 = xor i32 %v0_401e32, 149
  store i32 %v1_401e32, i32* inttoptr (i32 4763690 to i32*), align 4
  %v0_401e3c = load i32, i32* inttoptr (i32 4763965 to i32*), align 4
  %v1_401e3c = xor i32 %v0_401e3c, 69
  store i32 %v1_401e3c, i32* inttoptr (i32 4763965 to i32*), align 4
  %v0_401e43 = load i32, i32* %eax.global-to-local, align 4
  %v1_401e43 = load i32, i32* inttoptr (i32 4763934 to i32*), align 4
  %v4_401e43 = add i32 %v1_401e43, %v0_401e43
  %v18_401e43 = trunc i32 %v4_401e43 to i8
  %v25_401e43 = icmp ult i32 %v4_401e43, %v0_401e43
  store i1 %v25_401e43, i1* %cf.global-to-local, align 1
  store i32 %v4_401e43, i32* %eax.global-to-local, align 4
  %v0_401e49 = load i32, i32* %ecx.global-to-local, align 4
  %v1_401e49 = add i32 %v0_401e49, 1219603237
  %v2_401e49 = inttoptr i32 %v1_401e49 to i8*
  %v3_401e49 = load i8, i8* %v2_401e49, align 1
  %v6_401e49 = add i8 %v3_401e49, %v18_401e43
  store i8 %v6_401e49, i8* %v2_401e49, align 1
  %v0_401e4f = load i32, i32* %eax.global-to-local, align 4
  %v1_401e4f = udiv i32 %v0_401e4f, 256
  %v2_401e4f = trunc i32 %v1_401e4f to i8
  %v6_401e4f25 = mul nuw nsw i32 %v1_401e4f, 2
  %v6_401e4f = trunc i32 %v6_401e4f25 to i8
  %v11_401e4f = icmp ult i8 %v6_401e4f, %v2_401e4f
  store i1 %v11_401e4f, i1* %cf.global-to-local, align 1
  %v21_401e4f = mul i32 %v1_401e4f, 512
  %v23_401e4f = and i32 %v21_401e4f, 65024
  %v24_401e4f = and i32 %v0_401e4f, -65281
  %v25_401e4f = or i32 %v23_401e4f, %v24_401e4f
  store i32 %v25_401e4f, i32* %eax.global-to-local, align 4
  %v1_401e51 = inttoptr i32 %v25_401e4f to i8*
  %v2_401e51 = load i8, i8* %v1_401e51, align 1
  %v4_401e51 = trunc i32 %v0_401e4f to i8
  %v5_401e51 = add i8 %v2_401e51, %v4_401e51
  %v10_401e51 = icmp ult i8 %v5_401e51, %v2_401e51
  store i1 %v10_401e51, i1* %cf.global-to-local, align 1
  store i8 %v5_401e51, i8* %v1_401e51, align 1
  %v0_401e53 = load i32, i32* %ecx.global-to-local, align 4
  %v1_401e53 = inttoptr i32 %v0_401e53 to i8*
  %v2_401e53 = load i8, i8* %v1_401e53, align 1
  %v3_401e53 = load i32, i32* %eax.global-to-local, align 4
  %v4_401e53 = trunc i32 %v3_401e53 to i8
  %v5_401e53 = add i8 %v4_401e53, %v2_401e53
  store i8 %v5_401e53, i8* %v1_401e53, align 1
  %v0_401e55 = load i32, i32* %eax.global-to-local, align 4
  %v1_401e55 = add i32 %v0_401e55, 4764074
  store i32 %v1_401e55, i32* %eax.global-to-local, align 4
  %v0_401e5a = load i32, i32* %ebx.global-to-local, align 4
  %v1_401e5a = add i32 %v0_401e5a, 98
  %v12_401e5a = trunc i32 %v1_401e5a to i8
  store i32 %v1_401e5a, i32* %ebx.global-to-local, align 4
  %v0_401e5d = load i32, i32* %ecx.global-to-local, align 4
  %v1_401e5d = and i32 %v0_401e5d, -256
  store i1 false, i1* %cf.global-to-local, align 1
  %v19_401e5f = or i32 %v1_401e5d, 134
  store i32 %v19_401e5f, i32* %ecx.global-to-local, align 4
  %v2_401e62 = load i8, i8* inttoptr (i32 4763918 to i8*), align 2
  %v3_401e62 = sub i8 %v12_401e5a, %v2_401e62
  %v18_401e62 = zext i8 %v3_401e62 to i32
  %v20_401e62 = and i32 %v1_401e5a, -256
  %v21_401e62 = or i32 %v18_401e62, %v20_401e62
  store i32 %v21_401e62, i32* %ebx.global-to-local, align 4
  %v1_401e68 = and i32 %v1_401e55, 116
  store i32 %v1_401e68, i32* %eax.global-to-local, align 4
  store i32 1, i32* %edx.global-to-local, align 4
  %v1_401e70 = load i32, i32* inttoptr (i32 4763804 to i32*), align 4
  %v0_401e76 = load i32, i32* %edi.global-to-local, align 4
  %v1_401e76 = add i32 %v0_401e76, 11
  %v5_401e76 = icmp ult i32 %v0_401e76, -11
  store i32 %v1_401e76, i32* %edi.global-to-local, align 4
  %v0_401e79 = load i32, i32* %esi.global-to-local, align 4
  %v2_401e79 = zext i1 %v5_401e76 to i32
  %v3_401e79 = add i32 %v0_401e79, 113
  %v4_401e79 = add i32 %v3_401e79, %v2_401e79
  store i32 %v4_401e79, i32* %esi.global-to-local, align 4
  %v4_401e70 = or i32 %v1_401e68, 1
  %v2_401e7c = add i32 %v4_401e70, %v1_401e70
  store i32 %v2_401e7c, i32* %edx.global-to-local, align 4
  store i1 false, i1* %cf.global-to-local, align 1
  %v8_401e90 = call i1 @SetEnvironmentVariableW(i16* bitcast ([13 x i8]* @global_var_48b685.2 to i16*), i16* bitcast ([17 x i8]* @global_var_48b692.1 to i16*))
  %v9_401e90 = sext i1 %v8_401e90 to i32
  %v12_401e90 = inttoptr i32 %v9_401e90 to i8*
  store i32 %v9_401e90, i32* %eax.global-to-local, align 4
  store i32 -120, i32* %ecx.global-to-local, align 4
  store i32 0, i32* %edi.global-to-local, align 4
  %v0_401ea6 = load i32, i32* inttoptr (i32 4763797 to i32*), align 4
  %v1_401ea6 = or i32 %v0_401ea6, 62
  store i32 %v1_401ea6, i32* inttoptr (i32 4763797 to i32*), align 4
  store i32 -207, i32* %ecx.global-to-local, align 4
  store i32 1, i32* %edx.global-to-local, align 4
  %v1_401eb5 = load i32, i32* inttoptr (i32 4763779 to i32*), align 4
  %v5_401eb5 = add i32 %v1_401eb5, 2
  %v24_401eb5 = icmp ugt i32 %v1_401eb5, -3
  store i32 %v5_401eb5, i32* %edx.global-to-local, align 4
  %v0_401ebb = load i32, i32* %ebx.global-to-local, align 4
  %v1_401ebb = udiv i32 %v0_401ebb, 256
  %v2_401ebb = trunc i32 %v1_401ebb to i8
  %v4_401ebb = trunc i32 %v0_401ebb to i8
  %v6_401ebb = zext i1 %v24_401eb5 to i8
  %v7_401ebb = sub i8 %v2_401ebb, %v4_401ebb
  %v8_401ebb = add i8 %v7_401ebb, %v6_401ebb
  %v19_401ebb = sub i8 %v7_401ebb, %v6_401ebb
  %v20_401ebb = icmp ult i8 %v2_401ebb, %v19_401ebb
  %v21_401ebb = icmp ne i8 %v4_401ebb, -1
  %v22_401ebb = or i1 %v21_401ebb, %v20_401ebb
  %v23_401ebb = icmp ult i8 %v2_401ebb, %v4_401ebb
  %v24_401ebb = select i1 %v24_401eb5, i1 %v22_401ebb, i1 %v23_401ebb
  %v38_401ebb = zext i8 %v8_401ebb to i32
  %v40_401ebb = mul nuw nsw i32 %v38_401ebb, 256
  %v41_401ebb = and i32 %v0_401ebb, -65281
  %v42_401ebb = or i32 %v40_401ebb, %v41_401ebb
  store i32 %v42_401ebb, i32* %ebx.global-to-local, align 4
  %v0_401ebd = load i32, i32* %esi.global-to-local, align 4
  %v4_401ebd = zext i1 %v24_401ebb to i32
  %v5_401ebd = add i32 %v0_401ebd, %v9_401e90
  %v6_401ebd = add i32 %v5_401ebd, %v4_401ebd
  store i32 %v6_401ebd, i32* %esi.global-to-local, align 4
  %v0_401ebf = load i32, i32* inttoptr (i32 4764121 to i32*), align 4
  %v1_401ebf = or i32 %v0_401ebf, 118
  store i32 %v1_401ebf, i32* inttoptr (i32 4764121 to i32*), align 4
  %v0_401ec6 = load i32, i32* inttoptr (i32 4764022 to i32*), align 4
  %v1_401ec6 = or i32 %v0_401ec6, 162
  store i32 %v1_401ec6, i32* inttoptr (i32 4764022 to i32*), align 4
  %v0_401ed0 = load i32, i32* %edx.global-to-local, align 4
  %v1_401ed0 = load i32, i32* inttoptr (i32 4763944 to i32*), align 8
  %v2_401ed0 = or i32 %v1_401ed0, %v0_401ed0
  store i32 %v2_401ed0, i32* %edx.global-to-local, align 4
  %v0_401ed6 = load i32, i32* inttoptr (i32 4763833 to i32*), align 4
  %v1_401ed6 = or i32 %v0_401ed6, 141
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v1_401ed6, i32* inttoptr (i32 4763833 to i32*), align 4
  %v0_401ee0 = load i32, i32* %ebx.global-to-local, align 4
  %v1_401ee0 = udiv i32 %v0_401ee0, 256
  %v2_401ee0 = trunc i32 %v1_401ee0 to i8
  %v3_401ee0 = load i8, i8* inttoptr (i32 4763659 to i8*), align 1
  %v6_401ee0 = add i8 %v2_401ee0, %v3_401ee0
  %v26_401ee0 = icmp ult i8 %v6_401ee0, %v2_401ee0
  %v28_401ee0 = zext i8 %v6_401ee0 to i32
  %v30_401ee0 = mul nuw nsw i32 %v28_401ee0, 256
  %v31_401ee0 = and i32 %v0_401ee0, -65281
  %v32_401ee0 = or i32 %v30_401ee0, %v31_401ee0
  store i32 %v32_401ee0, i32* %ebx.global-to-local, align 4
  %v0_401ee6 = load i32, i32* %ecx.global-to-local, align 4
  %v2_401ee6 = zext i1 %v26_401ee0 to i32
  %v3_401ee6 = add i32 %v0_401ee6, 72
  %v4_401ee6 = add i32 %v3_401ee6, %v2_401ee6
  %v12_401ee6 = icmp ult i32 %v0_401ee6, -72
  %v13_401ee6 = or i1 %v12_401ee6, %v26_401ee0
  store i1 %v13_401ee6, i1* %cf.global-to-local, align 1
  store i32 %v4_401ee6, i32* %ecx.global-to-local, align 4
  call void @__pseudo_call(i32 4202225)
  %v0_401ef1 = load i32, i32* %esi.global-to-local, align 4
  %v3_401ef1 = load i1, i1* %cf.global-to-local, align 1
  %v4_401ef1 = zext i1 %v3_401ef1 to i32
  %v5_401ef1 = sub i32 %v0_401ef1, %v9_401e90
  %v6_401ef1 = add i32 %v4_401ef1, %v5_401ef1
  %v17_401ef1 = sub i32 %v5_401ef1, %v4_401ef1
  %v18_401ef1 = icmp ult i32 %v0_401ef1, %v17_401ef1
  %v19_401ef1 = icmp ne i8* %v12_401e90, inttoptr (i32 -1 to i8*)
  %v20_401ef1 = or i1 %v19_401ef1, %v18_401ef1
  %v21_401ef1 = icmp ult i32 %v0_401ef1, %v9_401e90
  %v22_401ef1 = select i1 %v3_401ef1, i1 %v20_401ef1, i1 %v21_401ef1
  store i32 %v6_401ef1, i32* %esi.global-to-local, align 4
  %v0_401ef3 = load i32, i32* %ecx.global-to-local, align 4
  %v1_401ef3 = load i32, i32* %edx.global-to-local, align 4
  %v3_401ef3 = zext i1 %v22_401ef1 to i32
  %v4_401ef3 = add i32 %v1_401ef3, %v0_401ef3
  %v5_401ef3 = add i32 %v4_401ef3, %v3_401ef3
  store i32 %v5_401ef3, i32* %ecx.global-to-local, align 4
  %v0_401ef5 = load i32, i32* inttoptr (i32 4763837 to i32*), align 4
  %v2_401ef5 = or i32 %v5_401ef3, %v0_401ef5
  store i32 %v2_401ef5, i32* inttoptr (i32 4763837 to i32*), align 4
  %v0_401efb = load i32, i32* %ebx.global-to-local, align 4
  %v1_401efb = load i32, i32* %esi.global-to-local, align 4
  %v2_401efb = add i32 %v1_401efb, %v0_401efb
  store i32 %v2_401efb, i32* %ebx.global-to-local, align 4
  %v0_401efd = load i32, i32* %ecx.global-to-local, align 4
  %v1_401efd = load i32, i32* inttoptr (i32 4763832 to i32*), align 8
  %v2_401efd = sub i32 %v0_401efd, %v1_401efd
  store i32 %v2_401efd, i32* %ecx.global-to-local, align 4
  %v0_401f03 = load i32, i32* inttoptr (i32 4763667 to i32*), align 4
  %v1_401f03 = or i32 %v0_401f03, 118
  store i32 %v1_401f03, i32* inttoptr (i32 4763667 to i32*), align 4
  %v0_401f0a = load i32, i32* inttoptr (i32 4763835 to i32*), align 4
  %v2_401f0a = sub i32 %v0_401f0a, %v2_401efd
  store i32 %v2_401f0a, i32* inttoptr (i32 4763835 to i32*), align 4
  %v0_401f10 = load i32, i32* %ecx.global-to-local, align 4
  %v1_401f10 = or i32 %v0_401f10, 37
  store i32 %v1_401f10, i32* %ecx.global-to-local, align 4
  %v0_401f13 = load i32, i32* %ebx.global-to-local, align 4
  %v1_401f13 = add i32 %v0_401f13, -60
  store i32 %v1_401f13, i32* %ebx.global-to-local, align 4
  %v0_401f16 = load i32, i32* inttoptr (i32 4763767 to i32*), align 4
  %v2_401f16 = or i32 %v0_401f16, %v1_401f10
  store i32 %v2_401f16, i32* inttoptr (i32 4763767 to i32*), align 4
  %v0_401f1c = load i32, i32* %ecx.global-to-local, align 4
  %v1_401f1c = load i32, i32* %esi.global-to-local, align 4
  %v2_401f1c = xor i32 %v1_401f1c, %v0_401f1c
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v2_401f1c, i32* %ecx.global-to-local, align 4
  %v3_401f1e = load i8, i8* %v12_401e90, align 1
  %v6_401f1e = sext i1 %v8_401e90 to i8
  %v6_401f22 = udiv i32 %v9_401e90, 256
  %v7_401f22 = trunc i32 %v6_401f22 to i8
  %factor = mul nsw i8 %v6_401f1e, 2
  %v7_401f20 = add i8 %v7_401f22, %factor
  %v8_401f22 = add i8 %v7_401f20, %v3_401f1e
  store i8 %v8_401f22, i8* %v12_401e90, align 1
  %v0_401f29 = load i32, i32* inttoptr (i32 4763720 to i32*), align 8
  %v3_401f29 = sub i32 %v0_401f29, %v9_401e90
  store i32 %v3_401f29, i32* inttoptr (i32 4763720 to i32*), align 8
  %v0_401f2f = load i32, i32* %ebx.global-to-local, align 4
  %v1_401f2f = add i32 %v0_401f2f, 7
  store i32 %v1_401f2f, i32* %ebx.global-to-local, align 4
  %v0_401f32 = load i32, i32* inttoptr (i32 4763978 to i32*), align 4
  %v1_401f32 = load i32, i32* %edi.global-to-local, align 4
  %v2_401f32 = xor i32 %v1_401f32, %v0_401f32
  store i32 %v2_401f32, i32* inttoptr (i32 4763978 to i32*), align 4
  %v1_401f38 = load i32, i32* inttoptr (i32 4764019 to i32*), align 4
  %v4_401f38 = add i32 %v1_401f38, %v1_401f2f
  %v25_401f38 = icmp ult i32 %v4_401f38, %v1_401f2f
  store i32 %v4_401f38, i32* %ebx.global-to-local, align 4
  store i32 1, i32* %edx.global-to-local, align 4
  %v1_401f43 = load i32, i32* inttoptr (i32 4763807 to i32*), align 4
  %v3_401f43 = zext i1 %v25_401f38 to i32
  %v4_401f43 = add i32 %v1_401f43, 1
  %v5_401f43 = add i32 %v4_401f43, %v3_401f43
  store i32 %v5_401f43, i32* %edx.global-to-local, align 4
  %v0_401f49 = load i32, i32* inttoptr (i32 4764087 to i32*), align 4
  %v1_401f49 = xor i32 %v0_401f49, 102
  store i32 %v1_401f49, i32* inttoptr (i32 4764087 to i32*), align 4
  %v2_401f50 = load i32, i32* inttoptr (i32 4763976 to i32*), align 8
  %v3_401f50 = or i32 %v2_401f50, %v9_401e90
  store i32 %v3_401f50, i32* %eax.global-to-local, align 4
  %v0_401f56 = load i32, i32* %edi.global-to-local, align 4
  %v1_401f56 = load i32, i32* inttoptr (i32 4764155 to i32*), align 4
  %v4_401f56 = add i32 %v1_401f56, %v0_401f56
  store i32 %v4_401f56, i32* %edi.global-to-local, align 4
  %v0_401f5c = load i32, i32* %esi.global-to-local, align 4
  %v1_401f5c = load i32, i32* inttoptr (i32 4763917 to i32*), align 4
  %v2_401f5c = or i32 %v1_401f5c, %v0_401f5c
  store i32 %v2_401f5c, i32* %esi.global-to-local, align 4
  %v3_401f62 = add i32 %v3_401f50, -61
  store i32 %v3_401f62, i32* %eax.global-to-local, align 4
  %v0_401f65 = load i32, i32* %ebx.global-to-local, align 4
  %v1_401f65 = or i32 %v0_401f65, -73
  store i32 %v1_401f65, i32* %ebx.global-to-local, align 4
  %v0_401f68 = load i32, i32* inttoptr (i32 4763689 to i32*), align 4
  %v3_401f68 = add i32 %v0_401f68, 21
  %v22_401f68 = icmp ugt i32 %v0_401f68, -22
  store i1 %v22_401f68, i1* %cf.global-to-local, align 1
  store i32 %v3_401f68, i32* inttoptr (i32 4763689 to i32*), align 4
  %v0_401f6f = load i8, i8* inttoptr (i32 4763662 to i8*), align 2
  %v1_401f6f = add i8 %v0_401f6f, -68
  %v5_401f6f = icmp ult i8 %v0_401f6f, 68
  store i1 %v5_401f6f, i1* %cf.global-to-local, align 1
  store i8 %v1_401f6f, i8* inttoptr (i32 4763662 to i8*), align 2
  %v0_401f76 = load i32, i32* %edx.global-to-local, align 4
  %v1_401f76 = trunc i32 %v0_401f76 to i8
  %v2_401f76 = load i8, i8* inttoptr (i32 4764036 to i8*), align 4
  %v3_401f76 = or i8 %v1_401f76, %v2_401f76
  %v9_401f76 = zext i8 %v3_401f76 to i32
  %v11_401f76 = and i32 %v0_401f76, -256
  %v12_401f76 = or i32 %v9_401f76, %v11_401f76
  store i32 %v12_401f76, i32* %edx.global-to-local, align 4
  %v0_401f7c = load i32, i32* inttoptr (i32 4763956 to i32*), align 4
  %v1_401f7c = load i32, i32* %edi.global-to-local, align 4
  %v2_401f7c = and i32 %v1_401f7c, %v0_401f7c
  store i32 %v2_401f7c, i32* inttoptr (i32 4763956 to i32*), align 4
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 1048576, i32* %eax.global-to-local, align 4
  %v10_401f9b = call i32* @OpenJobObjectW(i32 1048576, i1 false, i16* bitcast ([13 x i8]* @global_var_48b6a3.4 to i16*))
  %v11_401f9b = ptrtoint i32* %v10_401f9b to i32
  store i32 %v11_401f9b, i32* %eax.global-to-local, align 4
  store i1 false, i1* %cf.global-to-local, align 1
  %v1_401fa1 = icmp eq i32* %v10_401f9b, null
  %v1_401fa3 = icmp eq i1 %v1_401fa1, false
  call void @__pseudo_cond_branch(i1 %v1_401fa3, i32 ptrtoint (i16** @global_var_406dd5.3 to i32))
  %v0_401fa9 = load i8, i8* inttoptr (i32 4764110 to i8*), align 2
  %v1_401fa9 = add i8 %v0_401fa9, -28
  store i8 %v1_401fa9, i8* inttoptr (i32 4764110 to i8*), align 2
  %v1_401fb0 = load i32, i32* inttoptr (i32 4763952 to i32*), align 16
  %v2_401fb0 = or i32 %v1_401fb0, %v11_401f9b
  store i1 false, i1* %cf.global-to-local, align 1
  %v5_401fb0 = trunc i32 %v2_401fb0 to i8
  store i32 %v2_401fb0, i32* %eax.global-to-local, align 4
  %v0_401fb6 = load i8, i8* inttoptr (i32 4763702 to i8*), align 2
  %v3_401fb6 = and i8 %v0_401fb6, %v5_401fb0
  store i8 %v3_401fb6, i8* inttoptr (i32 4763702 to i8*), align 2
  %v0_401fbc = load i32, i32* %esi.global-to-local, align 4
  %v1_401fbc = load i32, i32* %ebx.global-to-local, align 4
  %v2_401fbc = add i32 %v1_401fbc, %v0_401fbc
  %v7_401fbc = icmp ult i32 %v2_401fbc, %v0_401fbc
  store i32 %v2_401fbc, i32* %esi.global-to-local, align 4
  %v1_401fbe = load i32, i32* inttoptr (i32 4764022 to i32*), align 4
  %v3_401fbe = zext i1 %v7_401fbc to i32
  %v4_401fbe = add i32 %v1_401fbe, %v2_401fbc
  %v5_401fbe = add i32 %v3_401fbe, %v4_401fbe
  %v24_401fbe = icmp ule i32 %v5_401fbe, %v2_401fbc
  %v25_401fbe = icmp ult i32 %v4_401fbe, %v2_401fbc
  %v26_401fbe = select i1 %v7_401fbc, i1 %v24_401fbe, i1 %v25_401fbe
  store i32 %v5_401fbe, i32* %esi.global-to-local, align 4
  %v0_401fc4 = load i32, i32* inttoptr (i32 4764045 to i32*), align 4
  %v3_401fc4 = select i1 %v26_401fbe, i32 217, i32 216
  %v4_401fc4 = add i32 %v3_401fc4, %v0_401fc4
  store i32 %v4_401fc4, i32* inttoptr (i32 4764045 to i32*), align 4
  %v0_401fce = load i32, i32* inttoptr (i32 4764036 to i32*), align 4
  %v1_401fce = load i32, i32* %ebx.global-to-local, align 4
  %v2_401fce = add i32 %v1_401fce, %v0_401fce
  %v7_401fce = icmp ult i32 %v2_401fce, %v0_401fce
  store i32 %v2_401fce, i32* inttoptr (i32 4764036 to i32*), align 4
  %v0_401fd4 = load i32, i32* inttoptr (i32 4764143 to i32*), align 4
  %v2_401fd4 = zext i1 %v7_401fce to i32
  %v3_401fd4 = add i32 %v0_401fd4, 75
  %v4_401fd4 = add i32 %v3_401fd4, %v2_401fd4
  store i32 %v4_401fd4, i32* inttoptr (i32 4764143 to i32*), align 4
  %v0_401fdb = load i32, i32* inttoptr (i32 4763895 to i32*), align 4
  %v1_401fdb = load i32, i32* %esi.global-to-local, align 4
  %v2_401fdb = and i32 %v1_401fdb, %v0_401fdb
  store i32 %v2_401fdb, i32* inttoptr (i32 4763895 to i32*), align 4
  %v0_401fe1 = load i32, i32* inttoptr (i32 4763680 to i32*), align 32
  %v3_401fe1 = add i32 %v0_401fe1, -103
  %v12_401fe1 = icmp ult i32 %v0_401fe1, 103
  store i32 %v3_401fe1, i32* inttoptr (i32 4763680 to i32*), align 32
  store i32 1, i32* %ecx.global-to-local, align 4
  %v1_401fed = load i32, i32* inttoptr (i32 4763893 to i32*), align 4
  %v4_401fed = select i1 %v12_401fe1, i32 2, i32 1
  %v5_401fed = add i32 %v4_401fed, %v1_401fed
  store i32 %v5_401fed, i32* %ecx.global-to-local, align 4
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 21, i32* %edx.global-to-local, align 4
  %v0_401ffb = load i8, i8* inttoptr (i32 4764007 to i8*), align 1
  %v5_401ffb = add i8 %v0_401ffb, -21
  %v21_401ffb = icmp ult i8 %v0_401ffb, 21
  store i1 %v21_401ffb, i1* %cf.global-to-local, align 1
  store i8 %v5_401ffb, i8* inttoptr (i32 4764007 to i8*), align 1
  %v0_402001 = load i8, i8* inttoptr (i32 4764067 to i8*), align 1
  %v1_402001 = add i8 %v0_402001, -19
  store i8 %v1_402001, i8* inttoptr (i32 4764067 to i8*), align 1
  %v0_402008 = load i32, i32* inttoptr (i32 4764077 to i32*), align 4
  %v1_402008 = load i32, i32* %ebx.global-to-local, align 4
  %v2_402008 = add i32 %v1_402008, %v0_402008
  %v7_402008 = icmp ult i32 %v2_402008, %v0_402008
  store i32 %v2_402008, i32* inttoptr (i32 4764077 to i32*), align 4
  %v0_40200e = load i32, i32* inttoptr (i32 4764106 to i32*), align 4
  %v1_40200e = load i32, i32* %eax.global-to-local, align 4
  %v3_40200e = zext i1 %v7_402008 to i32
  %v4_40200e = add i32 %v1_40200e, %v0_40200e
  %v5_40200e = add i32 %v4_40200e, %v3_40200e
  %v24_40200e = icmp ule i32 %v5_40200e, %v0_40200e
  %v25_40200e = icmp ult i32 %v4_40200e, %v0_40200e
  %v26_40200e = select i1 %v7_402008, i1 %v24_40200e, i1 %v25_40200e
  store i1 %v26_40200e, i1* %cf.global-to-local, align 1
  store i32 %v5_40200e, i32* inttoptr (i32 4764106 to i32*), align 4
  call void @__pseudo_call(i32 0)
  %v0_40201c = load i32, i32* inttoptr (i32 4764131 to i32*), align 4
  %v1_40201c = load i1, i1* %cf.global-to-local, align 1
  %v2_40201c = zext i1 %v1_40201c to i32
  %v3_40201c = add i32 %v0_40201c, 29
  %v4_40201c = add i32 %v3_40201c, %v2_40201c
  store i32 %v4_40201c, i32* inttoptr (i32 4764131 to i32*), align 4
  %v0_402023 = load i32, i32* inttoptr (i32 4763787 to i32*), align 4
  %v1_402023 = load i32, i32* %edi.global-to-local, align 4
  %v2_402023 = xor i32 %v1_402023, %v0_402023
  store i32 %v2_402023, i32* inttoptr (i32 4763787 to i32*), align 4
  %v1_402029 = load i32, i32* %ecx.global-to-local, align 4
  %v2_402029 = xor i32 %v1_402029, %v1_402023
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v2_402029, i32* %edi.global-to-local, align 4
  %v0_40202b = load i8, i8* inttoptr (i32 4764004 to i8*), align 4
  %v2_40202b = trunc i32 %v1_402029 to i8
  %v5_40202b = add i8 %v0_40202b, %v2_40202b
  %v25_40202b = icmp ult i8 %v5_40202b, %v0_40202b
  store i1 %v25_40202b, i1* %cf.global-to-local, align 1
  store i8 %v5_40202b, i8* inttoptr (i32 4764004 to i8*), align 4
  %v0_402031 = load i32, i32* %ecx.global-to-local, align 4
  %v1_402031 = udiv i32 %v0_402031, 256
  %v2_402031 = trunc i32 %v1_402031 to i8
  %v4_402031 = trunc i32 %v0_402031 to i8
  %v6_402031 = zext i1 %v25_40202b to i8
  %v7_402031 = add i8 %v2_402031, %v4_402031
  %v8_402031 = add i8 %v7_402031, %v6_402031
  %v26_402031 = icmp ule i8 %v8_402031, %v2_402031
  %v27_402031 = icmp ult i8 %v7_402031, %v2_402031
  %v28_402031 = select i1 %v25_40202b, i1 %v26_402031, i1 %v27_402031
  %v29_402031 = zext i8 %v8_402031 to i32
  %v31_402031 = mul nuw nsw i32 %v29_402031, 256
  %v32_402031 = and i32 %v0_402031, -65281
  %v33_402031 = or i32 %v31_402031, %v32_402031
  store i32 %v33_402031, i32* %ecx.global-to-local, align 4
  %v0_402033 = load i32, i32* %esi.global-to-local, align 4
  %v2_402033 = zext i1 %v28_402031 to i32
  %v3_402033 = add i32 %v0_402033, 64
  %v11_402033 = icmp ult i32 %v0_402033, -64
  %v12_402033 = or i1 %v11_402033, %v28_402031
  %v1_402036 = load i32, i32* %edx.global-to-local, align 4
  %v3_402036 = zext i1 %v12_402033 to i32
  %v4_402033 = add i32 %v3_402033, %v1_402036
  %v4_402036 = add i32 %v4_402033, %v2_402033
  %v5_402036 = add i32 %v4_402036, %v3_402036
  store i32 %v5_402036, i32* %esi.global-to-local, align 4
  %v0_402038 = load i32, i32* %eax.global-to-local, align 4
  %v0_402038.tr = trunc i32 %v0_402038 to i8
  %v3_402038 = and i8 %v0_402038.tr, 80
  %v7_40203b = add i8 %v3_402038, %v8_402031
  %v27_40203b = icmp ult i8 %v7_40203b, %v3_402038
  store i1 %v27_40203b, i1* %cf.global-to-local, align 1
  %v29_40203b = zext i8 %v7_40203b to i32
  store i32 %v29_40203b, i32* %eax.global-to-local, align 4
  %v3_40203d = load i8, i8* inttoptr (i32 4763913 to i8*), align 1
  %v10_40203d = zext i8 %v3_40203d to i32
  %v12_40203d = mul nuw nsw i32 %v10_40203d, 256
  %v14_40203d = or i32 %v12_40203d, %v29_40203b
  store i32 %v14_40203d, i32* %eax.global-to-local, align 4
  %v1_402043 = load i32, i32* %edi.global-to-local, align 4
  %v2_402043 = xor i32 %v1_402043, %v5_402036
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v2_402043, i32* %esi.global-to-local, align 4
  %v0_402045 = load i8, i8* inttoptr (i32 4763860 to i8*), align 4
  %v6_402045 = sub i8 %v0_402045, %v3_40203d
  store i8 %v6_402045, i8* inttoptr (i32 4763860 to i8*), align 4
  %v0_40204b = load i32, i32* inttoptr (i32 4763895 to i32*), align 4
  %v1_40204b = or i32 %v0_40204b, 54
  store i32 %v1_40204b, i32* inttoptr (i32 4763895 to i32*), align 4
  %v0_402052 = load i32, i32* %edx.global-to-local, align 4
  %v1_402052 = add i32 %v0_402052, 23
  %v1_402055 = add i32 %v0_402052, 69
  %v5_402055 = icmp ugt i32 %v1_402052, -47
  store i32 %v1_402055, i32* %edx.global-to-local, align 4
  %v0_402058 = load i32, i32* %esi.global-to-local, align 4
  %v1_402058 = load i32, i32* %eax.global-to-local, align 4
  %v3_402058 = zext i1 %v5_402055 to i32
  %v4_402058 = add i32 %v1_402058, %v0_402058
  %v5_402058 = add i32 %v4_402058, %v3_402058
  %v24_402058 = icmp ule i32 %v5_402058, %v0_402058
  %v25_402058 = icmp ult i32 %v4_402058, %v0_402058
  %v26_402058 = select i1 %v5_402055, i1 %v24_402058, i1 %v25_402058
  store i1 %v26_402058, i1* %cf.global-to-local, align 1
  store i32 %v5_402058, i32* %esi.global-to-local, align 4
  %v0_40205a = load i32, i32* %ecx.global-to-local, align 4
  %v1_40205a = udiv i32 %v0_40205a, 256
  %v2_40205a = trunc i32 %v1_40205a to i8
  %v3_40205a = load i8, i8* inttoptr (i32 4763681 to i8*), align 1
  %v4_40205a = sub i8 %v2_40205a, %v3_40205a
  %v9_40205a = icmp ult i8 %v2_40205a, %v3_40205a
  store i1 %v9_40205a, i1* %cf.global-to-local, align 1
  %v19_40205a = zext i8 %v4_40205a to i32
  %v21_40205a = mul nuw nsw i32 %v19_40205a, 256
  %v22_40205a = and i32 %v0_40205a, -65281
  %v23_40205a = or i32 %v21_40205a, %v22_40205a
  store i32 %v23_40205a, i32* %ecx.global-to-local, align 4
  %v0_402060 = load i8, i8* inttoptr (i32 4763715 to i8*), align 1
  %v1_402060 = add i8 %v0_402060, 61
  %v5_402060 = icmp ult i8 %v0_402060, -61
  store i1 %v5_402060, i1* %cf.global-to-local, align 1
  store i8 %v1_402060, i8* inttoptr (i32 4763715 to i8*), align 1
  %v0_402067 = load i32, i32* %eax.global-to-local, align 4
  %v1_402067 = inttoptr i32 %v0_402067 to i8*
  %v2_402067 = load i8, i8* %v1_402067, align 1
  %v4_402067 = trunc i32 %v0_402067 to i8
  %v5_402067 = add i8 %v4_402067, %v2_402067
  %v10_402067 = icmp ult i8 %v5_402067, %v2_402067
  store i1 %v10_402067, i1* %cf.global-to-local, align 1
  store i8 %v5_402067, i8* %v1_402067, align 1
  %v0_402069 = load i32, i32* %eax.global-to-local, align 4
  %v1_402069 = inttoptr i32 %v0_402069 to i8*
  %v2_402069 = load i8, i8* %v1_402069, align 1
  %v4_402069 = trunc i32 %v0_402069 to i8
  %v5_402069 = add i8 %v4_402069, %v2_402069
  %v10_402069 = icmp ult i8 %v5_402069, %v2_402069
  store i1 %v10_402069, i1* %cf.global-to-local, align 1
  store i8 %v5_402069, i8* %v1_402069, align 1
  %v0_40206b = load i32, i32* %ebx.global-to-local, align 4
  %v1_40206b = add i32 %v0_40206b, 28970439
  %v2_40206b = inttoptr i32 %v1_40206b to i8*
  %v3_40206b = load i8, i8* %v2_40206b, align 1
  %v4_40206b = load i32, i32* %eax.global-to-local, align 4
  %v5_40206b = trunc i32 %v4_40206b to i8
  %v6_40206b = add i8 %v5_40206b, %v3_40206b
  %v11_40206b = icmp ult i8 %v6_40206b, %v3_40206b
  store i1 %v11_40206b, i1* %cf.global-to-local, align 1
  store i8 %v6_40206b, i8* %v2_40206b, align 1
  %v0_402071 = load i32, i32* %eax.global-to-local, align 4
  %v1_402071 = inttoptr i32 %v0_402071 to i8*
  %v2_402071 = load i8, i8* %v1_402071, align 1
  %v4_402071 = trunc i32 %v0_402071 to i8
  %v5_402071 = add i8 %v4_402071, %v2_402071
  %v10_402071 = icmp ult i8 %v5_402071, %v2_402071
  store i1 %v10_402071, i1* %cf.global-to-local, align 1
  store i8 %v5_402071, i8* %v1_402071, align 1
  %v0_402073 = load i32, i32* %ebx.global-to-local, align 4
  %v1_402073 = inttoptr i32 %v0_402073 to i8*
  %v2_402073 = load i8, i8* %v1_402073, align 1
  %v3_402073 = load i32, i32* %edx.global-to-local, align 4
  %v4_402073 = trunc i32 %v3_402073 to i8
  %v5_402073 = add i8 %v4_402073, %v2_402073
  %v10_402073 = icmp ult i8 %v5_402073, %v2_402073
  store i1 %v10_402073, i1* %cf.global-to-local, align 1
  store i8 %v5_402073, i8* %v1_402073, align 1
  %v0_402075 = load i32, i32* %eax.global-to-local, align 4
  %v1_402075 = load i1, i1* %cf.global-to-local, align 1
  %v2_402075 = zext i1 %v1_402075 to i32
  %v3_402075 = add i32 %v0_402075, 4764125
  %v4_402075 = add i32 %v3_402075, %v2_402075
  store i32 %v4_402075, i32* %eax.global-to-local, align 4
  %v0_40207a = load i32, i32* inttoptr (i32 4763944 to i32*), align 8
  %v1_40207a = load i32, i32* %edi.global-to-local, align 4
  %v2_40207a = add i32 %v1_40207a, %v0_40207a
  store i32 %v2_40207a, i32* inttoptr (i32 4763944 to i32*), align 8
  %v0_402080 = load i32, i32* %esi.global-to-local, align 4
  %v2_402080 = sub i32 %v0_402080, %v1_40207a
  %v7_402080 = icmp ult i32 %v0_402080, %v1_40207a
  store i32 %v2_402080, i32* %esi.global-to-local, align 4
  %v0_402082 = load i32, i32* inttoptr (i32 4764074 to i32*), align 4
  %v2_402082 = zext i1 %v7_402080 to i32
  %v3_402082 = add i32 %v0_402082, 112
  %v4_402082 = add i32 %v3_402082, %v2_402082
  %v20_402082 = icmp ule i32 %v4_402082, %v0_402082
  %v21_402082 = icmp ugt i32 %v0_402082, -113
  %v22_402082 = select i1 %v7_402080, i1 %v20_402082, i1 %v21_402082
  store i32 %v4_402082, i32* inttoptr (i32 4764074 to i32*), align 4
  store i32 1, i32* %ecx.global-to-local, align 4
  %v1_40208e = load i32, i32* inttoptr (i32 4763705 to i32*), align 4
  %v3_40208e = zext i1 %v22_402082 to i32
  store i32 0, i32* %eax.global-to-local, align 4
  %v5_40208e = add i32 %v1_40208e, 20
  %v3_402096 = add i32 %v5_40208e, %v3_40208e
  store i32 %v3_402096, i32* %ecx.global-to-local, align 4
  %v0_402099 = load i32, i32* inttoptr (i32 4763676 to i32*), align 4
  %v2_402099 = xor i32 %v3_402096, %v0_402099
  store i32 %v2_402099, i32* inttoptr (i32 4763676 to i32*), align 4
  %v0_40209f = load i32, i32* %esi.global-to-local, align 4
  %v1_40209f = load i32, i32* %eax.global-to-local, align 4
  %v4_40209f = add i32 %v1_40209f, %v0_40209f
  store i32 %v4_40209f, i32* %esi.global-to-local, align 4
  store i1 false, i1* %cf.global-to-local, align 1
  %v8_4020b3 = call i1 @SetEnvironmentVariableW(i16* bitcast ([13 x i8]* @global_var_48b685.2 to i16*), i16* bitcast ([17 x i8]* @global_var_48b692.1 to i16*))
  %v9_4020b3 = sext i1 %v8_4020b3 to i32
  store i32 %v9_4020b3, i32* %eax.global-to-local, align 4
  %v0_4020b9 = load i32, i32* %ebx.global-to-local, align 4
  %v2_4020b9 = mul i32 %v0_4020b9, 2
  %v7_4020b9 = icmp ult i32 %v2_4020b9, %v0_4020b9
  store i1 %v7_4020b9, i1* %cf.global-to-local, align 1
  store i32 %v2_4020b9, i32* %ebx.global-to-local, align 4
  %v1_4020bb = udiv i32 %v9_4020b3, 256
  %v2_4020bb = trunc i32 %v1_4020bb to i8
  %v3_4020bb = load i8, i8* inttoptr (i32 4764158 to i8*), align 2
  %v4_4020bb = sub i8 %v2_4020bb, %v3_4020bb
  %v9_4020bb = icmp ult i8 %v2_4020bb, %v3_4020bb
  %v19_4020bb = zext i8 %v4_4020bb to i32
  %v21_4020bb = mul nuw nsw i32 %v19_4020bb, 256
  %v22_4020bb = select i1 %v8_4020b3, i32 -65281, i32 0
  %v23_4020bb = or i32 %v21_4020bb, %v22_4020bb
  store i32 %v23_4020bb, i32* %eax.global-to-local, align 4
  %v0_4020c1 = load i32, i32* inttoptr (i32 4764125 to i32*), align 4
  %v2_4020c1 = zext i1 %v9_4020bb to i32
  %v3_4020c1 = add i32 %v0_4020c1, 227
  %v4_4020c1 = add i32 %v3_4020c1, %v2_4020c1
  store i32 %v4_4020c1, i32* inttoptr (i32 4764125 to i32*), align 4
  store i32 -99, i32* %ecx.global-to-local, align 4
  %v0_4020d3 = load i32, i32* %esi.global-to-local, align 4
  %v1_4020d3 = load i32, i32* %edi.global-to-local, align 4
  %v4_4020d3 = sub i32 %v0_4020d3, %v1_4020d3
  %v20_4020d3 = icmp ult i32 %v0_4020d3, %v1_4020d3
  store i1 %v20_4020d3, i1* %cf.global-to-local, align 1
  store i32 %v4_4020d3, i32* %esi.global-to-local, align 4
  %v0_4020d5 = load i32, i32* %eax.global-to-local, align 4
  %v1_4020d5 = trunc i32 %v0_4020d5 to i8
  %v2_4020d5 = load i8, i8* inttoptr (i32 4764136 to i8*), align 8
  %v4_4020d5 = zext i1 %v20_4020d3 to i8
  %v5_4020d5 = add i8 %v2_4020d5, %v4_4020d5
  %v6_4020d5 = add i8 %v5_4020d5, %v1_4020d5
  %v27_4020d5 = zext i8 %v6_4020d5 to i32
  %v29_4020d5 = and i32 %v0_4020d5, -256
  %v30_4020d5 = or i32 %v27_4020d5, %v29_4020d5
  %v31_4020d5 = inttoptr i32 %v30_4020d5 to i8*
  store i32 %v30_4020d5, i32* %eax.global-to-local, align 4
  %v0_4020db = load i32, i32* %ebx.global-to-local, align 4
  %v1_4020db = add i32 %v0_4020db, -96
  %v1_4020de = xor i32 %v1_4020db, -90
  store i32 %v1_4020de, i32* %ebx.global-to-local, align 4
  store i32 50, i32* %edx.global-to-local, align 4
  %v0_4020e9 = load i32, i32* inttoptr (i32 4764153 to i32*), align 4
  %v2_4020e9 = or i32 %v0_4020e9, -99
  store i32 %v2_4020e9, i32* inttoptr (i32 4764153 to i32*), align 4
  %v1_4020ef = and i32 %v1_4020de, -85
  %v1_4020f2 = load i32, i32* %edi.global-to-local, align 4
  %v4_4020f2 = add i32 %v1_4020f2, %v1_4020ef
  store i32 %v4_4020f2, i32* %ebx.global-to-local, align 4
  %v0_4020f4 = load i32, i32* %esi.global-to-local, align 4
  %v1_4020f4 = load i32, i32* inttoptr (i32 4763967 to i32*), align 4
  %v2_4020f4 = or i32 %v1_4020f4, %v0_4020f4
  store i32 %v2_4020f4, i32* %esi.global-to-local, align 4
  %v0_4020fa = load i32, i32* %edx.global-to-local, align 4
  %v1_4020fa = load i32, i32* inttoptr (i32 4763916 to i32*), align 4
  %v4_4020fa = add i32 %v1_4020fa, %v0_4020fa
  store i32 %v4_4020fa, i32* %edx.global-to-local, align 4
  %v2_402100 = add i32 %v4_4020fa, %v2_4020f4
  %v7_402100 = icmp ult i32 %v2_402100, %v2_4020f4
  store i1 %v7_402100, i1* %cf.global-to-local, align 1
  store i32 %v2_402100, i32* %esi.global-to-local, align 4
  call void @__pseudo_call(i32 4202762)
  %v0_40210a = load i32, i32* inttoptr (i32 4764024 to i32*), align 8
  %v1_40210a = load i1, i1* %cf.global-to-local, align 1
  %v2_40210a = zext i1 %v1_40210a to i32
  %v3_40210a = add i32 %v0_40210a, -19
  %v4_40210a = add i32 %v3_40210a, %v2_40210a
  store i32 %v4_40210a, i32* inttoptr (i32 4764024 to i32*), align 8
  %v0_402111 = load i32, i32* %ebx.global-to-local, align 4
  store i1 false, i1* %cf.global-to-local, align 1
  %v13_402111 = xor i32 %v0_402111, 6656
  store i32 %v13_402111, i32* %ebx.global-to-local, align 4
  %v0_402114 = load i8, i8* inttoptr (i32 4763923 to i8*), align 1
  %v1_402114 = load i32, i32* %edx.global-to-local, align 4
  %v2_402114 = udiv i32 %v1_402114, 256
  %v3_402114 = trunc i32 %v2_402114 to i8
  %v4_402114 = add i8 %v3_402114, %v0_402114
  store i8 %v4_402114, i8* inttoptr (i32 4763923 to i8*), align 1
  %v0_40211a = load i32, i32* %ecx.global-to-local, align 4
  %v1_40211a = load i32, i32* %edi.global-to-local, align 4
  %v2_40211a = sub i32 %v0_40211a, %v1_40211a
  %v7_40211a = icmp ult i32 %v0_40211a, %v1_40211a
  store i32 %v2_40211a, i32* %ecx.global-to-local, align 4
  %v0_40211c = load i32, i32* %edx.global-to-local, align 4
  %v2_40211c = zext i1 %v7_40211a to i32
  %v3_40211c = add i32 %v0_40211c, 49
  %v4_40211c = add i32 %v3_40211c, %v2_40211c
  %v21_40211c = icmp ule i32 %v4_40211c, %v0_40211c
  %v22_40211c = icmp ugt i32 %v0_40211c, -50
  %v23_40211c = select i1 %v7_40211a, i1 %v21_40211c, i1 %v22_40211c
  store i1 %v23_40211c, i1* %cf.global-to-local, align 1
  store i32 %v4_40211c, i32* %edx.global-to-local, align 4
  %v0_40211f = load i8, i8* inttoptr (i32 4763675 to i8*), align 1
  %v4_40211f = sub i8 %v0_40211f, %v6_4020d5
  store i8 %v4_40211f, i8* inttoptr (i32 4763675 to i8*), align 1
  %v1_402125 = xor i32 %v4_40211c, -40
  %v1_402128 = add i32 %v1_402125, -61
  %v5_402128 = icmp ugt i32 %v1_402125, 60
  store i1 %v5_402128, i1* %cf.global-to-local, align 1
  store i32 %v1_402128, i32* %edx.global-to-local, align 4
  %v0_40212b = load i8, i8* inttoptr (i32 4763959 to i8*), align 1
  %v2_40212b = udiv i32 %v1_402128, 256
  %v3_40212b = trunc i32 %v2_40212b to i8
  %v4_40212b = xor i8 %v3_40212b, %v0_40212b
  store i8 %v4_40212b, i8* inttoptr (i32 4763959 to i8*), align 1
  %v0_402131 = load i32, i32* %ebx.global-to-local, align 4
  %v1_40213146 = add i32 %v0_402131, 43264
  %v18_402131 = and i32 %v1_40213146, 65280
  %v19_402131 = and i32 %v0_402131, -65281
  %v20_402131 = or i32 %v18_402131, %v19_402131
  store i32 %v20_402131, i32* %ebx.global-to-local, align 4
  %v0_402134 = load i32, i32* inttoptr (i32 4763982 to i32*), align 4
  %v2_402134 = add i32 %v20_402131, %v0_402134
  %v7_402134 = icmp ult i32 %v2_402134, %v0_402134
  store i1 %v7_402134, i1* %cf.global-to-local, align 1
  store i32 %v2_402134, i32* inttoptr (i32 4763982 to i32*), align 4
  %v0_40213a = load i8, i8* inttoptr (i32 4764071 to i8*), align 1
  %v1_40213a = add i8 %v0_40213a, 44
  %v5_40213a = icmp ult i8 %v0_40213a, -44
  store i1 %v5_40213a, i1* %cf.global-to-local, align 1
  store i8 %v1_40213a, i8* inttoptr (i32 4764071 to i8*), align 1
  %v0_402141 = load i32, i32* inttoptr (i32 4763731 to i32*), align 4
  %v1_402141 = load i32, i32* %esi.global-to-local, align 4
  %v3_402141 = zext i1 %v5_40213a to i32
  %v4_402141 = add i32 %v1_402141, %v0_402141
  %v5_402141 = add i32 %v3_402141, %v4_402141
  %v24_402141 = icmp ule i32 %v5_402141, %v0_402141
  %v25_402141 = icmp ult i32 %v4_402141, %v0_402141
  %v26_402141 = select i1 %v5_40213a, i1 %v24_402141, i1 %v25_402141
  store i1 %v26_402141, i1* %cf.global-to-local, align 1
  store i32 %v5_402141, i32* inttoptr (i32 4763731 to i32*), align 4
  %v3_402147 = load i8, i8* %v31_4020d5, align 1
  %factor86 = mul i8 %v6_4020d5, 6
  %v7_402151 = add i8 %v3_402147, %factor86
  store i8 %v7_402151, i8* %v31_4020d5, align 1
  %v1_402158 = load i32, i32* %edi.global-to-local, align 4
  %v2_402158 = add i32 %v1_402158, 1
  store i32 %v2_402158, i32* %ecx.global-to-local, align 4
  store i32 %v30_4020d5, i32* %eax.global-to-local, align 4
  %v0_40215d = load i32, i32* %ebx.global-to-local, align 4
  %v1_40215d = load i32, i32* inttoptr (i32 4763810 to i32*), align 4
  %v2_40215d = or i32 %v1_40215d, %v0_40215d
  store i32 %v2_40215d, i32* %ebx.global-to-local, align 4
  %v1_402163 = load i32, i32* inttoptr (i32 4763669 to i32*), align 4
  %v4_402163 = add i32 %v1_402163, %v30_4020d5
  %v25_402163 = icmp ult i32 %v4_402163, %v30_4020d5
  store i32 %v4_402163, i32* %eax.global-to-local, align 4
  %v0_402169 = load i32, i32* inttoptr (i32 4764131 to i32*), align 4
  %v1_402169 = load i32, i32* %esi.global-to-local, align 4
  %v3_402169 = zext i1 %v25_402163 to i32
  %v4_402169 = sub i32 %v0_402169, %v1_402169
  %v5_402169 = add i32 %v4_402169, %v3_402169
  store i32 %v5_402169, i32* inttoptr (i32 4764131 to i32*), align 4
  %v1_40216f = or i32 %v1_402169, -99
  %v1_402172 = load i32, i32* %edi.global-to-local, align 4
  %v4_402172 = sub i32 %v1_40216f, %v1_402172
  store i32 %v4_402172, i32* %esi.global-to-local, align 4
  %v1_402179 = load i32, i32* %eax.global-to-local, align 4
  %v2_402179 = add i32 %v1_402179, 1
  %v7_402179 = icmp eq i32 %v2_402179, 0
  store i1 %v7_402179, i1* %cf.global-to-local, align 1
  store i32 %v2_402179, i32* %edx.global-to-local, align 4
  %v0_40217b = load i32, i32* %ebx.global-to-local, align 4
  %v1_40217b = trunc i32 %v0_40217b to i8
  %v2_40217b = load i8, i8* inttoptr (i32 4764010 to i8*), align 2
  %v4_40217b = zext i1 %v7_402179 to i8
  %v5_40217b = add i8 %v1_40217b, %v2_40217b
  %v6_40217b = add i8 %v5_40217b, %v4_40217b
  %v24_40217b = icmp ule i8 %v6_40217b, %v1_40217b
  %v25_40217b = icmp ult i8 %v5_40217b, %v1_40217b
  %v26_40217b = select i1 %v7_402179, i1 %v24_40217b, i1 %v25_40217b
  store i1 %v26_40217b, i1* %cf.global-to-local, align 1
  %v27_40217b = zext i8 %v6_40217b to i32
  %v29_40217b = and i32 %v0_40217b, -256
  %v30_40217b = or i32 %v27_40217b, %v29_40217b
  store i32 %v30_40217b, i32* %ebx.global-to-local, align 4
  %v0_402181 = load i8, i8* inttoptr (i32 4764003 to i8*), align 1
  %v1_402181 = add i8 %v0_402181, -87
  store i8 %v1_402181, i8* inttoptr (i32 4764003 to i8*), align 1
  store i32 11, i32* %eax.global-to-local, align 4
  store i1 false, i1* %cf.global-to-local, align 1
  %v6_402199 = call i1 @IsBadStringPtrA(i8* getelementptr inbounds ([12 x i8], [12 x i8]* @global_var_48b6b4.5, i32 0, i32 0), i32 11)
  %v7_402199 = sext i1 %v6_402199 to i32
  store i32 %v7_402199, i32* %eax.global-to-local, align 4
  store i1 false, i1* %cf.global-to-local, align 1
  %v1_40219f = icmp eq i1 %v6_402199, false
  %v1_4021a1 = icmp eq i1 %v1_40219f, false
  call void @__pseudo_cond_branch(i1 %v1_4021a1, i32 ptrtoint (i16** @global_var_406dd5.3 to i32))
  %v0_4021a7 = load i32, i32* %edi.global-to-local, align 4
  %v2_4021a7 = load i1, i1* %cf.global-to-local, align 1
  %v3_4021a7 = zext i1 %v2_4021a7 to i32
  %v4_4021a7 = mul i32 %v0_4021a7, 2
  %v5_4021a7 = or i32 %v3_4021a7, %v4_4021a7
  %v24_4021a7 = icmp ule i32 %v5_4021a7, %v0_4021a7
  %v25_4021a7 = icmp ult i32 %v4_4021a7, %v0_4021a7
  %v26_4021a7 = select i1 %v2_4021a7, i1 %v24_4021a7, i1 %v25_4021a7
  store i32 %v5_4021a7, i32* %edi.global-to-local, align 4
  %v0_4021a9 = load i32, i32* inttoptr (i32 4764106 to i32*), align 4
  %v1_4021a9 = load i32, i32* %ebx.global-to-local, align 4
  %v3_4021a9 = zext i1 %v26_4021a7 to i32
  %v4_4021a9 = sub i32 %v0_4021a9, %v1_4021a9
  %v5_4021a9 = add i32 %v4_4021a9, %v3_4021a9
  store i32 %v5_4021a9, i32* inttoptr (i32 4764106 to i32*), align 4
  %v1_4021af47 = add i32 %v1_4021a9, 34816
  %v19_4021af = and i32 %v1_4021af47, 65280
  %v20_4021af = and i32 %v1_4021a9, -65281
  %v21_4021af = or i32 %v19_4021af, %v20_4021af
  store i32 %v21_4021af, i32* %ebx.global-to-local, align 4
  %v2_4021b7 = add i32 %v21_4021af, 1
  %v7_4021b7 = icmp eq i32 %v2_4021b7, 0
  store i32 %v2_4021b7, i32* %edx.global-to-local, align 4
  %v0_4021b9 = load i32, i32* inttoptr (i32 4763711 to i32*), align 4
  %v2_4021b9 = zext i1 %v7_4021b7 to i32
  %v3_4021b9 = add i32 %v0_4021b9, 255
  %v4_4021b9 = add i32 %v3_4021b9, %v2_4021b9
  %v21_4021b9 = icmp ule i32 %v4_4021b9, %v0_4021b9
  %v22_4021b9 = icmp ugt i32 %v0_4021b9, -256
  %v23_4021b9 = select i1 %v7_4021b7, i1 %v21_4021b9, i1 %v22_4021b9
  store i1 %v23_4021b9, i1* %cf.global-to-local, align 1
  store i32 %v4_4021b9, i32* inttoptr (i32 4763711 to i32*), align 4
  %v1_4021c3 = udiv i32 %v7_402199, 256
  %v2_4021c3 = trunc i32 %v1_4021c3 to i8
  %v3_4021c3 = load i8, i8* inttoptr (i32 4764032 to i8*), align 128
  %v4_4021c3 = or i8 %v3_4021c3, %v2_4021c3
  %v10_4021c3 = zext i8 %v4_4021c3 to i32
  %v12_4021c3 = mul nuw nsw i32 %v10_4021c3, 256
  %v13_4021c3 = select i1 %v6_402199, i32 -65281, i32 0
  %v14_4021c3 = or i32 %v12_4021c3, %v13_4021c3
  store i32 %v14_4021c3, i32* %eax.global-to-local, align 4
  %v0_4021c9 = load i32, i32* inttoptr (i32 4764113 to i32*), align 4
  %v4_4021c9 = add i32 %v14_4021c3, %v0_4021c9
  store i32 %v4_4021c9, i32* inttoptr (i32 4764113 to i32*), align 4
  %v0_4021cf = load i32, i32* %edx.global-to-local, align 4
  %v2_4021cf = xor i32 %v14_4021c3, %v0_4021cf
  %v1_4021d1 = add i32 %v2_4021cf, 113
  %v5_4021d1 = icmp ult i32 %v2_4021cf, -113
  store i32 %v1_4021d1, i32* %edx.global-to-local, align 4
  %v0_4021d4 = load i32, i32* %esi.global-to-local, align 4
  %v1_4021d4 = load i32, i32* inttoptr (i32 4763737 to i32*), align 4
  %v3_4021d4 = zext i1 %v5_4021d1 to i32
  %v4_4021d4 = add i32 %v1_4021d4, %v0_4021d4
  %v5_4021d4 = add i32 %v4_4021d4, %v3_4021d4
  store i32 %v5_4021d4, i32* %esi.global-to-local, align 4
  %v0_4021da = load i32, i32* %edi.global-to-local, align 4
  %v1_4021da = add i32 %v0_4021da, 27
  %v5_4021da = icmp ugt i32 %v0_4021da, -28
  store i32 %v1_4021da, i32* %edi.global-to-local, align 4
  %v0_4021dd = load i32, i32* inttoptr (i32 4764151 to i32*), align 4
  %v2_4021dd = zext i1 %v5_4021da to i32
  %v3_4021dd = add i32 %v0_4021dd, -105
  %v4_4021dd = add i32 %v3_4021dd, %v2_4021dd
  store i32 %v4_4021dd, i32* inttoptr (i32 4764151 to i32*), align 4
  %v0_4021e4 = load i32, i32* %ebx.global-to-local, align 4
  %v1_4021e4 = add i32 %v0_4021e4, -93
  store i32 %v1_4021e4, i32* %ebx.global-to-local, align 4
  %v0_4021e7 = load i32, i32* %edi.global-to-local, align 4
  %v1_4021e7 = add i32 %v0_4021e7, 95
  %v5_4021e7 = icmp ult i32 %v0_4021e7, -95
  store i1 %v5_4021e7, i1* %cf.global-to-local, align 1
  store i32 %v1_4021e7, i32* %edi.global-to-local, align 4
  call void @__pseudo_call(i32 4202994)
  store i32 83, i32* %ecx.global-to-local, align 4
  %v0_4021fa = load i32, i32* inttoptr (i32 4763935 to i32*), align 4
  %v3_4021fa = add i32 %v0_4021fa, -73
  %v12_4021fa = icmp ult i32 %v0_4021fa, 73
  store i1 %v12_4021fa, i1* %cf.global-to-local, align 1
  store i32 %v3_4021fa, i32* inttoptr (i32 4763935 to i32*), align 4
  %v0_402201 = load i32, i32* %edx.global-to-local, align 4
  %v1_402201 = trunc i32 %v0_402201 to i8
  %v2_402201 = load i8, i8* inttoptr (i32 4763924 to i8*), align 4
  %v4_402201 = zext i1 %v12_4021fa to i8
  %v5_402201 = add i8 %v1_402201, %v2_402201
  %v6_402201 = add i8 %v5_402201, %v4_402201
  %v24_402201 = icmp ule i8 %v6_402201, %v1_402201
  %v25_402201 = icmp ult i8 %v5_402201, %v1_402201
  %v26_402201 = select i1 %v12_4021fa, i1 %v24_402201, i1 %v25_402201
  %v27_402201 = zext i8 %v6_402201 to i32
  %v29_402201 = and i32 %v0_402201, -256
  %v30_402201 = or i32 %v27_402201, %v29_402201
  store i32 %v30_402201, i32* %edx.global-to-local, align 4
  %v0_402207 = load i32, i32* %esi.global-to-local, align 4
  %v2_402207 = zext i1 %v26_402201 to i32
  %v3_402207 = add i32 %v0_402207, 58
  %v4_402207 = add i32 %v3_402207, %v2_402207
  %v12_402207 = icmp ult i32 %v0_402207, -58
  %v13_402207 = or i1 %v12_402207, %v26_402201
  store i32 %v4_402207, i32* %esi.global-to-local, align 4
  %v0_40220a = load i32, i32* inttoptr (i32 4764009 to i32*), align 4
  %v1_40220a = load i32, i32* %ecx.global-to-local, align 4
  %v3_40220a = zext i1 %v13_402207 to i32
  %v4_40220a = sub i32 %v0_40220a, %v1_40220a
  %v5_40220a = add i32 %v4_40220a, %v3_40220a
  store i32 %v5_40220a, i32* inttoptr (i32 4764009 to i32*), align 4
  %v0_402210 = load i32, i32* %esi.global-to-local, align 4
  %v1_402210 = add i32 %v0_402210, -4
  store i32 %v1_402210, i32* %esi.global-to-local, align 4
  %v0_402213 = load i32, i32* inttoptr (i32 4764156 to i32*), align 4
  %v1_402213 = load i32, i32* %ecx.global-to-local, align 4
  %v2_402213 = sub i32 %v0_402213, %v1_402213
  store i32 %v2_402213, i32* inttoptr (i32 4764156 to i32*), align 4
  %v0_402219 = load i32, i32* %edi.global-to-local, align 4
  %v1_402219 = and i32 %v0_402219, -56
  store i32 %v1_402219, i32* %edi.global-to-local, align 4
  %v0_40221c = load i32, i32* %eax.global-to-local, align 4
  %v1_40221c = load i32, i32* inttoptr (i32 4764120 to i32*), align 8
  %v2_40221c = sub i32 %v0_40221c, %v1_40221c
  %v7_40221c = icmp ult i32 %v0_40221c, %v1_40221c
  %v1_402222 = load i32, i32* %edx.global-to-local, align 4
  %v3_402222 = zext i1 %v7_40221c to i32
  %v4_402222 = add i32 %v1_402222, %v2_40221c
  %v5_402222 = add i32 %v3_402222, %v4_402222
  %v24_402222 = icmp ule i32 %v5_402222, %v2_40221c
  %v25_402222 = icmp ult i32 %v4_402222, %v2_40221c
  %v26_402222 = select i1 %v7_40221c, i1 %v24_402222, i1 %v25_402222
  store i32 %v5_402222, i32* %eax.global-to-local, align 4
  %v0_402224 = load i32, i32* %ebx.global-to-local, align 4
  %v5_402224 = zext i1 %v26_402222 to i32
  %v6_402224 = add i32 %v0_402224, %v5_402222
  %v7_402224 = add i32 %v6_402224, %v5_402224
  %v28_402224 = and i32 %v7_402224, 255
  %v30_402224 = and i32 %v0_402224, -256
  %v31_402224 = or i32 %v28_402224, %v30_402224
  store i32 %v31_402224, i32* %ebx.global-to-local, align 4
  %v1_402226 = load i32, i32* inttoptr (i32 4763679 to i32*), align 4
  %v2_402226 = sub i32 %v1_402219, %v1_402226
  store i32 %v2_402226, i32* %edi.global-to-local, align 4
  %v1_40222c = load i32, i32* inttoptr (i32 4763787 to i32*), align 4
  %v2_40222c = sub i32 %v5_402222, %v1_40222c
  store i32 %v2_40222c, i32* %eax.global-to-local, align 4
  %v0_402232 = load i32, i32* inttoptr (i32 4764144 to i32*), align 16
  %v1_402232 = xor i32 %v0_402232, 32
  store i32 %v1_402232, i32* inttoptr (i32 4764144 to i32*), align 16
  %v1_402239 = load i32, i32* inttoptr (i32 4763705 to i32*), align 4
  %v2_402239 = sub i32 %v2_40222c, %v1_402239
  store i32 %v2_402239, i32* %eax.global-to-local, align 4
  %v0_40223f = load i32, i32* %ecx.global-to-local, align 4
  %v1_40223f = load i32, i32* inttoptr (i32 4763731 to i32*), align 4
  %v2_40223f = or i32 %v1_40223f, %v0_40223f
  store i32 %v2_40223f, i32* %ecx.global-to-local, align 4
  %v0_402245 = load i32, i32* %edx.global-to-local, align 4
  %v1_402245 = load i32, i32* inttoptr (i32 4763755 to i32*), align 4
  %v2_402245 = or i32 %v1_402245, %v0_402245
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v2_402245, i32* %edx.global-to-local, align 4
  %v1_40224b = udiv i32 %v2_402239, 256
  %v2_40224b = trunc i32 %v1_40224b to i8
  %v3_40224b = load i8, i8* inttoptr (i32 4763826 to i8*), align 2
  %v4_40224b = or i8 %v3_40224b, %v2_40224b
  %v10_40224b = zext i8 %v4_40224b to i32
  %v12_40224b = mul nuw nsw i32 %v10_40224b, 256
  %v13_40224b = and i32 %v2_402239, -65281
  %v14_40224b = or i32 %v12_40224b, %v13_40224b
  store i32 %v14_40224b, i32* %eax.global-to-local, align 4
  %v1_402251 = add i32 %v2_402245, 94
  store i32 %v1_402251, i32* %edx.global-to-local, align 4
  %v0_402254 = load i32, i32* %edi.global-to-local, align 4
  %v1_402254 = load i32, i32* inttoptr (i32 4763833 to i32*), align 4
  %v2_402254 = or i32 %v1_402254, %v0_402254
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v2_402254, i32* %edi.global-to-local, align 4
  %v1_40225a = inttoptr i32 %v14_40224b to i8*
  %v2_40225a = load i8, i8* %v1_40225a, align 1
  %v4_40225a = trunc i32 %v2_402239 to i8
  %v5_40225a = add i8 %v2_40225a, %v4_40225a
  %v10_40225a = icmp ult i8 %v5_40225a, %v2_40225a
  store i1 %v10_40225a, i1* %cf.global-to-local, align 1
  store i8 %v5_40225a, i8* %v1_40225a, align 1
  %v0_40225c = load i32, i32* %eax.global-to-local, align 4
  %v1_40225c = inttoptr i32 %v0_40225c to i8*
  %v2_40225c = load i8, i8* %v1_40225c, align 1
  %v4_40225c = trunc i32 %v0_40225c to i8
  %v5_40225c = add i8 %v4_40225c, %v2_40225c
  %v10_40225c = icmp ult i8 %v5_40225c, %v2_40225c
  store i1 %v10_40225c, i1* %cf.global-to-local, align 1
  store i8 %v5_40225c, i8* %v1_40225c, align 1
  %v0_40225e = load i32, i32* %eax.global-to-local, align 4
  %v1_40225e = inttoptr i32 %v0_40225e to i8*
  %v2_40225e = load i8, i8* %v1_40225e, align 1
  %v4_40225e = trunc i32 %v0_40225e to i8
  %v5_40225e = add i8 %v4_40225e, %v2_40225e
  %v10_40225e = icmp ult i8 %v5_40225e, %v2_40225e
  store i1 %v10_40225e, i1* %cf.global-to-local, align 1
  store i8 %v5_40225e, i8* %v1_40225e, align 1
  %v0_402260 = load i32, i32* %eax.global-to-local, align 4
  %v1_402260 = inttoptr i32 %v0_402260 to i8*
  %v2_402260 = load i8, i8* %v1_402260, align 1
  %v4_402260 = trunc i32 %v0_402260 to i8
  %v5_402260 = add i8 %v4_402260, %v2_402260
  store i8 %v5_402260, i8* %v1_402260, align 1
  store i32 130, i32* inttoptr (i32 4763971 to i32*), align 4
  %v0_40226c = load i32, i32* %edx.global-to-local, align 4
  %v1_40226c = and i32 %v0_40226c, -65281
  %v3_40226e = load i32, i32* %eax.global-to-local, align 4
  %v5_40226e = mul i32 %v3_40226e, 256
  %v20_40226e = add i32 %v5_40226e, 256
  %v22_40226e = and i32 %v20_40226e, 65280
  %v24_40226e = or i32 %v22_40226e, %v1_40226c
  store i32 %v24_40226e, i32* %edx.global-to-local, align 4
  %v0_402270 = load i32, i32* %edi.global-to-local, align 4
  %v2_402270 = add i32 %v0_402270, %v3_40226e
  store i32 %v2_402270, i32* %edi.global-to-local, align 4
  %v1_402272 = add i32 %v3_40226e, 16
  store i32 %v1_402272, i32* %eax.global-to-local, align 4
  %v1_402275 = load i32, i32* inttoptr (i32 4764038 to i32*), align 4
  %v2_402275 = sub i32 %v1_402272, %v1_402275
  %v7_402275 = icmp ult i32 %v1_402272, %v1_402275
  store i32 %v2_402275, i32* %eax.global-to-local, align 4
  %v0_40227b = load i32, i32* %ebx.global-to-local, align 4
  %v2_40227b = zext i1 %v7_402275 to i32
  %v3_40227b = add i32 %v0_40227b, -23
  %v4_40227b = add i32 %v3_40227b, %v2_40227b
  store i32 %v4_40227b, i32* %ebx.global-to-local, align 4
  %v0_40227e = load i32, i32* inttoptr (i32 4764153 to i32*), align 4
  %v1_40227e = xor i32 %v0_40227e, 194
  store i32 %v1_40227e, i32* inttoptr (i32 4764153 to i32*), align 4
  %v0_402288 = load i32, i32* inttoptr (i32 4763986 to i32*), align 4
  %v1_402288 = and i32 %v0_402288, 23
  store i32 %v1_402288, i32* inttoptr (i32 4763986 to i32*), align 4
  %v0_40228f = load i32, i32* %edx.global-to-local, align 4
  %v1_40228f = load i32, i32* %esi.global-to-local, align 4
  %v2_40228f = add i32 %v1_40228f, %v0_40228f
  %v7_40228f = icmp ult i32 %v2_40228f, %v0_40228f
  store i1 %v7_40228f, i1* %cf.global-to-local, align 1
  %v14_40228f = trunc i32 %v2_40228f to i8
  store i32 %v2_40228f, i32* %edx.global-to-local, align 4
  %v2_402291 = load i8, i8* inttoptr (i32 4764126 to i8*), align 2
  %v4_402291 = zext i1 %v7_40228f to i8
  %v5_402291 = add i8 %v2_402291, %v14_40228f
  %v6_402291 = add i8 %v5_402291, %v4_402291
  %v24_402291 = icmp ule i8 %v6_402291, %v14_40228f
  %v25_402291 = icmp ult i8 %v5_402291, %v14_40228f
  %v26_402291 = select i1 %v7_40228f, i1 %v24_402291, i1 %v25_402291
  %v27_402291 = zext i8 %v6_402291 to i32
  %v29_402291 = and i32 %v2_40228f, -256
  %v30_402291 = or i32 %v27_402291, %v29_402291
  store i32 %v30_402291, i32* %edx.global-to-local, align 4
  %v0_402297 = load i32, i32* %eax.global-to-local, align 4
  %v1_402297 = load i32, i32* inttoptr (i32 4763707 to i32*), align 4
  %v3_402297 = zext i1 %v26_402291 to i32
  %v4_402297 = add i32 %v1_402297, %v0_402297
  %v5_402297 = add i32 %v4_402297, %v3_402297
  store i32 %v5_402297, i32* %eax.global-to-local, align 4
  %v1_40229d = add i32 %v1_40228f, -101
  store i32 %v1_40229d, i32* %esi.global-to-local, align 4
  %v0_4022a0 = load i32, i32* inttoptr (i32 4763992 to i32*), align 8
  %v1_4022a0 = or i32 %v0_4022a0, 165
  store i32 %v1_4022a0, i32* inttoptr (i32 4763992 to i32*), align 8
  %v0_4022aa = load i32, i32* inttoptr (i32 4764141 to i32*), align 4
  %v3_4022aa = add i32 %v0_4022aa, 22
  store i32 %v3_4022aa, i32* inttoptr (i32 4764141 to i32*), align 4
  %v0_4022b1 = load i32, i32* inttoptr (i32 4763730 to i32*), align 4
  %v1_4022b1 = load i32, i32* %ebx.global-to-local, align 4
  %v2_4022b1 = sub i32 %v0_4022b1, %v1_4022b1
  store i32 %v2_4022b1, i32* inttoptr (i32 4763730 to i32*), align 4
  %v1_4022b7 = load i32, i32* %eax.global-to-local, align 4
  %v2_4022b7 = sub i32 %v1_4022b1, %v1_4022b7
  store i32 %v2_4022b7, i32* %ebx.global-to-local, align 4
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 1048576, i32* %eax.global-to-local, align 4
  %v10_4022d2 = call i32* @OpenJobObjectW(i32 1048576, i1 false, i16* bitcast ([13 x i8]* @global_var_48b6a3.4 to i16*))
  %v11_4022d2 = ptrtoint i32* %v10_4022d2 to i32
  store i32 %v11_4022d2, i32* %eax.global-to-local, align 4
  store i1 false, i1* %cf.global-to-local, align 1
  %v1_4022d8 = icmp eq i32* %v10_4022d2, null
  %v1_4022da = icmp eq i1 %v1_4022d8, false
  call void @__pseudo_cond_branch(i1 %v1_4022da, i32 ptrtoint (i16** @global_var_406dd5.3 to i32))
  %v0_4022e0 = load i32, i32* %ebx.global-to-local, align 4
  %v2_4022e0 = load i1, i1* %cf.global-to-local, align 1
  %v3_4022e0 = zext i1 %v2_4022e0 to i32
  %v4_4022e0 = sub i32 %v0_4022e0, %v11_4022d2
  %v5_4022e0 = add i32 %v4_4022e0, %v3_4022e0
  store i32 %v5_4022e0, i32* %ebx.global-to-local, align 4
  %v0_4022e2 = load i32, i32* inttoptr (i32 4763659 to i32*), align 4
  %v1_4022e2 = and i32 %v0_4022e2, 92
  store i32 %v1_4022e2, i32* inttoptr (i32 4763659 to i32*), align 4
  %v0_4022e9 = load i32, i32* %esi.global-to-local, align 4
  %v1_4022e9 = load i32, i32* inttoptr (i32 4763879 to i32*), align 4
  %v2_4022e9 = sub i32 %v0_4022e9, %v1_4022e9
  %v7_4022e9 = icmp ult i32 %v0_4022e9, %v1_4022e9
  store i32 %v2_4022e9, i32* %esi.global-to-local, align 4
  %v0_4022ef = load i32, i32* inttoptr (i32 4763988 to i32*), align 4
  %v3_4022ef = zext i1 %v7_4022e9 to i32
  %v4_4022ef = add i32 %v0_4022ef, %v2_4022e9
  %v5_4022ef = add i32 %v4_4022ef, %v3_4022ef
  store i32 %v5_4022ef, i32* inttoptr (i32 4763988 to i32*), align 4
  %v0_4022f5 = load i32, i32* inttoptr (i32 4764060 to i32*), align 4
  %v1_4022f5 = load i32, i32* %edi.global-to-local, align 4
  %v2_4022f5 = or i32 %v1_4022f5, %v0_4022f5
  store i32 %v2_4022f5, i32* inttoptr (i32 4764060 to i32*), align 4
  store i32 -5, i32* %edx.global-to-local, align 4
  %v4_402303 = add i32 %v11_4022d2, -80
  store i32 %v4_402303, i32* %eax.global-to-local, align 4
  %v1_40230b = load i32, i32* %ebx.global-to-local, align 4
  %v2_40230b = mul i32 %v1_40230b, 2
  %v2_40230d = add i32 %v2_40230b, 2
  store i32 %v2_40230d, i32* %ecx.global-to-local, align 4
  %v0_40230f = load i32, i32* inttoptr (i32 4764085 to i32*), align 4
  %v1_40230f = load i32, i32* %esi.global-to-local, align 4
  %v2_40230f = xor i32 %v1_40230f, %v0_40230f
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v2_40230f, i32* inttoptr (i32 4764085 to i32*), align 4
  %v0_402315 = load i32, i32* %ebx.global-to-local, align 4
  %v1_402315 = udiv i32 %v0_402315, 256
  %v2_402315 = trunc i32 %v1_402315 to i8
  %v3_402315 = load i8, i8* inttoptr (i32 4763718 to i8*), align 2
  %v6_402315 = add i8 %v2_402315, %v3_402315
  %v26_402315 = icmp ult i8 %v6_402315, %v2_402315
  store i1 %v26_402315, i1* %cf.global-to-local, align 1
  %v28_402315 = zext i8 %v6_402315 to i32
  %v30_402315 = mul nuw nsw i32 %v28_402315, 256
  %v31_402315 = and i32 %v0_402315, -65281
  %v32_402315 = or i32 %v30_402315, %v31_402315
  store i32 %v32_402315, i32* %ebx.global-to-local, align 4
  %v0_40231b = load i8, i8* inttoptr (i32 4763808 to i8*), align 32
  %v1_40231b = load i32, i32* %ecx.global-to-local, align 4
  %v2_40231b = trunc i32 %v1_40231b to i8
  %v3_40231b = add i8 %v2_40231b, %v0_40231b
  store i8 %v3_40231b, i8* inttoptr (i32 4763808 to i8*), align 32
  %v0_402321 = load i32, i32* inttoptr (i32 4764094 to i32*), align 4
  %v1_402321 = load i32, i32* %edx.global-to-local, align 4
  %v2_402321 = add i32 %v1_402321, %v0_402321
  store i32 %v2_402321, i32* inttoptr (i32 4764094 to i32*), align 4
  %v0_402327 = load i32, i32* inttoptr (i32 4763797 to i32*), align 4
  %v1_402327 = load i32, i32* %esi.global-to-local, align 4
  %v2_402327 = add i32 %v1_402327, %v0_402327
  %v7_402327 = icmp ult i32 %v2_402327, %v0_402327
  store i32 %v2_402327, i32* inttoptr (i32 4763797 to i32*), align 4
  %v0_40232d = load i32, i32* inttoptr (i32 4764094 to i32*), align 4
  %v2_40232d = zext i1 %v7_402327 to i32
  %v3_40232d = add i32 %v0_40232d, -116
  %v4_40232d = add i32 %v3_40232d, %v2_40232d
  %v12_40232d = icmp ult i32 %v0_40232d, 116
  %v13_40232d = or i1 %v7_402327, %v12_40232d
  store i32 %v4_40232d, i32* inttoptr (i32 4764094 to i32*), align 4
  %v0_402334 = load i32, i32* %edi.global-to-local, align 4
  %v1_402334 = load i32, i32* inttoptr (i32 4763735 to i32*), align 4
  %v3_402334 = zext i1 %v13_40232d to i32
  %v4_402334 = add i32 %v0_402334, -83
  %v5_402334 = add i32 %v4_402334, %v1_402334
  %v1_40233a = add i32 %v5_402334, %v3_402334
  store i32 %v1_40233a, i32* %edi.global-to-local, align 4
  %v0_40233d = load i32, i32* %eax.global-to-local, align 4
  %v1_40233d = load i32, i32* inttoptr (i32 4764128 to i32*), align 32
  %v2_40233d = sub i32 %v0_40233d, %v1_40233d
  store i32 %v2_40233d, i32* %eax.global-to-local, align 4
  store i32 143, i32* inttoptr (i32 4763790 to i32*), align 4
  %v2_40234d = add i32 %v1_40233a, %v2_40233d
  %v7_40234d = icmp ult i32 %v2_40234d, %v2_40233d
  store i1 %v7_40234d, i1* %cf.global-to-local, align 1
  store i32 %v2_40234d, i32* %eax.global-to-local, align 4
  call void @__pseudo_call(i32 sext (i1 ptrtoint (i1* @global_var_402357.9 to i1) to i32))
  %v0_402357 = load i32, i32* %esi.global-to-local, align 4
  %v1_402357 = load i32, i32* %ecx.global-to-local, align 4
  %v2_402357 = add i32 %v1_402357, %v0_402357
  %v7_402357 = icmp ult i32 %v2_402357, %v0_402357
  store i32 %v2_402357, i32* %esi.global-to-local, align 4
  %v0_402359 = load i32, i32* %eax.global-to-local, align 4
  %v1_402359 = load i32, i32* inttoptr (i32 4763652 to i32*), align 4
  %v3_402359 = zext i1 %v7_402357 to i32
  %v4_402359 = add i32 %v1_402359, %v0_402359
  %v5_402359 = add i32 %v4_402359, %v3_402359
  store i32 %v5_402359, i32* %eax.global-to-local, align 4
  %v0_40235f = load i32, i32* inttoptr (i32 4764007 to i32*), align 4
  %v1_40235f = load i32, i32* %edi.global-to-local, align 4
  %v2_40235f = xor i32 %v1_40235f, %v0_40235f
  store i32 %v2_40235f, i32* inttoptr (i32 4764007 to i32*), align 4
  %v0_402365 = load i32, i32* %edx.global-to-local, align 4
  %v3_402365 = load i32, i32* %ecx.global-to-local, align 4
  %tmp = mul i32 %v3_402365, -256
  %v1_40236549 = add i32 %v0_402365, %tmp
  %v23_402365 = and i32 %v1_40236549, 65280
  %v24_402365 = and i32 %v0_402365, -65281
  %v25_402365 = or i32 %v23_402365, %v24_402365
  store i32 %v25_402365, i32* %edx.global-to-local, align 4
  %v0_402367 = load i32, i32* %ebx.global-to-local, align 4
  %v1_402367 = load i32, i32* inttoptr (i32 4763968 to i32*), align 64
  %v2_402367 = sub i32 %v0_402367, %v1_402367
  store i32 %v2_402367, i32* %ebx.global-to-local, align 4
  %v0_40236d = load i32, i32* inttoptr (i32 4763683 to i32*), align 4
  %v1_40236d = load i32, i32* %edi.global-to-local, align 4
  %v2_40236d = sub i32 %v0_40236d, %v1_40236d
  %v7_40236d = icmp ult i32 %v0_40236d, %v1_40236d
  store i32 %v2_40236d, i32* inttoptr (i32 4763683 to i32*), align 4
  %v0_402373 = load i32, i32* %esi.global-to-local, align 4
  %v1_402373 = load i32, i32* %ecx.global-to-local, align 4
  %v3_402373 = zext i1 %v7_40236d to i32
  %v4_402373 = add i32 %v3_402373, %v0_402373
  %v5_402373 = add i32 %v4_402373, %v1_402373
  store i32 %v5_402373, i32* %esi.global-to-local, align 4
  %v0_402375 = load i32, i32* %edi.global-to-local, align 4
  %v1_402375 = add i32 %v0_402375, 34
  %v0_402378 = load i32, i32* %eax.global-to-local, align 4
  %v1_402378 = add i32 %v0_402378, 31
  store i32 %v1_402378, i32* %eax.global-to-local, align 4
  %v1_40237b = or i32 %v1_402375, -55
  store i32 %v1_40237b, i32* %edi.global-to-local, align 4
  %v1_40237e = load i32, i32* inttoptr (i32 4763942 to i32*), align 4
  %v4_40237e = add i32 %v1_40237e, %v5_402373
  %v25_40237e = icmp ult i32 %v4_40237e, %v5_402373
  store i32 %v4_40237e, i32* %esi.global-to-local, align 4
  %v1_402384 = load i32, i32* inttoptr (i32 4763847 to i32*), align 4
  %v3_402384 = zext i1 %v25_40237e to i32
  %v4_402384 = add i32 %v1_402384, %v1_402378
  %v5_402384 = add i32 %v4_402384, %v3_402384
  store i32 %v5_402384, i32* %eax.global-to-local, align 4
  %v1_40238a = add i32 %v1_402373, -120
  %v5_40238a = icmp ugt i32 %v1_402373, 119
  store i32 %v1_40238a, i32* %ecx.global-to-local, align 4
  %v0_40238d = load i32, i32* inttoptr (i32 4764121 to i32*), align 4
  %v2_40238d = zext i1 %v5_40238a to i32
  %v3_40238d = add i32 %v0_40238d, -124
  %v4_40238d = add i32 %v3_40238d, %v2_40238d
  %v12_40238d = icmp ult i32 %v0_40238d, 124
  %v13_40238d = or i1 %v5_40238a, %v12_40238d
  store i32 %v4_40238d, i32* inttoptr (i32 4764121 to i32*), align 4
  %v0_402394 = load i32, i32* inttoptr (i32 4764132 to i32*), align 4
  %v1_402394 = load i32, i32* %esi.global-to-local, align 4
  %v3_402394 = zext i1 %v13_40238d to i32
  %v4_402394 = add i32 %v1_402394, %v0_402394
  %v5_402394 = add i32 %v4_402394, %v3_402394
  %v24_402394 = icmp ule i32 %v5_402394, %v0_402394
  %v25_402394 = icmp ult i32 %v4_402394, %v0_402394
  %v26_402394 = select i1 %v13_40238d, i1 %v24_402394, i1 %v25_402394
  store i1 %v26_402394, i1* %cf.global-to-local, align 1
  store i32 %v5_402394, i32* inttoptr (i32 4764132 to i32*), align 4
  %v0_40239a = load i32, i32* %eax.global-to-local, align 4
  %v1_40239a = inttoptr i32 %v0_40239a to i8*
  %v2_40239a = load i8, i8* %v1_40239a, align 1
  %v4_40239a = trunc i32 %v0_40239a to i8
  %v5_40239a = add i8 %v4_40239a, %v2_40239a
  %v10_40239a = icmp ult i8 %v5_40239a, %v2_40239a
  store i1 %v10_40239a, i1* %cf.global-to-local, align 1
  store i8 %v5_40239a, i8* %v1_40239a, align 1
  %v0_40239c = load i32, i32* %eax.global-to-local, align 4
  %v1_40239c = inttoptr i32 %v0_40239c to i8*
  %v2_40239c = load i8, i8* %v1_40239c, align 1
  %v4_40239c = trunc i32 %v0_40239c to i8
  %v5_40239c = add i8 %v4_40239c, %v2_40239c
  %v10_40239c = icmp ult i8 %v5_40239c, %v2_40239c
  store i1 %v10_40239c, i1* %cf.global-to-local, align 1
  store i8 %v5_40239c, i8* %v1_40239c, align 1
  %v0_40239e = load i32, i32* %eax.global-to-local, align 4
  %v1_40239e = inttoptr i32 %v0_40239e to i8*
  %v2_40239e = load i8, i8* %v1_40239e, align 1
  %v4_40239e = trunc i32 %v0_40239e to i8
  %v5_40239e = add i8 %v4_40239e, %v2_40239e
  %v10_40239e = icmp ult i8 %v5_40239e, %v2_40239e
  store i1 %v10_40239e, i1* %cf.global-to-local, align 1
  store i8 %v5_40239e, i8* %v1_40239e, align 1
  %v0_4023a0 = load i32, i32* %eax.global-to-local, align 4
  %v1_4023a0 = inttoptr i32 %v0_4023a0 to i8*
  %v2_4023a0 = load i8, i8* %v1_4023a0, align 1
  %v4_4023a0 = trunc i32 %v0_4023a0 to i8
  %v5_4023a0 = add i8 %v4_4023a0, %v2_4023a0
  %v10_4023a0 = icmp ult i8 %v5_4023a0, %v2_4023a0
  store i1 %v10_4023a0, i1* %cf.global-to-local, align 1
  store i8 %v5_4023a0, i8* %v1_4023a0, align 1
  %v0_4023a2 = load i32, i32* %ecx.global-to-local, align 4
  %v1_4023a2 = inttoptr i32 %v0_4023a2 to i8*
  %v2_4023a2 = load i8, i8* %v1_4023a2, align 1
  %v4_4023a2 = trunc i32 %v0_4023a2 to i8
  %v5_4023a2 = add i8 %v4_4023a2, %v2_4023a2
  %v10_4023a2 = icmp ult i8 %v5_4023a2, %v2_4023a2
  store i1 %v10_4023a2, i1* %cf.global-to-local, align 1
  store i8 %v5_4023a2, i8* %v1_4023a2, align 1
  %v0_4023a4 = load i32, i32* %eax.global-to-local, align 4
  %v1_4023a4 = load i1, i1* %cf.global-to-local, align 1
  %v2_4023a4 = zext i1 %v1_4023a4 to i32
  %v3_4023a4 = add i32 %v0_4023a4, -4763920
  %v4_4023a4 = add i32 %v3_4023a4, %v2_4023a4
  store i32 %v4_4023a4, i32* %eax.global-to-local, align 4
  %v0_4023a9 = load i32, i32* inttoptr (i32 4763689 to i32*), align 4
  %v1_4023a9 = load i32, i32* %esi.global-to-local, align 4
  %v2_4023a9 = sub i32 %v0_4023a9, %v1_4023a9
  store i32 %v2_4023a9, i32* inttoptr (i32 4763689 to i32*), align 4
  %v1_4023af = load i32, i32* inttoptr (i32 4763996 to i32*), align 4
  %v2_4023af = sub i32 %v1_4023a9, %v1_4023af
  %v7_4023af = icmp ult i32 %v1_4023a9, %v1_4023af
  %v2_4023b5 = zext i1 %v7_4023af to i32
  %v3_4023b5 = add i32 %v2_4023af, 54
  %v4_4023b5 = add i32 %v3_4023b5, %v2_4023b5
  %v12_4023b5 = icmp ult i32 %v2_4023af, -54
  %v13_4023b5 = or i1 %v7_4023af, %v12_4023b5
  store i32 %v4_4023b5, i32* %esi.global-to-local, align 4
  %v0_4023b8 = load i32, i32* %edi.global-to-local, align 4
  %v1_4023b8 = load i32, i32* inttoptr (i32 4764105 to i32*), align 4
  %v3_4023b8 = zext i1 %v13_4023b5 to i32
  %v4_4023b8 = add i32 %v1_4023b8, %v0_4023b8
  %v5_4023b8 = add i32 %v4_4023b8, %v3_4023b8
  store i32 %v5_4023b8, i32* %edi.global-to-local, align 4
  %v0_4023be = load i32, i32* %ebx.global-to-local, align 4
  %v1_4023be = add i32 %v0_4023be, -35
  %v5_4023be = icmp ugt i32 %v0_4023be, 34
  store i32 %v1_4023be, i32* %ebx.global-to-local, align 4
  %v0_4023c1 = load i32, i32* inttoptr (i32 4763954 to i32*), align 4
  %v2_4023c1 = zext i1 %v5_4023be to i32
  %v3_4023c1 = add i32 %v0_4023c1, 40
  %v4_4023c1 = add i32 %v3_4023c1, %v2_4023c1
  store i32 %v4_4023c1, i32* inttoptr (i32 4763954 to i32*), align 4
  %v1_4023cd = load i32, i32* %edi.global-to-local, align 4
  %v2_4023cd = add i32 %v1_4023cd, 1
  %v7_4023cd = icmp eq i32 %v2_4023cd, 0
  store i32 %v2_4023cd, i32* %edx.global-to-local, align 4
  %v0_4023cf = load i32, i32* %ebx.global-to-local, align 4
  %v1_4023cf = load i32, i32* %eax.global-to-local, align 4
  %v3_4023cf = zext i1 %v7_4023cd to i32
  %v4_4023cf = sub i32 %v0_4023cf, %v1_4023cf
  %v5_4023cf = add i32 %v4_4023cf, %v3_4023cf
  %v16_4023cf = sub i32 %v4_4023cf, %v3_4023cf
  %v17_4023cf = icmp ult i32 %v0_4023cf, %v16_4023cf
  %v18_4023cf = icmp ne i32 %v1_4023cf, -1
  %v19_4023cf = or i1 %v18_4023cf, %v17_4023cf
  %v20_4023cf = icmp ult i32 %v0_4023cf, %v1_4023cf
  %v21_4023cf = select i1 %v7_4023cd, i1 %v19_4023cf, i1 %v20_4023cf
  store i32 %v5_4023cf, i32* %ebx.global-to-local, align 4
  %v0_4023d1 = load i32, i32* inttoptr (i32 4764033 to i32*), align 4
  %v3_4023d1 = zext i1 %v21_4023cf to i32
  %v4_4023d1 = add i32 %v0_4023d1, %v2_4023cd
  %v5_4023d1 = add i32 %v3_4023d1, %v4_4023d1
  %v24_4023d1 = icmp ule i32 %v5_4023d1, %v0_4023d1
  %v25_4023d1 = icmp ult i32 %v4_4023d1, %v0_4023d1
  %v26_4023d1 = select i1 %v21_4023cf, i1 %v24_4023d1, i1 %v25_4023d1
  store i32 %v5_4023d1, i32* inttoptr (i32 4764033 to i32*), align 4
  %v0_4023d7 = load i32, i32* inttoptr (i32 4763927 to i32*), align 4
  %v3_4023d7 = select i1 %v26_4023d1, i32 102, i32 101
  %v4_4023d7 = add i32 %v3_4023d7, %v0_4023d7
  store i32 %v4_4023d7, i32* inttoptr (i32 4763927 to i32*), align 4
  store i32 %v2_4023cd, i32* %edx.global-to-local, align 4
  %v0_4023e1 = load i32, i32* inttoptr (i32 4763819 to i32*), align 4
  %v1_4023e1 = load i32, i32* %eax.global-to-local, align 4
  %v2_4023e1 = and i32 %v1_4023e1, %v0_4023e1
  store i32 %v2_4023e1, i32* inttoptr (i32 4763819 to i32*), align 4
  %v0_4023e7 = load i32, i32* %ebx.global-to-local, align 4
  %v1_4023e7 = load i32, i32* inttoptr (i32 4764083 to i32*), align 4
  %v2_4023e7 = or i32 %v1_4023e7, %v0_4023e7
  store i32 %v2_4023e7, i32* %ebx.global-to-local, align 4
  %v0_4023ed = load i32, i32* %edx.global-to-local, align 4
  %v1_4023ed = load i32, i32* %eax.global-to-local, align 4
  %v2_4023ed = add i32 %v1_4023ed, %v0_4023ed
  store i32 %v2_4023ed, i32* %edx.global-to-local, align 4
  %v0_4023ef = load i32, i32* inttoptr (i32 4763726 to i32*), align 4
  %v2_4023ef = add i32 %v0_4023ef, %v2_4023e7
  store i32 %v2_4023ef, i32* inttoptr (i32 4763726 to i32*), align 4
  %v0_4023f5 = load i32, i32* inttoptr (i32 4763667 to i32*), align 4
  %v1_4023f5 = load i32, i32* %esi.global-to-local, align 4
  %v2_4023f5 = and i32 %v1_4023f5, %v0_4023f5
  store i32 %v2_4023f5, i32* inttoptr (i32 4763667 to i32*), align 4
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 1048576, i32* %eax.global-to-local, align 4
  %v9_402414 = call i32* @OpenJobObjectW(i32 1048576, i1 false, i16* bitcast ([13 x i8]* @global_var_48b6a3.4 to i16*))
  %v10_402414 = ptrtoint i32* %v9_402414 to i32
  store i32 %v10_402414, i32* %eax.global-to-local, align 4
  %sext = mul i32 %v10_402414, 16777216
  store i1 false, i1* %cf.global-to-local, align 1
  %v2_40241a = icmp eq i32 %sext, 0
  %v1_40241d = icmp eq i1 %v2_40241a, false
  call void @__pseudo_cond_branch(i1 %v1_40241d, i32 ptrtoint (i16** @global_var_406dd5.3 to i32))
  %v0_402423 = load i32, i32* inttoptr (i32 4763828 to i32*), align 4
  %v1_402423 = and i32 %v0_402423, 72
  store i32 %v1_402423, i32* inttoptr (i32 4763828 to i32*), align 4
  %v0_40242a = load i32, i32* %esi.global-to-local, align 4
  %v1_40242a = add i32 %v0_40242a, -107
  store i32 %v1_40242a, i32* %esi.global-to-local, align 4
  %v0_40242d = load i32, i32* inttoptr (i32 4764007 to i32*), align 4
  %v1_40242d = or i32 %v0_40242d, 46
  store i32 %v1_40242d, i32* inttoptr (i32 4764007 to i32*), align 4
  %v0_402434 = load i32, i32* inttoptr (i32 4764080 to i32*), align 16
  %v3_402434 = add i32 %v0_402434, 22
  %v22_402434 = icmp ugt i32 %v0_402434, -23
  store i32 %v3_402434, i32* inttoptr (i32 4764080 to i32*), align 16
  store i32 1, i32* %ecx.global-to-local, align 4
  %v1_402440 = load i32, i32* inttoptr (i32 4764041 to i32*), align 4
  %v4_402440 = select i1 %v22_402434, i32 2, i32 1
  %v5_402440 = add i32 %v4_402440, %v1_402440
  store i32 %v5_402440, i32* %ecx.global-to-local, align 4
  %v0_402446 = load i32, i32* %ebx.global-to-local, align 4
  %v1_402446 = add i32 %v0_402446, -113
  %v5_402446 = icmp ult i32 %v0_402446, 113
  store i1 %v5_402446, i1* %cf.global-to-local, align 1
  %v11_402446 = trunc i32 %v1_402446 to i8
  store i32 %v1_402446, i32* %ebx.global-to-local, align 4
  %v2_402449 = load i8, i8* inttoptr (i32 4763795 to i8*), align 1
  %v4_402449 = zext i1 %v5_402446 to i8
  %v5_402449 = add i8 %v4_402449, %v11_402446
  %v6_402449 = add i8 %v5_402449, %v2_402449
  %v27_402449 = zext i8 %v6_402449 to i32
  %v29_402449 = and i32 %v1_402446, -256
  %v30_402449 = or i32 %v27_402449, %v29_402449
  store i32 %v30_402449, i32* %ebx.global-to-local, align 4
  %v2_40244f = sdiv i32 %sext, 16777216
  %v3_40244f = add i32 %v5_402440, %v2_40244f
  store i32 %v3_40244f, i32* %ecx.global-to-local, align 4
  %v0_402451 = load i32, i32* inttoptr (i32 4763843 to i32*), align 4
  %v1_402451 = load i32, i32* %edi.global-to-local, align 4
  %v2_402451 = sub i32 %v0_402451, %v1_402451
  store i32 %v2_402451, i32* inttoptr (i32 4763843 to i32*), align 4
  %v1_402457 = and i32 %v1_402451, 15
  store i32 %v1_402457, i32* %edi.global-to-local, align 4
  %v0_40245a = load i32, i32* %ecx.global-to-local, align 4
  %v1_40245a = trunc i32 %v0_40245a to i8
  %v3_40245a = udiv i32 %v0_40245a, 256
  %v4_40245a = trunc i32 %v3_40245a to i8
  %v7_40245a = sub i32 %v0_40245a, %v3_40245a
  %v23_40245a = icmp ult i8 %v1_40245a, %v4_40245a
  %v38_40245a = and i32 %v7_40245a, 255
  %v40_40245a = and i32 %v0_40245a, -256
  %v41_40245a = or i32 %v38_40245a, %v40_40245a
  store i32 %v41_40245a, i32* %ecx.global-to-local, align 4
  %v0_40245c = load i32, i32* inttoptr (i32 4764054 to i32*), align 4
  %v4_40245c = zext i1 %v23_40245a to i32
  %v5_40245c = sub i32 %v0_40245c, %v2_40244f
  %v6_40245c = add i32 %v5_40245c, %v4_40245c
  store i32 %v6_40245c, i32* inttoptr (i32 4764054 to i32*), align 4
  %v0_402462 = load i32, i32* %edx.global-to-local, align 4
  %v1_402462 = and i32 %v0_402462, -256
  %v2_402464 = load i32, i32* %ebx.global-to-local, align 4
  %v3_402464 = udiv i32 %v2_402464, 256
  %v4_402464 = trunc i32 %v3_402464 to i8
  %v5_402464 = add i8 %v4_402464, 1
  %v10_402464 = icmp eq i8 %v5_402464, 0
  %v20_402464 = zext i8 %v5_402464 to i32
  %v23_402464 = or i32 %v20_402464, %v1_402462
  store i32 %v23_402464, i32* %edx.global-to-local, align 4
  %v0_402466 = load i32, i32* %edi.global-to-local, align 4
  %v3_402466 = zext i1 %v10_402464 to i32
  %v4_402466 = sub i32 %v0_402466, %v23_402464
  %v5_402466 = add i32 %v4_402466, %v3_402466
  %v16_402466 = sub i32 %v4_402466, %v3_402466
  %v17_402466 = icmp ult i32 %v0_402466, %v16_402466
  %v18_402466 = icmp ne i32 %v23_402464, -1
  %v19_402466 = or i1 %v18_402466, %v17_402466
  %v20_402466 = icmp ult i32 %v0_402466, %v23_402464
  %v21_402466 = select i1 %v10_402464, i1 %v19_402466, i1 %v20_402466
  store i1 %v21_402466, i1* %cf.global-to-local, align 1
  store i32 %v5_402466, i32* %edi.global-to-local, align 4
  call void @__pseudo_call(i32 0)
  %v0_402470 = load i8, i8* inttoptr (i32 4763877 to i8*), align 1
  %v1_402470 = xor i8 %v0_402470, -128
  store i8 %v1_402470, i8* inttoptr (i32 4763877 to i8*), align 1
  %v0_402477 = load i32, i32* inttoptr (i32 4763937 to i32*), align 4
  %v1_402477 = load i32, i32* %ecx.global-to-local, align 4
  %v2_402477 = and i32 %v1_402477, %v0_402477
  store i32 %v2_402477, i32* inttoptr (i32 4763937 to i32*), align 4
  %v2_40247d = udiv i32 %v2_40244f, 256
  %v3_40247d = trunc i32 %v2_40247d to i8
  %v24_40247d = icmp ugt i8 %v3_40247d, -111
  store i1 %v24_40247d, i1* %cf.global-to-local, align 1
  %v6_40247d = mul nuw i32 %v2_40247d, 256
  %v26_40247d = add i32 %v6_40247d, 28160
  %v29_40247d = and i32 %v26_40247d, 65280
  %v30_40247d = and i32 %v2_40244f, -65281
  %v31_40247d = or i32 %v29_40247d, %v30_40247d
  store i32 %v31_40247d, i32* %eax.global-to-local, align 4
  %v0_402480 = load i32, i32* %ebx.global-to-local, align 4
  %v1_402480 = trunc i32 %v0_402480 to i8
  %v2_402480 = load i8, i8* inttoptr (i32 4763736 to i8*), align 8
  %v4_402480 = zext i1 %v24_40247d to i8
  %v5_402480 = add i8 %v2_402480, %v4_402480
  %v6_402480 = add i8 %v5_402480, %v1_402480
  %v27_402480 = zext i8 %v6_402480 to i32
  %v29_402480 = and i32 %v0_402480, -256
  %v30_402480 = or i32 %v27_402480, %v29_402480
  store i32 %v30_402480, i32* %ebx.global-to-local, align 4
  store i32 102, i32* inttoptr (i32 4763685 to i32*), align 4
  %v0_402490 = load i32, i32* %edi.global-to-local, align 4
  %v1_402490 = load i32, i32* inttoptr (i32 4763857 to i32*), align 4
  %v2_402490 = add i32 %v0_402490, 29
  %v1_402496 = sub i32 %v2_402490, %v1_402490
  store i32 %v1_402496, i32* %edi.global-to-local, align 4
  %v0_402499 = load i32, i32* inttoptr (i32 4763782 to i32*), align 4
  %v1_402499 = load i32, i32* %esi.global-to-local, align 4
  %v2_402499 = sub i32 %v0_402499, %v1_402499
  %v7_402499 = icmp ult i32 %v0_402499, %v1_402499
  store i32 %v2_402499, i32* inttoptr (i32 4763782 to i32*), align 4
  %v0_40249f = load i32, i32* %ebx.global-to-local, align 4
  %v1_40249f = load i32, i32* %edx.global-to-local, align 4
  %v3_40249f = zext i1 %v7_402499 to i32
  %v4_40249f = add i32 %v3_40249f, %v0_40249f
  %v5_40249f = sub i32 %v4_40249f, %v1_40249f
  store i32 %v5_40249f, i32* %ebx.global-to-local, align 4
  %v0_4024a1 = load i32, i32* %eax.global-to-local, align 4
  %v1_4024a1 = load i32, i32* inttoptr (i32 4763974 to i32*), align 4
  %v2_4024a1 = or i32 %v1_4024a1, %v0_4024a1
  store i32 %v2_4024a1, i32* %eax.global-to-local, align 4
  %v0_4024a7 = load i32, i32* %esi.global-to-local, align 4
  %v1_4024a7 = load i32, i32* %edi.global-to-local, align 4
  %v4_4024a7 = sub i32 %v0_4024a7, %v1_4024a7
  store i32 %v4_4024a7, i32* %esi.global-to-local, align 4
  store i32 %v0_4024a7, i32* %edi.global-to-local, align 4
  %v0_4024ab = load i32, i32* %ecx.global-to-local, align 4
  %v1_4024ab = load i32, i32* inttoptr (i32 4763692 to i32*), align 4
  %v2_4024ab = or i32 %v1_4024ab, %v0_4024ab
  store i32 %v2_4024ab, i32* %ecx.global-to-local, align 4
  %v0_4024b1 = load i32, i32* inttoptr (i32 4763742 to i32*), align 4
  %v2_4024b1 = or i32 %v0_4024b1, %v2_4024a1
  store i32 %v2_4024b1, i32* inttoptr (i32 4763742 to i32*), align 4
  %v1_4024b7 = load i32, i32* %eax.global-to-local, align 4
  %v4_4024b7 = add i32 %v1_4024b7, %v2_4024ab
  %v25_4024b7 = icmp ult i32 %v4_4024b7, %v2_4024ab
  store i1 %v25_4024b7, i1* %cf.global-to-local, align 1
  store i32 %v4_4024b7, i32* %ecx.global-to-local, align 4
  %v1_4024b9 = inttoptr i32 %v1_4024b7 to i8*
  %v2_4024b9 = load i8, i8* %v1_4024b9, align 1
  %v4_4024b9 = trunc i32 %v1_4024b7 to i8
  %v5_4024b9 = add i8 %v2_4024b9, %v4_4024b9
  %v10_4024b9 = icmp ult i8 %v5_4024b9, %v2_4024b9
  store i1 %v10_4024b9, i1* %cf.global-to-local, align 1
  store i8 %v5_4024b9, i8* %v1_4024b9, align 1
  %v0_4024bb = load i32, i32* %eax.global-to-local, align 4
  %v1_4024bb = inttoptr i32 %v0_4024bb to i8*
  %v2_4024bb = load i8, i8* %v1_4024bb, align 1
  %v4_4024bb = trunc i32 %v0_4024bb to i8
  %v5_4024bb = add i8 %v4_4024bb, %v2_4024bb
  %v10_4024bb = icmp ult i8 %v5_4024bb, %v2_4024bb
  store i1 %v10_4024bb, i1* %cf.global-to-local, align 1
  store i8 %v5_4024bb, i8* %v1_4024bb, align 1
  %v0_4024bd = load i32, i32* %eax.global-to-local, align 4
  %v1_4024bd = inttoptr i32 %v0_4024bd to i8*
  %v2_4024bd = load i8, i8* %v1_4024bd, align 1
  %v4_4024bd = trunc i32 %v0_4024bd to i8
  %v5_4024bd = add i8 %v4_4024bd, %v2_4024bd
  %v10_4024bd = icmp ult i8 %v5_4024bd, %v2_4024bd
  store i1 %v10_4024bd, i1* %cf.global-to-local, align 1
  store i8 %v5_4024bd, i8* %v1_4024bd, align 1
  %v0_4024bf = load i32, i32* %ebx.global-to-local, align 4
  %v1_4024bf = add i32 %v0_4024bf, 1023519216
  %v2_4024bf = inttoptr i32 %v1_4024bf to i8*
  %v3_4024bf = load i8, i8* %v2_4024bf, align 1
  %v4_4024bf = load i32, i32* %eax.global-to-local, align 4
  %v5_4024bf = trunc i32 %v4_4024bf to i8
  %v6_4024bf = add i8 %v5_4024bf, %v3_4024bf
  %v11_4024bf = icmp ult i8 %v6_4024bf, %v3_4024bf
  store i1 %v11_4024bf, i1* %cf.global-to-local, align 1
  store i8 %v6_4024bf, i8* %v2_4024bf, align 1
  %v0_4024c5 = load i32, i32* %edx.global-to-local, align 4
  %v1_4024c5 = udiv i32 %v0_4024c5, 256
  %v2_4024c5 = trunc i32 %v1_4024c5 to i8
  %v3_4024c5 = load i32, i32* %eax.global-to-local, align 4
  %v4_4024c5 = add i32 %v3_4024c5, 1024983112
  %v5_4024c5 = inttoptr i32 %v4_4024c5 to i8*
  %v6_4024c5 = load i8, i8* %v5_4024c5, align 1
  %v7_4024c5 = load i1, i1* %cf.global-to-local, align 1
  %v8_4024c5 = zext i1 %v7_4024c5 to i8
  %v9_4024c5 = sub i8 %v2_4024c5, %v6_4024c5
  %v10_4024c5 = add i8 %v9_4024c5, %v8_4024c5
  %v39_4024c5 = zext i8 %v10_4024c5 to i32
  %v41_4024c5 = mul nuw nsw i32 %v39_4024c5, 256
  %v42_4024c5 = and i32 %v0_4024c5, -65281
  %v43_4024c5 = or i32 %v41_4024c5, %v42_4024c5
  store i32 %v43_4024c5, i32* %edx.global-to-local, align 4
  %v0_4024cb = load i32, i32* %ecx.global-to-local, align 4
  %v1_4024cb = add i32 %v0_4024cb, 226558024
  %v2_4024cb = inttoptr i32 %v1_4024cb to i32*
  %v3_4024cb = load i32, i32* %v2_4024cb, align 4
  %v5_4024cb = mul i32 %v3_4024cb, 512
  store i32 %v5_4024cb, i32* %v2_4024cb, align 4
  %v11_4024cb = and i32 %v3_4024cb, 8388608
  %v12_4024cb = icmp ne i32 %v11_4024cb, 0
  store i1 %v12_4024cb, i1* %cf.global-to-local, align 1
  %v0_4024d2 = load i32, i32* %ecx.global-to-local, align 4
  %v1_4024d2 = and i32 %v0_4024d2, -256
  %v2_4024d2 = or i32 %v1_4024d2, 72
  store i32 %v2_4024d2, i32* %ecx.global-to-local, align 4
  %v0_4024d4 = load i32, i32* %edi.global-to-local, align 4
  %v1_4024d4 = add i32 %v0_4024d4, -2097152000
  %v2_4024d4 = inttoptr i32 %v1_4024d4 to i8*
  %v3_4024d4 = load i8, i8* %v2_4024d4, align 1
  %v4_4024d4 = load i32, i32* %ebx.global-to-local, align 4
  %v5_4024d4 = trunc i32 %v4_4024d4 to i8
  %v6_4024d4 = add i8 %v5_4024d4, %v3_4024d4
  store i8 %v6_4024d4, i8* %v2_4024d4, align 1
  %v0_4024da = load i32, i32* %eax.global-to-local, align 4
  %v1_4024da = and i32 %v0_4024da, 4763782
  store i1 false, i1* %cf.global-to-local, align 1
  %v3_4024da = trunc i32 %v1_4024da to i8
  store i32 %v1_4024da, i32* %eax.global-to-local, align 4
  %v0_4024df = load i32, i32* %ebx.global-to-local, align 4
  %v1_4024df = add i32 %v0_4024df, 360805830
  %v2_4024df = inttoptr i32 %v1_4024df to i8*
  %v3_4024df = load i8, i8* %v2_4024df, align 1
  %v11_4024df = icmp ult i8 %v3_4024df, %v3_4024da
  store i1 %v11_4024df, i1* %cf.global-to-local, align 1
  %v0_4024e5 = call i32 @unknown_8e0048b0()
  store i32 %v0_4024e5, i32* %eax.global-to-local, align 4
  %v0_402855 = load i32, i32* %edi.global-to-local, align 4
  %v1_402855 = or i32 %v0_402855, 121
  store i32 %v1_402855, i32* %edi.global-to-local, align 4
  %v1_40285d = load i32, i32* %ebx.global-to-local, align 4
  %v7_40285f = icmp eq i32 %v1_40285d, -1
  store i32 1, i32* %edx.global-to-local, align 4
  %v1_402861 = load i32, i32* inttoptr (i32 4764014 to i32*), align 4
  %v3_402861 = zext i1 %v7_40285f to i32
  %v4_402861 = add i32 %v1_402861, 1
  %v5_402861 = add i32 %v4_402861, %v3_402861
  store i32 %v5_402861, i32* %edx.global-to-local, align 4
  %v0_402867 = load i32, i32* inttoptr (i32 4763936 to i32*), align 32
  %sext35 = mul i32 %v0_4024e5, 16777216
  %v2_402867 = sdiv i32 %sext35, 16777216
  %v3_402867 = add i32 %v0_402867, %v2_402867
  store i32 %v3_402867, i32* inttoptr (i32 4763936 to i32*), align 32
  store i32 234, i32* inttoptr (i32 4763908 to i32*), align 4
  %v0_402877 = load i32, i32* inttoptr (i32 4764111 to i32*), align 4
  %v1_402877 = xor i32 %v0_402877, 216
  store i32 %v1_402877, i32* inttoptr (i32 4764111 to i32*), align 4
  %v1_402886 = load i32, i32* %esi.global-to-local, align 4
  %v2_402886 = add i32 %v1_402886, 1
  %v7_402886 = icmp eq i32 %v2_402886, 0
  store i32 %v2_402886, i32* %ecx.global-to-local, align 4
  %v0_402888 = load i32, i32* %edx.global-to-local, align 4
  %v2_402888 = zext i1 %v7_402886 to i32
  %v3_402888 = add i32 %v0_402888, -123
  %v4_402888 = add i32 %v3_402888, %v2_402888
  %v12_402888 = icmp ult i32 %v0_402888, 123
  %v13_402888 = or i1 %v7_402886, %v12_402888
  store i32 %v4_402888, i32* %edx.global-to-local, align 4
  %v1_40288b = load i32, i32* inttoptr (i32 4764133 to i32*), align 4
  %v3_40288b = zext i1 %v13_402888 to i32
  %v4_40288b = add i32 %v1_40288b, %v4_402888
  %v5_40288b = add i32 %v3_40288b, %v4_40288b
  %v24_40288b = icmp ule i32 %v5_40288b, %v4_402888
  %v25_40288b = icmp ult i32 %v4_40288b, %v4_402888
  %v26_40288b = select i1 %v13_402888, i1 %v24_40288b, i1 %v25_40288b
  store i32 %v5_40288b, i32* %edx.global-to-local, align 4
  %v1_402891 = load i32, i32* inttoptr (i32 4764081 to i32*), align 4
  %v3_402891 = zext i1 %v26_40288b to i32
  %v4_402891 = add i32 %v1_402891, %v2_402886
  %v5_402891 = add i32 %v3_402891, %v4_402891
  %v24_402891 = icmp ule i32 %v5_402891, %v2_402886
  %v25_402891 = icmp ult i32 %v4_402891, %v2_402886
  %v26_402891 = select i1 %v26_40288b, i1 %v24_402891, i1 %v25_402891
  store i1 %v26_402891, i1* %cf.global-to-local, align 1
  store i32 %v5_402891, i32* %ecx.global-to-local, align 4
  %v0_402897 = load i8, i8* inttoptr (i32 4763688 to i8*), align 8
  %v1_402897 = add i8 %v0_402897, 70
  store i8 %v1_402897, i8* inttoptr (i32 4763688 to i8*), align 8
  %v3_40289e = and i32 %v0_4024e5, 195
  %v11_40289e = and i32 %v2_402867, -256
  %v8_40289e = or i32 %v3_40289e, %v11_40289e
  %v12_40289e = or i32 %v8_40289e, 60
  store i32 %v12_40289e, i32* %eax.global-to-local, align 4
  %v0_4028a0 = load i32, i32* inttoptr (i32 4763775 to i32*), align 4
  %v1_4028a0 = and i32 %v0_4028a0, 121
  store i32 %v1_4028a0, i32* inttoptr (i32 4763775 to i32*), align 4
  %v0_4028a7 = load i32, i32* %esi.global-to-local, align 4
  %v1_4028a7 = xor i32 %v0_4028a7, 110
  store i32 %v1_4028a7, i32* %esi.global-to-local, align 4
  %v1_4028aa = load i32, i32* inttoptr (i32 4763888 to i32*), align 16
  %v4_4028aa = add i32 %v1_4028aa, %v1_4028a7
  %v25_4028aa = icmp ult i32 %v4_4028aa, %v1_4028a7
  store i1 %v25_4028aa, i1* %cf.global-to-local, align 1
  store i32 %v4_4028aa, i32* %esi.global-to-local, align 4
  %v0_4028b0 = load i8, i8* inttoptr (i32 4764138 to i8*), align 2
  %v1_4028b0 = load i32, i32* %ecx.global-to-local, align 4
  %v2_4028b0 = trunc i32 %v1_4028b0 to i8
  %v3_4028b0 = and i8 %v2_4028b0, %v0_4028b0
  store i1 false, i1* %cf.global-to-local, align 1
  store i8 %v3_4028b0, i8* inttoptr (i32 4764138 to i8*), align 2
  %v0_4028b6 = load i32, i32* %esi.global-to-local, align 4
  %v1_4028b6 = load i32, i32* %eax.global-to-local, align 4
  %v4_4028b6 = sub i32 %v0_4028b6, %v1_4028b6
  store i32 %v4_4028b6, i32* %esi.global-to-local, align 4
  store i32 11, i32* %eax.global-to-local, align 4
  store i1 false, i1* %cf.global-to-local, align 1
  %v6_4028c9 = call i1 @IsBadStringPtrA(i8* getelementptr inbounds ([12 x i8], [12 x i8]* @global_var_48b6b4.5, i32 0, i32 0), i32 11)
  %v7_4028c9 = sext i1 %v6_4028c9 to i32
  store i32 %v7_4028c9, i32* %eax.global-to-local, align 4
  store i1 false, i1* %cf.global-to-local, align 1
  %v1_4028cf = icmp eq i1 %v6_4028c9, false
  %v1_4028d1 = icmp eq i1 %v1_4028cf, false
  call void @__pseudo_cond_branch(i1 %v1_4028d1, i32 ptrtoint (i16** @global_var_406dd5.3 to i32))
  %v0_4028d7 = load i32, i32* inttoptr (i32 4763807 to i32*), align 4
  %v1_4028d7 = load i32, i32* %esi.global-to-local, align 4
  %v2_4028d7 = load i1, i1* %cf.global-to-local, align 1
  %v3_4028d7 = zext i1 %v2_4028d7 to i32
  %v4_4028d7 = sub i32 %v0_4028d7, %v1_4028d7
  %v5_4028d7 = add i32 %v3_4028d7, %v4_4028d7
  %v16_4028d7 = sub i32 %v4_4028d7, %v3_4028d7
  %v17_4028d7 = icmp ult i32 %v0_4028d7, %v16_4028d7
  %v18_4028d7 = icmp ne i32 %v1_4028d7, -1
  %v19_4028d7 = or i1 %v18_4028d7, %v17_4028d7
  %v20_4028d7 = icmp ult i32 %v0_4028d7, %v1_4028d7
  %v21_4028d7 = select i1 %v2_4028d7, i1 %v19_4028d7, i1 %v20_4028d7
  store i32 %v5_4028d7, i32* inttoptr (i32 4763807 to i32*), align 4
  %v0_4028dd = load i32, i32* inttoptr (i32 4764041 to i32*), align 4
  %v2_4028dd = zext i1 %v21_4028d7 to i32
  %v3_4028dd = add i32 %v0_4028dd, -54
  %v4_4028dd = add i32 %v3_4028dd, %v2_4028dd
  %v12_4028dd = icmp ult i32 %v0_4028dd, 54
  %v13_4028dd = or i1 %v12_4028dd, %v21_4028d7
  store i32 %v4_4028dd, i32* inttoptr (i32 4764041 to i32*), align 4
  %v1_4028e4 = load i32, i32* inttoptr (i32 4763697 to i32*), align 4
  %v3_4028e4 = zext i1 %v13_4028dd to i32
  %v4_4028e4 = add i32 %v1_4028e4, %v7_4028c9
  %v5_4028e4 = add i32 %v4_4028e4, %v3_4028e4
  store i32 %v5_4028e4, i32* %eax.global-to-local, align 4
  %v0_4028ea = load i32, i32* inttoptr (i32 4763987 to i32*), align 4
  %v1_4028ea = load i32, i32* %edi.global-to-local, align 4
  %v2_4028ea = sub i32 %v0_4028ea, %v1_4028ea
  store i32 %v2_4028ea, i32* inttoptr (i32 4763987 to i32*), align 4
  %v0_4028f0 = load i32, i32* %ebx.global-to-local, align 4
  %v1_4028f0 = trunc i32 %v0_4028f0 to i8
  %v2_4028f0 = add i8 %v1_4028f0, 40
  %v6_4028f0 = icmp ugt i8 %v1_4028f0, -41
  store i1 %v6_4028f0, i1* %cf.global-to-local, align 1
  %v15_4028f0 = zext i8 %v2_4028f0 to i32
  %v17_4028f0 = and i32 %v0_4028f0, -256
  %v18_4028f0 = or i32 %v15_4028f0, %v17_4028f0
  store i32 %v18_4028f0, i32* %ebx.global-to-local, align 4
  %v2_4028f3 = load i8, i8* inttoptr (i32 4764005 to i8*), align 1
  %v3_4028f3 = or i8 %v2_4028f3, %v2_4028f0
  store i1 false, i1* %cf.global-to-local, align 1
  %v9_4028f3 = zext i8 %v3_4028f3 to i32
  %v12_4028f3 = or i32 %v9_4028f3, %v17_4028f0
  store i32 %v12_4028f3, i32* %ebx.global-to-local, align 4
  %v0_4028f9 = load i32, i32* %eax.global-to-local, align 4
  %v1_4028f9 = udiv i32 %v0_4028f9, 256
  %v2_4028f9 = trunc i32 %v1_4028f9 to i8
  %v3_4028f9 = load i8, i8* inttoptr (i32 4764076 to i8*), align 4
  %v4_4028f9 = sub i8 %v2_4028f9, %v3_4028f9
  %v9_4028f9 = icmp ult i8 %v2_4028f9, %v3_4028f9
  %v19_4028f9 = zext i8 %v4_4028f9 to i32
  %v21_4028f9 = mul nuw nsw i32 %v19_4028f9, 256
  %v22_4028f9 = and i32 %v0_4028f9, -65281
  %v23_4028f9 = or i32 %v21_4028f9, %v22_4028f9
  store i32 %v23_4028f9, i32* %eax.global-to-local, align 4
  %v0_4028ff = load i32, i32* inttoptr (i32 4764003 to i32*), align 4
  %v1_4028ff = load i32, i32* %esi.global-to-local, align 4
  %v3_4028ff = zext i1 %v9_4028f9 to i32
  %v4_4028ff = sub i32 %v0_4028ff, %v1_4028ff
  %v5_4028ff = add i32 %v4_4028ff, %v3_4028ff
  %v16_4028ff = sub i32 %v4_4028ff, %v3_4028ff
  %v17_4028ff = icmp ult i32 %v0_4028ff, %v16_4028ff
  %v18_4028ff = icmp ne i32 %v1_4028ff, -1
  %v19_4028ff = or i1 %v18_4028ff, %v17_4028ff
  %v20_4028ff = icmp ult i32 %v0_4028ff, %v1_4028ff
  %v21_4028ff = select i1 %v9_4028f9, i1 %v19_4028ff, i1 %v20_4028ff
  store i1 %v21_4028ff, i1* %cf.global-to-local, align 1
  store i32 %v5_4028ff, i32* inttoptr (i32 4764003 to i32*), align 4
  %v0_402905 = load i8, i8* inttoptr (i32 4764098 to i8*), align 2
  %v1_402905 = load i32, i32* %ebx.global-to-local, align 4
  %v2_402905 = udiv i32 %v1_402905, 256
  %v3_402905 = trunc i32 %v2_402905 to i8
  %v4_402905 = or i8 %v3_402905, %v0_402905
  store i8 %v4_402905, i8* inttoptr (i32 4764098 to i8*), align 2
  %v0_40290b = load i32, i32* inttoptr (i32 4763995 to i32*), align 4
  %v1_40290b = or i32 %v0_40290b, 163
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v1_40290b, i32* inttoptr (i32 4763995 to i32*), align 4
  call void @__pseudo_call(i32 4204829)
  %v0_40291d = load i32, i32* inttoptr (i32 4764031 to i32*), align 4
  %v1_40291d = load i1, i1* %cf.global-to-local, align 1
  %v2_40291d = zext i1 %v1_40291d to i32
  %v3_40291d = add i32 %v0_40291d, -50
  %v4_40291d = add i32 %v3_40291d, %v2_40291d
  store i32 %v4_40291d, i32* inttoptr (i32 4764031 to i32*), align 4
  %v0_402924 = load i32, i32* inttoptr (i32 4763873 to i32*), align 4
  %v1_402924 = load i32, i32* %edi.global-to-local, align 4
  %v2_402924 = add i32 %v1_402924, %v0_402924
  store i32 %v2_402924, i32* inttoptr (i32 4763873 to i32*), align 4
  %v0_40292a = load i32, i32* inttoptr (i32 4763992 to i32*), align 8
  %v1_40292a = and i32 %v0_40292a, 178
  store i32 %v1_40292a, i32* inttoptr (i32 4763992 to i32*), align 8
  %v0_402934 = load i32, i32* inttoptr (i32 4763886 to i32*), align 4
  %v1_402934 = load i32, i32* %esi.global-to-local, align 4
  %v2_402934 = and i32 %v1_402934, %v0_402934
  store i32 %v2_402934, i32* inttoptr (i32 4763886 to i32*), align 4
  %v0_40293a = load i32, i32* %ebx.global-to-local, align 4
  %v2_40293a = mul i32 %v0_40293a, 2
  store i32 %v2_40293a, i32* %ebx.global-to-local, align 4
  %v1_40293c = load i32, i32* inttoptr (i32 4763689 to i32*), align 4
  %v2_40293c = or i32 %v1_40293c, %v1_402934
  store i32 %v2_40293c, i32* %esi.global-to-local, align 4
  %v1_402942 = load i32, i32* inttoptr (i32 4764082 to i32*), align 4
  %v2_402942 = or i32 %v1_402942, %v2_40293c
  store i32 %v2_402942, i32* %esi.global-to-local, align 4
  %v0_402948 = load i32, i32* %eax.global-to-local, align 4
  %v1_402948 = and i32 %v0_402948, 90
  %v3_402948 = trunc i32 %v1_402948 to i8
  %v7_402948 = inttoptr i32 %v1_402948 to i8*
  store i32 %v1_402948, i32* %eax.global-to-local, align 4
  %v1_40294b = load i32, i32* inttoptr (i32 4763675 to i32*), align 4
  %v2_40294b = sub i32 %v2_40293a, %v1_40294b
  store i32 %v2_40294b, i32* %ebx.global-to-local, align 4
  %v0_402951 = load i32, i32* %edi.global-to-local, align 4
  %v3_402951 = sub i32 %v0_402951, %v1_402948
  store i32 %v3_402951, i32* %edi.global-to-local, align 4
  %v0_402953 = load i32, i32* inttoptr (i32 4764129 to i32*), align 4
  %v1_402953 = xor i32 %v0_402953, 230
  store i32 %v1_402953, i32* inttoptr (i32 4764129 to i32*), align 4
  %v0_40295d = load i32, i32* inttoptr (i32 4763744 to i32*), align 32
  %v3_40295d = add i32 %v0_40295d, -41
  %v12_40295d = icmp ult i32 %v0_40295d, 41
  store i1 %v12_40295d, i1* %cf.global-to-local, align 1
  store i32 %v3_40295d, i32* inttoptr (i32 4763744 to i32*), align 32
  %v3_402964 = load i8, i8* %v7_402948, align 2
  %factor87 = mul i8 %v3_402948, 7
  %v7_402970 = add i8 %v3_402964, %factor87
  %v7_402972 = add i8 %v7_402970, %v3_402948
  %v12_402972 = icmp ult i8 %v7_402972, %v7_402970
  store i1 %v12_402972, i1* %cf.global-to-local, align 1
  store i8 %v7_402972, i8* %v7_402948, align 2
  ret i32 %v1_402948

; uselistorder directives
  uselistorder i8 %v7_402970, { 1, 0 }
  uselistorder i32 %v0_40295d, { 1, 0 }
  uselistorder i8* %v7_402948, { 1, 0 }
  uselistorder i32 %v1_402948, { 0, 1, 3, 2, 4 }
  uselistorder i32 %v2_40293a, { 1, 0 }
  uselistorder i32 %v4_4028ff, { 1, 0 }
  uselistorder i32 %v3_4028ff, { 1, 0 }
  uselistorder i32 %v1_4028ff, { 1, 0, 2 }
  uselistorder i1 %v9_4028f9, { 1, 0 }
  uselistorder i32 %v0_4028f9, { 1, 0 }
  uselistorder i32 %v0_4028dd, { 1, 0 }
  uselistorder i1 %v21_4028d7, { 1, 0 }
  uselistorder i32 %v4_4028d7, { 1, 0 }
  uselistorder i32 %v3_4028d7, { 1, 0 }
  uselistorder i32 %v1_4028d7, { 1, 0, 2 }
  uselistorder i32 %v1_4028a7, { 1, 0, 2 }
  uselistorder i32 %v5_402891, { 1, 0 }
  uselistorder i32 %v4_402891, { 1, 0 }
  uselistorder i1 %v26_40288b, { 1, 0 }
  uselistorder i32 %v5_40288b, { 1, 0 }
  uselistorder i32 %v4_40288b, { 1, 0 }
  uselistorder i1 %v13_402888, { 1, 0 }
  uselistorder i32 %v4_402888, { 2, 1, 0, 3 }
  uselistorder i32 %v0_402888, { 1, 0 }
  uselistorder i32 %v2_402886, { 2, 1, 0, 4, 3 }
  uselistorder i32 %v0_4024e5, { 1, 0, 2 }
  uselistorder i32 %v3_4024cb, { 1, 0 }
  uselistorder i32 %v0_4024c5, { 1, 0 }
  uselistorder i8 %v3_4024bf, { 1, 0 }
  uselistorder i8 %v2_4024bd, { 1, 0 }
  uselistorder i8 %v2_4024bb, { 1, 0 }
  uselistorder i8 %v2_4024b9, { 1, 0 }
  uselistorder i32 %v1_4024b7, { 2, 1, 0 }
  uselistorder i32 %v2_40247d, { 1, 0 }
  uselistorder i32 %v4_402466, { 1, 0 }
  uselistorder i32 %v3_402466, { 1, 0 }
  uselistorder i32 %v23_402464, { 1, 2, 0, 3 }
  uselistorder i1 %v10_402464, { 1, 0 }
  uselistorder i8 %v5_402464, { 1, 0 }
  uselistorder i32 %v3_40245a, { 1, 0 }
  uselistorder i32 %v0_40245a, { 2, 1, 0, 3 }
  uselistorder i32 %v2_40244f, { 1, 0, 3, 2 }
  uselistorder i32 %v1_402446, { 0, 2, 1 }
  uselistorder i32 %v0_402446, { 1, 0 }
  uselistorder i32 %sext, { 1, 0 }
  uselistorder i32 %v5_4023d1, { 1, 0 }
  uselistorder i32 %v4_4023d1, { 1, 0 }
  uselistorder i32 %v0_4023d1, { 1, 2, 0 }
  uselistorder i1 %v21_4023cf, { 1, 0 }
  uselistorder i32 %v4_4023cf, { 1, 0 }
  uselistorder i32 %v3_4023cf, { 1, 0 }
  uselistorder i32 %v1_4023cf, { 1, 0, 2 }
  uselistorder i1 %v7_4023cd, { 1, 0 }
  uselistorder i32 %v2_4023cd, { 1, 0, 3, 2 }
  uselistorder i32 %v1_4023a9, { 1, 0, 2 }
  uselistorder i8 %v2_4023a2, { 1, 0 }
  uselistorder i8 %v2_4023a0, { 1, 0 }
  uselistorder i8 %v2_40239e, { 1, 0 }
  uselistorder i8 %v2_40239c, { 1, 0 }
  uselistorder i8 %v2_40239a, { 1, 0 }
  uselistorder i32 %v5_402394, { 1, 0 }
  uselistorder i32 %v4_402394, { 1, 0 }
  uselistorder i32 %v0_402394, { 1, 2, 0 }
  uselistorder i1 %v13_40238d, { 1, 0 }
  uselistorder i32 %v0_40238d, { 1, 0 }
  uselistorder i32 %v5_402373, { 1, 0, 2 }
  uselistorder i32 %v1_402373, { 1, 0, 2 }
  uselistorder i32 %v0_402365, { 1, 0 }
  uselistorder i32 %v0_402357, { 1, 0 }
  uselistorder i32 %v0_40232d, { 1, 0 }
  uselistorder i32 %v0_402327, { 1, 0 }
  uselistorder i8 %v2_402315, { 1, 0 }
  uselistorder i32 %v0_402315, { 1, 0 }
  uselistorder i32 %v11_4022d2, { 1, 0, 2 }
  uselistorder i8 %v6_402291, { 1, 0 }
  uselistorder i8 %v5_402291, { 1, 0 }
  uselistorder i8 %v14_40228f, { 2, 1, 0 }
  uselistorder i1 %v7_40228f, { 1, 0, 2 }
  uselistorder i32 %v1_40228f, { 1, 0 }
  uselistorder i32 %v0_40228f, { 1, 0 }
  uselistorder i32 %v1_402272, { 1, 0, 2 }
  uselistorder i32 %v3_40226e, { 2, 0, 1 }
  uselistorder i8 %v2_40225e, { 1, 0 }
  uselistorder i8 %v2_40225c, { 1, 0 }
  uselistorder i8 %v2_40225a, { 1, 0 }
  uselistorder i32 %v2_402239, { 1, 2, 0, 3 }
  uselistorder i32 %v0_402224, { 1, 0 }
  uselistorder i32 %v5_402222, { 1, 0, 3, 2 }
  uselistorder i32 %v4_402222, { 1, 0 }
  uselistorder i1 %v7_40221c, { 1, 0 }
  uselistorder i32 %v2_40221c, { 2, 1, 0 }
  uselistorder i32 %v0_402207, { 1, 0 }
  uselistorder i1 %v26_402201, { 1, 0 }
  uselistorder i8 %v6_402201, { 1, 0 }
  uselistorder i8 %v5_402201, { 1, 0 }
  uselistorder i1 %v12_4021fa, { 1, 0, 2 }
  uselistorder i32 %v0_4021fa, { 1, 0 }
  uselistorder i32 %v0_4021e7, { 1, 0 }
  uselistorder i32 %v4_4021b9, { 1, 0 }
  uselistorder i1 %v7_4021b7, { 1, 0 }
  uselistorder i32 %v2_4021b7, { 1, 0 }
  uselistorder i32 %v5_4021a7, { 1, 0 }
  uselistorder i32 %v0_4021a7, { 1, 2, 0 }
  uselistorder i8 %v6_40217b, { 1, 0 }
  uselistorder i8 %v5_40217b, { 1, 0 }
  uselistorder i1 %v7_402179, { 1, 0, 2 }
  uselistorder i32 %v2_402179, { 1, 0 }
  uselistorder i32 %v5_402141, { 1, 0 }
  uselistorder i32 %v4_402141, { 1, 0 }
  uselistorder i32 %v0_402141, { 1, 2, 0 }
  uselistorder i1 %v5_40213a, { 1, 0, 2 }
  uselistorder i8 %v0_40213a, { 1, 0 }
  uselistorder i32 %v0_402134, { 1, 0 }
  uselistorder i32 %v0_402131, { 1, 0 }
  uselistorder i32 %v1_402125, { 1, 0 }
  uselistorder i32 %v4_40211c, { 0, 2, 1 }
  uselistorder i1 %v7_40211a, { 1, 0 }
  uselistorder i32 %v2_4020f4, { 1, 0, 2 }
  uselistorder i8* %v31_4020d5, { 1, 0 }
  uselistorder i32 %v30_4020d5, { 1, 0, 2, 4, 3 }
  uselistorder i32 %v0_4020b9, { 1, 0 }
  uselistorder i32 %v4_402082, { 1, 0 }
  uselistorder i1 %v7_402080, { 1, 0 }
  uselistorder i32 %v1_40207a, { 1, 0, 2 }
  uselistorder i8 %v2_402073, { 1, 0 }
  uselistorder i8 %v2_402071, { 1, 0 }
  uselistorder i8 %v3_40206b, { 1, 0 }
  uselistorder i8 %v2_402069, { 1, 0 }
  uselistorder i8 %v2_402067, { 1, 0 }
  uselistorder i8 %v0_402060, { 1, 0 }
  uselistorder i32 %v0_40205a, { 1, 0 }
  uselistorder i32 %v5_402058, { 1, 0 }
  uselistorder i32 %v4_402058, { 1, 0 }
  uselistorder i32 %v0_402058, { 1, 2, 0 }
  uselistorder i1 %v5_402055, { 1, 0 }
  uselistorder i8 %v3_402038, { 1, 0 }
  uselistorder i32 %v0_402033, { 1, 0 }
  uselistorder i1 %v28_402031, { 1, 0 }
  uselistorder i8 %v8_402031, { 0, 2, 1 }
  uselistorder i8 %v7_402031, { 1, 0 }
  uselistorder i8 %v2_402031, { 1, 2, 0 }
  uselistorder i32 %v0_402031, { 1, 2, 0 }
  uselistorder i1 %v25_40202b, { 1, 0, 2 }
  uselistorder i8 %v0_40202b, { 1, 0 }
  uselistorder i32 %v1_402029, { 1, 0 }
  uselistorder i32 %v5_40200e, { 1, 0 }
  uselistorder i32 %v4_40200e, { 1, 0 }
  uselistorder i32 %v0_40200e, { 1, 2, 0 }
  uselistorder i1 %v7_402008, { 1, 0 }
  uselistorder i32 %v0_402008, { 1, 0 }
  uselistorder i8 %v0_401ffb, { 1, 0 }
  uselistorder i32 %v0_401fe1, { 1, 0 }
  uselistorder i32 %v0_401fce, { 1, 0 }
  uselistorder i32 %v5_401fbe, { 1, 0 }
  uselistorder i32 %v4_401fbe, { 1, 0 }
  uselistorder i1 %v7_401fbc, { 1, 0 }
  uselistorder i32 %v2_401fbc, { 2, 1, 0, 3, 4 }
  uselistorder i32 %v0_401fbc, { 1, 0 }
  uselistorder i8 %v0_401f6f, { 1, 0 }
  uselistorder i32 %v5_401ef1, { 1, 0 }
  uselistorder i32 %v4_401ef1, { 1, 0 }
  uselistorder i32 %v0_401ee6, { 1, 0 }
  uselistorder i1 %v26_401ee0, { 1, 0 }
  uselistorder i8 %v2_401ee0, { 1, 0 }
  uselistorder i32 %v0_401ee0, { 1, 0 }
  uselistorder i8 %v7_401ebb, { 1, 0 }
  uselistorder i8 %v4_401ebb, { 1, 0, 2 }
  uselistorder i32 %v0_401ebb, { 1, 2, 0 }
  uselistorder i1 %v24_401eb5, { 1, 0 }
  uselistorder i8* %v12_401e90, { 2, 0, 1 }
  uselistorder i32 %v9_401e90, { 1, 3, 0, 5, 4, 2, 6, 7 }
  uselistorder i32 %v0_401e76, { 1, 0 }
  uselistorder i32 %v1_401e5a, { 0, 2, 1 }
  uselistorder i8 %v2_401e51, { 1, 0 }
  uselistorder i32 %v0_401e4f, { 2, 1, 0 }
  uselistorder i32 %v4_401e43, { 1, 2, 0 }
  uselistorder i32 %v0_401e43, { 1, 0 }
  uselistorder i32 %v0_401e0e, { 1, 0 }
  uselistorder i32 %v5_401e00, { 1, 0 }
  uselistorder i32 %v4_401e00, { 1, 0 }
  uselistorder i32 %v0_401e00, { 1, 2, 0 }
  uselistorder i1 %v7_401dfe, { 1, 0 }
  uselistorder i32 %v0_401dfe, { 1, 0 }
  uselistorder i32 %v5_401de6, { 1, 0 }
  uselistorder i32 %v4_401de6, { 1, 0 }
  uselistorder i32 %v0_401de6, { 1, 2, 0 }
  uselistorder i1 %v7_401de0, { 1, 0 }
  uselistorder i32 %v0_401de0, { 1, 0 }
  uselistorder i32 %v0_401dd7, { 1, 0 }
  uselistorder i8 %v0_401dc3, { 1, 0 }
  uselistorder i32 %v2_401db9, { 1, 0 }
  uselistorder i32 %v1_401db2, { 1, 0 }
  uselistorder i32 %v5_401dac, { 2, 1, 0, 3 }
  uselistorder i32 %v0_401d93, { 1, 0 }
  uselistorder i32 %v1_401d83, { 1, 0 }
  uselistorder i32 %v0_401d60, { 1, 0 }
  uselistorder i32 %v0_401d5a, { 1, 0 }
  uselistorder i8 %v2_401d45, { 1, 0 }
  uselistorder i8 %v2_401d43, { 1, 0 }
  uselistorder i8 %v2_401d41, { 1, 0 }
  uselistorder i8 %v2_401d3f, { 1, 0 }
  uselistorder i32 %v5_401d39, { 1, 0 }
  uselistorder i32 %v4_401d39, { 1, 0 }
  uselistorder i32 %v0_401d39, { 1, 2, 0 }
  uselistorder i1 %v13_401d36, { 1, 0 }
  uselistorder i1 %v7_401d34, { 1, 0 }
  uselistorder i32 %v1_401d32, { 2, 0, 1 }
  uselistorder i32 %v1_401d2e, { 1, 0, 3, 4, 2 }
  uselistorder i32 %v2_401d16, { 1, 0 }
  uselistorder i8 %v7_401cf4, { 1, 0 }
  uselistorder i8 %v2_401cf4, { 1, 2, 0 }
  uselistorder i32 %v0_401cf4, { 1, 0 }
  uselistorder i8 %v0_401ce5, { 1, 0 }
  uselistorder i32 %v5_401cdf, { 1, 0 }
  uselistorder i32 %v4_401cdf, { 1, 0 }
  uselistorder i32 %v0_401cdf, { 1, 2, 0 }
  uselistorder i1 %v26_401cdd, { 1, 0 }
  uselistorder i32 %v5_401cdd, { 1, 0 }
  uselistorder i32 %v4_401cdd, { 1, 0 }
  uselistorder i1 %v7_401cd7, { 1, 0 }
  uselistorder i32 %v2_401cd7, { 2, 1, 0 }
  uselistorder i8 %v0_401cb1, { 1, 0 }
  uselistorder i32 %v4_401ca9, { 1, 0 }
  uselistorder i32 %v5_401c96, { 1, 0 }
  uselistorder i32 %v4_401c96, { 1, 0 }
  uselistorder i32 %v0_401c96, { 1, 2, 0 }
  uselistorder i1 %v5_401c93, { 1, 0 }
  uselistorder i32 %v10_401c7f, { 1, 0, 2 }
  uselistorder i32 %v3_401c5c, { 1, 0 }
  uselistorder i8 %v1_401c5c, { 1, 0 }
  uselistorder i8 %v8_401c51, { 1, 0 }
  uselistorder i8 %v7_401c51, { 1, 0 }
  uselistorder i8 %v18_401c4f, { 2, 1, 0 }
  uselistorder i32 %v4_401c4f, { 0, 2, 1 }
  uselistorder i32 %v1_401c4f, { 2, 0, 1, 3 }
  uselistorder i32 %v2_401c4a, { 1, 2, 0, 3 }
  uselistorder i32 %v5_401c44, { 2, 0, 1 }
  uselistorder i32 %v0_401c1b, { 1, 0 }
  uselistorder i8 %v6_401c13, { 1, 0 }
  uselistorder i8 %v5_401c13, { 1, 0 }
  uselistorder i1 %v13_401c09, { 1, 0, 2 }
  uselistorder i32 %v0_401c09, { 1, 0 }
  uselistorder i32 %v0_401c06, { 1, 0 }
  uselistorder i8 %v2_401c02, { 1, 0 }
  uselistorder i32 %v1_401c00, { 2, 1, 0 }
  uselistorder i32 %v13_401bdf, { 1, 0 }
  uselistorder i32 %v5_401bb1, { 1, 0 }
  uselistorder i32 %v4_401bb1, { 1, 0 }
  uselistorder i32 %v0_401bb1, { 1, 2, 0 }
  uselistorder i32 %v1_401b7b, { 2, 0, 1 }
  uselistorder i32 %v5_401b47, { 1, 2, 0, 3 }
  uselistorder i32 %v0_401b45, { 1, 0 }
  uselistorder i32 %v4_401b43, { 1, 0 }
  uselistorder i32 %v1_401b30, { 1, 0 }
  uselistorder i8 %v2_401b0b, { 1, 0 }
  uselistorder i8 %v2_401b09, { 1, 0 }
  uselistorder i8 %v2_401b07, { 1, 0 }
  uselistorder i8 %v2_401b05, { 1, 0 }
  uselistorder i8 %v2_401b03, { 1, 0 }
  uselistorder i8 %v2_401b01, { 1, 0 }
  uselistorder i8 %v2_401aff, { 1, 0 }
  uselistorder i32 %v5_401af3, { 1, 0, 2 }
  uselistorder i32 %v0_401aed, { 1, 0 }
  uselistorder i32 %v1_401ae2, { 1, 0, 2 }
  uselistorder i8 %v6_401ad1, { 1, 0 }
  uselistorder i8 %v5_401ad1, { 1, 0 }
  uselistorder i1 %v7_401acf, { 1, 0, 2 }
  uselistorder i32 %v0_401acf, { 1, 0 }
  uselistorder i32 %v4_401ac0, { 1, 0 }
  uselistorder i32 %v0_401ac0, { 1, 2, 0 }
  uselistorder i1 %v23_401ab6, { 1, 0 }
  uselistorder i32 %v4_401ab6, { 1, 0 }
  uselistorder i32 %v0_401ab6, { 1, 2, 0 }
  uselistorder i32 %v4_401ab0, { 1, 0 }
  uselistorder i1 %v11_401a9d, { 1, 0 }
  uselistorder i8 %v6_401a9d, { 1, 0 }
  uselistorder i32 %v3_401a9d, { 1, 2, 0 }
  uselistorder i32 %v3_401a7e, { 1, 0 }
  uselistorder i32 %v0_401a7e, { 1, 0 }
  uselistorder i1 %v21_401a7c, { 1, 0 }
  uselistorder i32 %v4_401a7c, { 1, 0 }
  uselistorder i32 %v3_401a7c, { 1, 0 }
  uselistorder i32 %v1_401a7c, { 1, 0, 2 }
  uselistorder i1 %v7_401a7a, { 1, 0 }
  uselistorder i32 %v10_401a6c, { 1, 0, 2 }
  uselistorder i32 %v5_401a34, { 1, 0 }
  uselistorder i32 %v4_401a34, { 1, 0 }
  uselistorder i32 %v0_401a34, { 1, 2, 0 }
  uselistorder i1 %v7_401a32, { 1, 0 }
  uselistorder i32 %v2_401a32, { 1, 0, 2, 3 }
  uselistorder i32 %v0_401a32, { 1, 0 }
  uselistorder i8 %v2_4019ed, { 1, 0 }
  uselistorder i8 %v2_4019eb, { 1, 0 }
  uselistorder i8 %v2_4019e9, { 1, 0 }
  uselistorder i8 %v2_4019e7, { 1, 0 }
  uselistorder i8 %v2_4019e5, { 1, 0 }
  uselistorder i8 %v7_4019df, { 1, 0 }
  uselistorder i8 %v6_4019df, { 1, 0 }
  uselistorder i1 %v10_4019dd, { 1, 0, 2 }
  uselistorder i8 %v2_4019dd, { 1, 0 }
  uselistorder i32 %v0_4019dd, { 1, 2, 0 }
  uselistorder i8 %v4_4019d7, { 1, 2, 0, 3 }
  uselistorder i32 %v0_4019d7, { 2, 1, 0 }
  uselistorder i8 %v7_4019ba, { 1, 0 }
  uselistorder i8 %v6_4019ba, { 1, 0 }
  uselistorder i8 %v2_4019ba, { 1, 2, 0 }
  uselistorder i32 %v0_4019ba, { 0, 2, 1 }
  uselistorder i1 %v7_4019b8, { 1, 0, 2 }
  uselistorder i32 %v0_4019b8, { 1, 0 }
  uselistorder i32 %v0_401992, { 1, 0 }
  uselistorder i32 %v2_401990, { 1, 0, 3, 2 }
  uselistorder i32 %v2_40197b, { 1, 0 }
  uselistorder i8 %v0_401924, { 1, 0 }
  uselistorder i32 %v5_4018eb, { 1, 0 }
  uselistorder i32 %v4_4018eb, { 1, 0 }
  uselistorder i32 %v0_4018eb, { 1, 2, 0 }
  uselistorder i1 %v7_4018e5, { 1, 0 }
  uselistorder i32 %v0_4018e5, { 1, 0 }
  uselistorder i8 %v2_4018d7, { 1, 0 }
  uselistorder i8 %v2_4018d5, { 1, 0 }
  uselistorder i8 %v2_4018d3, { 1, 0 }
  uselistorder i8 %v2_4018d1, { 1, 0 }
  uselistorder i32 %v0_4018be, { 1, 0 }
  uselistorder i32 %v5_4018b8, { 1, 0 }
  uselistorder i32 %v4_4018b8, { 1, 0 }
  uselistorder i32 %v0_4018b8, { 1, 2, 0 }
  uselistorder i1 %v7_4018b6, { 1, 0 }
  uselistorder i32 %v2_4018b6, { 2, 0, 1 }
  uselistorder i32 %v5_4018b4, { 1, 0 }
  uselistorder i32 %v4_4018ae, { 1, 0 }
  uselistorder i32 %v0_4018ae, { 1, 2, 0 }
  uselistorder i32 %v0_401895, { 1, 0 }
  uselistorder i32 %v5_401881, { 1, 0 }
  uselistorder i32 %v4_401881, { 1, 0 }
  uselistorder i1 %v7_40187f, { 1, 0 }
  uselistorder i32 %v2_40187f, { 2, 1, 0, 3, 4 }
  uselistorder i32 %v0_40187f, { 1, 0 }
  uselistorder i32 %v4_40186a, { 1, 0 }
  uselistorder i1 %v11_401868, { 1, 0 }
  uselistorder i8 %v2_401868, { 1, 0 }
  uselistorder i32 %v0_401868, { 1, 0 }
  uselistorder i32 %v0_401838, { 1, 0 }
  uselistorder i32 %v9_401816, { 1, 0, 2 }
  uselistorder i32 %v0_4017f4, { 0, 2, 1 }
  uselistorder i8 %v2_4017c5, { 1, 0 }
  uselistorder i32 %v4_4017b3, { 1, 0, 2, 3 }
  uselistorder i32 %v0_4017b3, { 1, 0 }
  uselistorder i32 %v5_401797, { 1, 0 }
  uselistorder i32 %v4_401797, { 1, 0 }
  uselistorder i32 %v0_401797, { 1, 2, 0 }
  uselistorder i1 %v7_401795, { 1, 0 }
  uselistorder i32 %v0_401795, { 1, 0 }
  uselistorder i32 %v0_40177d, { 1, 0 }
  uselistorder i32 %v5_401756, { 1, 0 }
  uselistorder i32 %v1_401742, { 1, 0, 2 }
  uselistorder i32 %v9_401730, { 0, 3, 2, 1, 4 }
  uselistorder i8 %v0_40170e, { 1, 0 }
  uselistorder i32 %v2_40170c, { 1, 0 }
  uselistorder i32 %v4_4016f0, { 1, 0 }
  uselistorder i1 %v7_4016ee, { 1, 0 }
  uselistorder i32 %v5_4016de, { 1, 0, 2 }
  uselistorder i32 %v5_4016d3, { 1, 0 }
  uselistorder i32 %v4_4016d3, { 1, 0 }
  uselistorder i32 %v0_4016d3, { 1, 2, 0 }
  uselistorder i32* %esi.global-to-local, { 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 26, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120 }
  uselistorder i32* %edi.global-to-local, { 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 104, 105, 106, 80, 78, 79, 81, 84, 82, 83, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103 }
  uselistorder i32* %ecx.global-to-local, { 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 25, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 103, 104, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102 }
  uselistorder i32* %ebx.global-to-local, { 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 54, 57, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145 }
  uselistorder i32* %eax.global-to-local, { 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 30, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 106, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 142, 138, 139, 140, 141, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169 }
  uselistorder i1* %cf.global-to-local, { 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 164, 165, 166, 167, 168, 169, 170, 171, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163 }
  uselistorder i32 4763819, { 1, 0 }
  uselistorder i32* inttoptr (i32 4763968 to i32*), { 2, 0, 1 }
  uselistorder i32* inttoptr (i32 4764131 to i32*), { 2, 3, 4, 5, 0, 1 }
  uselistorder i8 68, { 1, 0 }
  uselistorder i32* inttoptr (i32 4764059 to i32*), { 2, 3, 0, 1 }
  uselistorder i32 -12, { 1, 0 }
  uselistorder i32 221, { 2, 0, 1 }
  uselistorder i32 -58, { 1, 0 }
  uselistorder i32* inttoptr (i32 4764045 to i32*), { 1, 2, 3, 0 }
}

define i32 @function_402974() local_unnamed_addr {
bb:
  %cf.global-to-local = alloca i1, align 1
  %eax.global-to-local = alloca i32, align 4
  %ebx.global-to-local = alloca i32, align 4
  %ecx.global-to-local = alloca i32, align 4
  %edi.global-to-local = alloca i32, align 4
  %edx.global-to-local = alloca i32, align 4
  %esi.global-to-local = alloca i32, align 4
  br label %dec_label_pc_402974

dec_label_pc_402974:                              ; preds = %dec_label_pc_4070e0, %dec_label_pc_406df8, %dec_label_pc_406dd5, %bb
  %v0_402974 = load i32, i32* @ebp, align 4
  %v5_402978 = icmp ugt i32 %v0_402974, -5
  store i1 %v5_402978, i1* %cf.global-to-local, align 1
  %v0_40297c = load i32, i32* @ecx, align 4
  %v1_40297c = inttoptr i32 %v0_40297c to i8*
  %v2_40297c = load i8, i8* %v1_40297c, align 1
  %v3_40297c = add i8 %v2_40297c, 1
  store i8 %v3_40297c, i8* %v1_40297c, align 1
  %v0_40297e = load i32, i32* @esp, align 4
  %v1_40297e = add i32 %v0_40297e, -4
  %v2_40297e = inttoptr i32 %v1_40297e to i32*
  store i32 4204928, i32* %v2_40297e, align 4
  %v3_40297e = load i32, i32* @ebx, align 4
  %v4_40297e = inttoptr i32 %v3_40297e to i32*
  %v5_40297e = load i32, i32* %v4_40297e, align 4
  call void @__pseudo_call(i32 %v5_40297e)
  %v0_402980 = load i32, i32* @eax, align 4
  %v0_402985 = load i32, i32* @ecx, align 4
  %v1_402985 = and i32 %v0_402985, -65281
  %v19_402987 = or i32 %v1_402985, 8192
  store i32 %v19_402987, i32* @ecx, align 4
  store i32 33, i32* %edx.global-to-local, align 4
  %v1_402995 = add i32 %v0_402980, 4763542
  store i32 %v1_402995, i32* %eax.global-to-local, align 4
  store i32 224, i32* inttoptr (i32 4763728 to i32*), align 16
  %v1_4029a2 = load i32, i32* inttoptr (i32 4763803 to i32*), align 4
  %v2_4029a2 = sub i32 33, %v1_4029a2
  %v7_4029a2 = icmp ugt i32 %v1_4029a2, 33
  %v0_4029a8 = load i32, i32* @esi, align 4
  %v2_4029a8 = zext i1 %v7_4029a2 to i32
  %v3_4029a8 = add i32 %v0_4029a8, 113
  %v4_4029a8 = add i32 %v3_4029a8, %v2_4029a8
  store i32 %v4_4029a8, i32* @esi, align 4
  %v1_4029ab = load i32, i32* @ecx, align 4
  %v2_4029ab = sub i32 %v2_4029a2, %v1_4029ab
  %v1_4029ad = add i32 %v2_4029ab, 47
  %v5_4029ad = icmp ult i32 %v2_4029ab, -47
  store i1 %v5_4029ad, i1* %cf.global-to-local, align 1
  store i32 %v1_4029ad, i32* %edx.global-to-local, align 4
  %v0_4029b0 = load i32, i32* %eax.global-to-local, align 4
  %v1_4029b0 = trunc i32 %v0_4029b0 to i8
  %v2_4029b0 = load i8, i8* inttoptr (i32 4763944 to i8*), align 8
  %v4_4029b0 = zext i1 %v5_4029ad to i8
  %v5_4029b0 = add i8 %v1_4029b0, %v2_4029b0
  %v6_4029b0 = add i8 %v5_4029b0, %v4_4029b0
  %v24_4029b0 = icmp ule i8 %v6_4029b0, %v1_4029b0
  %v25_4029b0 = icmp ult i8 %v5_4029b0, %v1_4029b0
  %v26_4029b0 = select i1 %v5_4029ad, i1 %v24_4029b0, i1 %v25_4029b0
  store i1 %v26_4029b0, i1* %cf.global-to-local, align 1
  %v27_4029b0 = zext i8 %v6_4029b0 to i32
  %v29_4029b0 = and i32 %v0_4029b0, -256
  %v30_4029b0 = or i32 %v27_4029b0, %v29_4029b0
  store i32 %v30_4029b0, i32* %eax.global-to-local, align 4
  %v0_4029b6 = load i8, i8* inttoptr (i32 4764126 to i8*), align 2
  %v1_4029b6 = add i8 %v0_4029b6, 122
  store i8 %v1_4029b6, i8* inttoptr (i32 4764126 to i8*), align 2
  %v0_4029bd = load i32, i32* inttoptr (i32 4763998 to i32*), align 4
  %v1_4029bd = and i32 %v0_4029bd, 62
  store i32 %v1_4029bd, i32* inttoptr (i32 4763998 to i32*), align 4
  %v0_4029c4 = load i32, i32* @esp, align 4
  %v1_4029c4 = add i32 %v0_4029c4, -4
  %v2_4029c4 = inttoptr i32 %v1_4029c4 to i32*
  store i32 0, i32* %v2_4029c4, align 4
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 ptrtoint ([13 x i8]* @global_var_48b6a3.4 to i32), i32* %v2_4029c4, align 4
  %v1_4029d4 = load i32, i32* @esp, align 4
  %v2_4029d4 = add i32 %v1_4029d4, -4
  %v3_4029d4 = inttoptr i32 %v2_4029d4 to i32*
  store i32 0, i32* %v3_4029d4, align 4
  store i32 1048576, i32* %eax.global-to-local, align 4
  %v2_4029dc = add i32 %v1_4029d4, -8
  %v3_4029dc = inttoptr i32 %v2_4029dc to i32*
  store i32 1048576, i32* %v3_4029dc, align 4
  %v5_4029dd = call i32* @OpenJobObjectW(i32 ptrtoint (i32* @0 to i32), i1 ptrtoint (i32* @0 to i1), i16* bitcast (i32* @0 to i16*))
  %v6_4029dd = ptrtoint i32* %v5_4029dd to i32
  store i32 %v6_4029dd, i32* %eax.global-to-local, align 4
  store i1 false, i1* %cf.global-to-local, align 1
  %v2_4029e3 = icmp eq i32* %v5_4029dd, null
  %v1_4029e5 = icmp eq i1 %v2_4029e3, false
  br i1 %v1_4029e5, label %dec_label_pc_406dd5, label %dec_label_pc_4029eb

dec_label_pc_4029eb:                              ; preds = %dec_label_pc_402974
  %v0_4029eb = load i32, i32* inttoptr (i32 4764085 to i32*), align 4
  %v1_4029eb = load i32, i32* @esi, align 4
  %v2_4029eb = and i32 %v1_4029eb, %v0_4029eb
  store i32 %v2_4029eb, i32* inttoptr (i32 4764085 to i32*), align 4
  %v0_4029f1 = load i32, i32* inttoptr (i32 4764148 to i32*), align 4
  %v3_4029f1 = add i32 %v0_4029f1, -148
  store i32 %v3_4029f1, i32* inttoptr (i32 4764148 to i32*), align 4
  store i32 0, i32* %esi.global-to-local, align 4
  %v0_4029fd = load i32, i32* @ebx, align 4
  %v1_4029fd = load i32, i32* inttoptr (i32 4763887 to i32*), align 4
  %v4_4029fd = add i32 %v1_4029fd, %v0_4029fd
  %v25_4029fd = icmp ult i32 %v4_4029fd, %v0_4029fd
  store i1 %v25_4029fd, i1* %cf.global-to-local, align 1
  store i32 %v4_4029fd, i32* %ebx.global-to-local, align 4
  %v0_402a03 = load i8, i8* inttoptr (i32 4763842 to i8*), align 2
  %v2_402a03 = udiv i32 %v4_4029fd, 256
  %v3_402a03 = trunc i32 %v2_402a03 to i8
  %v4_402a03 = add i8 %v0_402a03, %v3_402a03
  %v9_402a03 = icmp ult i8 %v4_402a03, %v0_402a03
  store i1 %v9_402a03, i1* %cf.global-to-local, align 1
  store i8 %v4_402a03, i8* inttoptr (i32 4763842 to i8*), align 2
  %v0_402a09 = load i32, i32* inttoptr (i32 4763666 to i32*), align 4
  %v2_402a09 = zext i1 %v9_402a03 to i32
  %v3_402a09 = add i32 %v0_402a09, 238
  %v4_402a09 = add i32 %v3_402a09, %v2_402a09
  store i32 %v4_402a09, i32* inttoptr (i32 4763666 to i32*), align 4
  %v0_402a13 = load i32, i32* @edi, align 4
  %v1_402a13 = load i32, i32* %ebx.global-to-local, align 4
  %v2_402a13 = xor i32 %v1_402a13, %v0_402a13
  store i32 %v2_402a13, i32* %edi.global-to-local, align 4
  %v0_402a15 = load i32, i32* %esi.global-to-local, align 4
  %v2_402a15 = add i32 %v0_402a15, %v1_402a13
  store i32 %v2_402a15, i32* %esi.global-to-local, align 4
  %v0_402a17 = load i32, i32* inttoptr (i32 4764074 to i32*), align 4
  %v1_402a17 = xor i32 %v0_402a17, 103
  store i32 %v1_402a17, i32* inttoptr (i32 4764074 to i32*), align 4
  %v0_402a1e = load i32, i32* inttoptr (i32 4763655 to i32*), align 4
  %v2_402a1e = and i32 %v2_402a15, %v0_402a1e
  store i32 %v2_402a1e, i32* inttoptr (i32 4763655 to i32*), align 4
  %v0_402a24 = load i32, i32* inttoptr (i32 4763664 to i32*), align 16
  %v1_402a24 = or i32 %v0_402a24, 233
  store i32 %v1_402a24, i32* inttoptr (i32 4763664 to i32*), align 16
  %v0_402a2e = load i32, i32* inttoptr (i32 4763941 to i32*), align 4
  %v1_402a2e = load i32, i32* %edi.global-to-local, align 4
  %v2_402a2e = add i32 %v1_402a2e, %v0_402a2e
  store i32 %v2_402a2e, i32* inttoptr (i32 4763941 to i32*), align 4
  %v0_402a34 = load i32, i32* inttoptr (i32 4763752 to i32*), align 8
  %v1_402a34 = or i32 %v0_402a34, 185
  store i32 %v1_402a34, i32* inttoptr (i32 4763752 to i32*), align 8
  %v0_402a3e = load i32, i32* %esi.global-to-local, align 4
  %v1_402a3e = load i32, i32* %ebx.global-to-local, align 4
  %v2_402a3e = xor i32 %v1_402a3e, %v0_402a3e
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v2_402a3e, i32* %esi.global-to-local, align 4
  %v0_402a40 = load i32, i32* @esp, align 4
  %v1_402a40 = add i32 %v0_402a40, -4
  %v2_402a40 = inttoptr i32 %v1_402a40 to i32*
  store i32 4229589, i32* %v2_402a40, align 4
  %v1_402a45 = add i32 %v0_402a40, -8
  %v2_402a45 = inttoptr i32 %v1_402a45 to i32*
  store i32 4205128, i32* %v2_402a45, align 4
  call void @__pseudo_call(i32 4205128)
  %v0_402a48 = load i32, i32* %ebx.global-to-local, align 4
  %v1_402a48 = load i32, i32* inttoptr (i32 4763936 to i32*), align 32
  %v2_402a48 = or i32 %v1_402a48, %v0_402a48
  store i32 %v2_402a48, i32* %ebx.global-to-local, align 4
  %v2_402a4e = load i32, i32* inttoptr (i32 4763960 to i32*), align 8
  %v3_402a4e = sub i32 %v6_4029dd, %v2_402a4e
  %v8_402a4e = icmp ult i32 %v6_4029dd, %v2_402a4e
  store i32 %v3_402a4e, i32* %eax.global-to-local, align 4
  %v0_402a54 = load i32, i32* %edi.global-to-local, align 4
  %v2_402a54 = zext i1 %v8_402a4e to i32
  %v3_402a54 = add i32 %v0_402a54, 24
  %v4_402a54 = add i32 %v3_402a54, %v2_402a54
  store i32 %v4_402a54, i32* %edi.global-to-local, align 4
  %v0_402a57 = load i32, i32* inttoptr (i32 4763957 to i32*), align 4
  %v1_402a57 = or i32 %v0_402a57, 85
  store i32 %v1_402a57, i32* inttoptr (i32 4763957 to i32*), align 4
  %v0_402a5e = load i32, i32* inttoptr (i32 4763815 to i32*), align 4
  %v1_402a5e = or i32 %v0_402a5e, 207
  store i32 %v1_402a5e, i32* inttoptr (i32 4763815 to i32*), align 4
  store i32 0, i32* %ebx.global-to-local, align 4
  %v0_402a6a = load i32, i32* inttoptr (i32 4764070 to i32*), align 4
  %v1_402a6a = load i32, i32* %edi.global-to-local, align 4
  %v4_402a6a = sub i32 %v0_402a6a, %v1_402a6a
  %v20_402a6a = icmp ult i32 %v0_402a6a, %v1_402a6a
  store i1 %v20_402a6a, i1* %cf.global-to-local, align 1
  store i32 %v4_402a6a, i32* inttoptr (i32 4764070 to i32*), align 4
  %v0_402a70 = load i32, i32* %ebx.global-to-local, align 4
  %v1_402a70 = udiv i32 %v0_402a70, 256
  %v2_402a70 = trunc i32 %v1_402a70 to i8
  %v3_402a70 = load i8, i8* inttoptr (i32 4764120 to i8*), align 8
  %v5_402a70 = zext i1 %v20_402a6a to i8
  %v6_402a70 = add i8 %v2_402a70, %v3_402a70
  %v7_402a70 = add i8 %v6_402a70, %v5_402a70
  %v25_402a70 = icmp ule i8 %v7_402a70, %v2_402a70
  %v26_402a70 = icmp ult i8 %v6_402a70, %v2_402a70
  %v27_402a70 = select i1 %v20_402a6a, i1 %v25_402a70, i1 %v26_402a70
  store i1 %v27_402a70, i1* %cf.global-to-local, align 1
  %v28_402a70 = zext i8 %v7_402a70 to i32
  %v30_402a70 = mul nuw nsw i32 %v28_402a70, 256
  %v31_402a70 = and i32 %v0_402a70, -65281
  %v32_402a70 = or i32 %v30_402a70, %v31_402a70
  store i32 %v32_402a70, i32* %ebx.global-to-local, align 4
  %v0_402a76 = load i8, i8* inttoptr (i32 4763682 to i8*), align 2
  %v1_402a76 = add i8 %v0_402a76, -67
  store i8 %v1_402a76, i8* inttoptr (i32 4763682 to i8*), align 2
  %v1_402a7d = load i32, i32* inttoptr (i32 4763808 to i32*), align 32
  %v2_402a7d = sub i32 %v32_402a70, %v1_402a7d
  store i32 %v2_402a7d, i32* %ebx.global-to-local, align 4
  %v0_402a83 = load i32, i32* %esi.global-to-local, align 4
  %v1_402a83 = add i32 %v0_402a83, -90
  %v5_402a83 = icmp ult i32 %v0_402a83, 90
  store i32 %v1_402a83, i32* %esi.global-to-local, align 4
  %v0_402a86 = load i32, i32* %edi.global-to-local, align 4
  %v1_402a86 = load i32, i32* inttoptr (i32 4763670 to i32*), align 4
  %v3_402a86 = zext i1 %v5_402a83 to i32
  %v4_402a86 = add i32 %v3_402a86, %v0_402a86
  %v5_402a86 = add i32 %v4_402a86, %v1_402a86
  store i32 %v5_402a86, i32* %edi.global-to-local, align 4
  store i32 114, i32* %ecx.global-to-local, align 4
  %v1_402a94 = load i32, i32* inttoptr (i32 4763939 to i32*), align 4
  %v4_402a94 = add i32 %v1_402a94, %v2_402a7d
  store i32 %v4_402a94, i32* %ebx.global-to-local, align 4
  %v1_402a9a = add i32 %v0_402a83, 37
  %v4_402a9a = icmp ugt i32 %v1_402a83, -128
  store i1 %v4_402a9a, i1* %cf.global-to-local, align 1
  store i32 %v1_402a9a, i32* %esi.global-to-local, align 4
  %v2_402a9d = load i8, i8* inttoptr (i32 4763792 to i8*), align 16
  %v5_402a9d = select i1 %v4_402a9a, i8 115, i8 114
  %v6_402a9d = add i8 %v5_402a9d, %v2_402a9d
  %v27_402a9d = zext i8 %v6_402a9d to i32
  store i32 %v27_402a9d, i32* %ecx.global-to-local, align 4
  %v2_402aa3 = sub i32 %v4_402a94, %v1_402a9a
  %v7_402aa3 = icmp ult i32 %v4_402a94, %v1_402a9a
  store i1 %v7_402aa3, i1* %cf.global-to-local, align 1
  store i32 %v2_402aa3, i32* %ebx.global-to-local, align 4
  %v0_402aa5 = load i32, i32* %eax.global-to-local, align 4
  %v1_402aa5 = inttoptr i32 %v0_402aa5 to i8*
  %v2_402aa5 = load i8, i8* %v1_402aa5, align 1
  %v4_402aa5 = trunc i32 %v0_402aa5 to i8
  %v5_402aa5 = add i8 %v4_402aa5, %v2_402aa5
  %v10_402aa5 = icmp ult i8 %v5_402aa5, %v2_402aa5
  store i1 %v10_402aa5, i1* %cf.global-to-local, align 1
  store i8 %v5_402aa5, i8* %v1_402aa5, align 1
  %v0_402aa7 = load i32, i32* %eax.global-to-local, align 4
  %v1_402aa7 = inttoptr i32 %v0_402aa7 to i8*
  %v2_402aa7 = load i8, i8* %v1_402aa7, align 1
  %v4_402aa7 = trunc i32 %v0_402aa7 to i8
  %v5_402aa7 = add i8 %v4_402aa7, %v2_402aa7
  %v10_402aa7 = icmp ult i8 %v5_402aa7, %v2_402aa7
  store i1 %v10_402aa7, i1* %cf.global-to-local, align 1
  store i8 %v5_402aa7, i8* %v1_402aa7, align 1
  %v0_402aa9 = load i32, i32* %eax.global-to-local, align 4
  %v1_402aa9 = inttoptr i32 %v0_402aa9 to i8*
  %v2_402aa9 = load i8, i8* %v1_402aa9, align 1
  %v4_402aa9 = trunc i32 %v0_402aa9 to i8
  %v5_402aa9 = add i8 %v4_402aa9, %v2_402aa9
  %v10_402aa9 = icmp ult i8 %v5_402aa9, %v2_402aa9
  store i1 %v10_402aa9, i1* %cf.global-to-local, align 1
  store i8 %v5_402aa9, i8* %v1_402aa9, align 1
  %v0_402aab = load i32, i32* %eax.global-to-local, align 4
  %v1_402aab = inttoptr i32 %v0_402aab to i8*
  %v2_402aab = load i8, i8* %v1_402aab, align 1
  %v4_402aab = trunc i32 %v0_402aab to i8
  %v5_402aab = add i8 %v4_402aab, %v2_402aab
  %v10_402aab = icmp ult i8 %v5_402aab, %v2_402aab
  store i1 %v10_402aab, i1* %cf.global-to-local, align 1
  store i8 %v5_402aab, i8* %v1_402aab, align 1
  %v0_402aad = load i32, i32* %ecx.global-to-local, align 4
  %v1_402aad = inttoptr i32 %v0_402aad to i8*
  %v2_402aad = load i8, i8* %v1_402aad, align 1
  %v3_402aad = load i32, i32* %edx.global-to-local, align 4
  %v4_402aad = udiv i32 %v3_402aad, 256
  %v5_402aad = trunc i32 %v4_402aad to i8
  %v6_402aad = add i8 %v5_402aad, %v2_402aad
  store i8 %v6_402aad, i8* %v1_402aad, align 1
  %v5_402aaf = load i32, i32* %ebx.global-to-local, align 4
  %v0_402ab3 = load i32, i32* %edx.global-to-local, align 4
  %v1_402ab3 = and i32 %v0_402ab3, -65281
  %v2_402ab3 = or i32 %v1_402ab3, 18432
  store i32 %v2_402ab3, i32* %edx.global-to-local, align 4
  %v1_402ab5 = trunc i32 %v5_402aaf to i8
  %v2_402ab5 = load i32, i32* %eax.global-to-local, align 4
  %v3_402ab5 = trunc i32 %v2_402ab5 to i8
  %v4_402ab5 = add i8 %v3_402ab5, %v1_402ab5
  %v19_402ab5 = zext i8 %v4_402ab5 to i32
  %v21_402ab5 = and i32 %v5_402aaf, -65536
  %v22_402ab5 = or i32 %v19_402ab5, %v21_402ab5
  store i32 %v22_402ab5, i32* %ebx.global-to-local, align 4
  %v1_402ab7 = xor i32 %v2_402ab5, 101
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v1_402ab7, i32* %eax.global-to-local, align 4
  %v0_402aba = load i8, i8* inttoptr (i32 4763939 to i8*), align 1
  %v3_402aba = xor i8 %v0_402aba, %v4_402ab5
  store i8 %v3_402aba, i8* inttoptr (i32 4763939 to i8*), align 1
  %v0_402ac0 = load i32, i32* %edi.global-to-local, align 4
  %v1_402ac0 = and i32 %v0_402ac0, -3
  store i32 %v1_402ac0, i32* %edi.global-to-local, align 4
  %v0_402ac3 = load i32, i32* inttoptr (i32 4763941 to i32*), align 4
  %v1_402ac3 = or i32 %v0_402ac3, 255
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v1_402ac3, i32* inttoptr (i32 4763941 to i32*), align 4
  %v0_402acd = load i8, i8* inttoptr (i32 4764107 to i8*), align 1
  %v1_402acd = add i8 %v0_402acd, 124
  store i8 %v1_402acd, i8* inttoptr (i32 4764107 to i8*), align 1
  %v0_402ad4 = load i32, i32* inttoptr (i32 4763893 to i32*), align 4
  %v1_402ad4 = and i32 %v0_402ad4, 169
  store i32 %v1_402ad4, i32* inttoptr (i32 4763893 to i32*), align 4
  %v0_402ade = load i32, i32* %edi.global-to-local, align 4
  %v1_402ade = add i32 %v0_402ade, 113
  %v5_402ade = icmp ugt i32 %v0_402ade, -114
  store i32 %v1_402ade, i32* %edi.global-to-local, align 4
  %v1_402ae1 = load i32, i32* inttoptr (i32 4763920 to i32*), align 16
  %v3_402ae1 = zext i1 %v5_402ade to i32
  %v4_402ae1 = add i32 %v1_402ae1, %v1_402ade
  %v5_402ae1 = add i32 %v4_402ae1, %v3_402ae1
  %v24_402ae1 = icmp ule i32 %v5_402ae1, %v1_402ade
  %v25_402ae1 = icmp ult i32 %v4_402ae1, %v1_402ade
  %v26_402ae1 = select i1 %v5_402ade, i1 %v24_402ae1, i1 %v25_402ae1
  store i32 %v5_402ae1, i32* %edi.global-to-local, align 4
  %v0_402ae7 = load i32, i32* inttoptr (i32 4764005 to i32*), align 4
  %v3_402ae7 = select i1 %v26_402ae1, i32 22, i32 21
  %v4_402ae7 = add i32 %v3_402ae7, %v0_402ae7
  store i32 %v4_402ae7, i32* inttoptr (i32 4764005 to i32*), align 4
  %v1_402af3 = load i32, i32* %eax.global-to-local, align 4
  %v2_402af3 = add i32 %v1_402af3, 1
  %v7_402af3 = icmp eq i32 %v2_402af3, 0
  store i32 %v2_402af3, i32* %edx.global-to-local, align 4
  %v0_402af5 = load i32, i32* %esi.global-to-local, align 4
  %v1_402af5 = load i32, i32* inttoptr (i32 4763940 to i32*), align 4
  %v3_402af5 = zext i1 %v7_402af3 to i32
  %v4_402af5 = add i32 %v1_402af5, %v0_402af5
  %v5_402af5 = add i32 %v4_402af5, %v3_402af5
  %v24_402af5 = icmp ule i32 %v5_402af5, %v0_402af5
  %v25_402af5 = icmp ult i32 %v4_402af5, %v0_402af5
  %v26_402af5 = select i1 %v7_402af3, i1 %v24_402af5, i1 %v25_402af5
  store i1 %v26_402af5, i1* %cf.global-to-local, align 1
  store i32 %v5_402af5, i32* %esi.global-to-local, align 4
  %v0_402afb = load i8, i8* inttoptr (i32 4763828 to i8*), align 4
  %v1_402afb = load i32, i32* %ebx.global-to-local, align 4
  %v2_402afb = trunc i32 %v1_402afb to i8
  %v3_402afb = add i8 %v2_402afb, %v0_402afb
  store i8 %v3_402afb, i8* inttoptr (i32 4763828 to i8*), align 4
  %v0_402b01 = load i32, i32* %edx.global-to-local, align 4
  %v1_402b0147 = add i32 %v0_402b01, 2560
  %v18_402b01 = and i32 %v1_402b0147, 65280
  %v19_402b01 = and i32 %v0_402b01, -65281
  %v20_402b01 = or i32 %v18_402b01, %v19_402b01
  store i32 %v20_402b01, i32* %edx.global-to-local, align 4
  %v0_402b04 = load i32, i32* @esp, align 4
  %v1_402b04 = add i32 %v0_402b04, -4
  %v2_402b04 = inttoptr i32 %v1_402b04 to i32*
  store i32 ptrtoint ([17 x i8]* @global_var_48b692.1 to i32), i32* %v2_402b04, align 4
  %v0_402b0d = load i32, i32* @esp, align 4
  %v1_402b0d = add i32 %v0_402b0d, -4
  %v2_402b0d = inttoptr i32 %v1_402b0d to i32*
  store i32 0, i32* %v2_402b0d, align 4
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 ptrtoint ([13 x i8]* @global_var_48b685.2 to i32), i32* %v2_402b0d, align 4
  %v4_402b16 = call i1 @SetEnvironmentVariableW(i16* bitcast (i32* @0 to i16*), i16* bitcast (i32* @0 to i16*))
  %v5_402b16 = sext i1 %v4_402b16 to i32
  store i32 %v5_402b16, i32* %eax.global-to-local, align 4
  %v0_402b1c = load i32, i32* %ebx.global-to-local, align 4
  %v1_402b1c = load i32, i32* inttoptr (i32 4763868 to i32*), align 4
  %v2_402b1c = sub i32 %v0_402b1c, %v1_402b1c
  store i32 %v2_402b1c, i32* %ebx.global-to-local, align 4
  %v0_402b22 = load i32, i32* inttoptr (i32 4764157 to i32*), align 4
  %v1_402b22 = or i32 %v0_402b22, 18
  store i32 %v1_402b22, i32* inttoptr (i32 4764157 to i32*), align 4
  %v0_402b29 = load i32, i32* inttoptr (i32 4763988 to i32*), align 4
  %v1_402b29 = load i32, i32* %edi.global-to-local, align 4
  %v2_402b29 = or i32 %v1_402b29, %v0_402b29
  store i32 %v2_402b29, i32* inttoptr (i32 4763988 to i32*), align 4
  %v1_402b34 = load i32, i32* %esi.global-to-local, align 4
  %v2_402b34 = add i32 %v1_402b34, 1
  store i32 %v2_402b34, i32* %ecx.global-to-local, align 4
  %v0_402b36 = load i32, i32* %ebx.global-to-local, align 4
  %v1_402b36 = add i32 %v0_402b36, 49
  %v5_402b36 = icmp ugt i32 %v0_402b36, -50
  store i1 %v5_402b36, i1* %cf.global-to-local, align 1
  %v11_402b36 = trunc i32 %v1_402b36 to i8
  store i32 %v1_402b36, i32* %ebx.global-to-local, align 4
  %v2_402b39 = load i8, i8* inttoptr (i32 4763973 to i8*), align 1
  %v3_402b39 = sub i8 %v11_402b36, %v2_402b39
  %v18_402b39 = zext i8 %v3_402b39 to i32
  %v20_402b39 = and i32 %v1_402b36, -256
  %v21_402b39 = or i32 %v18_402b39, %v20_402b39
  store i32 %v21_402b39, i32* %ebx.global-to-local, align 4
  %v0_402b3f = load i32, i32* inttoptr (i32 4763821 to i32*), align 4
  %v1_402b3f = xor i32 %v0_402b3f, 112
  store i32 %v1_402b3f, i32* inttoptr (i32 4763821 to i32*), align 4
  %v0_402b46 = load i32, i32* %ecx.global-to-local, align 4
  %v1_402b46 = add i32 %v0_402b46, -66
  %v5_402b46 = icmp ult i32 %v0_402b46, 66
  store i32 %v1_402b46, i32* %ecx.global-to-local, align 4
  %v1_402b49 = load i32, i32* %ebx.global-to-local, align 4
  %v3_402b49 = zext i1 %v5_402b46 to i32
  %v4_402b49 = sub i32 %v5_402b16, %v1_402b49
  %v5_402b49 = add i32 %v4_402b49, %v3_402b49
  %v16_402b49 = sub i32 %v4_402b49, %v3_402b49
  %v17_402b49 = icmp ult i32 %v5_402b16, %v16_402b49
  %v18_402b49 = icmp ne i32 %v1_402b49, -1
  %v19_402b49 = or i1 %v18_402b49, %v17_402b49
  %v20_402b49 = icmp ult i32 %v5_402b16, %v1_402b49
  %v21_402b49 = select i1 %v5_402b46, i1 %v19_402b49, i1 %v20_402b49
  store i32 %v5_402b49, i32* %eax.global-to-local, align 4
  %v0_402b4b = load i32, i32* inttoptr (i32 4763992 to i32*), align 8
  %v2_402b4b = zext i1 %v21_402b49 to i32
  %v3_402b4b = add i32 %v0_402b4b, 26
  %v4_402b4b = add i32 %v3_402b4b, %v2_402b4b
  store i32 %v4_402b4b, i32* inttoptr (i32 4763992 to i32*), align 8
  %v0_402b52 = load i32, i32* %esi.global-to-local, align 4
  %v1_402b52 = add i32 %v0_402b52, -90
  %v5_402b52 = icmp ult i32 %v0_402b52, 90
  store i1 %v5_402b52, i1* %cf.global-to-local, align 1
  store i32 %v1_402b52, i32* %esi.global-to-local, align 4
  %v0_402b55 = load i32, i32* @esp, align 4
  %v1_402b55 = add i32 %v0_402b55, -4
  %v2_402b55 = inttoptr i32 %v1_402b55 to i32*
  store i32 4204916, i32* %v2_402b55, align 4
  %v1_402b5a = add i32 %v0_402b55, -8
  %v2_402b5a = inttoptr i32 %v1_402b5a to i32*
  store i32 4205405, i32* %v2_402b5a, align 4
  call void @__pseudo_call(i32 4205405)
  %v0_402b5d = load i32, i32* %edx.global-to-local, align 4
  %v1_402b5d = and i32 %v0_402b5d, -256
  %v2_402b5f = load i32, i32* %ebx.global-to-local, align 4
  %v4_402b5f = add i32 %v2_402b5f, 1
  %v19_402b5f = and i32 %v4_402b5f, 175
  %v22_402b5f = or i32 %v1_402b5d, %v19_402b5f
  %v1_402b61 = or i32 %v22_402b5f, 80
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v1_402b61, i32* %edx.global-to-local, align 4
  %v0_402b64 = load i8, i8* inttoptr (i32 4764055 to i8*), align 1
  %v1_402b64 = add i8 %v0_402b64, -23
  store i8 %v1_402b64, i8* inttoptr (i32 4764055 to i8*), align 1
  %v0_402b6b = load i32, i32* %esi.global-to-local, align 4
  %v1_402b6e = add i32 %v0_402b6b, -179
  store i32 %v1_402b6e, i32* %esi.global-to-local, align 4
  %v0_402b71 = load i32, i32* %ebx.global-to-local, align 4
  %v1_402b71 = trunc i32 %v0_402b71 to i8
  %v2_402b71 = load i32, i32* %edx.global-to-local, align 4
  %v3_402b71 = trunc i32 %v2_402b71 to i8
  %v4_402b71 = add i8 %v3_402b71, %v1_402b71
  %v9_402b71 = icmp ult i8 %v4_402b71, %v1_402b71
  %v19_402b71 = zext i8 %v4_402b71 to i32
  %v21_402b71 = and i32 %v0_402b71, -256
  %v22_402b71 = or i32 %v19_402b71, %v21_402b71
  store i32 %v22_402b71, i32* %ebx.global-to-local, align 4
  %v0_402b73 = load i32, i32* %eax.global-to-local, align 4
  %v1_402b73 = load i32, i32* inttoptr (i32 4763689 to i32*), align 4
  %v3_402b73 = zext i1 %v9_402b71 to i32
  %v4_402b73 = add i32 %v1_402b73, %v0_402b73
  %v5_402b73 = add i32 %v3_402b73, %v4_402b73
  %v24_402b73 = icmp ule i32 %v5_402b73, %v0_402b73
  %v25_402b73 = icmp ult i32 %v4_402b73, %v0_402b73
  %v26_402b73 = select i1 %v9_402b71, i1 %v24_402b73, i1 %v25_402b73
  store i1 %v26_402b73, i1* %cf.global-to-local, align 1
  store i32 %v5_402b73, i32* %eax.global-to-local, align 4
  %v0_402b79 = load i8, i8* inttoptr (i32 4763797 to i8*), align 1
  %v1_402b79 = add i8 %v0_402b79, 10
  %v5_402b79 = icmp ult i8 %v0_402b79, -10
  store i1 %v5_402b79, i1* %cf.global-to-local, align 1
  store i8 %v1_402b79, i8* inttoptr (i32 4763797 to i8*), align 1
  %v2_402b80 = zext i1 %v5_402b79 to i32
  %v3_402b80 = add i32 %v5_402b73, 19
  %v4_402b80 = add i32 %v3_402b80, %v2_402b80
  %v12_402b80 = icmp ult i32 %v5_402b73, -19
  %v13_402b80 = or i1 %v12_402b80, %v5_402b79
  store i32 %v4_402b80, i32* %eax.global-to-local, align 4
  %v0_402b83 = load i32, i32* %esi.global-to-local, align 4
  %v1_402b83 = load i32, i32* inttoptr (i32 4763879 to i32*), align 4
  %v3_402b83 = zext i1 %v13_402b80 to i32
  %v4_402b83 = add i32 %v3_402b83, %v0_402b83
  %v5_402b83 = add i32 %v4_402b83, %v1_402b83
  store i32 %v5_402b83, i32* %esi.global-to-local, align 4
  %v1_402b89 = load i32, i32* inttoptr (i32 4763716 to i32*), align 4
  %v2_402b89 = sub i32 %v4_402b80, %v1_402b89
  %v7_402b89 = icmp ult i32 %v4_402b80, %v1_402b89
  store i1 %v7_402b89, i1* %cf.global-to-local, align 1
  store i32 %v2_402b89, i32* %eax.global-to-local, align 4
  %v1_402b8f = udiv i32 %v2_402b89, 256
  %v2_402b8f = trunc i32 %v1_402b8f to i8
  %v3_402b8f = load i8, i8* inttoptr (i32 4763939 to i8*), align 1
  %v5_402b8f = zext i1 %v7_402b89 to i8
  %v6_402b8f = add i8 %v2_402b8f, %v5_402b8f
  %v7_402b8f = add i8 %v6_402b8f, %v3_402b8f
  %v28_402b8f = zext i8 %v7_402b8f to i32
  %v30_402b8f = mul nuw nsw i32 %v28_402b8f, 256
  %v31_402b8f = and i32 %v2_402b89, -65281
  %v32_402b8f = or i32 %v30_402b8f, %v31_402b8f
  store i32 %v32_402b8f, i32* %eax.global-to-local, align 4
  %v0_402b95 = load i32, i32* %ecx.global-to-local, align 4
  %v1_402b95 = add i32 %v0_402b95, 3
  store i32 %v1_402b95, i32* %ecx.global-to-local, align 4
  %v0_402b98 = load i32, i32* inttoptr (i32 4763799 to i32*), align 4
  %v1_402b98 = and i32 %v0_402b98, 158
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v1_402b98, i32* inttoptr (i32 4763799 to i32*), align 4
  %v0_402ba2 = load i32, i32* %eax.global-to-local, align 4
  %v1_402ba2 = inttoptr i32 %v0_402ba2 to i8*
  %v2_402ba2 = load i8, i8* %v1_402ba2, align 1
  %v4_402ba2 = trunc i32 %v0_402ba2 to i8
  %v5_402ba2 = add i8 %v4_402ba2, %v2_402ba2
  %v10_402ba2 = icmp ult i8 %v5_402ba2, %v2_402ba2
  store i1 %v10_402ba2, i1* %cf.global-to-local, align 1
  store i8 %v5_402ba2, i8* %v1_402ba2, align 1
  %v0_402ba4 = load i32, i32* %eax.global-to-local, align 4
  %v1_402ba4 = inttoptr i32 %v0_402ba4 to i8*
  %v2_402ba4 = load i8, i8* %v1_402ba4, align 1
  %v4_402ba4 = trunc i32 %v0_402ba4 to i8
  %v5_402ba4 = add i8 %v4_402ba4, %v2_402ba4
  %v10_402ba4 = icmp ult i8 %v5_402ba4, %v2_402ba4
  store i1 %v10_402ba4, i1* %cf.global-to-local, align 1
  store i8 %v5_402ba4, i8* %v1_402ba4, align 1
  %v0_402ba6 = load i32, i32* %eax.global-to-local, align 4
  %v1_402ba6 = inttoptr i32 %v0_402ba6 to i8*
  %v2_402ba6 = load i8, i8* %v1_402ba6, align 1
  %v4_402ba6 = trunc i32 %v0_402ba6 to i8
  %v5_402ba6 = add i8 %v4_402ba6, %v2_402ba6
  %v10_402ba6 = icmp ult i8 %v5_402ba6, %v2_402ba6
  store i1 %v10_402ba6, i1* %cf.global-to-local, align 1
  store i8 %v5_402ba6, i8* %v1_402ba6, align 1
  %v0_402ba8 = load i32, i32* %eax.global-to-local, align 4
  %v1_402ba8 = inttoptr i32 %v0_402ba8 to i8*
  %v2_402ba8 = load i8, i8* %v1_402ba8, align 1
  %v4_402ba8 = trunc i32 %v0_402ba8 to i8
  %v5_402ba8 = add i8 %v4_402ba8, %v2_402ba8
  %v10_402ba8 = icmp ult i8 %v5_402ba8, %v2_402ba8
  store i1 %v10_402ba8, i1* %cf.global-to-local, align 1
  store i8 %v5_402ba8, i8* %v1_402ba8, align 1
  %v0_402baa = load i32, i32* %eax.global-to-local, align 4
  %v1_402baa = inttoptr i32 %v0_402baa to i8*
  %v2_402baa = load i8, i8* %v1_402baa, align 1
  %v4_402baa = trunc i32 %v0_402baa to i8
  %v5_402baa = add i8 %v4_402baa, %v2_402baa
  %v10_402baa = icmp ult i8 %v5_402baa, %v2_402baa
  store i1 %v10_402baa, i1* %cf.global-to-local, align 1
  store i8 %v5_402baa, i8* %v1_402baa, align 1
  %v0_402bac = load i32, i32* %eax.global-to-local, align 4
  %v1_402bac = inttoptr i32 %v0_402bac to i8*
  %v2_402bac = load i8, i8* %v1_402bac, align 1
  %v4_402bac = trunc i32 %v0_402bac to i8
  %v5_402bac = add i8 %v4_402bac, %v2_402bac
  store i8 %v5_402bac, i8* %v1_402bac, align 1
  %v0_402bae = load i32, i32* %esi.global-to-local, align 4
  %v1_402bae = load i32, i32* %ebx.global-to-local, align 4
  %v2_402bae = sub i32 %v0_402bae, %v1_402bae
  %v7_402bae = icmp ult i32 %v0_402bae, %v1_402bae
  store i32 %v2_402bae, i32* %esi.global-to-local, align 4
  %v3_402bb0 = load i32, i32* %eax.global-to-local, align 4
  %v8_402bb0118 = select i1 %v7_402bae, i32 256, i32 0
  %v1_402bb0119 = add i32 %v8_402bb0118, %v1_402bae
  %v9_402bb0116 = and i32 %v1_402bb0119, 65280
  %v4_402bb0117 = add i32 %v9_402bb0116, %v3_402bb0
  %v32_402bb0 = and i32 %v4_402bb0117, 65280
  %v33_402bb0 = and i32 %v1_402bae, -65281
  %v34_402bb0 = or i32 %v32_402bb0, %v33_402bb0
  store i32 %v34_402bb0, i32* %ebx.global-to-local, align 4
  store i32 0, i32* %eax.global-to-local, align 4
  store i32 1, i32* %ecx.global-to-local, align 4
  %v1_402bb9 = load i32, i32* inttoptr (i32 4763662 to i32*), align 4
  %v4_402bb9 = add i32 %v1_402bb9, 1
  %v16_402bb9 = icmp eq i32 %v4_402bb9, 0
  store i32 %v4_402bb9, i32* %ecx.global-to-local, align 4
  %v0_402bbf = load i32, i32* inttoptr (i32 4764068 to i32*), align 4
  %v3_402bbf = select i1 %v16_402bb9, i32 78, i32 77
  %v4_402bbf = add i32 %v3_402bbf, %v0_402bbf
  store i32 %v4_402bbf, i32* inttoptr (i32 4764068 to i32*), align 4
  %v0_402bc6 = load i32, i32* inttoptr (i32 4764094 to i32*), align 4
  %v1_402bc6 = xor i32 %v0_402bc6, 215
  store i32 %v1_402bc6, i32* inttoptr (i32 4764094 to i32*), align 4
  %v0_402bd0 = load i32, i32* %ecx.global-to-local, align 4
  %v1_402bd0 = load i32, i32* %edi.global-to-local, align 4
  %v4_402bd0 = add i32 %v1_402bd0, %v0_402bd0
  store i32 %v4_402bd0, i32* %ecx.global-to-local, align 4
  %v0_402bd2 = load i32, i32* inttoptr (i32 4763932 to i32*), align 4
  %v2_402bd2 = add i32 %v0_402bd2, %v4_402bd0
  %v7_402bd2 = icmp ult i32 %v2_402bd2, %v0_402bd2
  store i32 %v2_402bd2, i32* inttoptr (i32 4763932 to i32*), align 4
  %v0_402bd8 = load i32, i32* %eax.global-to-local, align 4
  %v2_402bd8 = zext i1 %v7_402bd2 to i32
  %v3_402bd8 = add i32 %v0_402bd8, -91
  %v4_402bd8 = add i32 %v3_402bd8, %v2_402bd8
  %v12_402bd8 = icmp ult i32 %v0_402bd8, 91
  %v13_402bd8 = or i1 %v7_402bd2, %v12_402bd8
  store i1 %v13_402bd8, i1* %cf.global-to-local, align 1
  %v22_402bd8 = trunc i32 %v4_402bd8 to i8
  store i32 %v4_402bd8, i32* %eax.global-to-local, align 4
  %v2_402bdb = load i8, i8* inttoptr (i32 4763859 to i8*), align 1
  %v3_402bdb = or i8 %v2_402bdb, %v22_402bd8
  %v9_402bdb = zext i8 %v3_402bdb to i32
  %v11_402bdb = and i32 %v4_402bd8, -256
  %v12_402bdb = or i32 %v9_402bdb, %v11_402bdb
  store i32 %v12_402bdb, i32* %eax.global-to-local, align 4
  %v0_402be1 = load i32, i32* inttoptr (i32 4764044 to i32*), align 4
  %v3_402be1 = add i32 %v0_402be1, -226
  store i32 %v3_402be1, i32* inttoptr (i32 4764044 to i32*), align 4
  %v0_402beb = load i32, i32* inttoptr (i32 4763946 to i32*), align 4
  %v1_402beb = or i32 %v0_402beb, 37
  store i32 %v1_402beb, i32* inttoptr (i32 4763946 to i32*), align 4
  %v0_402bf2 = load i32, i32* %edi.global-to-local, align 4
  %v1_402bf2 = load i32, i32* %ebx.global-to-local, align 4
  %v4_402bf2 = sub i32 %v0_402bf2, %v1_402bf2
  %v20_402bf2 = icmp ult i32 %v0_402bf2, %v1_402bf2
  store i1 %v20_402bf2, i1* %cf.global-to-local, align 1
  store i32 %v4_402bf2, i32* %edi.global-to-local, align 4
  store i32 0, i32* %eax.global-to-local, align 4
  %v1_402bfb = load i32, i32* @esp, align 4
  %v2_402bfb = add i32 %v1_402bfb, -4
  %v3_402bfb = inttoptr i32 %v2_402bfb to i32*
  store i32 0, i32* %v3_402bfb, align 4
  %v2_402bfc = call i32* @EncodePointer(i32* nonnull @0)
  %v3_402bfc = ptrtoint i32* %v2_402bfc to i32
  %v5_402bfc = trunc i32 %v3_402bfc to i8
  store i32 %v3_402bfc, i32* %eax.global-to-local, align 4
  %v1_402c07 = load i32, i32* %ebx.global-to-local, align 4
  %v2_402c07 = add i32 %v1_402c07, 1
  store i32 %v2_402c07, i32* %edx.global-to-local, align 4
  %v0_402c09 = load i32, i32* inttoptr (i32 4764069 to i32*), align 4
  %v1_402c09 = and i32 %v0_402c09, 33
  store i32 %v1_402c09, i32* inttoptr (i32 4764069 to i32*), align 4
  store i32 1, i32* %ecx.global-to-local, align 4
  %v1_402c15 = load i32, i32* inttoptr (i32 4763787 to i32*), align 4
  %v4_402c15 = add i32 %v1_402c15, 1
  %v16_402c15 = icmp eq i32 %v4_402c15, 0
  store i1 %v16_402c15, i1* %cf.global-to-local, align 1
  store i32 %v4_402c15, i32* %ecx.global-to-local, align 4
  %v3_402c1b = load i8, i8* inttoptr (i32 4763663 to i8*), align 1
  %v4_402c1b = or i8 %v3_402c1b, %v5_402bfc
  %v10_402c1b = zext i8 %v4_402c1b to i32
  %sext25 = mul i32 %v3_402bfc, 16777216
  %v12_402c1b = sdiv i32 %sext25, 16777216
  %v13_402c1b = and i32 %v12_402c1b, -256
  %v14_402c1b = or i32 %v10_402c1b, %v13_402c1b
  store i32 %v14_402c1b, i32* %eax.global-to-local, align 4
  %v0_402c21 = load i32, i32* %esi.global-to-local, align 4
  %v1_402c21 = load i32, i32* inttoptr (i32 4763905 to i32*), align 4
  %v2_402c21 = sub i32 %v0_402c21, %v1_402c21
  store i32 %v2_402c21, i32* %esi.global-to-local, align 4
  %v0_402c27 = load i32, i32* inttoptr (i32 4763714 to i32*), align 4
  %v2_402c27 = or i32 %v0_402c27, %v4_402c15
  store i32 %v2_402c27, i32* inttoptr (i32 4763714 to i32*), align 4
  %v0_402c2d = load i32, i32* %eax.global-to-local, align 4
  %v1_402c2d = load i32, i32* %edi.global-to-local, align 4
  %v4_402c2d = add i32 %v1_402c2d, %v0_402c2d
  %v25_402c2d = icmp ult i32 %v4_402c2d, %v0_402c2d
  store i32 %v4_402c2d, i32* %eax.global-to-local, align 4
  %v0_402c2f = load i32, i32* %ebx.global-to-local, align 4
  %v2_402c2f = zext i1 %v25_402c2d to i32
  %v3_402c2f = add i32 %v0_402c2f, 7
  %v4_402c2f = add i32 %v3_402c2f, %v2_402c2f
  store i32 %v4_402c2f, i32* %ebx.global-to-local, align 4
  %v0_402c32 = load i32, i32* inttoptr (i32 4763935 to i32*), align 4
  %v2_402c32 = sub i32 %v0_402c32, %v1_402c2d
  store i32 %v2_402c32, i32* inttoptr (i32 4763935 to i32*), align 4
  %v0_402c38 = load i32, i32* inttoptr (i32 4763922 to i32*), align 4
  %v1_402c38 = load i32, i32* %edi.global-to-local, align 4
  %v2_402c38 = and i32 %v1_402c38, %v0_402c38
  store i32 %v2_402c38, i32* inttoptr (i32 4763922 to i32*), align 4
  %v0_402c3e = load i32, i32* %esi.global-to-local, align 4
  %v4_402c3e = add i32 %v1_402c38, %v0_402c3e
  store i32 %v4_402c3e, i32* %esi.global-to-local, align 4
  %v0_402c40 = load i32, i32* %ebx.global-to-local, align 4
  %v1_402c40 = add i32 %v0_402c40, -27
  %v5_402c40 = icmp ugt i32 %v0_402c40, 26
  store i32 %v1_402c40, i32* %ebx.global-to-local, align 4
  %v0_402c43 = load i32, i32* %eax.global-to-local, align 4
  %v1_402c43 = load i32, i32* %ecx.global-to-local, align 4
  %v3_402c43 = zext i1 %v5_402c40 to i32
  %v4_402c43 = add i32 %v1_402c43, %v0_402c43
  %v5_402c43 = add i32 %v4_402c43, %v3_402c43
  %v24_402c43 = icmp ule i32 %v5_402c43, %v0_402c43
  %v25_402c43 = icmp ult i32 %v4_402c43, %v0_402c43
  %v26_402c43 = select i1 %v5_402c40, i1 %v24_402c43, i1 %v25_402c43
  store i32 %v5_402c43, i32* %eax.global-to-local, align 4
  %v1_402c45 = load i32, i32* inttoptr (i32 4764047 to i32*), align 4
  %v3_402c45 = zext i1 %v26_402c43 to i32
  %v4_402c45 = add i32 %v1_402c45, %v5_402c43
  %v5_402c45 = add i32 %v3_402c45, %v4_402c45
  %v24_402c45 = icmp ule i32 %v5_402c45, %v5_402c43
  %v25_402c45 = icmp ult i32 %v4_402c45, %v5_402c43
  %v26_402c45 = select i1 %v26_402c43, i1 %v24_402c45, i1 %v25_402c45
  store i32 %v5_402c45, i32* %eax.global-to-local, align 4
  %v1_402c4b = load i32, i32* inttoptr (i32 4763824 to i32*), align 16
  %v3_402c4b = zext i1 %v26_402c45 to i32
  %v4_402c4b = add i32 %v1_402c4b, %v4_402c3e
  %v5_402c4b = add i32 %v3_402c4b, %v4_402c4b
  %v24_402c4b = icmp ule i32 %v5_402c4b, %v4_402c3e
  %v25_402c4b = icmp ult i32 %v4_402c4b, %v4_402c3e
  %v26_402c4b = select i1 %v26_402c45, i1 %v24_402c4b, i1 %v25_402c4b
  store i32 %v5_402c4b, i32* %esi.global-to-local, align 4
  %v3_402c51 = zext i1 %v26_402c4b to i32
  %v4_402c51 = add i32 %v5_402c45, %v1_402c40
  %v5_402c51 = add i32 %v4_402c51, %v3_402c51
  store i32 %v5_402c51, i32* %eax.global-to-local, align 4
  %v1_402c53 = xor i32 %v1_402c40, 61
  store i32 %v1_402c53, i32* %ebx.global-to-local, align 4
  %v0_402c56 = load i32, i32* inttoptr (i32 4764094 to i32*), align 4
  %v2_402c56 = add i32 %v0_402c56, %v1_402c53
  store i32 %v2_402c56, i32* inttoptr (i32 4764094 to i32*), align 4
  %v0_402c5c = load i32, i32* inttoptr (i32 4763939 to i32*), align 4
  %v1_402c5c = load i32, i32* %edx.global-to-local, align 4
  %v2_402c5c = add i32 %v1_402c5c, %v0_402c5c
  %v7_402c5c = icmp ult i32 %v2_402c5c, %v0_402c5c
  store i1 %v7_402c5c, i1* %cf.global-to-local, align 1
  store i32 %v2_402c5c, i32* inttoptr (i32 4763939 to i32*), align 4
  %v0_402c62 = load i32, i32* @esp, align 4
  %v1_402c62 = add i32 %v0_402c62, -4
  %v2_402c62 = inttoptr i32 %v1_402c62 to i32*
  store i32 4243922, i32* %v2_402c62, align 4
  %v1_402c67 = add i32 %v0_402c62, -8
  %v2_402c67 = inttoptr i32 %v1_402c67 to i32*
  store i32 4205674, i32* %v2_402c67, align 4
  call void @__pseudo_call(i32 4205674)
  %v1_402c6a = load i1, i1* %cf.global-to-local, align 1
  %v2_402c6a = zext i1 %v1_402c6a to i32
  store i32 %v2_402c6a, i32* %eax.global-to-local, align 4
  %v0_402c6c = load i32, i32* %ecx.global-to-local, align 4
  %v1_402c6c = load i32, i32* %edi.global-to-local, align 4
  %v2_402c6c = xor i32 %v1_402c6c, %v0_402c6c
  store i32 %v2_402c6c, i32* %ecx.global-to-local, align 4
  %v0_402c6e = load i32, i32* inttoptr (i32 4763713 to i32*), align 4
  %v1_402c6e = load i32, i32* %ebx.global-to-local, align 4
  %v2_402c6e = or i32 %v1_402c6e, %v0_402c6e
  store i32 %v2_402c6e, i32* inttoptr (i32 4763713 to i32*), align 4
  %v0_402c74 = load i32, i32* inttoptr (i32 4763870 to i32*), align 4
  %v3_402c74 = add i32 %v0_402c74, 111
  store i32 %v3_402c74, i32* inttoptr (i32 4763870 to i32*), align 4
  store i32 0, i32* %eax.global-to-local, align 4
  %v0_402c7d = load i32, i32* %ecx.global-to-local, align 4
  %v1_402c7d = load i32, i32* %ebx.global-to-local, align 4
  %v2_402c7d = xor i32 %v1_402c7d, %v0_402c7d
  %v0_402c85 = load i32, i32* %edi.global-to-local, align 4
  %v3_402c85 = add i32 %v0_402c85, 74
  store i32 %v3_402c85, i32* %edi.global-to-local, align 4
  %v9_402c88 = or i32 %v2_402c7d, 232
  store i32 %v9_402c88, i32* %ecx.global-to-local, align 4
  %v0_402c8b = load i32, i32* %edx.global-to-local, align 4
  %v2_402c8b = add i32 %v0_402c8b, %v3_402c85
  store i32 %v2_402c8b, i32* %edx.global-to-local, align 4
  store i1 false, i1* %cf.global-to-local, align 1
  call void @llvm.trap()
  unreachable

dec_label_pc_406dd5:                              ; preds = %dec_label_pc_402974
  %v2_406dd5 = inttoptr i32 %v1_4029d4 to i32*
  store i32 4765330, i32* %v2_406dd5, align 4
  %v0_406dde = load i32, i32* @esp, align 4
  %v1_406dde = add i32 %v0_406dde, -4
  %v2_406dde = inttoptr i32 %v1_406dde to i32*
  store i32 0, i32* %v2_406dde, align 4
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 4765317, i32* %v2_406dde, align 4
  %v4_406de7 = call i1 @SetEnvironmentVariableW(i16* bitcast (i32* @0 to i16*), i16* bitcast (i32* @0 to i16*))
  %v5_406de7 = sext i1 %v4_406de7 to i32
  store i32 %v5_406de7, i32* @eax, align 4
  %v0_406ded = load i32, i32* @ebp, align 4
  %v1_406ded = trunc i32 %v0_406ded to i16
  %v3_406ded = icmp ult i16 %v1_406ded, -768
  store i1 %v3_406ded, i1* %cf.global-to-local, align 1
  br i1 %v3_406ded, label %dec_label_pc_402974, label %dec_label_pc_406df8

dec_label_pc_406df8:                              ; preds = %dec_label_pc_406dd5
  %v0_406df8 = load i32, i32* inttoptr (i32 4763782 to i32*), align 4
  %v1_406df8 = load i32, i32* @ebx, align 4
  %v2_406df8 = or i32 %v1_406df8, %v0_406df8
  store i32 %v2_406df8, i32* inttoptr (i32 4763782 to i32*), align 4
  %v0_406dfe = load i32, i32* @edi, align 4
  %v1_406dfe = xor i32 %v0_406dfe, -53
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v1_406dfe, i32* %edi.global-to-local, align 4
  %v0_406e01 = load i8, i8* inttoptr (i32 4763968 to i8*), align 64
  %v1_406e01 = add i8 %v0_406e01, -27
  store i8 %v1_406e01, i8* inttoptr (i32 4763968 to i8*), align 64
  store i32 104, i32* %ecx.global-to-local, align 4
  %v0_406e10 = load i32, i32* inttoptr (i32 4763742 to i32*), align 4
  %v1_406e10 = load i32, i32* @esi, align 4
  %v2_406e10 = add i32 %v1_406e10, %v0_406e10
  %v7_406e10 = icmp ult i32 %v2_406e10, %v0_406e10
  store i1 %v7_406e10, i1* %cf.global-to-local, align 1
  store i32 %v2_406e10, i32* inttoptr (i32 4763742 to i32*), align 4
  %v0_406e16 = load i32, i32* @eax, align 4
  %v1_406e16 = trunc i32 %v0_406e16 to i8
  %v2_406e16 = load i8, i8* inttoptr (i32 4764063 to i8*), align 1
  %v4_406e16 = zext i1 %v7_406e10 to i8
  %v5_406e16 = add i8 %v1_406e16, %v2_406e16
  %v6_406e16 = add i8 %v5_406e16, %v4_406e16
  %v24_406e16 = icmp ule i8 %v6_406e16, %v1_406e16
  %v25_406e16 = icmp ult i8 %v5_406e16, %v1_406e16
  %v26_406e16 = select i1 %v7_406e10, i1 %v24_406e16, i1 %v25_406e16
  store i1 %v26_406e16, i1* %cf.global-to-local, align 1
  %v27_406e16 = zext i8 %v6_406e16 to i32
  %v29_406e16 = and i32 %v0_406e16, -256
  %v30_406e16 = or i32 %v27_406e16, %v29_406e16
  store i32 %v30_406e16, i32* %eax.global-to-local, align 4
  %v0_406e1c = load i32, i32* @ebx, align 4
  %v1_406e1c = udiv i32 %v0_406e1c, 256
  %v2_406e1c = trunc i32 %v1_406e1c to i8
  %v3_406e1c = load i8, i8* inttoptr (i32 4764064 to i8*), align 32
  %v4_406e1c = sub i8 %v2_406e1c, %v3_406e1c
  %v9_406e1c = icmp ult i8 %v2_406e1c, %v3_406e1c
  %v19_406e1c = zext i8 %v4_406e1c to i32
  %v21_406e1c = mul nuw nsw i32 %v19_406e1c, 256
  %v22_406e1c = and i32 %v0_406e1c, -65281
  %v23_406e1c = or i32 %v21_406e1c, %v22_406e1c
  store i32 %v23_406e1c, i32* %ebx.global-to-local, align 4
  %v0_406e22 = load i32, i32* @esi, align 4
  %v3_406e22 = zext i1 %v9_406e1c to i32
  %v4_406e22 = mul i32 %v0_406e22, 2
  %v5_406e22 = or i32 %v3_406e22, %v4_406e22
  %v24_406e22 = icmp ule i32 %v5_406e22, %v0_406e22
  %v25_406e22 = icmp ult i32 %v4_406e22, %v0_406e22
  %v26_406e22 = select i1 %v9_406e1c, i1 %v24_406e22, i1 %v25_406e22
  store i1 %v26_406e22, i1* %cf.global-to-local, align 1
  store i32 %v5_406e22, i32* %esi.global-to-local, align 4
  %v0_406e24 = load i32, i32* %ecx.global-to-local, align 4
  %v1_406e24 = trunc i32 %v0_406e24 to i8
  %v2_406e24 = load i8, i8* inttoptr (i32 4763758 to i8*), align 2
  %v3_406e24 = or i8 %v1_406e24, %v2_406e24
  %v9_406e24 = zext i8 %v3_406e24 to i32
  %v11_406e24 = and i32 %v0_406e24, -256
  %v12_406e24 = or i32 %v9_406e24, %v11_406e24
  store i32 %v12_406e24, i32* %ecx.global-to-local, align 4
  %v4_406e2a = sub i32 %v5_406e22, %v23_406e1c
  %v20_406e2a = icmp ult i32 %v5_406e22, %v23_406e1c
  store i1 %v20_406e2a, i1* %cf.global-to-local, align 1
  store i32 %v4_406e2a, i32* %esi.global-to-local, align 4
  store i32 ptrtoint ([13 x i8]* @global_var_48b643.12 to i32), i32* %edi.global-to-local, align 4
  store i8 107, i8* getelementptr inbounds ([13 x i8], [13 x i8]* @global_var_48b643.12, i32 0, i32 0), align 1
  %v0_406e36 = load i8, i8* inttoptr (i32 4764147 to i8*), align 1
  %v3_406e36 = xor i8 %v6_406e16, %v0_406e36
  store i8 %v3_406e36, i8* inttoptr (i32 4764147 to i8*), align 1
  %v0_406e3c = load i32, i32* inttoptr (i32 4763932 to i32*), align 4
  %v1_406e3c = xor i32 %v0_406e3c, 97
  store i32 %v1_406e3c, i32* inttoptr (i32 4763932 to i32*), align 4
  %v0_406e43 = load i32, i32* inttoptr (i32 4763813 to i32*), align 4
  %v1_406e43 = and i32 %v0_406e43, 134
  store i32 %v1_406e43, i32* inttoptr (i32 4763813 to i32*), align 4
  %v0_406e4d = load i32, i32* %ecx.global-to-local, align 4
  %v2_406e4d = load i32, i32* %eax.global-to-local, align 4
  %v4_406e4d = add i32 %v2_406e4d, %v0_406e4d
  %v19_406e4d = and i32 %v4_406e4d, 255
  %v21_406e4d = and i32 %v0_406e4d, -256
  %v22_406e4d = or i32 %v19_406e4d, %v21_406e4d
  %v1_406e4f = add i32 %v22_406e4d, 40
  %v5_406e4f = icmp ult i32 %v22_406e4d, -40
  store i32 %v1_406e4f, i32* %ecx.global-to-local, align 4
  %v1_406e52 = load i32, i32* %esi.global-to-local, align 4
  %v3_406e52 = zext i1 %v5_406e4f to i32
  %v4_406e52 = sub i32 %v2_406e4d, %v1_406e52
  %v5_406e52 = add i32 %v3_406e52, %v4_406e52
  %v16_406e52 = sub i32 %v4_406e52, %v3_406e52
  %v17_406e52 = icmp ult i32 %v2_406e4d, %v16_406e52
  %v18_406e52 = icmp ne i32 %v1_406e52, -1
  %v19_406e52 = or i1 %v18_406e52, %v17_406e52
  %v20_406e52 = icmp ult i32 %v2_406e4d, %v1_406e52
  %v21_406e52 = select i1 %v5_406e4f, i1 %v19_406e52, i1 %v20_406e52
  store i1 %v21_406e52, i1* %cf.global-to-local, align 1
  store i32 %v5_406e52, i32* %eax.global-to-local, align 4
  %v0_406e54 = load i8, i8* inttoptr (i32 4763756 to i8*), align 4
  %v1_406e54 = load i32, i32* %ebx.global-to-local, align 4
  %v2_406e54 = trunc i32 %v1_406e54 to i8
  %v3_406e54 = sub i8 %v0_406e54, %v2_406e54
  %v8_406e54 = icmp ult i8 %v0_406e54, %v2_406e54
  store i1 %v8_406e54, i1* %cf.global-to-local, align 1
  store i8 %v3_406e54, i8* inttoptr (i32 4763756 to i8*), align 4
  %v0_406e5a = load i8, i8* inttoptr (i32 4763954 to i8*), align 2
  %v1_406e5a = load i32, i32* %ecx.global-to-local, align 4
  %v2_406e5a = udiv i32 %v1_406e5a, 256
  %v3_406e5a = trunc i32 %v2_406e5a to i8
  %v5_406e5a = zext i1 %v8_406e54 to i8
  %v6_406e5a = add i8 %v3_406e5a, %v0_406e5a
  %v7_406e5a = add i8 %v6_406e5a, %v5_406e5a
  %v25_406e5a = icmp ule i8 %v7_406e5a, %v0_406e5a
  %v26_406e5a = icmp ult i8 %v6_406e5a, %v0_406e5a
  %v27_406e5a = select i1 %v8_406e54, i1 %v25_406e5a, i1 %v26_406e5a
  store i1 %v27_406e5a, i1* %cf.global-to-local, align 1
  store i8 %v7_406e5a, i8* inttoptr (i32 4763954 to i8*), align 2
  store i32 1, i32* %edx.global-to-local, align 4
  %v1_406e65 = load i32, i32* inttoptr (i32 4764070 to i32*), align 4
  %v3_406e65 = zext i1 %v27_406e5a to i32
  %v4_406e65 = add i32 %v1_406e65, 1
  %v5_406e65 = add i32 %v4_406e65, %v3_406e65
  %v1_406e6b = load i32, i32* %ebx.global-to-local, align 4
  %v2_406e6b = add i32 %v5_406e65, %v1_406e6b
  store i32 %v2_406e6b, i32* %edx.global-to-local, align 4
  %v1_406e6d67 = add i32 %v1_406e6b, 30208
  %v19_406e6d = and i32 %v1_406e6d67, 65280
  %v20_406e6d = and i32 %v1_406e6b, -65281
  %v21_406e6d = or i32 %v19_406e6d, %v20_406e6d
  store i32 %v21_406e6d, i32* %ebx.global-to-local, align 4
  %v0_406e70 = load i32, i32* inttoptr (i32 4763918 to i32*), align 4
  %v1_406e70 = xor i32 %v0_406e70, 242
  store i32 %v1_406e70, i32* inttoptr (i32 4763918 to i32*), align 4
  %v0_406e7a = load i32, i32* inttoptr (i32 4764000 to i32*), align 32
  %v1_406e7a = load i32, i32* %eax.global-to-local, align 4
  %v2_406e7a = and i32 %v1_406e7a, %v0_406e7a
  store i32 %v2_406e7a, i32* inttoptr (i32 4764000 to i32*), align 32
  %v0_406e80 = load i32, i32* %ebx.global-to-local, align 4
  %v1_406e80 = load i32, i32* %esi.global-to-local, align 4
  %v2_406e80 = sub i32 %v0_406e80, %v1_406e80
  %v7_406e80 = icmp ult i32 %v0_406e80, %v1_406e80
  store i32 %v2_406e80, i32* %ebx.global-to-local, align 4
  %v0_406e82 = load i32, i32* inttoptr (i32 4763773 to i32*), align 4
  %v1_406e82 = load i32, i32* %edx.global-to-local, align 4
  %v3_406e82 = zext i1 %v7_406e80 to i32
  %v4_406e82 = add i32 %v3_406e82, %v0_406e82
  %v5_406e82 = sub i32 %v4_406e82, %v1_406e82
  store i32 %v5_406e82, i32* inttoptr (i32 4763773 to i32*), align 4
  %v0_406e88 = load i32, i32* inttoptr (i32 4764029 to i32*), align 4
  %v1_406e88 = or i32 %v0_406e88, 70
  store i32 %v1_406e88, i32* inttoptr (i32 4764029 to i32*), align 4
  %v0_406e8f = load i32, i32* %ecx.global-to-local, align 4
  %v1_406e8f = add i32 %v0_406e8f, -108
  %v5_406e8f = icmp ugt i32 %v0_406e8f, 107
  store i32 %v1_406e8f, i32* %ecx.global-to-local, align 4
  %v0_406e92 = load i32, i32* %eax.global-to-local, align 4
  %v1_406e92 = load i32, i32* inttoptr (i32 4763943 to i32*), align 4
  %v3_406e92 = zext i1 %v5_406e8f to i32
  %v4_406e92 = add i32 %v3_406e92, %v0_406e92
  %v5_406e92 = add i32 %v4_406e92, %v1_406e92
  store i32 %v5_406e92, i32* %eax.global-to-local, align 4
  %v1_406e98 = and i32 %v1_406e8f, -124
  %v1_406e9b = add i32 %v1_406e98, -41
  %v5_406e9b = icmp ugt i32 %v1_406e98, 40
  store i32 %v1_406e9b, i32* %ecx.global-to-local, align 4
  %v0_406e9e = load i32, i32* %edi.global-to-local, align 4
  %v1_406e9e = load i32, i32* @esp, align 4
  %v2_406e9e = add i32 %v1_406e9e, -4
  %v3_406e9e = inttoptr i32 %v2_406e9e to i32*
  store i32 %v0_406e9e, i32* %v3_406e9e, align 4
  store i32 32, i32* inttoptr (i32 4763884 to i32*), align 4
  %v0_406ea9 = load i32, i32* %edi.global-to-local, align 4
  %v3_406ea9 = select i1 %v5_406e9b, i32 121, i32 120
  %v4_406ea9 = add i32 %v3_406ea9, %v0_406ea9
  store i32 %v4_406ea9, i32* %edi.global-to-local, align 4
  %v0_406eac = load i32, i32* inttoptr (i32 4764090 to i32*), align 4
  %v1_406eac = load i32, i32* %esi.global-to-local, align 4
  %v2_406eac = sub i32 %v0_406eac, %v1_406eac
  store i32 %v2_406eac, i32* inttoptr (i32 4764090 to i32*), align 4
  %v2_406eb2 = xor i32 %v4_406ea9, %v1_406eac
  store i32 %v2_406eb2, i32* %esi.global-to-local, align 4
  %v0_406eb4 = load i32, i32* %ebx.global-to-local, align 4
  %v2_406eb4 = add i32 %v0_406eb4, %v2_406eb2
  store i32 %v2_406eb4, i32* %ebx.global-to-local, align 4
  %v0_406eb6 = load i32, i32* inttoptr (i32 4764016 to i32*), align 16
  %v1_406eb6 = load i32, i32* %edx.global-to-local, align 4
  %v2_406eb6 = add i32 %v1_406eb6, %v0_406eb6
  store i32 %v2_406eb6, i32* inttoptr (i32 4764016 to i32*), align 16
  %v0_406ebc = load i32, i32* inttoptr (i32 4763878 to i32*), align 4
  %v2_406ebc = or i32 %v1_406eb6, %v0_406ebc
  store i32 %v2_406ebc, i32* inttoptr (i32 4763878 to i32*), align 4
  %v1_406ec2 = load i32, i32* inttoptr (i32 4764077 to i32*), align 4
  %v4_406ec2 = add i32 %v1_406ec2, %v1_406eb6
  store i32 %v4_406ec2, i32* %edx.global-to-local, align 4
  %v0_406ec8 = load i32, i32* inttoptr (i32 4763742 to i32*), align 4
  %v1_406ec8 = xor i32 %v0_406ec8, 182
  store i32 %v1_406ec8, i32* inttoptr (i32 4763742 to i32*), align 4
  %v0_406ed2 = load i32, i32* inttoptr (i32 4764025 to i32*), align 4
  %v1_406ed2 = load i32, i32* %ecx.global-to-local, align 4
  %v2_406ed2 = sub i32 %v0_406ed2, %v1_406ed2
  %v7_406ed2 = icmp ult i32 %v0_406ed2, %v1_406ed2
  store i32 %v2_406ed2, i32* inttoptr (i32 4764025 to i32*), align 4
  %v0_406ed8 = load i32, i32* %eax.global-to-local, align 4
  %v1_406ed8 = load i32, i32* %ebx.global-to-local, align 4
  %v3_406ed8 = zext i1 %v7_406ed2 to i32
  %v4_406ed8 = sub i32 %v0_406ed8, %v1_406ed8
  %v5_406ed8 = add i32 %v4_406ed8, %v3_406ed8
  %v16_406ed8 = sub i32 %v4_406ed8, %v3_406ed8
  %v17_406ed8 = icmp ult i32 %v0_406ed8, %v16_406ed8
  %v18_406ed8 = icmp ne i32 %v1_406ed8, -1
  %v19_406ed8 = or i1 %v18_406ed8, %v17_406ed8
  %v20_406ed8 = icmp ult i32 %v0_406ed8, %v1_406ed8
  %v21_406ed8 = select i1 %v7_406ed2, i1 %v19_406ed8, i1 %v20_406ed8
  store i32 %v5_406ed8, i32* %eax.global-to-local, align 4
  %v0_406eda = load i32, i32* %edi.global-to-local, align 4
  %v1_406eda = load i32, i32* inttoptr (i32 4763724 to i32*), align 4
  %v3_406eda = zext i1 %v21_406ed8 to i32
  %v4_406eda = add i32 %v1_406eda, %v0_406eda
  %v5_406eda = add i32 %v4_406eda, %v3_406eda
  store i32 %v5_406eda, i32* %edi.global-to-local, align 4
  %v0_406ee0 = load i32, i32* inttoptr (i32 4764084 to i32*), align 4
  %v2_406ee0 = xor i32 %v0_406ee0, %v1_406ed8
  store i32 %v2_406ee0, i32* inttoptr (i32 4764084 to i32*), align 4
  %v0_406ee6 = load i32, i32* inttoptr (i32 4763724 to i32*), align 4
  %v1_406ee6 = or i32 %v0_406ee6, 69
  store i32 %v1_406ee6, i32* inttoptr (i32 4763724 to i32*), align 4
  %v0_406eed = load i32, i32* %esi.global-to-local, align 4
  %v1_406eed = load i32, i32* %ecx.global-to-local, align 4
  %v4_406eed = sub i32 %v0_406eed, %v1_406eed
  store i32 %v4_406eed, i32* %esi.global-to-local, align 4
  %v0_406eef = load i32, i32* %edi.global-to-local, align 4
  %v1_406eef = load i32, i32* %edx.global-to-local, align 4
  %v2_406eef = sub i32 %v0_406eef, %v1_406eef
  %v7_406eef = icmp ult i32 %v0_406eef, %v1_406eef
  store i1 %v7_406eef, i1* %cf.global-to-local, align 1
  store i32 %v2_406eef, i32* %edi.global-to-local, align 4
  %v1_406ef1 = udiv i32 %v1_406eef, 256
  %v2_406ef1 = trunc i32 %v1_406ef1 to i8
  %v3_406ef1 = load i8, i8* inttoptr (i32 4763906 to i8*), align 2
  %v4_406ef1 = or i8 %v3_406ef1, %v2_406ef1
  store i1 false, i1* %cf.global-to-local, align 1
  %v10_406ef1 = zext i8 %v4_406ef1 to i32
  %v12_406ef1 = mul nuw nsw i32 %v10_406ef1, 256
  %v13_406ef1 = and i32 %v1_406eef, -65281
  %v14_406ef1 = or i32 %v12_406ef1, %v13_406ef1
  store i32 %v14_406ef1, i32* %edx.global-to-local, align 4
  store i32 4765500, i32* %eax.global-to-local, align 4
  %v3_406efd = call i32* @LoadLibraryA(i8* bitcast (i32* @0 to i8*))
  %v4_406efd = ptrtoint i32* %v3_406efd to i32
  store i32 %v4_406efd, i32* %eax.global-to-local, align 4
  store i32 %v4_406efd, i32* inttoptr (i32 4765192 to i32*), align 8
  %v0_406f04 = load i32, i32* inttoptr (i32 4763693 to i32*), align 4
  %v1_406f04 = load i1, i1* %cf.global-to-local, align 1
  %v2_406f04 = zext i1 %v1_406f04 to i32
  %v3_406f04 = add i32 %v0_406f04, -146
  %v4_406f04 = add i32 %v3_406f04, %v2_406f04
  store i32 %v4_406f04, i32* inttoptr (i32 4763693 to i32*), align 4
  %v0_406f0e = load i32, i32* %edi.global-to-local, align 4
  %v1_406f0e = load i32, i32* inttoptr (i32 4763699 to i32*), align 4
  %v2_406f0e = add i32 %v0_406f0e, 81
  %v1_406f14 = sub i32 %v2_406f0e, %v1_406f0e
  %v1_406f17 = or i32 %v1_406f14, -108
  store i32 %v1_406f17, i32* %edi.global-to-local, align 4
  %v0_406f1a = load i32, i32* %edx.global-to-local, align 4
  %v3_406f1a = add i32 %v0_406f1a, 121
  store i32 %v3_406f1a, i32* %edx.global-to-local, align 4
  %v0_406f1d = load i32, i32* %ebx.global-to-local, align 4
  %v1_406f1d = load i32, i32* %ecx.global-to-local, align 4
  %v2_406f1d = xor i32 %v1_406f1d, %v0_406f1d
  store i32 %v2_406f1d, i32* %ebx.global-to-local, align 4
  %v0_406f1f = load i32, i32* inttoptr (i32 4764006 to i32*), align 4
  %v3_406f1f = add i32 %v0_406f1f, 224
  store i32 %v3_406f1f, i32* inttoptr (i32 4764006 to i32*), align 4
  %v0_406f29 = load i32, i32* inttoptr (i32 4764067 to i32*), align 4
  %v1_406f29 = load i32, i32* %edx.global-to-local, align 4
  %v2_406f29 = add i32 %v1_406f29, %v0_406f29
  store i32 %v2_406f29, i32* inttoptr (i32 4764067 to i32*), align 4
  %v0_406f2f = load i32, i32* inttoptr (i32 4763741 to i32*), align 4
  %v1_406f2f = load i32, i32* %edi.global-to-local, align 4
  %v2_406f2f = add i32 %v1_406f2f, %v0_406f2f
  %v7_406f2f = icmp ult i32 %v2_406f2f, %v0_406f2f
  store i32 %v2_406f2f, i32* inttoptr (i32 4763741 to i32*), align 4
  %v0_406f35 = load i32, i32* %edx.global-to-local, align 4
  %v1_406f35 = load i32, i32* %ebx.global-to-local, align 4
  %v3_406f35 = zext i1 %v7_406f2f to i32
  %v4_406f35 = sub i32 %v0_406f35, %v1_406f35
  %v5_406f35 = add i32 %v4_406f35, %v3_406f35
  store i32 %v5_406f35, i32* %edx.global-to-local, align 4
  %v0_406f37 = load i32, i32* %ecx.global-to-local, align 4
  %v2_406f37 = mul i32 %v0_406f37, 2
  %v7_406f37 = icmp ult i32 %v2_406f37, %v0_406f37
  store i32 ptrtoint ([15 x i8]* @global_var_48b634.13 to i32), i32* %ecx.global-to-local, align 4
  store i8 86, i8* getelementptr inbounds ([15 x i8], [15 x i8]* @global_var_48b634.13, i32 0, i32 0), align 1
  store i8 97, i8* getelementptr inbounds ([10 x i8], [10 x i8]* @global_var_48b639.14, i32 0, i32 0), align 1
  %v1_406f47 = load i32, i32* @esp, align 4
  %v2_406f47 = add i32 %v1_406f47, -4
  %v3_406f47 = inttoptr i32 %v2_406f47 to i32*
  store i32 ptrtoint ([15 x i8]* @global_var_48b634.13 to i32), i32* %v3_406f47, align 4
  %v0_406f48 = load i32, i32* %ebx.global-to-local, align 4
  %v1_406f48 = load i32, i32* inttoptr (i32 4763767 to i32*), align 4
  %v3_406f48 = zext i1 %v7_406f37 to i32
  %v4_406f48 = add i32 %v0_406f48, %v3_406f48
  %v5_406f48 = add i32 %v4_406f48, %v1_406f48
  store i32 %v5_406f48, i32* %ebx.global-to-local, align 4
  %v0_406f4e = load i32, i32* %ecx.global-to-local, align 4
  %v1_406f4e = load i32, i32* %edi.global-to-local, align 4
  %v2_406f4e = xor i32 %v1_406f4e, %v0_406f4e
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v2_406f4e, i32* %ecx.global-to-local, align 4
  %v1_406f50 = udiv i32 %v5_406f48, 256
  %v2_406f50 = trunc i32 %v1_406f50 to i8
  %v3_406f50 = load i8, i8* inttoptr (i32 4764009 to i8*), align 1
  %v6_406f50 = add i8 %v3_406f50, %v2_406f50
  %v26_406f50 = icmp ult i8 %v6_406f50, %v2_406f50
  %v28_406f50 = zext i8 %v6_406f50 to i32
  %v30_406f50 = mul nuw nsw i32 %v28_406f50, 256
  %v31_406f50 = and i32 %v5_406f48, -65281
  %v32_406f50 = or i32 %v30_406f50, %v31_406f50
  store i32 %v32_406f50, i32* %ebx.global-to-local, align 4
  %v0_406f56 = load i32, i32* inttoptr (i32 4764132 to i32*), align 4
  %v2_406f56 = zext i1 %v26_406f50 to i32
  %v3_406f56 = add i32 %v0_406f56, 173
  %v4_406f56 = add i32 %v3_406f56, %v2_406f56
  store i32 %v4_406f56, i32* inttoptr (i32 4764132 to i32*), align 4
  %v1_406f60 = load i32, i32* %esi.global-to-local, align 4
  %v2_406f60 = sub i32 %v32_406f50, %v1_406f60
  store i32 %v2_406f60, i32* %ebx.global-to-local, align 4
  %v0_406f62 = load i32, i32* inttoptr (i32 4763951 to i32*), align 4
  %v1_406f62 = or i32 %v0_406f62, 189
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v1_406f62, i32* inttoptr (i32 4763951 to i32*), align 4
  %v0_406f6c = load i32, i32* %ecx.global-to-local, align 4
  %v1_406f6c = trunc i32 %v0_406f6c to i8
  %v2_406f6c = load i8, i8* inttoptr (i32 4763899 to i8*), align 1
  %v3_406f6c = or i8 %v1_406f6c, %v2_406f6c
  %v9_406f6c = zext i8 %v3_406f6c to i32
  %v11_406f6c = and i32 %v0_406f6c, -256
  %v12_406f6c = or i32 %v9_406f6c, %v11_406f6c
  store i32 %v12_406f6c, i32* %ecx.global-to-local, align 4
  %v0_406f72 = load i32, i32* %edi.global-to-local, align 4
  %v1_406f72 = load i32, i32* %ebx.global-to-local, align 4
  %v2_406f72 = xor i32 %v1_406f72, %v0_406f72
  store i32 %v2_406f72, i32* %edi.global-to-local, align 4
  %v0_406f74 = load i32, i32* %esi.global-to-local, align 4
  %v1_406f74 = load i32, i32* inttoptr (i32 4764019 to i32*), align 4
  %v4_406f74 = add i32 %v1_406f74, %v0_406f74
  store i32 %v4_406f74, i32* %esi.global-to-local, align 4
  %v0_406f7a = load i32, i32* %edx.global-to-local, align 4
  %v11_406f7a = xor i32 %v0_406f7a, 164
  store i32 %v11_406f7a, i32* %edx.global-to-local, align 4
  %v0_406f7d = load i32, i32* inttoptr (i32 4763969 to i32*), align 4
  %v2_406f7d = and i32 %v0_406f7d, %v2_406f72
  store i32 %v2_406f7d, i32* inttoptr (i32 4763969 to i32*), align 4
  %v0_406f83 = load i32, i32* inttoptr (i32 4763975 to i32*), align 4
  %v3_406f83 = add i32 %v0_406f83, 19
  store i32 %v3_406f83, i32* inttoptr (i32 4763975 to i32*), align 4
  %v0_406f8a = load i32, i32* %ecx.global-to-local, align 4
  %v1_406f8a = add i32 %v0_406f8a, -35
  store i32 %v1_406f8a, i32* %ecx.global-to-local, align 4
  %v0_406f8d = load i32, i32* %ebx.global-to-local, align 4
  %v1_406f8d = add i32 %v0_406f8d, -83
  store i32 %v1_406f8d, i32* %ebx.global-to-local, align 4
  %v0_406f90 = load i32, i32* %esi.global-to-local, align 4
  %v1_406f90 = load i32, i32* inttoptr (i32 4764041 to i32*), align 4
  %v2_406f90 = or i32 %v1_406f90, %v0_406f90
  store i32 %v2_406f90, i32* %esi.global-to-local, align 4
  %v0_406f96 = load i32, i32* inttoptr (i32 4763977 to i32*), align 4
  %v3_406f96 = add i32 %v0_406f96, 204
  %v22_406f96 = icmp ugt i32 %v0_406f96, -205
  store i32 %v3_406f96, i32* inttoptr (i32 4763977 to i32*), align 4
  %v0_406fa0 = load i32, i32* inttoptr (i32 4763776 to i32*), align 128
  %v1_406fa0 = load i32, i32* %ecx.global-to-local, align 4
  %v3_406fa0 = zext i1 %v22_406f96 to i32
  %v4_406fa0 = add i32 %v3_406fa0, %v0_406fa0
  %v5_406fa0 = add i32 %v4_406fa0, %v1_406fa0
  store i32 %v5_406fa0, i32* inttoptr (i32 4763776 to i32*), align 128
  %v1_406fa6 = load i32, i32* @esp, align 4
  %v2_406fa6 = add i32 %v1_406fa6, -4
  %v3_406fa6 = inttoptr i32 %v2_406fa6 to i32*
  store i32 %v4_406efd, i32* %v3_406fa6, align 4
  %v0_406fa7 = load i32, i32* %ebx.global-to-local, align 4
  %v1_406fa7 = or i32 %v0_406fa7, -64
  store i32 %v1_406fa7, i32* %ebx.global-to-local, align 4
  %v0_406faa = load i32, i32* inttoptr (i32 4763838 to i32*), align 4
  %v3_406faa = add i32 %v0_406faa, -187
  store i32 %v3_406faa, i32* inttoptr (i32 4763838 to i32*), align 4
  %v0_406fb4 = load i32, i32* %ecx.global-to-local, align 4
  %v1_406fb4 = load i32, i32* %esi.global-to-local, align 4
  %v2_406fb4 = sub i32 %v0_406fb4, %v1_406fb4
  %v7_406fb4 = icmp ult i32 %v0_406fb4, %v1_406fb4
  store i1 %v7_406fb4, i1* %cf.global-to-local, align 1
  store i32 %v2_406fb4, i32* %ecx.global-to-local, align 4
  %v0_406fb6 = load i8, i8* inttoptr (i32 4763818 to i8*), align 2
  %v1_406fb6 = load i32, i32* %edx.global-to-local, align 4
  %v2_406fb6 = trunc i32 %v1_406fb6 to i8
  %v3_406fb6 = add i8 %v2_406fb6, %v0_406fb6
  %v8_406fb6 = icmp ult i8 %v3_406fb6, %v0_406fb6
  store i1 %v8_406fb6, i1* %cf.global-to-local, align 1
  store i8 %v3_406fb6, i8* inttoptr (i32 4763818 to i8*), align 2
  %v0_406fbc = load i32, i32* inttoptr (i32 4763879 to i32*), align 4
  %v1_406fbc = load i32, i32* %edi.global-to-local, align 4
  %v3_406fbc = zext i1 %v8_406fb6 to i32
  %v4_406fbc = sub i32 %v0_406fbc, %v1_406fbc
  %v5_406fbc = add i32 %v3_406fbc, %v4_406fbc
  %v16_406fbc = sub i32 %v4_406fbc, %v3_406fbc
  %v17_406fbc = icmp ult i32 %v0_406fbc, %v16_406fbc
  %v18_406fbc = icmp ne i32 %v1_406fbc, -1
  %v19_406fbc = or i1 %v18_406fbc, %v17_406fbc
  %v20_406fbc = icmp ult i32 %v0_406fbc, %v1_406fbc
  %v21_406fbc = select i1 %v8_406fb6, i1 %v19_406fbc, i1 %v20_406fbc
  store i32 %v5_406fbc, i32* inttoptr (i32 4763879 to i32*), align 4
  %v0_406fc2 = load i32, i32* inttoptr (i32 4763775 to i32*), align 4
  %v2_406fc2 = zext i1 %v21_406fbc to i32
  %v3_406fc2 = add i32 %v0_406fc2, 169
  %v4_406fc2 = add i32 %v3_406fc2, %v2_406fc2
  %v21_406fc2 = icmp ule i32 %v4_406fc2, %v0_406fc2
  %v22_406fc2 = icmp ugt i32 %v0_406fc2, -170
  %v23_406fc2 = select i1 %v21_406fbc, i1 %v21_406fc2, i1 %v22_406fc2
  store i32 %v4_406fc2, i32* inttoptr (i32 4763775 to i32*), align 4
  %v0_406fcc = load i32, i32* inttoptr (i32 4763870 to i32*), align 4
  %v1_406fcc = load i32, i32* %edi.global-to-local, align 4
  %v3_406fcc = zext i1 %v23_406fc2 to i32
  %v4_406fcc = add i32 %v1_406fcc, %v0_406fcc
  %v5_406fcc = add i32 %v4_406fcc, %v3_406fcc
  store i32 %v5_406fcc, i32* inttoptr (i32 4763870 to i32*), align 4
  %v0_406fd2 = load i32, i32* inttoptr (i32 4764094 to i32*), align 4
  %v1_406fd2 = xor i32 %v0_406fd2, 142
  store i32 %v1_406fd2, i32* inttoptr (i32 4764094 to i32*), align 4
  %v0_406fdc = load i32, i32* inttoptr (i32 4763940 to i32*), align 4
  %v1_406fdc = load i32, i32* %ebx.global-to-local, align 4
  %v2_406fdc = and i32 %v1_406fdc, %v0_406fdc
  store i32 %v2_406fdc, i32* inttoptr (i32 4763940 to i32*), align 4
  %v0_406fe2 = load i32, i32* %esi.global-to-local, align 4
  %v3_406fe2 = add i32 %v0_406fe2, 29
  store i32 %v3_406fe2, i32* %esi.global-to-local, align 4
  %v0_406fe5 = load i32, i32* %ecx.global-to-local, align 4
  %v1_406fe5 = add i32 %v0_406fe5, 36
  %v5_406fe5 = icmp ugt i32 %v0_406fe5, -37
  store i1 %v5_406fe5, i1* %cf.global-to-local, align 1
  store i32 %v1_406fe5, i32* %ecx.global-to-local, align 4
  %v0_406fe8 = load i8, i8* inttoptr (i32 4763869 to i8*), align 1
  %v1_406fe8 = add i8 %v0_406fe8, 89
  %v5_406fe8 = icmp ult i8 %v0_406fe8, -89
  store i1 %v5_406fe8, i1* %cf.global-to-local, align 1
  store i8 %v1_406fe8, i8* inttoptr (i32 4763869 to i8*), align 1
  store i32 ptrtoint ([13 x i8]* @global_var_48b650.15 to i32), i32* %ecx.global-to-local, align 4
  %v1_406ff6 = load i32, i32* @esp, align 4
  %v2_406ff6 = add i32 %v1_406ff6, -4
  %v3_406ff6 = inttoptr i32 %v2_406ff6 to i32*
  store i32 ptrtoint ([13 x i8]* @global_var_48b650.15 to i32), i32* %v3_406ff6, align 4
  store i32 ptrtoint ([13 x i8]* @global_var_48b650.15 to i32), i32* %ecx.global-to-local, align 4
  store i16 28492, i16* bitcast ([13 x i8]* @global_var_48b650.15 to i16*), align 2
  %v0_406fff = load i8, i8* inttoptr (i32 4763760 to i8*), align 16
  %v4_406fff = load i1, i1* %cf.global-to-local, align 1
  %v5_406fff = zext i1 %v4_406fff to i8
  %v6_406fff = sub i8 %v0_406fff, trunc (i32 udiv (i32 ptrtoint ([13 x i8]* @global_var_48b650.15 to i32), i32 256) to i8)
  %v7_406fff = add i8 %v6_406fff, %v5_406fff
  store i8 %v7_406fff, i8* inttoptr (i32 4763760 to i8*), align 16
  %v0_407005 = load i32, i32* inttoptr (i32 4763997 to i32*), align 4
  %v1_407005 = load i32, i32* %ecx.global-to-local, align 4
  %v2_407005 = add i32 %v1_407005, %v0_407005
  store i32 %v2_407005, i32* inttoptr (i32 4763997 to i32*), align 4
  %v0_40700b = load i32, i32* %edi.global-to-local, align 4
  %v1_40700b = load i32, i32* %esi.global-to-local, align 4
  %v2_40700b = sub i32 %v0_40700b, %v1_40700b
  store i32 %v2_40700b, i32* %edi.global-to-local, align 4
  %v0_40700d = load i32, i32* inttoptr (i32 4764121 to i32*), align 4
  %v1_40700d = xor i32 %v0_40700d, 67
  store i32 %v1_40700d, i32* inttoptr (i32 4764121 to i32*), align 4
  %v0_407014 = load i32, i32* inttoptr (i32 4763884 to i32*), align 4
  %v1_407014 = load i32, i32* %ecx.global-to-local, align 4
  %v4_407014 = sub i32 %v0_407014, %v1_407014
  %v20_407014 = icmp ult i32 %v0_407014, %v1_407014
  store i32 %v4_407014, i32* inttoptr (i32 4763884 to i32*), align 4
  %v0_40701a = load i32, i32* inttoptr (i32 4763961 to i32*), align 4
  %v1_40701a = load i32, i32* %edx.global-to-local, align 4
  %v3_40701a = zext i1 %v20_407014 to i32
  %v4_40701a = sub i32 %v0_40701a, %v1_40701a
  %v5_40701a = add i32 %v4_40701a, %v3_40701a
  %v16_40701a = sub i32 %v4_40701a, %v3_40701a
  %v17_40701a = icmp ult i32 %v0_40701a, %v16_40701a
  %v18_40701a = icmp ne i32 %v1_40701a, -1
  %v19_40701a = or i1 %v18_40701a, %v17_40701a
  %v20_40701a = icmp ult i32 %v0_40701a, %v1_40701a
  %v21_40701a = select i1 %v20_407014, i1 %v19_40701a, i1 %v20_40701a
  store i32 %v5_40701a, i32* inttoptr (i32 4763961 to i32*), align 4
  %v0_407020 = load i32, i32* inttoptr (i32 4764104 to i32*), align 8
  %v1_407020 = load i32, i32* %edx.global-to-local, align 4
  %v3_407020 = zext i1 %v21_40701a to i32
  %v4_407020 = sub i32 %v0_407020, %v1_407020
  %v5_407020 = add i32 %v4_407020, %v3_407020
  store i32 %v5_407020, i32* inttoptr (i32 4764104 to i32*), align 8
  %v0_407026 = load i32, i32* inttoptr (i32 4763948 to i32*), align 4
  %v1_407026 = load i32, i32* %ebx.global-to-local, align 4
  %v2_407026 = add i32 %v1_407026, %v0_407026
  store i32 %v2_407026, i32* inttoptr (i32 4763948 to i32*), align 4
  %v0_40702c = load i32, i32* %edx.global-to-local, align 4
  %v2_40702c = sub i32 %v0_40702c, %v1_407026
  store i32 %v2_40702c, i32* %edx.global-to-local, align 4
  store i32 122, i32* inttoptr (i32 4763809 to i32*), align 4
  %v1_407038 = load i32, i32* @esp, align 4
  %v2_407038 = add i32 %v1_407038, -4
  %v3_407038 = inttoptr i32 %v2_407038 to i32*
  store i32 %v4_406efd, i32* %v3_407038, align 4
  %v0_407039 = load i32, i32* %ebx.global-to-local, align 4
  %v1_40703968 = add i32 %v0_407039, 46592
  %v19_407039 = and i32 %v1_40703968, 65280
  %v20_407039 = and i32 %v0_407039, -65281
  %v21_407039 = or i32 %v19_407039, %v20_407039
  %v1_40703c = add i32 %v21_407039, 71
  store i32 %v1_40703c, i32* %ebx.global-to-local, align 4
  %v0_40703f = load i32, i32* inttoptr (i32 4763831 to i32*), align 4
  %v1_40703f = load i32, i32* %edi.global-to-local, align 4
  %v2_40703f = xor i32 %v1_40703f, %v0_40703f
  store i32 %v2_40703f, i32* inttoptr (i32 4763831 to i32*), align 4
  %v0_407045 = load i32, i32* %edx.global-to-local, align 4
  %v1_407045 = load i32, i32* %ecx.global-to-local, align 4
  %v2_407045 = add i32 %v1_407045, %v0_407045
  store i32 %v2_407045, i32* %edx.global-to-local, align 4
  %v0_407047 = load i32, i32* inttoptr (i32 4763928 to i32*), align 8
  %v1_407047 = load i32, i32* %esi.global-to-local, align 4
  %v2_407047 = or i32 %v1_407047, %v0_407047
  store i32 %v2_407047, i32* inttoptr (i32 4763928 to i32*), align 8
  %v1_40704d = load i32, i32* %ecx.global-to-local, align 4
  %tmp110 = and i32 %v1_40704d, 65280
  %v13_40704d = xor i32 %tmp110, %v2_407045
  store i32 %v13_40704d, i32* %edx.global-to-local, align 4
  %v0_40704f = load i32, i32* inttoptr (i32 4764034 to i32*), align 4
  %v3_40704f = add i32 %v0_40704f, 64
  store i32 %v3_40704f, i32* inttoptr (i32 4764034 to i32*), align 4
  %v0_407056 = load i32, i32* %ebx.global-to-local, align 4
  %v2_407056 = mul i32 %v0_407056, 2
  store i32 %v2_407056, i32* %ebx.global-to-local, align 4
  %v0_407058 = load i32, i32* %edi.global-to-local, align 4
  %v1_407058 = xor i32 %v0_407058, -63
  store i32 %v1_407058, i32* %edi.global-to-local, align 4
  %v0_40705b = load i32, i32* %edx.global-to-local, align 4
  %v1_40705b = add i32 %v0_40705b, -78
  %v5_40705b = icmp ugt i32 %v0_40705b, 77
  store i1 %v5_40705b, i1* %cf.global-to-local, align 1
  store i32 %v1_40705b, i32* %edx.global-to-local, align 4
  %v1_40705e = udiv i32 %v1_40705b, 256
  %v2_40705e = trunc i32 %v1_40705e to i8
  %v3_40705e = load i8, i8* inttoptr (i32 4764040 to i8*), align 8
  %v5_40705e = zext i1 %v5_40705b to i8
  %v6_40705e = add i8 %v3_40705e, %v2_40705e
  %v7_40705e = add i8 %v6_40705e, %v5_40705e
  %v25_40705e = icmp ule i8 %v7_40705e, %v2_40705e
  %v26_40705e = icmp ult i8 %v6_40705e, %v2_40705e
  %v27_40705e = select i1 %v5_40705b, i1 %v25_40705e, i1 %v26_40705e
  %v28_40705e = zext i8 %v7_40705e to i32
  %v30_40705e = mul nuw nsw i32 %v28_40705e, 256
  %v31_40705e = and i32 %v1_40705b, -65281
  %v32_40705e = or i32 %v30_40705e, %v31_40705e
  store i32 %v32_40705e, i32* %edx.global-to-local, align 4
  %v0_407064 = load i32, i32* inttoptr (i32 4764071 to i32*), align 4
  %v2_407064 = zext i1 %v27_40705e to i32
  %v3_407064 = add i32 %v0_407064, -45
  %v4_407064 = add i32 %v3_407064, %v2_407064
  %v12_407064 = icmp ult i32 %v0_407064, 45
  %v13_407064 = or i1 %v12_407064, %v27_40705e
  store i1 %v13_407064, i1* %cf.global-to-local, align 1
  store i32 %v4_407064, i32* inttoptr (i32 4764071 to i32*), align 4
  %v0_40706b = load i8, i8* inttoptr (i32 4763731 to i8*), align 1
  %v1_40706b = add i8 %v0_40706b, -93
  %v5_40706b = icmp ult i8 %v0_40706b, 93
  store i1 %v5_40706b, i1* %cf.global-to-local, align 1
  store i8 %v1_40706b, i8* inttoptr (i32 4763731 to i8*), align 1
  store i32 4765460, i32* %eax.global-to-local, align 4
  %v3_407078 = call i32 ()* @GetProcAddress(i32* nonnull @0, i8* bitcast (i32* @0 to i8*))
  %v4_407078 = ptrtoint i32 ()* %v3_407078 to i32
  store i32 %v4_407078, i32* %eax.global-to-local, align 4
  %v0_40707a = load i32, i32* %edx.global-to-local, align 4
  %v1_40707a = load i32, i32* %esi.global-to-local, align 4
  %v2_40707a = load i1, i1* %cf.global-to-local, align 1
  %v3_40707a = zext i1 %v2_40707a to i32
  %v4_40707a = sub i32 %v0_40707a, %v1_40707a
  %v5_40707a = add i32 %v3_40707a, %v4_40707a
  store i32 %v5_40707a, i32* %edx.global-to-local, align 4
  %v0_40707c = load i32, i32* inttoptr (i32 4764016 to i32*), align 16
  %v2_40707c = xor i32 %v0_40707c, %v5_40707a
  store i32 %v2_40707c, i32* inttoptr (i32 4764016 to i32*), align 16
  %v0_407082 = load i32, i32* %ecx.global-to-local, align 4
  %v4_407082 = sub i32 %v0_407082, %v5_40707a
  store i32 %v4_407082, i32* %ecx.global-to-local, align 4
  %v0_407084 = load i32, i32* %edi.global-to-local, align 4
  %v1_407084 = add i32 %v0_407084, -123
  store i32 %v1_407084, i32* %edi.global-to-local, align 4
  %v0_407087 = load i32, i32* %ebx.global-to-local, align 4
  %v1_407087 = load i32, i32* inttoptr (i32 4764123 to i32*), align 4
  %v2_407087 = or i32 %v1_407087, %v0_407087
  store i32 %v2_407087, i32* %ebx.global-to-local, align 4
  %v0_40708d = load i32, i32* %esi.global-to-local, align 4
  %v1_40708d = load i32, i32* inttoptr (i32 4763752 to i32*), align 8
  %v4_40708d = add i32 %v1_40708d, %v0_40708d
  %v25_40708d = icmp ult i32 %v4_40708d, %v0_40708d
  store i32 %v4_40708d, i32* %esi.global-to-local, align 4
  %v0_407093 = load i32, i32* inttoptr (i32 4763940 to i32*), align 4
  %v3_407093 = zext i1 %v25_40708d to i32
  %v4_407093 = sub i32 %v0_407093, %v1_407084
  %v5_407093 = add i32 %v4_407093, %v3_407093
  %v16_407093 = sub i32 %v4_407093, %v3_407093
  %v17_407093 = icmp ult i32 %v0_407093, %v16_407093
  %v18_407093 = icmp ne i32 %v1_407084, -1
  %v19_407093 = or i1 %v18_407093, %v17_407093
  %v20_407093 = icmp ult i32 %v0_407093, %v1_407084
  %v21_407093 = select i1 %v25_40708d, i1 %v19_407093, i1 %v20_407093
  store i32 %v5_407093, i32* inttoptr (i32 4763940 to i32*), align 4
  %v0_407099 = load i32, i32* %esi.global-to-local, align 4
  %v2_407099 = zext i1 %v21_407093 to i32
  %v3_407099 = add i32 %v0_407099, -9
  %v4_407099 = add i32 %v3_407099, %v2_407099
  store i32 %v4_407099, i32* @esi, align 4
  %v0_40709c = load i32, i32* inttoptr (i32 4763665 to i32*), align 4
  %v1_40709c = load i32, i32* %edi.global-to-local, align 4
  %v2_40709c = add i32 %v1_40709c, %v0_40709c
  store i32 %v2_40709c, i32* inttoptr (i32 4763665 to i32*), align 4
  %v0_4070a2 = load i32, i32* %ebx.global-to-local, align 4
  %v1_4070a2 = add i32 %v0_4070a2, 97
  store i32 %v1_4070a2, i32* @ebx, align 4
  %v1_4070a5 = load i32, i32* inttoptr (i32 4763817 to i32*), align 4
  %v2_4070a5 = sub i32 %v1_40709c, %v1_4070a5
  %v7_4070a5 = icmp ult i32 %v1_40709c, %v1_4070a5
  store i1 %v7_4070a5, i1* %cf.global-to-local, align 1
  store i32 %v2_4070a5, i32* @edi, align 4
  store i32 %v4_407078, i32* inttoptr (i32 4765188 to i32*), align 4
  %v1_4070b0 = load i32, i32* @esp, align 4
  %v2_4070b0 = add i32 %v1_4070b0, -4
  %v3_4070b0 = inttoptr i32 %v2_4070b0 to i32*
  store i32 %v4_407078, i32* %v3_4070b0, align 4
  store i32 0, i32* %eax.global-to-local, align 4
  %v2_4070b8 = add i32 %v1_4070b0, -8
  %v3_4070b8 = inttoptr i32 %v2_4070b8 to i32*
  store i32 0, i32* %v3_4070b8, align 4
  %v2_4070b9 = call i32* @EncodePointer(i32* nonnull @0)
  %v3_4070b9 = ptrtoint i32* %v2_4070b9 to i32
  store i32 %v3_4070b9, i32* %eax.global-to-local, align 4
  %v2_4070bf = load i32, i32* %v3_4070b0, align 4
  store i32 %v2_4070bf, i32* %eax.global-to-local, align 4
  store i16 29806, i16* bitcast ([12 x i8]* @global_var_48b628.16 to i16*), align 8
  store i32 ptrtoint ([12 x i8]* @global_var_48b628.16 to i32), i32* @ecx, align 4
  store i32 ptrtoint ([12 x i8]* @global_var_48b628.16 to i32), i32* %v3_4070b0, align 4
  %v0_4070d1 = call i32 @unknown_48b604()
  store i32 %v0_4070d1, i32* @eax, align 4
  %v1_4070d7 = load i32, i32* @esp, align 4
  %v2_4070d7 = add i32 %v1_4070d7, -4
  %v3_4070d7 = inttoptr i32 %v2_4070d7 to i32*
  store i32 %v0_4070d1, i32* %v3_4070d7, align 4
  %v0_4070d8 = load i32, i32* @eax, align 4
  store i1 false, i1* %cf.global-to-local, align 1
  %v1_4070d8 = icmp eq i32 %v0_4070d8, 0
  br i1 %v1_4070d8, label %dec_label_pc_402974, label %dec_label_pc_4070e0

dec_label_pc_4070e0:                              ; preds = %dec_label_pc_406df8
  %v0_4070e0 = load i32, i32* inttoptr (i32 4763906 to i32*), align 4
  %v1_4070e0 = load i32, i32* @ebx, align 4
  %v4_4070e0 = sub i32 %v0_4070e0, %v1_4070e0
  %v20_4070e0 = icmp ult i32 %v0_4070e0, %v1_4070e0
  store i1 %v20_4070e0, i1* %cf.global-to-local, align 1
  store i32 %v4_4070e0, i32* inttoptr (i32 4763906 to i32*), align 4
  %v0_4070e6 = load i8, i8* inttoptr (i32 4763909 to i8*), align 1
  %v1_4070e6 = add i8 %v0_4070e6, -119
  store i8 %v1_4070e6, i8* inttoptr (i32 4763909 to i8*), align 1
  %v1_4070f2 = load i32, i32* @esi, align 4
  %v2_4070f2 = add i32 %v1_4070f2, 1
  %v7_4070f2 = icmp eq i32 %v2_4070f2, 0
  store i32 %v2_4070f2, i32* %edx.global-to-local, align 4
  %v0_4070f4 = load i32, i32* inttoptr (i32 4764015 to i32*), align 4
  %v2_4070f4 = zext i1 %v7_4070f2 to i32
  %v3_4070f4 = add i32 %v0_4070f4, 95
  %v4_4070f4 = add i32 %v3_4070f4, %v2_4070f4
  store i32 %v4_4070f4, i32* inttoptr (i32 4764015 to i32*), align 4
  %v0_4070fb = load i32, i32* inttoptr (i32 4763667 to i32*), align 4
  %v1_4070fb = load i32, i32* @ebx, align 4
  %v2_4070fb = add i32 %v1_4070fb, %v0_4070fb
  %v7_4070fb = icmp ult i32 %v2_4070fb, %v0_4070fb
  store i32 %v2_4070fb, i32* inttoptr (i32 4763667 to i32*), align 4
  %v0_407101 = load i32, i32* inttoptr (i32 4764064 to i32*), align 32
  %v2_407101 = zext i1 %v7_4070fb to i32
  %v3_407101 = add i32 %v0_407101, -195
  %v4_407101 = add i32 %v3_407101, %v2_407101
  %v12_407101 = icmp ult i32 %v0_407101, 195
  %v13_407101 = or i1 %v7_4070fb, %v12_407101
  store i32 %v4_407101, i32* inttoptr (i32 4764064 to i32*), align 32
  %v0_40710b = load i32, i32* inttoptr (i32 4764123 to i32*), align 4
  %v1_40710b = load i32, i32* @esi, align 4
  %v3_40710b = zext i1 %v13_407101 to i32
  %v4_40710b = add i32 %v1_40710b, %v0_40710b
  %v5_40710b = add i32 %v4_40710b, %v3_40710b
  %v24_40710b = icmp ule i32 %v5_40710b, %v0_40710b
  %v25_40710b = icmp ult i32 %v4_40710b, %v0_40710b
  %v26_40710b = select i1 %v13_407101, i1 %v24_40710b, i1 %v25_40710b
  store i1 %v26_40710b, i1* %cf.global-to-local, align 1
  store i32 %v5_40710b, i32* inttoptr (i32 4764123 to i32*), align 4
  %v0_407111 = load i32, i32* %edx.global-to-local, align 4
  %v1_407111 = udiv i32 %v0_407111, 256
  %v2_407111 = trunc i32 %v1_407111 to i8
  %v3_407111 = load i8, i8* inttoptr (i32 4764131 to i8*), align 1
  %v4_407111 = sub i8 %v2_407111, %v3_407111
  %v19_407111 = zext i8 %v4_407111 to i32
  %v21_407111 = mul nuw nsw i32 %v19_407111, 256
  %v22_407111 = and i32 %v0_407111, -65281
  %v23_407111 = or i32 %v21_407111, %v22_407111
  store i32 %v23_407111, i32* %edx.global-to-local, align 4
  %v0_407117 = load i32, i32* @eax, align 4
  %v1_407117 = load i32, i32* @edi, align 4
  %v2_407117 = xor i32 %v1_407117, %v0_407117
  store i32 %v2_407117, i32* %eax.global-to-local, align 4
  %v3_407119 = add i32 %v1_407117, -53
  store i32 %v3_407119, i32* %edi.global-to-local, align 4
  %v0_40711c = load i32, i32* inttoptr (i32 4763677 to i32*), align 4
  %v1_40711c = and i32 %v0_40711c, 226
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v1_40711c, i32* inttoptr (i32 4763677 to i32*), align 4
  %v0_407126 = load i8, i8* inttoptr (i32 4763708 to i8*), align 4
  %v1_407126 = add i8 %v0_407126, -123
  store i8 %v1_407126, i8* inttoptr (i32 4763708 to i8*), align 4
  %v0_40712d = load i32, i32* %eax.global-to-local, align 4
  %v1_40712d = and i32 %v0_40712d, -98
  store i32 %v1_40712d, i32* %eax.global-to-local, align 4
  store i16 25713, i16* bitcast ([12 x i8]* @global_var_48b628.16 to i16*), align 8
  %v0_407139 = load i32, i32* inttoptr (i32 4764151 to i32*), align 4
  %v1_407139 = load i32, i32* %edx.global-to-local, align 4
  %v4_407139 = add i32 %v1_407139, %v0_407139
  store i32 %v4_407139, i32* inttoptr (i32 4764151 to i32*), align 4
  %v0_40713f = load i32, i32* inttoptr (i32 4763844 to i32*), align 4
  %v1_40713f = xor i32 %v0_40713f, 188
  store i32 %v1_40713f, i32* inttoptr (i32 4763844 to i32*), align 4
  %v0_407149 = load i32, i32* inttoptr (i32 4764132 to i32*), align 4
  %v1_407149 = load i32, i32* %edx.global-to-local, align 4
  %v2_407149 = sub i32 %v0_407149, %v1_407149
  %v7_407149 = icmp ult i32 %v0_407149, %v1_407149
  store i32 %v2_407149, i32* inttoptr (i32 4764132 to i32*), align 4
  %v0_40714f = load i32, i32* inttoptr (i32 4764050 to i32*), align 4
  %v1_40714f = load i32, i32* @ebx, align 4
  %v3_40714f = zext i1 %v7_407149 to i32
  %v4_40714f = add i32 %v3_40714f, %v0_40714f
  %v5_40714f = add i32 %v4_40714f, %v1_40714f
  store i32 %v5_40714f, i32* inttoptr (i32 4764050 to i32*), align 4
  %v0_407155 = load i32, i32* %eax.global-to-local, align 4
  %v1_407155 = load i32, i32* @ebx, align 4
  %tmp111 = and i32 %v1_407155, 65280
  %v13_407155 = xor i32 %tmp111, %v0_407155
  store i32 %v13_407155, i32* %eax.global-to-local, align 4
  store i32 0, i32* %esi.global-to-local, align 4
  %v0_407159 = load i32, i32* %edi.global-to-local, align 4
  %v1_407159 = load i32, i32* inttoptr (i32 4763970 to i32*), align 4
  %v4_407159 = add i32 %v1_407159, %v0_407159
  store i32 %v4_407159, i32* %edi.global-to-local, align 4
  store i32 -29, i32* %ecx.global-to-local, align 4
  %v0_407167 = load i32, i32* inttoptr (i32 4763792 to i32*), align 16
  %v1_407167 = or i32 %v0_407167, 131
  store i32 %v1_407167, i32* inttoptr (i32 4763792 to i32*), align 16
  %v1_407171 = load i32, i32* inttoptr (i32 4764024 to i32*), align 8
  %v4_407171 = add i32 %v1_407171, %v4_407159
  store i32 %v4_407171, i32* %edi.global-to-local, align 4
  %v0_407177 = load i32, i32* %esi.global-to-local, align 4
  %v1_407177 = and i32 %v0_407177, -125
  store i32 %v1_407177, i32* %esi.global-to-local, align 4
  %v0_40717a = load i32, i32* @ebx, align 4
  %v1_40717a = or i32 %v0_40717a, 80
  store i32 %v1_40717a, i32* @ebx, align 4
  %v1_40717d = load i32, i32* inttoptr (i32 4763909 to i32*), align 4
  %v2_40717d = sub i32 %v1_407177, %v1_40717d
  %v1_407183 = add i32 %v2_40717d, -73
  %v5_407183 = icmp ugt i32 %v2_40717d, 72
  store i32 %v1_407183, i32* @esi, align 4
  %v1_407186 = load i32, i32* inttoptr (i32 4763999 to i32*), align 4
  %v3_407186 = zext i1 %v5_407183 to i32
  %v4_407186 = add i32 %v1_407186, %v4_407171
  %v5_407186 = add i32 %v4_407186, %v3_407186
  store i32 %v5_407186, i32* @edi, align 4
  %v0_40718c = load i32, i32* %edx.global-to-local, align 4
  %v1_40718c = load i32, i32* inttoptr (i32 4764006 to i32*), align 4
  %v2_40718c = sub i32 %v0_40718c, %v1_40718c
  %v7_40718c = icmp ult i32 %v0_40718c, %v1_40718c
  store i1 %v7_40718c, i1* %cf.global-to-local, align 1
  store i32 %v2_40718c, i32* %edx.global-to-local, align 4
  %v0_407192 = load i8, i8* inttoptr (i32 4763776 to i8*), align 128
  %v1_407192 = add i8 %v0_407192, -61
  %v5_407192 = icmp ult i8 %v0_407192, 61
  store i1 %v5_407192, i1* %cf.global-to-local, align 1
  store i8 %v1_407192, i8* inttoptr (i32 4763776 to i8*), align 128
  %v0_407199 = load i32, i32* inttoptr (i32 4763978 to i32*), align 4
  %v2_407199 = zext i1 %v5_407192 to i32
  %v3_407199 = add i32 %v0_407199, -11
  %v4_407199 = add i32 %v3_407199, %v2_407199
  %v12_407199 = icmp ult i32 %v0_407199, 11
  %v13_407199 = or i1 %v12_407199, %v5_407192
  store i1 %v13_407199, i1* %cf.global-to-local, align 1
  store i32 %v4_407199, i32* inttoptr (i32 4763978 to i32*), align 4
  store i32 ptrtoint ([12 x i8]* @global_var_48b628.16 to i32), i32* %ecx.global-to-local, align 4
  %v1_4071a7 = load i32, i32* @esp, align 4
  %v2_4071a7 = add i32 %v1_4071a7, -4
  %v3_4071a7 = inttoptr i32 %v2_4071a7 to i32*
  store i32 ptrtoint ([12 x i8]* @global_var_48b628.16 to i32), i32* %v3_4071a7, align 4
  %v0_4071a8 = load i32, i32* %eax.global-to-local, align 4
  %v1_4071a8 = udiv i32 %v0_4071a8, 256
  %v2_4071a8 = trunc i32 %v1_4071a8 to i8
  %v3_4071a8 = load i8, i8* inttoptr (i32 4763673 to i8*), align 1
  %v4_4071a8 = sub i8 %v2_4071a8, %v3_4071a8
  %v9_4071a8 = icmp ult i8 %v2_4071a8, %v3_4071a8
  %v19_4071a8 = zext i8 %v4_4071a8 to i32
  %v21_4071a8 = mul nuw nsw i32 %v19_4071a8, 256
  %v22_4071a8 = and i32 %v0_4071a8, -65281
  %v23_4071a8 = or i32 %v21_4071a8, %v22_4071a8
  store i32 %v23_4071a8, i32* %eax.global-to-local, align 4
  %v0_4071ae = load i32, i32* %edx.global-to-local, align 4
  %v1_4071ae = load i32, i32* inttoptr (i32 4763699 to i32*), align 4
  %v3_4071ae = zext i1 %v9_4071a8 to i32
  %v4_4071ae = add i32 %v1_4071ae, %v0_4071ae
  %v5_4071ae = add i32 %v4_4071ae, %v3_4071ae
  %v1_4071b4 = or i32 %v5_4071ae, 101
  store i32 %v1_4071b4, i32* %edx.global-to-local, align 4
  %v0_4071b7 = load i32, i32* inttoptr (i32 4763797 to i32*), align 4
  %v1_4071b7 = load i32, i32* @edi, align 4
  %v2_4071b7 = and i32 %v1_4071b7, %v0_4071b7
  store i32 %v2_4071b7, i32* inttoptr (i32 4763797 to i32*), align 4
  %v0_4071bd = load i32, i32* %eax.global-to-local, align 4
  %v3_4071bd = add i32 %v0_4071bd, 25
  store i32 %v3_4071bd, i32* %eax.global-to-local, align 4
  %v0_4071c0 = load i32, i32* %ecx.global-to-local, align 4
  %v1_4071c0 = add i32 %v0_4071c0, 105
  %v5_4071c0 = icmp ult i32 %v0_4071c0, -105
  store i32 %v1_4071c0, i32* @ecx, align 4
  %v0_4071c3 = load i32, i32* %edx.global-to-local, align 4
  %v1_4071c3 = load i32, i32* inttoptr (i32 4763811 to i32*), align 4
  %v3_4071c3 = zext i1 %v5_4071c0 to i32
  %v4_4071c3 = add i32 %v3_4071c3, %v0_4071c3
  %v5_4071c3 = add i32 %v4_4071c3, %v1_4071c3
  store i32 %v5_4071c3, i32* %edx.global-to-local, align 4
  %v0_4071c9 = load i32, i32* inttoptr (i32 4763778 to i32*), align 4
  %v1_4071c9 = xor i32 %v0_4071c9, 212
  store i32 %v1_4071c9, i32* inttoptr (i32 4763778 to i32*), align 4
  %v0_4071d3 = load i32, i32* inttoptr (i32 4763962 to i32*), align 4
  %v1_4071d3 = load i32, i32* %eax.global-to-local, align 4
  %v2_4071d3 = or i32 %v1_4071d3, %v0_4071d3
  store i32 %v2_4071d3, i32* inttoptr (i32 4763962 to i32*), align 4
  %v0_4071d9 = load i32, i32* inttoptr (i32 4764122 to i32*), align 4
  %v1_4071d9 = load i32, i32* @ebx, align 4
  %v2_4071d9 = xor i32 %v1_4071d9, %v0_4071d9
  store i32 %v2_4071d9, i32* inttoptr (i32 4764122 to i32*), align 4
  %v0_4071df = load i32, i32* inttoptr (i32 4763813 to i32*), align 4
  %v1_4071df = load i32, i32* @ebx, align 4
  %v2_4071df = xor i32 %v1_4071df, %v0_4071df
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v2_4071df, i32* inttoptr (i32 4763813 to i32*), align 4
  %v0_4071e5 = load i32, i32* inttoptr (i32 4765188 to i32*), align 4
  store i32 %v0_4071e5, i32* %eax.global-to-local, align 4
  %v0_4071ea = call i32 @unknown_48b604()
  store i32 %v0_4071ea, i32* @eax, align 4
  store i1 false, i1* %cf.global-to-local, align 1
  %v1_4071ec = icmp eq i32 %v0_4071ea, 0
  %v1_4071ee = icmp eq i1 %v1_4071ec, false
  br i1 %v1_4071ee, label %dec_label_pc_402974, label %dec_label_pc_4071f4

dec_label_pc_4071f4:                              ; preds = %dec_label_pc_4070e0
  %v0_4071f4 = load i32, i32* inttoptr (i32 4763653 to i32*), align 4
  %v3_4071f4 = add i32 %v0_4071f4, 98
  %v22_4071f4 = icmp ugt i32 %v0_4071f4, -99
  store i32 %v3_4071f4, i32* inttoptr (i32 4763653 to i32*), align 4
  %v0_4071fb = load i32, i32* @ebx, align 4
  %v1_4071fb = load i32, i32* inttoptr (i32 4763867 to i32*), align 4
  %v3_4071fb = zext i1 %v22_4071f4 to i32
  %v4_4071fb = add i32 %v1_4071fb, %v0_4071fb
  %v5_4071fb = add i32 %v4_4071fb, %v3_4071fb
  %v24_4071fb = icmp ule i32 %v5_4071fb, %v0_4071fb
  %v25_4071fb = icmp ult i32 %v4_4071fb, %v0_4071fb
  %v26_4071fb = select i1 %v22_4071f4, i1 %v24_4071fb, i1 %v25_4071fb
  store i32 %v5_4071fb, i32* %ebx.global-to-local, align 4
  %v0_407201 = load i32, i32* inttoptr (i32 4763887 to i32*), align 4
  %v3_407201 = select i1 %v26_4071fb, i32 8, i32 7
  %v4_407201 = add i32 %v3_407201, %v0_407201
  store i32 %v4_407201, i32* inttoptr (i32 4763887 to i32*), align 4
  %v0_407208 = load i32, i32* %edx.global-to-local, align 4
  %v4_407208 = sub i32 %v0_407208, %v5_4071fb
  %v20_407208 = and i32 %v4_407208, 255
  %v22_407208 = and i32 %v0_407208, -256
  %v23_407208 = or i32 %v20_407208, %v22_407208
  %v1_40720a = load i32, i32* @esi, align 4
  %v2_40720a = add i32 %v23_407208, %v1_40720a
  store i32 %v2_40720a, i32* %edx.global-to-local, align 4
  %v0_40720c = load i32, i32* @eax, align 4
  %v1_40720c = load i32, i32* inttoptr (i32 4763977 to i32*), align 4
  %v2_40720c = sub i32 %v0_40720c, %v1_40720c
  store i32 %v2_40720c, i32* %eax.global-to-local, align 4
  %v0_407212 = load i32, i32* inttoptr (i32 4763955 to i32*), align 4
  %v1_407212 = load i32, i32* @edi, align 4
  %v2_407212 = add i32 %v1_407212, %v0_407212
  %v7_407212 = icmp ult i32 %v2_407212, %v0_407212
  store i32 %v2_407212, i32* inttoptr (i32 4763955 to i32*), align 4
  %v0_407218 = load i32, i32* inttoptr (i32 4764159 to i32*), align 4
  %v1_407218 = load i32, i32* @edi, align 4
  %v3_407218 = zext i1 %v7_407212 to i32
  %v4_407218 = add i32 %v1_407218, %v0_407218
  %v5_407218 = add i32 %v4_407218, %v3_407218
  store i32 %v5_407218, i32* inttoptr (i32 4764159 to i32*), align 4
  %v0_40721e = load i32, i32* inttoptr (i32 4763934 to i32*), align 4
  %v1_40721e = load i32, i32* @edi, align 4
  %v2_40721e = xor i32 %v1_40721e, %v0_40721e
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v2_40721e, i32* inttoptr (i32 4763934 to i32*), align 4
  %v0_407224 = load i32, i32* %edx.global-to-local, align 4
  %v1_407224 = udiv i32 %v0_407224, 256
  %v2_407224 = trunc i32 %v1_407224 to i8
  %v3_407224 = load i8, i8* inttoptr (i32 4764090 to i8*), align 2
  %v6_407224 = add i8 %v2_407224, %v3_407224
  %v26_407224 = icmp ult i8 %v6_407224, %v2_407224
  %v28_407224 = zext i8 %v6_407224 to i32
  %v30_407224 = mul nuw nsw i32 %v28_407224, 256
  %v31_407224 = and i32 %v0_407224, -65281
  %v32_407224 = or i32 %v30_407224, %v31_407224
  store i32 %v32_407224, i32* %edx.global-to-local, align 4
  %v0_40722a = load i32, i32* inttoptr (i32 4763876 to i32*), align 4
  %v2_40722a = zext i1 %v26_407224 to i32
  %v3_40722a = add i32 %v0_40722a, 26
  %v4_40722a = add i32 %v3_40722a, %v2_40722a
  %v21_40722a = icmp ule i32 %v4_40722a, %v0_40722a
  %v22_40722a = icmp ugt i32 %v0_40722a, -27
  %v23_40722a = select i1 %v26_407224, i1 %v21_40722a, i1 %v22_40722a
  store i32 %v4_40722a, i32* inttoptr (i32 4763876 to i32*), align 4
  %v0_407231 = load i32, i32* %ebx.global-to-local, align 4
  %v1_407231 = load i32, i32* %edx.global-to-local, align 4
  %v3_407231 = zext i1 %v23_40722a to i32
  %v4_407231 = add i32 %v1_407231, %v0_407231
  %v5_407231 = add i32 %v3_407231, %v4_407231
  %v24_407231 = icmp ule i32 %v5_407231, %v0_407231
  %v25_407231 = icmp ult i32 %v4_407231, %v0_407231
  %v26_407231 = select i1 %v23_40722a, i1 %v24_407231, i1 %v25_407231
  store i32 %v5_407231, i32* %ebx.global-to-local, align 4
  %v1_407233 = load i32, i32* @ecx, align 4
  %v3_407233 = zext i1 %v26_407231 to i32
  %v4_407233 = sub i32 %v1_407231, %v1_407233
  %v5_407233 = add i32 %v3_407233, %v4_407233
  %v16_407233 = sub i32 %v4_407233, %v3_407233
  %v17_407233 = icmp ult i32 %v1_407231, %v16_407233
  %v18_407233 = icmp ne i32 %v1_407233, -1
  %v19_407233 = or i1 %v18_407233, %v17_407233
  %v20_407233 = icmp ult i32 %v1_407231, %v1_407233
  %v21_407233 = select i1 %v26_407231, i1 %v19_407233, i1 %v20_407233
  store i32 %v5_407233, i32* %edx.global-to-local, align 4
  %v0_407235 = load i32, i32* inttoptr (i32 4763940 to i32*), align 4
  %v2_407235 = zext i1 %v21_407233 to i32
  %v3_407235 = add i32 %v0_407235, -69
  %v4_407235 = add i32 %v3_407235, %v2_407235
  store i32 %v4_407235, i32* inttoptr (i32 4763940 to i32*), align 4
  %v0_40723c = load i32, i32* %ebx.global-to-local, align 4
  %v1_40723c = add i32 %v0_40723c, 101
  store i32 %v1_40723c, i32* %ebx.global-to-local, align 4
  %v0_40723f = load i32, i32* %edx.global-to-local, align 4
  %v1_40723f = load i32, i32* %eax.global-to-local, align 4
  %v2_40723f = add i32 %v1_40723f, %v0_40723f
  %v7_40723f = icmp ult i32 %v2_40723f, %v0_40723f
  %v1_407241 = load i32, i32* @esi, align 4
  %v3_407241 = zext i1 %v7_40723f to i32
  %v4_407241 = add i32 %v1_407241, %v2_40723f
  %v5_407241 = add i32 %v3_407241, %v4_407241
  %v24_407241 = icmp ule i32 %v5_407241, %v2_40723f
  %v25_407241 = icmp ult i32 %v4_407241, %v2_40723f
  %v26_407241 = select i1 %v7_40723f, i1 %v24_407241, i1 %v25_407241
  store i32 %v5_407241, i32* %edx.global-to-local, align 4
  %v0_407243 = load i32, i32* inttoptr (i32 4764014 to i32*), align 4
  %v2_407243 = zext i1 %v26_407241 to i32
  %v3_407243 = add i32 %v0_407243, -48
  %v4_407243 = add i32 %v3_407243, %v2_407243
  %v11_407243 = icmp ult i32 %v0_407243, 48
  %v12_407243 = or i1 %v11_407243, %v26_407241
  store i32 %v4_407243, i32* inttoptr (i32 4764014 to i32*), align 4
  %v0_40724a = load i32, i32* %ebx.global-to-local, align 4
  %v1_40724a = load i32, i32* inttoptr (i32 4763755 to i32*), align 4
  %v3_40724a = zext i1 %v12_407243 to i32
  %v4_40724a = add i32 %v1_40724a, %v0_40724a
  %v5_40724a = add i32 %v3_40724a, %v4_40724a
  %v24_40724a = icmp ule i32 %v5_40724a, %v0_40724a
  %v25_40724a = icmp ult i32 %v4_40724a, %v0_40724a
  %v26_40724a = select i1 %v12_407243, i1 %v24_40724a, i1 %v25_40724a
  store i32 %v5_40724a, i32* %ebx.global-to-local, align 4
  %v1_407250 = load i32, i32* inttoptr (i32 4763713 to i32*), align 4
  %v3_407250 = zext i1 %v26_40724a to i32
  %v4_407250 = add i32 %v5_40724a, %v1_407250
  %v5_407250 = add i32 %v3_407250, %v4_407250
  %v24_407250 = icmp ule i32 %v5_407250, %v5_40724a
  %v25_407250 = icmp ult i32 %v4_407250, %v5_40724a
  %v26_407250 = select i1 %v26_40724a, i1 %v24_407250, i1 %v25_407250
  store i32 %v5_407250, i32* %ebx.global-to-local, align 4
  %v0_407256 = load i32, i32* @esi, align 4
  %v3_407256 = select i1 %v26_407250, i32 128, i32 127
  %v4_407256 = add i32 %v3_407256, %v0_407256
  %v21_407256 = icmp ule i32 %v4_407256, %v0_407256
  %v22_407256 = icmp ugt i32 %v0_407256, -128
  %v23_407256 = select i1 %v26_407250, i1 %v21_407256, i1 %v22_407256
  store i32 %v4_407256, i32* %esi.global-to-local, align 4
  %v0_407259 = load i32, i32* %edx.global-to-local, align 4
  %v1_407259 = udiv i32 %v0_407259, 256
  %v2_407259 = trunc i32 %v1_407259 to i8
  %v4_407259 = zext i1 %v23_407256 to i32
  %v5_407259 = add nuw nsw i32 %v1_407259, 247
  %v6_407259 = add nuw nsw i32 %v5_407259, %v4_407259
  %v14_407259 = icmp ult i8 %v2_407259, 9
  %v15_407259 = or i1 %v14_407259, %v23_407256
  %v27_407259 = mul i32 %v6_407259, 256
  %v29_407259 = and i32 %v27_407259, 65280
  %v30_407259 = and i32 %v0_407259, -65281
  %v31_407259 = or i32 %v29_407259, %v30_407259
  store i32 %v31_407259, i32* %edx.global-to-local, align 4
  %v0_40725c = load i32, i32* inttoptr (i32 4763690 to i32*), align 4
  %v2_40725c = zext i1 %v15_407259 to i32
  %v3_40725c = add i32 %v0_40725c, 126
  %v4_40725c = add i32 %v3_40725c, %v2_40725c
  store i32 %v4_40725c, i32* inttoptr (i32 4763690 to i32*), align 4
  %v0_407263 = load i32, i32* %eax.global-to-local, align 4
  %v1_407263 = add i32 %v0_407263, 127
  store i32 %v1_407263, i32* %eax.global-to-local, align 4
  %v0_407266 = load i32, i32* %edx.global-to-local, align 4
  %v2_407266 = xor i32 %v0_407266, %v1_407263
  store i32 %v2_407266, i32* %edx.global-to-local, align 4
  %v0_407268 = load i32, i32* inttoptr (i32 4764143 to i32*), align 4
  %v1_407268 = load i32, i32* %ebx.global-to-local, align 4
  %v2_407268 = and i32 %v1_407268, %v0_407268
  store i32 %v2_407268, i32* inttoptr (i32 4764143 to i32*), align 4
  store i32 74, i32* inttoptr (i32 4763911 to i32*), align 4
  store i32 8, i32* inttoptr (i32 4763977 to i32*), align 4
  %v0_407282 = load i32, i32* inttoptr (i32 4763848 to i32*), align 8
  %v3_407282 = add i32 %v0_407282, -17
  %v12_407282 = icmp ult i32 %v0_407282, 17
  store i1 %v12_407282, i1* %cf.global-to-local, align 1
  store i32 %v3_407282, i32* inttoptr (i32 4763848 to i32*), align 8
  %v0_407289 = load i8, i8* inttoptr (i32 4763857 to i8*), align 1
  %v1_407289 = add i8 %v0_407289, 8
  store i8 %v1_407289, i8* inttoptr (i32 4763857 to i8*), align 1
  %v0_407290 = load i32, i32* @esp, align 4
  %v1_407290 = add i32 %v0_407290, -4
  %v2_407290 = inttoptr i32 %v1_407290 to i32*
  store i32 1, i32* %v2_407290, align 4
  %v0_407292 = load i32, i32* %eax.global-to-local, align 4
  %v1_40729269 = add i32 %v0_407292, 49152
  %v16_407292 = and i32 %v1_40729269, 65280
  %v17_407292 = and i32 %v0_407292, -65281
  %v18_407292 = or i32 %v16_407292, %v17_407292
  %v1_407295 = load i32, i32* @ecx, align 4
  %v2_407295 = xor i32 %v18_407292, %v1_407295
  store i32 %v2_407295, i32* %eax.global-to-local, align 4
  %v0_407297 = load i32, i32* %edx.global-to-local, align 4
  %v1_407297 = load i32, i32* inttoptr (i32 4763773 to i32*), align 4
  %v4_407297 = add i32 %v1_407297, %v0_407297
  %v25_407297 = icmp ult i32 %v4_407297, %v0_407297
  store i32 %v4_407297, i32* %edx.global-to-local, align 4
  %v0_40729d = load i32, i32* %esi.global-to-local, align 4
  %v1_40729d = load i32, i32* inttoptr (i32 4764068 to i32*), align 4
  %v3_40729d = zext i1 %v25_407297 to i32
  %v4_40729d = add i32 %v1_40729d, %v0_40729d
  %v5_40729d = add i32 %v4_40729d, %v3_40729d
  store i32 %v5_40729d, i32* %esi.global-to-local, align 4
  %v0_4072a3 = load i32, i32* inttoptr (i32 4763951 to i32*), align 4
  %v1_4072a3 = or i32 %v0_4072a3, 253
  store i32 %v1_4072a3, i32* inttoptr (i32 4763951 to i32*), align 4
  %v0_4072ad = load i32, i32* %eax.global-to-local, align 4
  %v1_4072ad = or i32 %v0_4072ad, 36
  store i32 %v1_4072ad, i32* %eax.global-to-local, align 4
  %v0_4072b0 = load i32, i32* inttoptr (i32 4763962 to i32*), align 4
  %v1_4072b0 = load i32, i32* %edx.global-to-local, align 4
  %v2_4072b0 = or i32 %v1_4072b0, %v0_4072b0
  store i32 %v2_4072b0, i32* inttoptr (i32 4763962 to i32*), align 4
  %v4_4072b6 = mul i32 %v1_4072b0, 2
  %v19_4072b6 = and i32 %v4_4072b6, 254
  %v21_4072b6 = and i32 %v1_4072b0, -256
  %v22_4072b6 = or i32 %v19_4072b6, %v21_4072b6
  store i32 %v22_4072b6, i32* %edx.global-to-local, align 4
  %v0_4072b8 = load i32, i32* %ebx.global-to-local, align 4
  %v1_4072b8 = load i32, i32* @edi, align 4
  %v2_4072b8 = add i32 %v1_4072b8, %v0_4072b8
  %v7_4072b8 = icmp ult i32 %v2_4072b8, %v0_4072b8
  store i32 %v2_4072b8, i32* %ebx.global-to-local, align 4
  %v0_4072ba = load i32, i32* inttoptr (i32 4763909 to i32*), align 4
  %v3_4072ba = zext i1 %v7_4072b8 to i32
  %v4_4072ba = add i32 %v0_4072ba, %v1_4072b8
  %v5_4072ba = add i32 %v3_4072ba, %v4_4072ba
  %v24_4072ba = icmp ule i32 %v5_4072ba, %v0_4072ba
  %v25_4072ba = icmp ult i32 %v4_4072ba, %v0_4072ba
  %v26_4072ba = select i1 %v7_4072b8, i1 %v24_4072ba, i1 %v25_4072ba
  store i32 %v5_4072ba, i32* inttoptr (i32 4763909 to i32*), align 4
  %v0_4072c0 = load i32, i32* @edi, align 4
  %v1_4072c0 = load i32, i32* inttoptr (i32 4763929 to i32*), align 4
  %v3_4072c0 = zext i1 %v26_4072ba to i32
  %v4_4072c0 = add i32 %v1_4072c0, %v0_4072c0
  %v5_4072c0 = add i32 %v3_4072c0, %v4_4072c0
  %v24_4072c0 = icmp ule i32 %v5_4072c0, %v0_4072c0
  %v25_4072c0 = icmp ult i32 %v4_4072c0, %v0_4072c0
  %v26_4072c0 = select i1 %v26_4072ba, i1 %v24_4072c0, i1 %v25_4072c0
  store i32 %v5_4072c0, i32* %edi.global-to-local, align 4
  %v0_4072c6 = load i32, i32* %ebx.global-to-local, align 4
  %v1_4072c6 = load i32, i32* inttoptr (i32 4764111 to i32*), align 4
  %v3_4072c6 = zext i1 %v26_4072c0 to i32
  %v4_4072c6 = add i32 %v1_4072c6, %v0_4072c6
  %v5_4072c6 = add i32 %v3_4072c6, %v4_4072c6
  %v24_4072c6 = icmp ule i32 %v5_4072c6, %v0_4072c6
  %v25_4072c6 = icmp ult i32 %v4_4072c6, %v0_4072c6
  %v26_4072c6 = select i1 %v26_4072c0, i1 %v24_4072c6, i1 %v25_4072c6
  store i1 %v26_4072c6, i1* %cf.global-to-local, align 1
  store i32 %v5_4072c6, i32* %ebx.global-to-local, align 4
  %v0_4072cc = load i32, i32* %eax.global-to-local, align 4
  %v1_4072cc = udiv i32 %v0_4072cc, 256
  %v2_4072cc = trunc i32 %v1_4072cc to i8
  %v3_4072cc = load i8, i8* inttoptr (i32 4764064 to i8*), align 32
  %v5_4072cc = zext i1 %v26_4072c6 to i8
  %v6_4072cc = add i8 %v2_4072cc, %v3_4072cc
  %v7_4072cc = add i8 %v6_4072cc, %v5_4072cc
  %v28_4072cc = zext i8 %v7_4072cc to i32
  %v30_4072cc = mul nuw nsw i32 %v28_4072cc, 256
  %v31_4072cc = and i32 %v0_4072cc, -65281
  %v32_4072cc = or i32 %v30_4072cc, %v31_4072cc
  store i32 %v32_4072cc, i32* %eax.global-to-local, align 4
  %v0_4072d2 = load i32, i32* %edx.global-to-local, align 4
  %v1_4072d2 = add i32 %v0_4072d2, -115
  %v10_4072d5 = or i32 %v1_4072d2, 2
  %v1_4072d8 = add i32 %v10_4072d5, -63
  store i32 %v1_4072d8, i32* %edx.global-to-local, align 4
  %v2_4072db = mul i32 %v5_4072c6, 2
  %v7_4072db = icmp ult i32 %v2_4072db, %v5_4072c6
  store i1 %v7_4072db, i1* %cf.global-to-local, align 1
  store i32 %v2_4072db, i32* %ebx.global-to-local, align 4
  %v0_4072dd = load i8, i8* inttoptr (i32 4763674 to i8*), align 2
  %v4_4072dd = add i8 %v0_4072dd, %v7_4072cc
  %v9_4072dd = icmp ult i8 %v4_4072dd, %v0_4072dd
  store i1 %v9_4072dd, i1* %cf.global-to-local, align 1
  store i8 %v4_4072dd, i8* inttoptr (i32 4763674 to i8*), align 2
  %v0_4072e3 = load i32, i32* @ecx, align 4
  %v1_4072e3 = load i32, i32* inttoptr (i32 4763926 to i32*), align 4
  %v3_4072e3 = zext i1 %v9_4072dd to i32
  %v4_4072e3 = add i32 %v1_4072e3, %v0_4072e3
  %v5_4072e3 = add i32 %v3_4072e3, %v4_4072e3
  %v24_4072e3 = icmp ule i32 %v5_4072e3, %v0_4072e3
  %v25_4072e3 = icmp ult i32 %v4_4072e3, %v0_4072e3
  %v26_4072e3 = select i1 %v9_4072dd, i1 %v24_4072e3, i1 %v25_4072e3
  store i1 %v26_4072e3, i1* %cf.global-to-local, align 1
  store i32 %v5_4072e3, i32* %ecx.global-to-local, align 4
  br label %dec_label_pc_4072e9

dec_label_pc_4072e9:                              ; preds = %dec_label_pc_4072e9, %dec_label_pc_4071f4
  %v0_4072e9 = load i32, i32* @esp, align 4
  %v1_4072e9 = add i32 %v0_4072e9, -4
  %v2_4072e9 = inttoptr i32 %v1_4072e9 to i32*
  store i32 1, i32* %v2_4072e9, align 4
  %v1_4072eb = add i32 %v0_4072e9, -8
  %v2_4072eb = inttoptr i32 %v1_4072eb to i32*
  store i32 -1, i32* %v2_4072eb, align 4
  store i32 4765452, i32* %eax.global-to-local, align 4
  %v3_4072f3 = call i32 @WaitForSingleObject(i32* nonnull @0, i32 ptrtoint (i32* @0 to i32))
  store i32 164, i32* inttoptr (i32 4763777 to i32*), align 4
  %v1_4072ff = and i32 %v3_4072f3, 7
  store i32 %v1_4072ff, i32* %eax.global-to-local, align 4
  %v0_407302 = load i32, i32* %edx.global-to-local, align 4
  %v1_407302 = add i32 %v0_407302, 112
  store i32 %v1_407302, i32* %edx.global-to-local, align 4
  %v0_407305 = load i32, i32* inttoptr (i32 4763732 to i32*), align 4
  %v1_407305 = xor i32 %v0_407305, 234
  store i32 %v1_407305, i32* inttoptr (i32 4763732 to i32*), align 4
  %v0_40730f = load i32, i32* %ecx.global-to-local, align 4
  %v1_40730f = load i32, i32* %esi.global-to-local, align 4
  %v2_40730f = add i32 %v1_40730f, %v0_40730f
  store i32 %v2_40730f, i32* %ecx.global-to-local, align 4
  %v0_407311 = load i32, i32* %eax.global-to-local, align 4
  %v2_407311 = load i32, i32* %edx.global-to-local, align 4
  %v4_407311 = add i32 %v2_407311, %v0_407311
  %v19_407311 = and i32 %v4_407311, 255
  %v21_407311 = and i32 %v0_407311, -256
  %v22_407311 = or i32 %v19_407311, %v21_407311
  store i32 %v22_407311, i32* %eax.global-to-local, align 4
  %v0_407313 = load i32, i32* %ebx.global-to-local, align 4
  %v1_407313 = load i32, i32* inttoptr (i32 4763828 to i32*), align 4
  %v2_407313 = sub i32 %v0_407313, %v1_407313
  store i32 %v2_407313, i32* %ebx.global-to-local, align 4
  %v0_407319 = load i32, i32* %edi.global-to-local, align 4
  %v1_407319 = add i32 %v0_407319, -118
  %v5_407319 = icmp ult i32 %v0_407319, 118
  store i32 %v1_407319, i32* %edi.global-to-local, align 4
  %v1_40731c = load i32, i32* inttoptr (i32 4764121 to i32*), align 4
  %v3_40731c = zext i1 %v5_407319 to i32
  %v4_40731c = add i32 %v1_40731c, %v1_407319
  %v5_40731c = add i32 %v4_40731c, %v3_40731c
  %v24_40731c = icmp ule i32 %v5_40731c, %v1_407319
  %v25_40731c = icmp ult i32 %v4_40731c, %v1_407319
  %v26_40731c = select i1 %v5_407319, i1 %v24_40731c, i1 %v25_40731c
  store i32 %v5_40731c, i32* %edi.global-to-local, align 4
  %v2_407322 = zext i1 %v26_40731c to i32
  %v3_407322 = add i32 %v2_407313, 98
  %v4_407322 = add i32 %v3_407322, %v2_407322
  store i32 %v4_407322, i32* %ebx.global-to-local, align 4
  %v0_407325 = load i32, i32* inttoptr (i32 4764142 to i32*), align 4
  %v2_407325 = and i32 %v2_407311, %v0_407325
  store i32 %v2_407325, i32* inttoptr (i32 4764142 to i32*), align 4
  %v1_40732b = add i32 %v4_407322, -106
  store i32 %v1_40732b, i32* %ebx.global-to-local, align 4
  %v0_40732e = load i32, i32* %esi.global-to-local, align 4
  %v2_40732e = xor i32 %v0_40732e, %v1_40732b
  store i32 %v2_40732e, i32* %esi.global-to-local, align 4
  %v0_407330 = load i32, i32* inttoptr (i32 4763817 to i32*), align 4
  %v1_407330 = load i32, i32* %edx.global-to-local, align 4
  %v2_407330 = or i32 %v1_407330, %v0_407330
  store i32 %v2_407330, i32* inttoptr (i32 4763817 to i32*), align 4
  %v0_407336 = load i32, i32* inttoptr (i32 4764122 to i32*), align 4
  %v1_407336 = or i32 %v0_407336, 29
  store i32 %v1_407336, i32* inttoptr (i32 4764122 to i32*), align 4
  %v1_40733d = load i32, i32* %ebx.global-to-local, align 4
  %v4_40733d = sub i32 %v1_407330, %v1_40733d
  %v20_40733d = icmp ult i32 %v1_407330, %v1_40733d
  store i32 %v4_40733d, i32* %edx.global-to-local, align 4
  %v1_40733f = load i32, i32* %edi.global-to-local, align 4
  %v3_40733f = zext i1 %v20_40733d to i32
  %v4_40733f = sub i32 %v1_40733d, %v1_40733f
  %v5_40733f = add i32 %v4_40733f, %v3_40733f
  store i32 %v5_40733f, i32* %ebx.global-to-local, align 4
  %v0_407341 = load i32, i32* inttoptr (i32 4763967 to i32*), align 4
  %v1_407341 = load i32, i32* %ecx.global-to-local, align 4
  %v2_407341 = and i32 %v1_407341, %v0_407341
  store i32 %v2_407341, i32* inttoptr (i32 4763967 to i32*), align 4
  %v3_407347 = add i32 %v5_40733f, 45
  %v1_40734a = add i32 %v5_40733f, -44
  %v5_40734a = icmp ugt i32 %v3_407347, 88
  store i1 %v5_40734a, i1* %cf.global-to-local, align 1
  store i32 %v1_40734a, i32* %ebx.global-to-local, align 4
  %v0_40734d = load i32, i32* @esp, align 4
  %v1_40734d = inttoptr i32 %v0_40734d to i32*
  %v2_40734d = load i32, i32* %v1_40734d, align 4
  %v3_40734d = add i32 %v2_40734d, -1
  %v10_40734d = icmp eq i32 %v3_40734d, 0
  store i32 %v3_40734d, i32* %v1_40734d, align 4
  %v1_407350 = icmp eq i1 %v10_40734d, false
  br i1 %v1_407350, label %dec_label_pc_4072e9, label %dec_label_pc_407353

dec_label_pc_407353:                              ; preds = %dec_label_pc_4072e9
  %v0_407353 = load i32, i32* %edx.global-to-local, align 4
  %v1_407353 = and i32 %v0_407353, -42
  store i32 %v1_407353, i32* %edx.global-to-local, align 4
  %v0_407356 = load i32, i32* inttoptr (i32 4764005 to i32*), align 4
  %v2_407356 = xor i32 %v0_407356, %v1_407353
  store i32 %v2_407356, i32* inttoptr (i32 4764005 to i32*), align 4
  %v0_40735c = load i32, i32* %edi.global-to-local, align 4
  %v1_40735c = load i32, i32* %eax.global-to-local, align 4
  %v2_40735c = sub i32 %v0_40735c, %v1_40735c
  store i32 %v2_40735c, i32* %edi.global-to-local, align 4
  %v0_40735e = load i32, i32* %edx.global-to-local, align 4
  %v1_40735e = or i32 %v0_40735e, 63
  store i32 %v1_40735e, i32* %edx.global-to-local, align 4
  %v0_407361 = load i32, i32* %ebx.global-to-local, align 4
  %v1_407361 = load i32, i32* inttoptr (i32 4764036 to i32*), align 4
  %v2_407361 = sub i32 %v0_407361, %v1_407361
  %v7_407361 = icmp ult i32 %v0_407361, %v1_407361
  store i32 %v2_407361, i32* %ebx.global-to-local, align 4
  %v3_407367 = zext i1 %v7_407361 to i32
  %v4_407367 = mul i32 %v1_40735e, 2
  %v5_407367 = or i32 %v3_407367, %v4_407367
  %v24_407367 = icmp ule i32 %v5_407367, %v1_40735e
  %v25_407367 = icmp ult i32 %v4_407367, %v1_40735e
  %v26_407367 = select i1 %v7_407361, i1 %v24_407367, i1 %v25_407367
  store i32 %v5_407367, i32* %edx.global-to-local, align 4
  %v0_407369 = load i32, i32* %esi.global-to-local, align 4
  %v3_407369 = zext i1 %v26_407367 to i32
  %v4_407369 = add i32 %v0_407369, %v2_40735c
  %v5_407369 = add i32 %v4_407369, %v3_407369
  store i32 %v5_407369, i32* %esi.global-to-local, align 4
  %v1_40736b = load i32, i32* inttoptr (i32 4764122 to i32*), align 4
  %v2_40736b = sub i32 %v2_40735c, %v1_40736b
  %v7_40736b = icmp ult i32 %v2_40735c, %v1_40736b
  store i32 %v2_40736b, i32* %edi.global-to-local, align 4
  %v0_407371 = load i32, i32* inttoptr (i32 4763772 to i32*), align 4
  %v3_407371 = zext i1 %v7_40736b to i32
  %v4_407371 = sub i32 %v0_407371, %v5_407369
  %v5_407371 = add i32 %v4_407371, %v3_407371
  store i32 %v5_407371, i32* inttoptr (i32 4763772 to i32*), align 4
  %v0_407377 = load i32, i32* inttoptr (i32 4764025 to i32*), align 4
  %v1_407377 = load i32, i32* %esi.global-to-local, align 4
  %v2_407377 = sub i32 %v0_407377, %v1_407377
  %v7_407377 = icmp ult i32 %v0_407377, %v1_407377
  store i32 %v2_407377, i32* inttoptr (i32 4764025 to i32*), align 4
  %v0_40737d = load i32, i32* inttoptr (i32 4763960 to i32*), align 8
  %v1_40737d = load i32, i32* %edx.global-to-local, align 4
  %v3_40737d = zext i1 %v7_407377 to i32
  %v4_40737d = add i32 %v3_40737d, %v0_40737d
  %v5_40737d = sub i32 %v4_40737d, %v1_40737d
  store i32 %v5_40737d, i32* inttoptr (i32 4763960 to i32*), align 8
  %v0_407383 = load i32, i32* inttoptr (i32 4763965 to i32*), align 4
  %v1_407383 = load i32, i32* %esi.global-to-local, align 4
  %v2_407383 = or i32 %v1_407383, %v0_407383
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v2_407383, i32* inttoptr (i32 4763965 to i32*), align 4
  %v0_407389 = load i32, i32* %eax.global-to-local, align 4
  %v1_407389 = trunc i32 %v0_407389 to i8
  %v2_407389 = load i8, i8* inttoptr (i32 4764077 to i8*), align 1
  %v5_407389 = add i8 %v1_407389, %v2_407389
  %v27_407389 = zext i8 %v5_407389 to i32
  %v29_407389 = and i32 %v0_407389, -256
  %v30_407389 = or i32 %v27_407389, %v29_407389
  store i32 %v30_407389, i32* %eax.global-to-local, align 4
  %v0_40738f = load i32, i32* inttoptr (i32 4763842 to i32*), align 4
  %v1_40738f = or i32 %v0_40738f, 39
  store i32 %v1_40738f, i32* inttoptr (i32 4763842 to i32*), align 4
  %v0_407396 = load i32, i32* %ecx.global-to-local, align 4
  %v3_407396 = load i32, i32* %edx.global-to-local, align 4
  %v4_407396 = and i32 %v3_407396, 65280
  %v1_40739671 = sub i32 %v0_407396, %v4_407396
  %v24_407396 = and i32 %v1_40739671, 65280
  %v25_407396 = and i32 %v0_407396, -65281
  %v26_407396 = or i32 %v24_407396, %v25_407396
  store i32 %v26_407396, i32* %ecx.global-to-local, align 4
  store i8 0, i8* inttoptr (i32 4765204 to i8*), align 4
  %v0_4073a2 = load i32, i32* @esp, align 4
  %v1_4073a2 = add i32 %v0_4073a2, -4
  %v2_4073a2 = inttoptr i32 %v1_4073a2 to i32*
  store i32 4765330, i32* %v2_4073a2, align 4
  %v0_4073ab = load i32, i32* @esp, align 4
  %v1_4073ab = add i32 %v0_4073ab, -4
  %v2_4073ab = inttoptr i32 %v1_4073ab to i32*
  store i32 0, i32* %v2_4073ab, align 4
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 4765317, i32* %v2_4073ab, align 4
  %v0_4073b4 = load i32, i32* @esp, align 4
  %v4_4073b4 = call i1 @SetEnvironmentVariableW(i16* bitcast (i32* @0 to i16*), i16* bitcast (i32* @0 to i16*))
  %v5_4073b4 = sext i1 %v4_4073b4 to i32
  store i32 %v5_4073b4, i32* %eax.global-to-local, align 4
  %v1_4073ba = add i32 %v0_4073b4, 4
  %v2_4073ba = inttoptr i32 %v1_4073ba to i32*
  store i32 4765330, i32* %v2_4073ba, align 4
  %v0_4073c3 = load i32, i32* @esp, align 4
  %v1_4073c3 = add i32 %v0_4073c3, -4
  %v2_4073c3 = inttoptr i32 %v1_4073c3 to i32*
  store i32 0, i32* %v2_4073c3, align 4
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 4765317, i32* %v2_4073c3, align 4
  %v4_4073cc = call i1 @SetEnvironmentVariableW(i16* bitcast (i32* @0 to i16*), i16* bitcast (i32* @0 to i16*))
  %v5_4073cc = sext i1 %v4_4073cc to i32
  store i32 %v5_4073cc, i32* %eax.global-to-local, align 4
  %v0_4073d2 = load i32, i32* %ebx.global-to-local, align 4
  %v1_4073d2 = add i32 %v0_4073d2, 27
  %v5_4073d2 = icmp ugt i32 %v0_4073d2, -28
  store i32 %v1_4073d2, i32* %ebx.global-to-local, align 4
  %v1_4073d5 = load i32, i32* inttoptr (i32 4763985 to i32*), align 4
  %v3_4073d5 = zext i1 %v5_4073d2 to i32
  %v4_4073d5 = add i32 %v1_4073d5, %v1_4073d2
  %v5_4073d5 = add i32 %v4_4073d5, %v3_4073d5
  store i32 %v5_4073d5, i32* %ebx.global-to-local, align 4
  %v0_4073db = load i32, i32* %edi.global-to-local, align 4
  %v1_4073db = and i32 %v0_4073db, 28
  store i32 %v1_4073db, i32* %edi.global-to-local, align 4
  %v0_4073de = load i32, i32* inttoptr (i32 4764033 to i32*), align 4
  %v1_4073de = load i32, i32* %esi.global-to-local, align 4
  %v2_4073de = or i32 %v1_4073de, %v0_4073de
  store i32 %v2_4073de, i32* inttoptr (i32 4764033 to i32*), align 4
  %v1_4073e4 = load i32, i32* inttoptr (i32 4763932 to i32*), align 4
  %v4_4073e4 = add i32 %v1_4073e4, %v1_4073de
  store i32 %v4_4073e4, i32* %esi.global-to-local, align 4
  %v0_4073ea = load i32, i32* inttoptr (i32 4764159 to i32*), align 4
  %v2_4073ea = add i32 %v0_4073ea, %v4_4073e4
  store i32 %v2_4073ea, i32* inttoptr (i32 4764159 to i32*), align 4
  %v0_4073f0 = load i32, i32* inttoptr (i32 4764139 to i32*), align 4
  %v1_4073f0 = load i32, i32* %edi.global-to-local, align 4
  %v2_4073f0 = sub i32 %v0_4073f0, %v1_4073f0
  %v7_4073f0 = icmp ult i32 %v0_4073f0, %v1_4073f0
  store i32 %v2_4073f0, i32* inttoptr (i32 4764139 to i32*), align 4
  %v0_4073f6 = load i32, i32* %esi.global-to-local, align 4
  %v1_4073f6 = load i32, i32* inttoptr (i32 4763686 to i32*), align 4
  %v3_4073f6 = zext i1 %v7_4073f0 to i32
  %v4_4073f6 = add i32 %v1_4073f6, %v0_4073f6
  %v5_4073f6 = add i32 %v4_4073f6, %v3_4073f6
  %v24_4073f6 = icmp ule i32 %v5_4073f6, %v0_4073f6
  %v25_4073f6 = icmp ult i32 %v4_4073f6, %v0_4073f6
  %v26_4073f6 = select i1 %v7_4073f0, i1 %v24_4073f6, i1 %v25_4073f6
  store i32 %v5_4073f6, i32* %esi.global-to-local, align 4
  %v0_4073fc = load i32, i32* inttoptr (i32 4764066 to i32*), align 4
  %v1_4073fc = load i32, i32* %edi.global-to-local, align 4
  %v3_4073fc = zext i1 %v26_4073f6 to i32
  %v4_4073fc = sub i32 %v0_4073fc, %v1_4073fc
  %v5_4073fc = add i32 %v3_4073fc, %v4_4073fc
  %v16_4073fc = sub i32 %v4_4073fc, %v3_4073fc
  %v17_4073fc = icmp ult i32 %v0_4073fc, %v16_4073fc
  %v18_4073fc = icmp ne i32 %v1_4073fc, -1
  %v19_4073fc = or i1 %v18_4073fc, %v17_4073fc
  %v20_4073fc = icmp ult i32 %v0_4073fc, %v1_4073fc
  %v21_4073fc = select i1 %v26_4073f6, i1 %v19_4073fc, i1 %v20_4073fc
  store i32 %v5_4073fc, i32* inttoptr (i32 4764066 to i32*), align 4
  %v0_407402 = load i32, i32* %edi.global-to-local, align 4
  %v1_407402 = load i32, i32* %ebx.global-to-local, align 4
  %v3_407402 = zext i1 %v21_4073fc to i32
  %v4_407402 = sub i32 %v0_407402, %v1_407402
  %v5_407402 = add i32 %v3_407402, %v4_407402
  store i32 %v5_407402, i32* %edi.global-to-local, align 4
  %v1_407404 = load i32, i32* inttoptr (i32 4763903 to i32*), align 4
  %v2_407404 = sub i32 %v1_407402, %v1_407404
  store i32 %v2_407404, i32* %ebx.global-to-local, align 4
  %v0_40740a = load i32, i32* @esp, align 4
  %v1_40740a = inttoptr i32 %v0_40740a to i32*
  %v2_40740a = load i32, i32* %v1_40740a, align 4
  store i32 %v2_40740a, i32* %ebx.global-to-local, align 4
  %v2_407418 = add i32 %v5_407402, 1
  %v7_407418 = icmp eq i32 %v2_407418, 0
  store i32 %v2_407418, i32* %ecx.global-to-local, align 4
  %v3_40741a = zext i1 %v7_407418 to i32
  %v4_40741a = sub i32 -64, %v5_407402
  %v5_40741a = add i32 %v4_40741a, %v3_40741a
  %v1_40741c = load i32, i32* %esi.global-to-local, align 4
  %v2_40741c = xor i32 %v1_40741c, %v5_40741a
  store i32 %v2_40741c, i32* %edx.global-to-local, align 4
  %v0_40741e = load i32, i32* inttoptr (i32 4763704 to i32*), align 8
  %v2_40741e = xor i32 %v5_407402, %v0_40741e
  store i32 %v2_40741e, i32* inttoptr (i32 4763704 to i32*), align 8
  %v0_407424 = load i32, i32* inttoptr (i32 4763761 to i32*), align 4
  %v1_407424 = or i32 %v0_407424, 98
  store i32 %v1_407424, i32* inttoptr (i32 4763761 to i32*), align 4
  %v0_40742b = load i32, i32* %edx.global-to-local, align 4
  %v1_40742b = load i32, i32* inttoptr (i32 4763973 to i32*), align 4
  %v2_40742b = sub i32 %v0_40742b, %v1_40742b
  store i32 %v2_40742b, i32* %edx.global-to-local, align 4
  %v0_407431 = load i32, i32* inttoptr (i32 4764065 to i32*), align 4
  %v2_407431 = add i32 %v0_407431, %v2_40742b
  %v7_407431 = icmp ult i32 %v2_407431, %v0_407431
  store i1 %v7_407431, i1* %cf.global-to-local, align 1
  store i32 %v2_407431, i32* inttoptr (i32 4764065 to i32*), align 4
  %v0_407437 = load i8, i8* inttoptr (i32 4763669 to i8*), align 1
  %v1_407437 = add i8 %v0_407437, -126
  %v5_407437 = icmp ult i8 %v0_407437, 126
  store i1 %v5_407437, i1* %cf.global-to-local, align 1
  store i8 %v1_407437, i8* inttoptr (i32 4763669 to i8*), align 1
  %v0_40743e = load i32, i32* %edx.global-to-local, align 4
  %v1_40743e = load i32, i32* inttoptr (i32 4763913 to i32*), align 4
  %v3_40743e = zext i1 %v5_407437 to i32
  %v4_40743e = add i32 %v1_40743e, %v0_40743e
  %v5_40743e = add i32 %v4_40743e, %v3_40743e
  store i32 %v5_40743e, i32* %edx.global-to-local, align 4
  %v0_407444 = load i32, i32* %ecx.global-to-local, align 4
  %v1_407444 = load i32, i32* %edi.global-to-local, align 4
  %v2_407444 = sub i32 %v0_407444, %v1_407444
  store i32 %v2_407444, i32* %ecx.global-to-local, align 4
  %v0_407446 = load i32, i32* %ebx.global-to-local, align 4
  %v1_407446 = load i32, i32* @esp, align 4
  %v2_407446 = add i32 %v1_407446, -4
  %v3_407446 = inttoptr i32 %v2_407446 to i32*
  store i32 %v0_407446, i32* %v3_407446, align 4
  %v0_407447 = load i32, i32* %ebx.global-to-local, align 4
  %v1_40744a = add i32 %v0_407447, 60
  store i32 %v1_40744a, i32* %ebx.global-to-local, align 4
  %v1_40744b = inttoptr i32 %v1_40744a to i32*
  %v2_40744b = load i32, i32* %v1_40744b, align 4
  store i32 %v2_40744b, i32* %ebx.global-to-local, align 4
  %v2_40744d = load i32, i32* %v3_407446, align 4
  %v4_40744d = add i32 %v2_40744d, %v2_40744b
  store i32 %v4_40744d, i32* %v3_407446, align 4
  %v0_407450 = load i32, i32* @esp, align 4
  %v1_407450 = inttoptr i32 %v0_407450 to i32*
  %v2_407450 = load i32, i32* %v1_407450, align 4
  store i32 %v2_407450, i32* %ebx.global-to-local, align 4
  %v0_407451 = load i32, i32* inttoptr (i32 4764111 to i32*), align 4
  %v1_407451 = load i32, i32* %edx.global-to-local, align 4
  %v2_407451 = add i32 %v1_407451, %v0_407451
  store i32 %v2_407451, i32* inttoptr (i32 4764111 to i32*), align 4
  %v1_407457 = load i32, i32* %esi.global-to-local, align 4
  %v2_407457 = xor i32 %v1_407457, %v1_407451
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v2_407457, i32* %edx.global-to-local, align 4
  %v0_407459 = load i8, i8* inttoptr (i32 4763769 to i8*), align 1
  %v2_407459 = udiv i32 %v5_4073cc, 256
  %v3_407459 = trunc i32 %v2_407459 to i8
  %v4_407459 = and i8 %v0_407459, %v3_407459
  store i8 %v4_407459, i8* inttoptr (i32 4763769 to i8*), align 1
  %v0_40745f = load i32, i32* %edi.global-to-local, align 4
  %v1_40745f = load i32, i32* inttoptr (i32 4763980 to i32*), align 4
  %v2_40745f = sub i32 %v0_40745f, %v1_40745f
  %v7_40745f = icmp ult i32 %v0_40745f, %v1_40745f
  store i32 %v2_40745f, i32* %edi.global-to-local, align 4
  %v0_407465 = load i32, i32* inttoptr (i32 4763817 to i32*), align 4
  %v2_407465 = zext i1 %v7_40745f to i32
  %v3_407465 = add i32 %v0_407465, 73
  %v4_407465 = add i32 %v3_407465, %v2_407465
  store i32 %v4_407465, i32* inttoptr (i32 4763817 to i32*), align 4
  %v0_40746c = load i32, i32* inttoptr (i32 4764044 to i32*), align 4
  %v1_40746c = or i32 %v0_40746c, 83
  store i32 %v1_40746c, i32* inttoptr (i32 4764044 to i32*), align 4
  %v0_407473 = load i32, i32* inttoptr (i32 4763781 to i32*), align 4
  %v2_407473 = or i32 %v0_407473, %v5_4073cc
  store i32 %v2_407473, i32* inttoptr (i32 4763781 to i32*), align 4
  %v0_407479 = load i32, i32* %esi.global-to-local, align 4
  %v4_407479 = sub i32 %v0_407479, %v5_4073cc
  %v20_407479 = icmp ult i32 %v0_407479, %v5_4073cc
  store i32 %v4_407479, i32* %esi.global-to-local, align 4
  %v1_40747b = load i32, i32* %ecx.global-to-local, align 4
  %v3_40747b = zext i1 %v20_407479 to i32
  %v4_40747b = add i32 %v1_40747b, %v5_4073cc
  %v5_40747b = add i32 %v4_40747b, %v3_40747b
  store i32 %v5_40747b, i32* %eax.global-to-local, align 4
  store i32 64, i32* inttoptr (i32 4763890 to i32*), align 4
  %v0_407487 = load i32, i32* inttoptr (i32 4763926 to i32*), align 4
  %v1_407487 = xor i32 %v0_407487, 147
  store i32 %v1_407487, i32* inttoptr (i32 4763926 to i32*), align 4
  %v0_407491 = load i32, i32* inttoptr (i32 4763685 to i32*), align 4
  %v1_407491 = xor i32 %v0_407491, 2
  store i32 %v1_407491, i32* inttoptr (i32 4763685 to i32*), align 4
  %v0_407498 = load i32, i32* %ecx.global-to-local, align 4
  %v1_407498 = load i32, i32* %edi.global-to-local, align 4
  %v4_407498 = add i32 %v1_407498, %v0_407498
  store i32 %v4_407498, i32* %ecx.global-to-local, align 4
  %v0_40749a = load i32, i32* %ebx.global-to-local, align 4
  %v1_40749a = add i32 %v0_40749a, 164
  store i32 %v1_40749a, i32* %ebx.global-to-local, align 4
  store i32 %v1_40749a, i32* @global_var_48b65d.17, align 4
  %v0_4074a6 = load i32, i32* %eax.global-to-local, align 4
  %v1_4074a6 = add i32 %v0_4074a6, 113
  store i32 %v1_4074a6, i32* %eax.global-to-local, align 4
  %v0_4074a9 = load i32, i32* inttoptr (i32 4763728 to i32*), align 16
  %v1_4074a9 = load i32, i32* %edx.global-to-local, align 4
  %v2_4074a9 = add i32 %v1_4074a9, %v0_4074a9
  %v7_4074a9 = icmp ult i32 %v2_4074a9, %v0_4074a9
  store i32 %v2_4074a9, i32* inttoptr (i32 4763728 to i32*), align 16
  %v0_4074af = load i32, i32* %esi.global-to-local, align 4
  %v1_4074af = load i32, i32* inttoptr (i32 4763707 to i32*), align 4
  %v3_4074af = zext i1 %v7_4074a9 to i32
  %v4_4074af = add i32 %v1_4074af, %v0_4074af
  %v5_4074af = add i32 %v4_4074af, %v3_4074af
  store i32 %v5_4074af, i32* %esi.global-to-local, align 4
  %v0_4074b5 = load i32, i32* inttoptr (i32 4764083 to i32*), align 4
  %v2_4074b5 = or i32 %v0_4074b5, %v5_4074af
  store i32 %v2_4074b5, i32* inttoptr (i32 4764083 to i32*), align 4
  %v0_4074bb = load i32, i32* inttoptr (i32 4763771 to i32*), align 4
  %v1_4074bb = load i32, i32* %eax.global-to-local, align 4
  %v4_4074bb = sub i32 %v0_4074bb, %v1_4074bb
  %v20_4074bb = icmp ult i32 %v0_4074bb, %v1_4074bb
  store i32 %v4_4074bb, i32* inttoptr (i32 4763771 to i32*), align 4
  %v0_4074c1 = load i32, i32* %ecx.global-to-local, align 4
  %v1_4074c1 = load i32, i32* %edx.global-to-local, align 4
  %v3_4074c1 = zext i1 %v20_4074bb to i32
  %v4_4074c1 = add i32 %v3_4074c1, %v0_4074c1
  %v5_4074c1 = sub i32 %v4_4074c1, %v1_4074c1
  store i32 %v5_4074c1, i32* %ecx.global-to-local, align 4
  %v0_4074c3 = load i32, i32* inttoptr (i32 4763783 to i32*), align 4
  %v1_4074c3 = xor i32 %v0_4074c3, 214
  store i32 %v1_4074c3, i32* inttoptr (i32 4763783 to i32*), align 4
  %v0_4074cd = load i32, i32* %esi.global-to-local, align 4
  %v3_4074cd = add i32 %v0_4074cd, -6
  %v12_4074cd = icmp ult i32 %v0_4074cd, 6
  store i1 %v12_4074cd, i1* %cf.global-to-local, align 1
  store i32 %v3_4074cd, i32* %esi.global-to-local, align 4
  %v0_4074d0 = load i32, i32* %eax.global-to-local, align 4
  %v1_4074d0 = udiv i32 %v0_4074d0, 256
  %v2_4074d0 = trunc i32 %v1_4074d0 to i8
  %v3_4074d0 = load i8, i8* inttoptr (i32 4763699 to i8*), align 1
  %v5_4074d0 = zext i1 %v12_4074cd to i8
  %v6_4074d0 = add i8 %v3_4074d0, %v5_4074d0
  %v7_4074d0 = add i8 %v6_4074d0, %v2_4074d0
  %v28_4074d0 = zext i8 %v7_4074d0 to i32
  %v30_4074d0 = mul nuw nsw i32 %v28_4074d0, 256
  %v31_4074d0 = and i32 %v0_4074d0, -65281
  %v32_4074d0 = or i32 %v30_4074d0, %v31_4074d0
  store i32 %v32_4074d0, i32* %eax.global-to-local, align 4
  %v0_4074d6 = load i32, i32* inttoptr (i32 4764043 to i32*), align 4
  %v1_4074d6 = xor i32 %v0_4074d6, 220
  store i32 %v1_4074d6, i32* inttoptr (i32 4764043 to i32*), align 4
  %v1_4074e0 = load i32, i32* inttoptr (i32 4763965 to i32*), align 4
  %v2_4074e0 = sub i32 %v32_4074d0, %v1_4074e0
  store i32 %v2_4074e0, i32* %eax.global-to-local, align 4
  %v0_4074e6 = load i32, i32* %esi.global-to-local, align 4
  %v2_4074e6 = mul i32 %v0_4074e6, 2
  %v1_4074e8 = add i32 %v2_4074e6, -15
  %v5_4074e8 = icmp ugt i32 %v2_4074e6, 14
  store i32 %v1_4074e8, i32* %esi.global-to-local, align 4
  %v0_4074eb = load i32, i32* %edx.global-to-local, align 4
  %v2_4074eb = zext i1 %v5_4074e8 to i32
  %v3_4074eb = add i32 %v0_4074eb, -13
  %v4_4074eb = add i32 %v3_4074eb, %v2_4074eb
  store i32 %v4_4074eb, i32* %edx.global-to-local, align 4
  %v0_4074ee = load i32, i32* inttoptr (i32 4764088 to i32*), align 8
  %v2_4074ee = or i32 %v0_4074ee, %v1_4074e8
  store i32 %v2_4074ee, i32* inttoptr (i32 4764088 to i32*), align 8
  %v0_4074f4 = load i32, i32* %eax.global-to-local, align 4
  %v1_4074f7 = add i32 %v0_4074f4, -59
  %v1_4074fa = xor i32 %v1_4074f7, 102
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v1_4074fa, i32* %eax.global-to-local, align 4
  %v0_4074fd = load i8, i8* inttoptr (i32 4764056 to i8*), align 8
  %v1_4074fd = load i32, i32* %edx.global-to-local, align 4
  %v2_4074fd = trunc i32 %v1_4074fd to i8
  %v5_4074fd = add i8 %v2_4074fd, %v0_4074fd
  %v25_4074fd = icmp ult i8 %v5_4074fd, %v0_4074fd
  store i1 %v25_4074fd, i1* %cf.global-to-local, align 1
  store i8 %v5_4074fd, i8* inttoptr (i32 4764056 to i8*), align 8
  %v0_407503 = load i32, i32* %eax.global-to-local, align 4
  %v1_407503 = load i32, i32* %edi.global-to-local, align 4
  %v3_407503 = zext i1 %v25_4074fd to i32
  %v4_407503 = add i32 %v1_407503, %v0_407503
  %v5_407503 = add i32 %v3_407503, %v4_407503
  %v24_407503 = icmp ule i32 %v5_407503, %v0_407503
  %v25_407503 = icmp ult i32 %v4_407503, %v0_407503
  %v26_407503 = select i1 %v25_4074fd, i1 %v24_407503, i1 %v25_407503
  store i1 %v26_407503, i1* %cf.global-to-local, align 1
  store i32 %v5_407503, i32* %eax.global-to-local, align 4
  %v0_407505 = load i8, i8* inttoptr (i32 4763778 to i8*), align 2
  %v1_407505 = add i8 %v0_407505, -74
  store i8 %v1_407505, i8* inttoptr (i32 4763778 to i8*), align 2
  %v0_40750c = load i32, i32* %ecx.global-to-local, align 4
  %v2_40750c = mul i32 %v0_40750c, 2
  store i32 %v2_40750c, i32* %ecx.global-to-local, align 4
  %v0_40750e = load i32, i32* inttoptr (i32 4764007 to i32*), align 4
  %v1_40750e = or i32 %v0_40750e, 87
  store i32 %v1_40750e, i32* inttoptr (i32 4764007 to i32*), align 4
  %v1_407515 = load i32, i32* inttoptr (i32 4764049 to i32*), align 4
  %v4_407515 = add i32 %v1_407515, %v2_40750c
  store i32 %v4_407515, i32* %ecx.global-to-local, align 4
  %v0_40751b = load i32, i32* %edx.global-to-local, align 4
  %v1_40751b = load i32, i32* inttoptr (i32 4763847 to i32*), align 4
  %v2_40751b = sub i32 %v0_40751b, %v1_40751b
  %v7_40751b = icmp ult i32 %v0_40751b, %v1_40751b
  store i32 %v2_40751b, i32* %edx.global-to-local, align 4
  %v0_407521 = load i32, i32* inttoptr (i32 4763789 to i32*), align 4
  %v1_407521 = load i32, i32* %esi.global-to-local, align 4
  %v3_407521 = zext i1 %v7_40751b to i32
  %v4_407521 = add i32 %v1_407521, %v0_407521
  %v5_407521 = add i32 %v4_407521, %v3_407521
  %v24_407521 = icmp ule i32 %v5_407521, %v0_407521
  %v25_407521 = icmp ult i32 %v4_407521, %v0_407521
  %v26_407521 = select i1 %v7_40751b, i1 %v24_407521, i1 %v25_407521
  store i32 %v5_407521, i32* inttoptr (i32 4763789 to i32*), align 4
  %v0_407527 = load i32, i32* inttoptr (i32 4764010 to i32*), align 4
  %v1_407527 = load i32, i32* %eax.global-to-local, align 4
  %v3_407527 = zext i1 %v26_407521 to i32
  %v4_407527 = sub i32 %v0_407527, %v1_407527
  %v5_407527 = add i32 %v3_407527, %v4_407527
  %v16_407527 = sub i32 %v4_407527, %v3_407527
  %v17_407527 = icmp ult i32 %v0_407527, %v16_407527
  %v18_407527 = icmp ne i32 %v1_407527, -1
  %v19_407527 = or i1 %v18_407527, %v17_407527
  %v20_407527 = icmp ult i32 %v0_407527, %v1_407527
  %v21_407527 = select i1 %v26_407521, i1 %v19_407527, i1 %v20_407527
  store i32 %v5_407527, i32* inttoptr (i32 4764010 to i32*), align 4
  %v0_40752d = load i32, i32* %eax.global-to-local, align 4
  %v1_40752d = udiv i32 %v0_40752d, 256
  %v3_40752d = load i32, i32* %edx.global-to-local, align 4
  %v6_40752d = zext i1 %v21_407527 to i32
  %v7_40752d = add i32 %v1_40752d, %v3_40752d
  %v8_40752d = add i32 %v7_40752d, %v6_40752d
  %v29_40752d = mul i32 %v8_40752d, 256
  %v31_40752d = and i32 %v29_40752d, 65280
  %v32_40752d = and i32 %v0_40752d, -65281
  %v33_40752d = or i32 %v31_40752d, %v32_40752d
  store i32 %v33_40752d, i32* %eax.global-to-local, align 4
  %v1_40752f = xor i32 %v3_40752d, 38
  store i32 %v1_40752f, i32* %edx.global-to-local, align 4
  %v0_407532 = load i32, i32* %ecx.global-to-local, align 4
  %v1_407532 = add i32 %v0_407532, 103
  store i32 %v1_407532, i32* %ecx.global-to-local, align 4
  %v0_407535 = load i32, i32* inttoptr (i32 4764066 to i32*), align 4
  %v1_407535 = or i32 %v0_407535, 131
  store i32 %v1_407535, i32* inttoptr (i32 4764066 to i32*), align 4
  store i32 89, i32* inttoptr (i32 4763919 to i32*), align 4
  %v0_407549 = load i32, i32* inttoptr (i32 4763967 to i32*), align 4
  %v3_407549 = add i32 %v0_407549, -11
  %v12_407549 = icmp ult i32 %v0_407549, 11
  store i1 %v12_407549, i1* %cf.global-to-local, align 1
  store i32 %v3_407549, i32* inttoptr (i32 4763967 to i32*), align 4
  store i32 4765460, i32* %eax.global-to-local, align 4
  %v3_407556 = call i32 ()* @GetProcAddress(i32* nonnull @0, i8* bitcast (i32* @0 to i8*))
  %v4_407556 = ptrtoint i32 ()* %v3_407556 to i32
  store i32 %v4_407556, i32* %eax.global-to-local, align 4
  store i32 %v4_407556, i32* inttoptr (i32 4765196 to i32*), align 4
  %v0_40755d = load i32, i32* %ecx.global-to-local, align 4
  %v1_40755d = udiv i32 %v0_40755d, 256
  %v2_40755d = trunc i32 %v1_40755d to i8
  %v3_40755d = load i8, i8* inttoptr (i32 4763811 to i8*), align 1
  %v4_40755d = sub i8 %v2_40755d, %v3_40755d
  %v9_40755d = icmp ult i8 %v2_40755d, %v3_40755d
  %v19_40755d = zext i8 %v4_40755d to i32
  %v21_40755d = mul nuw nsw i32 %v19_40755d, 256
  %v22_40755d = and i32 %v0_40755d, -65281
  %v23_40755d = or i32 %v21_40755d, %v22_40755d
  store i32 %v23_40755d, i32* %ecx.global-to-local, align 4
  %v0_407563 = load i32, i32* inttoptr (i32 4763890 to i32*), align 4
  %v2_407563 = zext i1 %v9_40755d to i32
  %v3_407563 = add i32 %v0_407563, 55
  %v4_407563 = add i32 %v3_407563, %v2_407563
  store i32 %v4_407563, i32* inttoptr (i32 4763890 to i32*), align 4
  %v0_40756a = load i32, i32* %edx.global-to-local, align 4
  %v1_40756a = add i32 %v0_40756a, 56
  %v5_40756a = icmp ult i32 %v0_40756a, -56
  store i32 %v1_40756a, i32* %edx.global-to-local, align 4
  %v1_40756d = load i32, i32* inttoptr (i32 4763713 to i32*), align 4
  %v3_40756d = zext i1 %v5_40756a to i32
  %v4_40756d = add i32 %v1_40756d, %v4_407556
  %v5_40756d = add i32 %v4_40756d, %v3_40756d
  store i32 %v5_40756d, i32* %eax.global-to-local, align 4
  %v0_407573 = load i32, i32* inttoptr (i32 4763780 to i32*), align 4
  %v2_407573 = add i32 %v0_407573, %v1_40756a
  %v7_407573 = icmp ult i32 %v2_407573, %v0_407573
  store i32 %v2_407573, i32* inttoptr (i32 4763780 to i32*), align 4
  %v0_407579 = load i32, i32* inttoptr (i32 4763859 to i32*), align 4
  %v1_407579 = load i32, i32* %edx.global-to-local, align 4
  %v3_407579 = zext i1 %v7_407573 to i32
  %v4_407579 = add i32 %v1_407579, %v0_407579
  %v5_407579 = add i32 %v4_407579, %v3_407579
  %v24_407579 = icmp ule i32 %v5_407579, %v0_407579
  %v25_407579 = icmp ult i32 %v4_407579, %v0_407579
  %v26_407579 = select i1 %v7_407573, i1 %v24_407579, i1 %v25_407579
  store i32 %v5_407579, i32* inttoptr (i32 4763859 to i32*), align 4
  %v0_40757f = load i32, i32* %edx.global-to-local, align 4
  %v1_40757f = load i32, i32* %eax.global-to-local, align 4
  %v3_40757f = zext i1 %v26_407579 to i32
  %v4_40757f = sub i32 %v0_40757f, %v1_40757f
  %v5_40757f = add i32 %v3_40757f, %v4_40757f
  %v16_40757f = sub i32 %v4_40757f, %v3_40757f
  %v17_40757f = icmp ult i32 %v0_40757f, %v16_40757f
  %v18_40757f = icmp ne i32 %v1_40757f, -1
  %v19_40757f = or i1 %v18_40757f, %v17_40757f
  %v20_40757f = icmp ult i32 %v0_40757f, %v1_40757f
  %v21_40757f = select i1 %v26_407579, i1 %v19_40757f, i1 %v20_40757f
  store i1 %v21_40757f, i1* %cf.global-to-local, align 1
  store i32 %v5_40757f, i32* %edx.global-to-local, align 4
  %v0_407581 = load i8, i8* inttoptr (i32 4763894 to i8*), align 2
  %v2_407581 = trunc i32 %v1_40757f to i8
  %v3_407581 = add i8 %v0_407581, %v2_407581
  %v8_407581 = icmp ult i8 %v3_407581, %v0_407581
  store i1 %v8_407581, i1* %cf.global-to-local, align 1
  store i8 %v3_407581, i8* inttoptr (i32 4763894 to i8*), align 2
  %v0_407587 = load i32, i32* %eax.global-to-local, align 4
  %v1_407587 = load i32, i32* inttoptr (i32 4763881 to i32*), align 4
  %v3_407587 = zext i1 %v8_407581 to i32
  %v4_407587 = add i32 %v1_407587, %v0_407587
  %v5_407587 = add i32 %v3_407587, %v4_407587
  %v24_407587 = icmp ule i32 %v5_407587, %v0_407587
  %v25_407587 = icmp ult i32 %v4_407587, %v0_407587
  %v26_407587 = select i1 %v8_407581, i1 %v24_407587, i1 %v25_407587
  store i32 %v5_407587, i32* %eax.global-to-local, align 4
  %v0_40758d = load i32, i32* inttoptr (i32 4763672 to i32*), align 8
  %v1_40758d = load i32, i32* %ecx.global-to-local, align 4
  %v3_40758d = zext i1 %v26_407587 to i32
  %v4_40758d = add i32 %v1_40758d, %v0_40758d
  %v5_40758d = add i32 %v3_40758d, %v4_40758d
  %v24_40758d = icmp ule i32 %v5_40758d, %v0_40758d
  %v25_40758d = icmp ult i32 %v4_40758d, %v0_40758d
  %v26_40758d = select i1 %v26_407587, i1 %v24_40758d, i1 %v25_40758d
  store i32 %v5_40758d, i32* inttoptr (i32 4763672 to i32*), align 8
  %v0_407593 = load i32, i32* %edi.global-to-local, align 4
  %v1_407593 = load i32, i32* inttoptr (i32 4763732 to i32*), align 4
  %v3_407593 = zext i1 %v26_40758d to i32
  %v4_407593 = add i32 %v1_407593, %v0_407593
  %v5_407593 = add i32 %v4_407593, %v3_407593
  store i32 %v5_407593, i32* %edi.global-to-local, align 4
  %v1_407599 = load i32, i32* inttoptr (i32 4763662 to i32*), align 4
  %v2_407599 = or i32 %v5_407593, %v1_407599
  store i32 %v2_407599, i32* %edi.global-to-local, align 4
  %v0_40759f = load i32, i32* %esi.global-to-local, align 4
  %v1_40759f = load i32, i32* inttoptr (i32 4763792 to i32*), align 16
  %v4_40759f = add i32 %v1_40759f, %v0_40759f
  store i32 %v4_40759f, i32* %esi.global-to-local, align 4
  %v0_4075a5 = load i32, i32* %ecx.global-to-local, align 4
  %v2_4075a5 = add i32 %v0_4075a5, %v4_40759f
  %v7_4075a5 = icmp ult i32 %v2_4075a5, %v0_4075a5
  store i1 %v7_4075a5, i1* %cf.global-to-local, align 1
  %v14_4075a5 = trunc i32 %v2_4075a5 to i8
  store i32 %v2_4075a5, i32* %ecx.global-to-local, align 4
  %v0_4075a7 = load i8, i8* inttoptr (i32 4763980 to i8*), align 4
  %v3_4075a7 = and i8 %v0_4075a7, %v14_4075a5
  store i1 false, i1* %cf.global-to-local, align 1
  store i8 %v3_4075a7, i8* inttoptr (i32 4763980 to i8*), align 4
  %v1_4075ad = trunc i32 %v2_4075a5 to i8
  %v2_4075ad = load i8, i8* inttoptr (i32 4763658 to i8*), align 2
  %v5_4075ad = add i8 %v1_4075ad, %v2_4075ad
  %v6_4075ad = add i8 %v1_4075ad, %v2_4075ad
  %v25_4075ad = icmp ult i8 %v5_4075ad, %v1_4075ad
  store i1 %v25_4075ad, i1* %cf.global-to-local, align 1
  %v27_4075ad = zext i8 %v6_4075ad to i32
  %v29_4075ad = and i32 %v2_4075a5, -256
  %v30_4075ad = or i32 %v27_4075ad, %v29_4075ad
  store i32 %v30_4075ad, i32* %ecx.global-to-local, align 4
  store i32 0, i32* %eax.global-to-local, align 4
  call void @llvm.trap()
  unreachable

; uselistorder directives
  uselistorder i8 %v1_4075ad, { 1, 0, 2 }
  uselistorder i32 %v2_4075a5, { 1, 0, 2, 3, 4 }
  uselistorder i32 %v0_4075a5, { 1, 0 }
  uselistorder i32 %v5_40758d, { 1, 0 }
  uselistorder i32 %v4_40758d, { 1, 0 }
  uselistorder i32 %v0_40758d, { 1, 2, 0 }
  uselistorder i1 %v26_407587, { 1, 0 }
  uselistorder i32 %v5_407587, { 1, 0 }
  uselistorder i32 %v4_407587, { 1, 0 }
  uselistorder i32 %v0_407587, { 1, 2, 0 }
  uselistorder i1 %v8_407581, { 1, 0, 2 }
  uselistorder i8 %v0_407581, { 1, 0 }
  uselistorder i32 %v4_40757f, { 1, 0 }
  uselistorder i32 %v3_40757f, { 1, 0 }
  uselistorder i32 %v1_40757f, { 0, 2, 1, 3 }
  uselistorder i32 %v5_407579, { 1, 0 }
  uselistorder i32 %v4_407579, { 1, 0 }
  uselistorder i32 %v0_407579, { 1, 2, 0 }
  uselistorder i1 %v7_407573, { 1, 0 }
  uselistorder i32 %v0_407573, { 1, 0 }
  uselistorder i32 %v0_40756a, { 1, 0 }
  uselistorder i32 %v0_40755d, { 1, 0 }
  uselistorder i32 %v4_407556, { 0, 2, 1 }
  uselistorder i32 %v0_407549, { 1, 0 }
  uselistorder i32 %v3_40752d, { 1, 0 }
  uselistorder i32 %v0_40752d, { 1, 0 }
  uselistorder i32 %v4_407527, { 1, 0 }
  uselistorder i32 %v3_407527, { 1, 0 }
  uselistorder i32 %v1_407527, { 1, 0, 2 }
  uselistorder i32 %v5_407521, { 1, 0 }
  uselistorder i32 %v4_407521, { 1, 0 }
  uselistorder i32 %v0_407521, { 1, 2, 0 }
  uselistorder i1 %v7_40751b, { 1, 0 }
  uselistorder i32 %v5_407503, { 1, 0 }
  uselistorder i32 %v4_407503, { 1, 0 }
  uselistorder i32 %v0_407503, { 1, 2, 0 }
  uselistorder i1 %v25_4074fd, { 1, 0, 2 }
  uselistorder i8 %v0_4074fd, { 1, 0 }
  uselistorder i32 %v0_4074d0, { 1, 0 }
  uselistorder i32 %v0_4074cd, { 1, 0 }
  uselistorder i32 %v0_4074a9, { 1, 0 }
  uselistorder i8 %v0_407437, { 1, 0 }
  uselistorder i32 %v0_407431, { 1, 0 }
  uselistorder i32 %v2_407418, { 1, 0 }
  uselistorder i32 %v4_4073fc, { 1, 0 }
  uselistorder i32 %v3_4073fc, { 1, 0 }
  uselistorder i32 %v1_4073fc, { 1, 0, 2 }
  uselistorder i32 %v5_4073f6, { 1, 0 }
  uselistorder i32 %v4_4073f6, { 1, 0 }
  uselistorder i32 %v0_4073f6, { 1, 2, 0 }
  uselistorder i1 %v7_4073f0, { 1, 0 }
  uselistorder i32 %v5_4073cc, { 1, 4, 3, 2, 0, 5 }
  uselistorder i32 %v0_407396, { 1, 0 }
  uselistorder i32 %v5_407367, { 1, 0 }
  uselistorder i1 %v7_407361, { 1, 0 }
  uselistorder i32 %v1_40735e, { 2, 1, 0, 3 }
  uselistorder i32 %v2_40735c, { 2, 1, 0, 3 }
  uselistorder i32 %v3_40734d, { 1, 0 }
  uselistorder i32 %v5_40733f, { 1, 0, 2 }
  uselistorder i32 %v1_407330, { 1, 0, 2 }
  uselistorder i32 %v5_40731c, { 1, 0 }
  uselistorder i32 %v4_40731c, { 1, 0 }
  uselistorder i1 %v5_407319, { 1, 0 }
  uselistorder i32 %v1_407319, { 2, 1, 0, 3 }
  uselistorder i32 %v0_407319, { 1, 0 }
  uselistorder i32 %v0_407311, { 1, 0 }
  uselistorder i32 %v5_4072e3, { 1, 0 }
  uselistorder i32 %v4_4072e3, { 1, 0 }
  uselistorder i32 %v0_4072e3, { 1, 2, 0 }
  uselistorder i1 %v9_4072dd, { 1, 0, 2 }
  uselistorder i8 %v0_4072dd, { 1, 0 }
  uselistorder i32 %v0_4072cc, { 1, 0 }
  uselistorder i32 %v5_4072c6, { 1, 0, 3, 2 }
  uselistorder i32 %v4_4072c6, { 1, 0 }
  uselistorder i32 %v0_4072c6, { 1, 2, 0 }
  uselistorder i1 %v26_4072c0, { 1, 0 }
  uselistorder i32 %v5_4072c0, { 1, 0 }
  uselistorder i32 %v4_4072c0, { 1, 0 }
  uselistorder i32 %v0_4072c0, { 1, 2, 0 }
  uselistorder i1 %v26_4072ba, { 1, 0 }
  uselistorder i32 %v5_4072ba, { 1, 0 }
  uselistorder i32 %v4_4072ba, { 1, 0 }
  uselistorder i32 %v0_4072ba, { 1, 2, 0 }
  uselistorder i1 %v7_4072b8, { 1, 0 }
  uselistorder i32 %v0_4072b8, { 1, 0 }
  uselistorder i32 %v0_407297, { 1, 0 }
  uselistorder i32 %v0_407292, { 1, 0 }
  uselistorder i32 %v0_407282, { 1, 0 }
  uselistorder i32 %v1_407259, { 1, 0 }
  uselistorder i32 %v0_407259, { 1, 0 }
  uselistorder i32 %v4_407256, { 1, 0 }
  uselistorder i32 %v0_407256, { 1, 2, 0 }
  uselistorder i1 %v26_407250, { 1, 0 }
  uselistorder i32 %v5_407250, { 1, 0 }
  uselistorder i32 %v4_407250, { 1, 0 }
  uselistorder i1 %v26_40724a, { 1, 0 }
  uselistorder i32 %v5_40724a, { 3, 2, 0, 4, 1 }
  uselistorder i32 %v4_40724a, { 1, 0 }
  uselistorder i32 %v0_40724a, { 1, 2, 0 }
  uselistorder i1 %v12_407243, { 1, 0 }
  uselistorder i32 %v0_407243, { 1, 0 }
  uselistorder i32 %v5_407241, { 1, 0 }
  uselistorder i32 %v4_407241, { 1, 0 }
  uselistorder i1 %v7_40723f, { 1, 0 }
  uselistorder i32 %v2_40723f, { 2, 1, 0, 3 }
  uselistorder i32 %v0_40723f, { 1, 0 }
  uselistorder i32 %v4_407233, { 1, 0 }
  uselistorder i32 %v3_407233, { 1, 0 }
  uselistorder i32 %v1_407233, { 1, 0, 2 }
  uselistorder i32 %v5_407231, { 1, 0 }
  uselistorder i32 %v4_407231, { 1, 0 }
  uselistorder i32 %v1_407231, { 3, 2, 1, 0 }
  uselistorder i32 %v0_407231, { 1, 2, 0 }
  uselistorder i1 %v23_40722a, { 1, 0 }
  uselistorder i32 %v4_40722a, { 1, 0 }
  uselistorder i1 %v26_407224, { 1, 0 }
  uselistorder i8 %v2_407224, { 1, 0 }
  uselistorder i32 %v0_407224, { 1, 0 }
  uselistorder i32 %v0_407212, { 1, 0 }
  uselistorder i32 %v0_407208, { 1, 0 }
  uselistorder i32 %v5_4071fb, { 0, 2, 1 }
  uselistorder i32 %v4_4071fb, { 1, 0 }
  uselistorder i32 %v0_4071fb, { 1, 2, 0 }
  uselistorder i32 %v0_4071c0, { 1, 0 }
  uselistorder i32 %v0_4071a8, { 1, 0 }
  uselistorder i32 %v0_407199, { 1, 0 }
  uselistorder i1 %v5_407192, { 1, 0, 2 }
  uselistorder i8 %v0_407192, { 1, 0 }
  uselistorder i32 %v2_40717d, { 1, 0 }
  uselistorder i32 %v1_407117, { 1, 0 }
  uselistorder i32 %v0_407111, { 1, 0 }
  uselistorder i32 %v5_40710b, { 1, 0 }
  uselistorder i32 %v4_40710b, { 1, 0 }
  uselistorder i32 %v0_40710b, { 1, 2, 0 }
  uselistorder i1 %v13_407101, { 1, 0 }
  uselistorder i32 %v0_407101, { 1, 0 }
  uselistorder i32 %v0_4070fb, { 1, 0 }
  uselistorder i32 %v2_4070f2, { 1, 0 }
  uselistorder i32 %v1_40709c, { 1, 0, 2 }
  uselistorder i32 %v4_407093, { 1, 0 }
  uselistorder i32 %v0_40708d, { 1, 0 }
  uselistorder i32 %v1_407084, { 1, 2, 0, 3 }
  uselistorder i32 %v4_407078, { 1, 0, 2 }
  uselistorder i8 %v0_40706b, { 1, 0 }
  uselistorder i32 %v0_407064, { 1, 0 }
  uselistorder i1 %v27_40705e, { 1, 0 }
  uselistorder i8 %v7_40705e, { 1, 0 }
  uselistorder i8 %v6_40705e, { 1, 0 }
  uselistorder i8 %v2_40705e, { 1, 2, 0 }
  uselistorder i1 %v5_40705b, { 1, 0, 2 }
  uselistorder i32 %v1_40705b, { 1, 0, 2 }
  uselistorder i32 %v0_407039, { 1, 0 }
  uselistorder i32 %v4_40701a, { 1, 0 }
  uselistorder i32 %v3_40701a, { 1, 0 }
  uselistorder i32 %v1_40701a, { 1, 0, 2 }
  uselistorder i1 %v20_407014, { 1, 0 }
  uselistorder i8 %v0_406fe8, { 1, 0 }
  uselistorder i32 %v4_406fc2, { 1, 0 }
  uselistorder i1 %v21_406fbc, { 1, 0 }
  uselistorder i32 %v4_406fbc, { 1, 0 }
  uselistorder i32 %v3_406fbc, { 1, 0 }
  uselistorder i32 %v1_406fbc, { 1, 0, 2 }
  uselistorder i1 %v8_406fb6, { 1, 0, 2 }
  uselistorder i8 %v0_406fb6, { 1, 0 }
  uselistorder i8 %v2_406f50, { 1, 0 }
  uselistorder i32 %v5_406f48, { 1, 0, 2 }
  uselistorder i32 %v0_406f37, { 1, 0 }
  uselistorder i32 %v0_406f2f, { 1, 0 }
  uselistorder i32 %v4_406efd, { 0, 1, 3, 2 }
  uselistorder i32 %v1_406eef, { 1, 0, 2, 3 }
  uselistorder i32 %v4_406ed8, { 1, 0 }
  uselistorder i32 %v3_406ed8, { 1, 0 }
  uselistorder i32 %v1_406ed8, { 0, 2, 1, 3 }
  uselistorder i1 %v7_406ed2, { 1, 0 }
  uselistorder i32 %v1_406e98, { 1, 0 }
  uselistorder i32 %v1_406e6b, { 2, 1, 0 }
  uselistorder i8 %v7_406e5a, { 1, 0 }
  uselistorder i8 %v6_406e5a, { 1, 0 }
  uselistorder i8 %v0_406e5a, { 1, 2, 0 }
  uselistorder i1 %v8_406e54, { 1, 0, 2 }
  uselistorder i32 %v4_406e52, { 1, 0 }
  uselistorder i32 %v3_406e52, { 1, 0 }
  uselistorder i32 %v1_406e52, { 1, 0, 2 }
  uselistorder i1 %v5_406e4f, { 1, 0 }
  uselistorder i32 %v2_406e4d, { 3, 2, 1, 0 }
  uselistorder i32 %v0_406e4d, { 1, 0 }
  uselistorder i32 %v5_406e22, { 1, 0, 3, 2 }
  uselistorder i32 %v0_406e22, { 1, 2, 0 }
  uselistorder i32 %v23_406e1c, { 1, 0, 2 }
  uselistorder i1 %v9_406e1c, { 1, 0 }
  uselistorder i32 %v0_406e1c, { 1, 0 }
  uselistorder i8 %v6_406e16, { 0, 2, 1 }
  uselistorder i8 %v5_406e16, { 1, 0 }
  uselistorder i1 %v7_406e10, { 1, 0, 2 }
  uselistorder i32 %v0_406e10, { 1, 0 }
  uselistorder i32 %v0_402c5c, { 1, 0 }
  uselistorder i32 %v5_402c4b, { 1, 0 }
  uselistorder i32 %v4_402c4b, { 1, 0 }
  uselistorder i1 %v26_402c45, { 1, 0 }
  uselistorder i32 %v5_402c45, { 0, 2, 1 }
  uselistorder i32 %v4_402c45, { 1, 0 }
  uselistorder i1 %v26_402c43, { 1, 0 }
  uselistorder i32 %v5_402c43, { 3, 2, 0, 4, 1 }
  uselistorder i32 %v4_402c43, { 1, 0 }
  uselistorder i32 %v0_402c43, { 1, 2, 0 }
  uselistorder i1 %v5_402c40, { 1, 0 }
  uselistorder i32 %v4_402c3e, { 2, 1, 0, 3 }
  uselistorder i32 %v1_402c2d, { 1, 0 }
  uselistorder i32 %v0_402c2d, { 1, 0 }
  uselistorder i32 %v4_402c15, { 0, 2, 1 }
  uselistorder i32 %v0_402bd8, { 1, 0 }
  uselistorder i32 %v0_402bd2, { 1, 0 }
  uselistorder i32 %v4_402bb9, { 1, 0 }
  uselistorder i32 %v1_402bae, { 1, 0, 2, 3 }
  uselistorder i8 %v2_402baa, { 1, 0 }
  uselistorder i8 %v2_402ba8, { 1, 0 }
  uselistorder i8 %v2_402ba6, { 1, 0 }
  uselistorder i8 %v2_402ba4, { 1, 0 }
  uselistorder i8 %v2_402ba2, { 1, 0 }
  uselistorder i32 %v2_402b89, { 1, 0, 2 }
  uselistorder i32 %v4_402b80, { 1, 0, 2 }
  uselistorder i1 %v5_402b79, { 1, 0, 2 }
  uselistorder i8 %v0_402b79, { 1, 0 }
  uselistorder i32 %v5_402b73, { 0, 1, 3, 2 }
  uselistorder i32 %v4_402b73, { 1, 0 }
  uselistorder i32 %v0_402b73, { 1, 2, 0 }
  uselistorder i1 %v9_402b71, { 1, 0 }
  uselistorder i8 %v1_402b71, { 1, 0 }
  uselistorder i32 %v0_402b52, { 1, 0 }
  uselistorder i32 %v4_402b49, { 1, 0 }
  uselistorder i32 %v3_402b49, { 1, 0 }
  uselistorder i32 %v1_402b49, { 1, 0, 2 }
  uselistorder i1 %v5_402b46, { 1, 0 }
  uselistorder i32 %v0_402b46, { 1, 0 }
  uselistorder i32 %v5_402b16, { 2, 1, 0, 3 }
  uselistorder i32 %v0_402b01, { 1, 0 }
  uselistorder i32 %v5_402af5, { 1, 0 }
  uselistorder i32 %v4_402af5, { 1, 0 }
  uselistorder i32 %v0_402af5, { 1, 2, 0 }
  uselistorder i1 %v7_402af3, { 1, 0 }
  uselistorder i32 %v2_402af3, { 1, 0 }
  uselistorder i32 %v5_402ae1, { 1, 0 }
  uselistorder i32 %v4_402ae1, { 1, 0 }
  uselistorder i1 %v5_402ade, { 1, 0 }
  uselistorder i32 %v1_402ade, { 2, 1, 0, 3 }
  uselistorder i8 %v2_402aab, { 1, 0 }
  uselistorder i8 %v2_402aa9, { 1, 0 }
  uselistorder i8 %v2_402aa7, { 1, 0 }
  uselistorder i8 %v2_402aa5, { 1, 0 }
  uselistorder i32 %v1_402a9a, { 1, 0, 2 }
  uselistorder i32 %v4_402a94, { 1, 0, 2 }
  uselistorder i32 %v0_402a83, { 0, 2, 1 }
  uselistorder i8 %v7_402a70, { 1, 0 }
  uselistorder i8 %v6_402a70, { 1, 0 }
  uselistorder i8 %v2_402a70, { 1, 2, 0 }
  uselistorder i32 %v0_402a70, { 1, 0 }
  uselistorder i1 %v20_402a6a, { 1, 0, 2 }
  uselistorder i8 %v0_402a03, { 1, 0 }
  uselistorder i32 %v0_4029fd, { 1, 0 }
  uselistorder i32 %v6_4029dd, { 1, 0, 2 }
  uselistorder i8 %v6_4029b0, { 1, 0 }
  uselistorder i8 %v5_4029b0, { 1, 0 }
  uselistorder i1 %v5_4029ad, { 1, 0, 2 }
  uselistorder i32* %esi.global-to-local, { 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75 }
  uselistorder i32* %edi.global-to-local, { 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71 }
  uselistorder i32* %ebx.global-to-local, { 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 98, 99, 84, 83, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 94, 96, 97 }
  uselistorder i32* %eax.global-to-local, { 0, 1, 2, 3, 4, 5, 7, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 54, 57, 56, 58, 59, 60, 62, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 87, 82, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 107, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106 }
  uselistorder i1* %cf.global-to-local, { 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 93, 94, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 92, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91 }
  uselistorder i32* inttoptr (i32 4763919 to i32*), { 4, 0, 1, 2, 3 }
  uselistorder i32 147, { 1, 0 }
  uselistorder i32 -106, { 1, 0 }
  uselistorder i32 ()* @unknown_48b604, { 1, 0 }
  uselistorder i32 ptrtoint ([12 x i8]* @global_var_48b628.16 to i32), { 0, 2, 1, 3 }
  uselistorder i32 -123, { 1, 0 }
  uselistorder i32 ()* (i32*, i8*)* @GetProcAddress, { 1, 0 }
  uselistorder i32* inttoptr (i32 4763961 to i32*), { 1, 2, 0 }
  uselistorder i32* inttoptr (i32 4763838 to i32*), { 1, 2, 3, 0 }
  uselistorder i32 -83, { 1, 0 }
  uselistorder i32 134, { 3, 1, 0, 2 }
  uselistorder i32 4764064, { 1, 0 }
  uselistorder i32 232, { 0, 2, 1 }
  uselistorder i32 215, { 1, 0 }
  uselistorder i32* inttoptr (i32 4763689 to i32*), { 5, 0, 1, 2, 3, 4 }
  uselistorder i32 4764055, { 1, 0 }
  uselistorder i32 4764157, { 1, 0 }
  uselistorder i32* inttoptr (i32 4764157 to i32*), { 1, 2, 0 }
  uselistorder i32 4764005, { 1, 0 }
  uselistorder i32* inttoptr (i32 4763920 to i32*), { 2, 0, 1 }
  uselistorder i32 4764074, { 2, 1, 0 }
  uselistorder i32* inttoptr (i32 4764074 to i32*), { 2, 3, 0, 1 }
  uselistorder i32* inttoptr (i32 4763666 to i32*), { 1, 2, 0 }
  uselistorder i32* inttoptr (i32 4764085 to i32*), { 2, 3, 0, 1 }
  uselistorder i32* @0, { 4, 5, 7, 3, 0, 6, 1, 2, 8 }
  uselistorder i8* inttoptr (i32 4764126 to i8*), { 1, 2, 0 }
  uselistorder i32 -47, { 1, 0 }
  uselistorder i32* @ecx, { 124, 125, 126, 127, 128, 129, 130, 131, 132, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123 }
}

define i32 @entry_point(i8 %arg1) local_unnamed_addr {
entry:
  %cf.global-to-local = alloca i1, align 1
  %eax.global-to-local = alloca i32, align 4
  %ebx.global-to-local = alloca i32, align 4
  %ecx.global-to-local = alloca i32, align 4
  %edi.global-to-local = alloca i32, align 4
  %edx.global-to-local = alloca i32, align 4
  %esi.global-to-local = alloca i32, align 4
  %st0.global-to-local = alloca x86_fp80, align 4
  %stack_var_-268 = alloca i16*, align 4
  %stack_var_-4 = alloca i32, align 4
  %v3_409b65 = load i32, i32* @ebp, align 4
  store i32 %v3_409b65, i32* %stack_var_-4, align 4
  %v5_409b6b = icmp ult i32* %stack_var_-4, inttoptr (i32 68 to i32*)
  store i32 1, i32* %eax.global-to-local, align 4
  %v1_409b73 = load i32, i32* inttoptr (i32 4763688 to i32*), align 8
  %v4_409b73 = select i1 %v5_409b6b, i32 2, i32 1
  %v5_409b73 = add i32 %v4_409b73, %v1_409b73
  store i32 %v5_409b73, i32* %eax.global-to-local, align 4
  %v0_409b79 = load i32, i32* inttoptr (i32 4763753 to i32*), align 4
  %v1_409b79 = and i32 %v0_409b79, 14
  store i32 %v1_409b79, i32* inttoptr (i32 4763753 to i32*), align 4
  %v2_409b85 = add i32 %v5_409b73, 1
  %v7_409b85 = icmp eq i32 %v2_409b85, 0
  %v2_409b87 = zext i1 %v7_409b85 to i32
  %v3_409b87 = add i32 %v5_409b73, -8
  %v4_409b87 = add i32 %v3_409b87, %v2_409b87
  %v22_409b87 = icmp ule i32 %v4_409b87, %v2_409b85
  %v23_409b87 = icmp ugt i32 %v2_409b85, 8
  %v24_409b87 = select i1 %v7_409b85, i1 %v22_409b87, i1 %v23_409b87
  store i32 %v4_409b87, i32* %edx.global-to-local, align 4
  %v0_409b8a = load i32, i32* inttoptr (i32 4763700 to i32*), align 4
  %v2_409b8a = zext i1 %v24_409b87 to i32
  %v3_409b8a = add i32 %v0_409b8a, -81
  %v4_409b8a = add i32 %v3_409b8a, %v2_409b8a
  %v12_409b8a = icmp ult i32 %v0_409b8a, 81
  %v13_409b8a = or i1 %v12_409b8a, %v24_409b87
  store i32 %v4_409b8a, i32* inttoptr (i32 4763700 to i32*), align 4
  store i32 1, i32* %ebx.global-to-local, align 4
  %v1_409b96 = load i32, i32* inttoptr (i32 4764049 to i32*), align 4
  %v3_409b96 = zext i1 %v13_409b8a to i32
  %v4_409b96 = add i32 %v1_409b96, 1
  %v5_409b96 = add i32 %v3_409b96, %v4_409b96
  %v24_409b96 = icmp ult i32 %v5_409b96, 2
  %v25_409b96 = icmp eq i32 %v4_409b96, 0
  %v26_409b96 = select i1 %v13_409b8a, i1 %v24_409b96, i1 %v25_409b96
  store i32 %v5_409b96, i32* %ebx.global-to-local, align 4
  %v0_409b9c = load i32, i32* inttoptr (i32 4764056 to i32*), align 8
  %v2_409b9c = zext i1 %v26_409b96 to i32
  %v3_409b9c = add i32 %v0_409b9c, -163
  %v4_409b9c = add i32 %v3_409b9c, %v2_409b9c
  store i32 %v4_409b9c, i32* inttoptr (i32 4764056 to i32*), align 8
  %v1_409bab = load i32, i32* %eax.global-to-local, align 4
  %v2_409bab = add i32 %v1_409bab, 1
  store i32 %v2_409bab, i32* %ecx.global-to-local, align 4
  store i32 118, i32* %edi.global-to-local, align 4
  store i32 155, i32* inttoptr (i32 4763824 to i32*), align 16
  %v0_409bbf = load i32, i32* %edx.global-to-local, align 4
  %v1_409bbf = load i32, i32* inttoptr (i32 4763832 to i32*), align 8
  %v4_409bbf = add i32 %v1_409bbf, %v0_409bbf
  store i32 %v4_409bbf, i32* %edx.global-to-local, align 4
  %v0_409bc5 = load i32, i32* %ecx.global-to-local, align 4
  %v1_409bc5 = add i32 %v0_409bc5, -109
  %v5_409bc5 = icmp ugt i32 %v0_409bc5, 108
  store i1 %v5_409bc5, i1* %cf.global-to-local, align 1
  store i32 %v1_409bc5, i32* %ecx.global-to-local, align 4
  store i32 24, i32* inttoptr (i32 4763895 to i32*), align 4
  store i32 0, i32* %eax.global-to-local, align 4
  %v5_409bda = call i32* @EncodePointer(i32* null)
  %v6_409bda = ptrtoint i32* %v5_409bda to i32
  %v9_409bda = trunc i32 %v6_409bda to i8
  store i32 %v6_409bda, i32* %eax.global-to-local, align 4
  %v3_409be0 = load i8, i8* inttoptr (i32 4763923 to i8*), align 1
  %v4_409be0 = sub i8 %v9_409bda, %v3_409be0
  %v19_409be0 = zext i8 %v4_409be0 to i32
  %sext9 = mul i32 %v6_409bda, 16777216
  %v21_409be0 = sdiv i32 %sext9, 16777216
  %v22_409be0 = and i32 %v21_409be0, -256
  %v23_409be0 = or i32 %v19_409be0, %v22_409be0
  store i32 %v23_409be0, i32* %eax.global-to-local, align 4
  %v0_409be6 = load i32, i32* %ebx.global-to-local, align 4
  %v1_409be6 = and i32 %v0_409be6, -43
  store i32 %v1_409be6, i32* %ebx.global-to-local, align 4
  store i32 119, i32* inttoptr (i32 4763969 to i32*), align 4
  %v2_409bf8 = add nsw i32 %v1_409be6, 1
  %v0_409bfa = load i32, i32* %edi.global-to-local, align 4
  %v1_409bfa = load i32, i32* %eax.global-to-local, align 4
  %v2_409bfa = add i32 %v1_409bfa, %v0_409bfa
  %v7_409bfa = icmp ult i32 %v2_409bfa, %v0_409bfa
  store i32 %v2_409bfa, i32* %edi.global-to-local, align 4
  %v3_409bfc = zext i1 %v7_409bfa to i32
  %v4_409bfc = add i32 %v2_409bf8, %v1_409bfa
  %v5_409bfc = add i32 %v4_409bfc, %v3_409bfc
  store i32 %v5_409bfc, i32* %edx.global-to-local, align 4
  store i32 81, i32* %esi.global-to-local, align 4
  %v0_409c06 = load i32, i32* inttoptr (i32 4763828 to i32*), align 4
  %v2_409c06 = add i32 %v0_409c06, %v2_409bfa
  %v7_409c06 = icmp ult i32 %v2_409c06, %v0_409c06
  store i1 %v7_409c06, i1* %cf.global-to-local, align 1
  store i32 %v2_409c06, i32* inttoptr (i32 4763828 to i32*), align 4
  %v0_409c0c = load i32, i32* %eax.global-to-local, align 4
  %v1_409c0c = trunc i32 %v0_409c0c to i8
  %v2_409c0c = load i8, i8* inttoptr (i32 4763664 to i8*), align 16
  %v4_409c0c = zext i1 %v7_409c06 to i8
  %v5_409c0c = add i8 %v2_409c0c, %v4_409c0c
  %v6_409c0c = add i8 %v5_409c0c, %v1_409c0c
  %v27_409c0c = zext i8 %v6_409c0c to i32
  %v29_409c0c = and i32 %v0_409c0c, -256
  %v30_409c0c = or i32 %v27_409c0c, %v29_409c0c
  store i32 %v30_409c0c, i32* %eax.global-to-local, align 4
  %v0_409c12 = load i32, i32* inttoptr (i32 4764119 to i32*), align 4
  %v1_409c12 = and i32 %v0_409c12, 189
  store i32 %v1_409c12, i32* inttoptr (i32 4764119 to i32*), align 4
  %v0_409c1c = load i32, i32* inttoptr (i32 4763950 to i32*), align 4
  %v1_409c1c = load i32, i32* %ebx.global-to-local, align 4
  %v2_409c1c = add i32 %v1_409c1c, %v0_409c1c
  %v7_409c1c = icmp ult i32 %v2_409c1c, %v0_409c1c
  store i32 %v2_409c1c, i32* inttoptr (i32 4763950 to i32*), align 4
  %v0_409c22 = load i32, i32* inttoptr (i32 4764039 to i32*), align 4
  %v2_409c22 = zext i1 %v7_409c1c to i32
  %v3_409c22 = add i32 %v0_409c22, -122
  %v4_409c22 = add i32 %v3_409c22, %v2_409c22
  store i32 %v4_409c22, i32* inttoptr (i32 4764039 to i32*), align 4
  %v0_409c29 = load i32, i32* %edi.global-to-local, align 4
  %v1_409c29 = or i32 %v0_409c29, -64
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v1_409c29, i32* %edi.global-to-local, align 4
  call void @__pseudo_call(i32 4234292)
  %v0_409c34 = load i32, i32* inttoptr (i32 4764021 to i32*), align 4
  %v1_409c34 = load i1, i1* %cf.global-to-local, align 1
  %v2_409c34 = zext i1 %v1_409c34 to i32
  %v3_409c34 = add i32 %v0_409c34, -46
  %v4_409c34 = add i32 %v3_409c34, %v2_409c34
  store i32 %v4_409c34, i32* inttoptr (i32 4764021 to i32*), align 4
  %v0_409c3b = load i32, i32* inttoptr (i32 4763862 to i32*), align 4
  %v1_409c3b = load i32, i32* %eax.global-to-local, align 4
  %v2_409c3b = or i32 %v1_409c3b, %v0_409c3b
  store i32 %v2_409c3b, i32* inttoptr (i32 4763862 to i32*), align 4
  store i32 0, i32* %ebx.global-to-local, align 4
  %v0_409c43 = load i32, i32* inttoptr (i32 4764108 to i32*), align 4
  %v1_409c43 = load i32, i32* %esi.global-to-local, align 4
  %v2_409c43 = and i32 %v1_409c43, %v0_409c43
  store i32 %v2_409c43, i32* inttoptr (i32 4764108 to i32*), align 4
  %v0_409c49 = load i32, i32* %edi.global-to-local, align 4
  %v1_409c49 = load i32, i32* inttoptr (i32 4764128 to i32*), align 32
  %v4_409c49 = add i32 %v1_409c49, %v0_409c49
  store i32 %v4_409c49, i32* %edi.global-to-local, align 4
  %v0_409c4f = load i32, i32* %ebx.global-to-local, align 4
  %v1_409c4f = add i32 %v0_409c4f, -1
  %v5_409c4f = icmp eq i32 %v0_409c4f, 0
  store i32 %v1_409c4f, i32* %ebx.global-to-local, align 4
  %v0_409c52 = load i32, i32* %edx.global-to-local, align 4
  %v1_409c52 = load i32, i32* inttoptr (i32 4763747 to i32*), align 4
  %v3_409c52 = zext i1 %v5_409c4f to i32
  %v4_409c52 = add i32 %v1_409c52, %v0_409c52
  %v5_409c52 = add i32 %v4_409c52, %v3_409c52
  %v24_409c52 = icmp ule i32 %v5_409c52, %v0_409c52
  %v25_409c52 = icmp ult i32 %v4_409c52, %v0_409c52
  %v26_409c52 = select i1 %v5_409c4f, i1 %v24_409c52, i1 %v25_409c52
  store i32 %v5_409c52, i32* %edx.global-to-local, align 4
  %v0_409c58 = load i32, i32* %eax.global-to-local, align 4
  %v1_409c58 = load i32, i32* inttoptr (i32 4763947 to i32*), align 4
  %v3_409c58 = zext i1 %v26_409c52 to i32
  %v4_409c58 = add i32 %v1_409c58, %v0_409c58
  %v5_409c58 = add i32 %v4_409c58, %v3_409c58
  store i32 %v5_409c58, i32* %eax.global-to-local, align 4
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 89, i32* %ecx.global-to-local, align 4
  store i32 66, i32* inttoptr (i32 4764008 to i32*), align 8
  %v2_409c70 = load i8, i8* inttoptr (i32 4763886 to i8*), align 2
  %v5_409c70 = add i8 %v2_409c70, 89
  %v27_409c70 = zext i8 %v5_409c70 to i32
  store i32 %v27_409c70, i32* %ecx.global-to-local, align 4
  store i32 228, i32* inttoptr (i32 4763933 to i32*), align 4
  %v0_409c80 = load i32, i32* inttoptr (i32 4763723 to i32*), align 4
  %v1_409c80 = load i32, i32* %edx.global-to-local, align 4
  %v2_409c80 = add i32 %v1_409c80, %v0_409c80
  %v7_409c80 = icmp ult i32 %v2_409c80, %v0_409c80
  store i1 %v7_409c80, i1* %cf.global-to-local, align 1
  store i32 %v2_409c80, i32* inttoptr (i32 4763723 to i32*), align 4
  %v0_409c86 = load i32, i32* %eax.global-to-local, align 4
  %v1_409c86 = inttoptr i32 %v0_409c86 to i8*
  %v2_409c86 = load i8, i8* %v1_409c86, align 1
  %v4_409c86 = trunc i32 %v0_409c86 to i8
  %v5_409c86 = add i8 %v4_409c86, %v2_409c86
  %v10_409c86 = icmp ult i8 %v5_409c86, %v2_409c86
  store i1 %v10_409c86, i1* %cf.global-to-local, align 1
  store i8 %v5_409c86, i8* %v1_409c86, align 1
  %v0_409c88 = load i32, i32* %eax.global-to-local, align 4
  %v1_409c88 = inttoptr i32 %v0_409c88 to i8*
  %v2_409c88 = load i8, i8* %v1_409c88, align 1
  %v4_409c88 = trunc i32 %v0_409c88 to i8
  %v5_409c88 = add i8 %v4_409c88, %v2_409c88
  %v10_409c88 = icmp ult i8 %v5_409c88, %v2_409c88
  store i1 %v10_409c88, i1* %cf.global-to-local, align 1
  store i8 %v5_409c88, i8* %v1_409c88, align 1
  %v0_409c8a = load i32, i32* %eax.global-to-local, align 4
  %v1_409c8a = inttoptr i32 %v0_409c8a to i8*
  %v2_409c8a = load i8, i8* %v1_409c8a, align 1
  %v4_409c8a = trunc i32 %v0_409c8a to i8
  %v5_409c8a = add i8 %v4_409c8a, %v2_409c8a
  %v10_409c8a = icmp ult i8 %v5_409c8a, %v2_409c8a
  store i1 %v10_409c8a, i1* %cf.global-to-local, align 1
  store i8 %v5_409c8a, i8* %v1_409c8a, align 1
  %v0_409c8c = load i32, i32* %eax.global-to-local, align 4
  %v1_409c8c = inttoptr i32 %v0_409c8c to i8*
  %v2_409c8c = load i8, i8* %v1_409c8c, align 1
  %v4_409c8c = udiv i32 %v0_409c8c, 256
  %v5_409c8c = trunc i32 %v4_409c8c to i8
  %v6_409c8c = add i8 %v5_409c8c, %v2_409c8c
  store i8 %v6_409c8c, i8* %v1_409c8c, align 1
  %v0_409c8e = load i32, i32* %eax.global-to-local, align 4
  %v1_409c8e = add i32 %v0_409c8e, 4763797
  store i32 %v1_409c8e, i32* %eax.global-to-local, align 4
  store i32 88, i32* %edx.global-to-local, align 4
  %v0_409c9b = load i32, i32* inttoptr (i32 4764108 to i32*), align 4
  %v2_409c9b = add i32 %v0_409c9b, %v1_409c8e
  store i32 %v2_409c9b, i32* inttoptr (i32 4764108 to i32*), align 4
  %v0_409ca1 = load i32, i32* inttoptr (i32 4763915 to i32*), align 4
  %v2_409ca1 = or i32 %v1_409c8e, %v0_409ca1
  store i32 %v2_409ca1, i32* inttoptr (i32 4763915 to i32*), align 4
  %v0_409ca7 = load i32, i32* %edi.global-to-local, align 4
  %v3_409ca7 = add i32 %v0_409ca7, -22
  %v22_409ca7 = trunc i32 %v3_409ca7 to i8
  store i32 %v3_409ca7, i32* %edi.global-to-local, align 4
  store i32 0, i32* %eax.global-to-local, align 4
  %v0_409cac = load i32, i32* %ebx.global-to-local, align 4
  %v1_409cac = load i32, i32* inttoptr (i32 4763769 to i32*), align 4
  %v4_409cac = add i32 %v1_409cac, %v0_409cac
  store i32 %v3_409ca7, i32* %eax.global-to-local, align 4
  %v0_409cb4 = load i32, i32* %ecx.global-to-local, align 4
  %v1_409cb4 = and i32 %v0_409cb4, -65281
  %v5_409cb6 = add i8 %v22_409ca7, 1
  %v10_409cb6 = icmp eq i8 %v5_409cb6, 0
  %v20_409cb6 = zext i8 %v5_409cb6 to i32
  %v22_409cb6 = mul nuw nsw i32 %v20_409cb6, 256
  %v24_409cb6 = or i32 %v1_409cb4, %v22_409cb6
  store i32 %v24_409cb6, i32* %ecx.global-to-local, align 4
  %v2_409cb8 = zext i1 %v10_409cb6 to i32
  %v3_409cb8 = add i32 %v4_409cac, 80
  %v4_409cb8 = add i32 %v3_409cb8, %v2_409cb8
  %v11_409cb8 = icmp ult i32 %v4_409cac, -80
  %v12_409cb8 = or i1 %v10_409cb6, %v11_409cb8
  store i1 %v12_409cb8, i1* %cf.global-to-local, align 1
  store i32 %v4_409cb8, i32* %ebx.global-to-local, align 4
  %v0_409cbb = load i8, i8* inttoptr (i32 4764123 to i8*), align 1
  %v1_409cbb = load i32, i32* %edx.global-to-local, align 4
  %v2_409cbb = udiv i32 %v1_409cbb, 256
  %v3_409cbb = trunc i32 %v2_409cbb to i8
  %v5_409cbb = zext i1 %v12_409cb8 to i8
  %v6_409cbb = sub i8 %v0_409cbb, %v3_409cbb
  %v7_409cbb = add i8 %v6_409cbb, %v5_409cbb
  %v18_409cbb = sub i8 %v6_409cbb, %v5_409cbb
  %v19_409cbb = icmp ult i8 %v0_409cbb, %v18_409cbb
  %v20_409cbb = icmp ne i8 %v3_409cbb, -1
  %v21_409cbb = or i1 %v20_409cbb, %v19_409cbb
  %v22_409cbb = icmp ult i8 %v0_409cbb, %v3_409cbb
  %v23_409cbb = select i1 %v12_409cb8, i1 %v21_409cbb, i1 %v22_409cbb
  store i1 %v23_409cbb, i1* %cf.global-to-local, align 1
  store i8 %v7_409cbb, i8* inttoptr (i32 4764123 to i8*), align 1
  %v0_409cc1 = load i32, i32* inttoptr (i32 4763771 to i32*), align 4
  %v2_409cc1 = zext i1 %v23_409cbb to i32
  %v3_409cc1 = add i32 %v0_409cc1, -178
  %v4_409cc1 = add i32 %v3_409cc1, %v2_409cc1
  store i32 %v4_409cc1, i32* inttoptr (i32 4763771 to i32*), align 4
  %v0_409ccb = load i32, i32* %ebx.global-to-local, align 4
  %v1_409ccb = load i32, i32* %edi.global-to-local, align 4
  %v2_409ccb = sub i32 %v0_409ccb, %v1_409ccb
  %v7_409ccb = icmp ult i32 %v0_409ccb, %v1_409ccb
  store i32 %v2_409ccb, i32* %ebx.global-to-local, align 4
  %v0_409ccd = load i32, i32* %edx.global-to-local, align 4
  %v1_409ccd = load i32, i32* %ecx.global-to-local, align 4
  %v3_409ccd = zext i1 %v7_409ccb to i32
  %v4_409ccd = add i32 %v3_409ccd, %v0_409ccd
  %v5_409ccd = sub i32 %v4_409ccd, %v1_409ccd
  store i32 %v5_409ccd, i32* %edx.global-to-local, align 4
  %v1_409ccf = load i32, i32* inttoptr (i32 4764013 to i32*), align 4
  %v2_409ccf = or i32 %v1_409ccf, %v1_409ccd
  store i32 %v2_409ccf, i32* %ecx.global-to-local, align 4
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 1048576, i32* %eax.global-to-local, align 4
  %v9_409cee = call i32* @OpenJobObjectW(i32 1048576, i1 false, i16* bitcast ([13 x i8]* @global_var_48b6a3.4 to i16*))
  %v10_409cee = ptrtoint i32* %v9_409cee to i32
  store i32 %v10_409cee, i32* %eax.global-to-local, align 4
  store i1 false, i1* %cf.global-to-local, align 1
  %v1_409cf4 = icmp eq i32* %v9_409cee, null
  %v1_409cf7 = icmp eq i1 %v1_409cf4, false
  call void @__pseudo_cond_branch(i1 %v1_409cf7, i32 ptrtoint (i16** @global_var_406dd5.3 to i32))
  %v1_409cfd = udiv i32 %v10_409cee, 256
  %v2_409cfd = trunc i32 %v1_409cfd to i8
  %v3_409cfd = load i8, i8* inttoptr (i32 4764084 to i8*), align 4
  %v4_409cfd = or i8 %v3_409cfd, %v2_409cfd
  %v10_409cfd = zext i8 %v4_409cfd to i32
  %v12_409cfd = mul nuw nsw i32 %v10_409cfd, 256
  %v13_409cfd = and i32 %v10_409cee, -65281
  %v14_409cfd = or i32 %v12_409cfd, %v13_409cfd
  store i32 %v14_409cfd, i32* %eax.global-to-local, align 4
  %v0_409d03 = load i32, i32* inttoptr (i32 4763808 to i32*), align 32
  %v1_409d03 = load i32, i32* %ebx.global-to-local, align 4
  %v2_409d03 = or i32 %v1_409d03, %v0_409d03
  store i32 %v2_409d03, i32* inttoptr (i32 4763808 to i32*), align 32
  %v1_409d09 = load i32, i32* %esi.global-to-local, align 4
  %v4_409d09 = add i32 %v1_409d09, %v1_409d03
  %v25_409d09 = icmp ult i32 %v4_409d09, %v1_409d03
  store i1 %v25_409d09, i1* %cf.global-to-local, align 1
  store i32 %v4_409d09, i32* %ebx.global-to-local, align 4
  store i32 210, i32* inttoptr (i32 4763902 to i32*), align 4
  %v0_409d15 = load i8, i8* inttoptr (i32 4763901 to i8*), align 1
  %v2_409d15 = udiv i32 %v4_409d09, 256
  %v3_409d15 = trunc i32 %v2_409d15 to i8
  %v4_409d15 = add i8 %v3_409d15, %v0_409d15
  store i8 %v4_409d15, i8* inttoptr (i32 4763901 to i8*), align 1
  %v0_409d1b = load i32, i32* %ebx.global-to-local, align 4
  %v1_409d1b = add i32 %v0_409d1b, -28
  store i32 %v1_409d1b, i32* %ebx.global-to-local, align 4
  store i32 59, i32* %edx.global-to-local, align 4
  %v0_409d26 = load i32, i32* %edi.global-to-local, align 4
  %v4_409d26 = mul i32 %v0_409d26, 2
  %v25_409d26 = icmp ult i32 %v4_409d26, %v0_409d26
  store i1 %v25_409d26, i1* %cf.global-to-local, align 1
  store i32 %v4_409d26, i32* %edi.global-to-local, align 4
  %v0_409d28 = load i32, i32* %eax.global-to-local, align 4
  %v1_409d28 = trunc i32 %v0_409d28 to i8
  %v2_409d28 = load i8, i8* inttoptr (i32 4763799 to i8*), align 1
  %v4_409d28 = zext i1 %v25_409d26 to i8
  %v5_409d28 = add i8 %v1_409d28, %v2_409d28
  %v6_409d28 = add i8 %v5_409d28, %v4_409d28
  %v24_409d28 = icmp ule i8 %v6_409d28, %v1_409d28
  %v25_409d28 = icmp ult i8 %v5_409d28, %v1_409d28
  %v26_409d28 = select i1 %v25_409d26, i1 %v24_409d28, i1 %v25_409d28
  %v27_409d28 = zext i8 %v6_409d28 to i32
  %v29_409d28 = and i32 %v0_409d28, -256
  %v30_409d28 = or i32 %v27_409d28, %v29_409d28
  store i32 %v30_409d28, i32* %eax.global-to-local, align 4
  %v3_409d2e = zext i1 %v26_409d28 to i32
  %v4_409d2e = mul i32 %v1_409d1b, 2
  %v5_409d2e = or i32 %v3_409d2e, %v4_409d2e
  %v24_409d2e = icmp ule i32 %v5_409d2e, %v1_409d1b
  %v25_409d2e = icmp ult i32 %v4_409d2e, %v1_409d1b
  %v26_409d2e = select i1 %v26_409d28, i1 %v24_409d2e, i1 %v25_409d2e
  %v4_409d30 = select i1 %v26_409d2e, i32 -10, i32 -11
  store i32 %v4_409d30, i32* %edx.global-to-local, align 4
  store i32 32, i32* %ecx.global-to-local, align 4
  %v1_409d3b = add i32 %v5_409d2e, 59
  %v5_409d3b = icmp ugt i32 %v5_409d2e, -60
  store i1 %v5_409d3b, i1* %cf.global-to-local, align 1
  store i32 %v1_409d3b, i32* %ebx.global-to-local, align 4
  %v0_409d3e = load i8, i8* inttoptr (i32 4763788 to i8*), align 4
  %v3_409d3e = add i8 %v0_409d3e, -32
  store i8 %v3_409d3e, i8* inttoptr (i32 4763788 to i8*), align 4
  %v0_409d44 = load i32, i32* %eax.global-to-local, align 4
  %v1_409d44 = load i32, i32* inttoptr (i32 4763653 to i32*), align 4
  %v2_409d44 = sub i32 %v0_409d44, %v1_409d44
  store i32 %v2_409d44, i32* %eax.global-to-local, align 4
  %v0_409d4a = load i32, i32* %edx.global-to-local, align 4
  %v1_409d4a = load i32, i32* inttoptr (i32 4763789 to i32*), align 4
  %v2_409d4a = sub i32 %v0_409d4a, %v1_409d4a
  store i32 %v2_409d4a, i32* %edx.global-to-local, align 4
  %v2_409d50 = add i32 %v2_409d44, 81
  %v15_409d50 = and i32 %v2_409d50, 255
  %v17_409d50 = and i32 %v2_409d44, -256
  %v18_409d50 = or i32 %v15_409d50, %v17_409d50
  store i32 %v18_409d50, i32* %eax.global-to-local, align 4
  %v0_409d52 = load i32, i32* %ebx.global-to-local, align 4
  %v1_409d52 = load i32, i32* inttoptr (i32 4764126 to i32*), align 4
  %v2_409d52 = sub i32 %v0_409d52, %v1_409d52
  store i32 %v2_409d52, i32* %ebx.global-to-local, align 4
  %v0_409d58 = load i32, i32* %edi.global-to-local, align 4
  %v1_409d58 = add i32 %v0_409d58, 108
  %v5_409d58 = icmp ult i32 %v0_409d58, -108
  store i1 %v5_409d58, i1* %cf.global-to-local, align 1
  store i32 %v1_409d58, i32* %edi.global-to-local, align 4
  call void @__pseudo_call(i32 -1)
  %v0_409d63 = load i32, i32* %edx.global-to-local, align 4
  %v1_409d63 = load i32, i32* inttoptr (i32 4763827 to i32*), align 4
  %v2_409d63 = load i1, i1* %cf.global-to-local, align 1
  %v3_409d63 = zext i1 %v2_409d63 to i32
  %v4_409d63 = add i32 %v1_409d63, %v0_409d63
  %v5_409d63 = add i32 %v4_409d63, %v3_409d63
  store i32 %v5_409d63, i32* %edx.global-to-local, align 4
  %v0_409d69 = load i32, i32* inttoptr (i32 4763786 to i32*), align 4
  %v1_409d69 = load i32, i32* %esi.global-to-local, align 4
  %v2_409d69 = add i32 %v1_409d69, %v0_409d69
  %v7_409d69 = icmp ult i32 %v2_409d69, %v0_409d69
  store i32 %v2_409d69, i32* inttoptr (i32 4763786 to i32*), align 4
  %v0_409d6f = load i32, i32* inttoptr (i32 4763899 to i32*), align 4
  %v1_409d6f = load i32, i32* %ebx.global-to-local, align 4
  %v3_409d6f = zext i1 %v7_409d69 to i32
  %v4_409d6f = sub i32 %v0_409d6f, %v1_409d6f
  %v5_409d6f = add i32 %v4_409d6f, %v3_409d6f
  store i32 %v5_409d6f, i32* inttoptr (i32 4763899 to i32*), align 4
  %v0_409d75 = load i32, i32* %edx.global-to-local, align 4
  %v3_409d75 = load i32, i32* %ecx.global-to-local, align 4
  %v4_409d75 = and i32 %v3_409d75, 65280
  %v1_409d7527 = sub i32 %v0_409d75, %v4_409d75
  %v24_409d75 = and i32 %v1_409d7527, 65280
  %v25_409d75 = and i32 %v0_409d75, -65281
  %v26_409d75 = or i32 %v24_409d75, %v25_409d75
  %v0_409d77 = load i32, i32* %eax.global-to-local, align 4
  %v1_409d77 = load i32, i32* %ebx.global-to-local, align 4
  %v2_409d77 = add i32 %v1_409d77, %v0_409d77
  store i32 %v2_409d77, i32* %eax.global-to-local, align 4
  %v1_409d79 = xor i32 %v26_409d75, 41
  store i32 %v1_409d79, i32* %edx.global-to-local, align 4
  %v1_409d7c = load i32, i32* %esi.global-to-local, align 4
  %v2_409d7c = add i32 %v1_409d7c, %v1_409d77
  %v7_409d7c = icmp ult i32 %v2_409d7c, %v1_409d77
  store i32 %v2_409d7c, i32* %ebx.global-to-local, align 4
  %v0_409d7e = load i32, i32* inttoptr (i32 4763854 to i32*), align 4
  %v3_409d7e = zext i1 %v7_409d7c to i32
  %v4_409d7e = sub i32 %v0_409d7e, %v1_409d7c
  %v5_409d7e = add i32 %v4_409d7e, %v3_409d7e
  store i32 %v5_409d7e, i32* inttoptr (i32 4763854 to i32*), align 4
  %v0_409d84 = load i32, i32* %edi.global-to-local, align 4
  %v1_409d84 = load i32, i32* inttoptr (i32 4764030 to i32*), align 4
  %v2_409d84 = sub i32 %v0_409d84, %v1_409d84
  %v7_409d84 = icmp ult i32 %v0_409d84, %v1_409d84
  store i1 %v7_409d84, i1* %cf.global-to-local, align 1
  store i32 %v2_409d84, i32* %edi.global-to-local, align 4
  %v0_409d8a = load i8, i8* inttoptr (i32 4763770 to i8*), align 2
  %v1_409d8a = add i8 %v0_409d8a, 96
  store i8 %v1_409d8a, i8* inttoptr (i32 4763770 to i8*), align 2
  %v0_409d91 = load i32, i32* %ecx.global-to-local, align 4
  %v1_409d91 = load i32, i32* inttoptr (i32 4764033 to i32*), align 4
  %v2_409d91 = sub i32 %v0_409d91, %v1_409d91
  %v7_409d91 = icmp ult i32 %v0_409d91, %v1_409d91
  store i1 %v7_409d91, i1* %cf.global-to-local, align 1
  store i32 %v2_409d91, i32* %ecx.global-to-local, align 4
  %v0_409d97 = load i32, i32* %eax.global-to-local, align 4
  %v1_409d97 = inttoptr i32 %v0_409d97 to i8*
  %v2_409d97 = load i8, i8* %v1_409d97, align 1
  %v4_409d97 = trunc i32 %v0_409d97 to i8
  %v5_409d97 = add i8 %v4_409d97, %v2_409d97
  %v10_409d97 = icmp ult i8 %v5_409d97, %v2_409d97
  store i1 %v10_409d97, i1* %cf.global-to-local, align 1
  store i8 %v5_409d97, i8* %v1_409d97, align 1
  %v0_409d99 = load i32, i32* %eax.global-to-local, align 4
  %v1_409d99 = inttoptr i32 %v0_409d99 to i8*
  %v2_409d99 = load i8, i8* %v1_409d99, align 1
  %v4_409d99 = trunc i32 %v0_409d99 to i8
  %v5_409d99 = add i8 %v4_409d99, %v2_409d99
  %v10_409d99 = icmp ult i8 %v5_409d99, %v2_409d99
  store i1 %v10_409d99, i1* %cf.global-to-local, align 1
  store i8 %v5_409d99, i8* %v1_409d99, align 1
  %v0_409d9b = load i32, i32* %eax.global-to-local, align 4
  %v1_409d9b = inttoptr i32 %v0_409d9b to i8*
  %v2_409d9b = load i8, i8* %v1_409d9b, align 1
  %v4_409d9b = trunc i32 %v0_409d9b to i8
  %v5_409d9b = add i8 %v4_409d9b, %v2_409d9b
  %v10_409d9b = icmp ult i8 %v5_409d9b, %v2_409d9b
  store i1 %v10_409d9b, i1* %cf.global-to-local, align 1
  store i8 %v5_409d9b, i8* %v1_409d9b, align 1
  %v0_409d9d = load i32, i32* %eax.global-to-local, align 4
  %v1_409d9d = inttoptr i32 %v0_409d9d to i8*
  %v2_409d9d = load i8, i8* %v1_409d9d, align 1
  %v4_409d9d = trunc i32 %v0_409d9d to i8
  %v5_409d9d = add i8 %v4_409d9d, %v2_409d9d
  %v10_409d9d = icmp ult i8 %v5_409d9d, %v2_409d9d
  store i1 %v10_409d9d, i1* %cf.global-to-local, align 1
  store i8 %v5_409d9d, i8* %v1_409d9d, align 1
  %v0_409d9f = load i32, i32* %eax.global-to-local, align 4
  %v1_409d9f = inttoptr i32 %v0_409d9f to i8*
  %v2_409d9f = load i8, i8* %v1_409d9f, align 1
  %v4_409d9f = trunc i32 %v0_409d9f to i8
  %v5_409d9f = add i8 %v4_409d9f, %v2_409d9f
  %v10_409d9f = icmp ult i8 %v5_409d9f, %v2_409d9f
  store i1 %v10_409d9f, i1* %cf.global-to-local, align 1
  store i8 %v5_409d9f, i8* %v1_409d9f, align 1
  %v0_409da1 = load i32, i32* %edx.global-to-local, align 4
  %v1_409da1 = add i32 %v0_409da1, 1
  %v2_409da1 = inttoptr i32 %v1_409da1 to i8*
  %v3_409da1 = load i8, i8* %v2_409da1, align 1
  %v4_409da1 = load i32, i32* %ebx.global-to-local, align 4
  %v5_409da1 = udiv i32 %v4_409da1, 256
  %v6_409da1 = trunc i32 %v5_409da1 to i8
  %v7_409da1 = add i8 %v6_409da1, %v3_409da1
  %v12_409da1 = icmp ult i8 %v7_409da1, %v3_409da1
  store i1 %v12_409da1, i1* %cf.global-to-local, align 1
  store i8 %v7_409da1, i8* %v2_409da1, align 1
  %v0_409da7 = load i32, i32* %edx.global-to-local, align 4
  %v1_409da7 = load i32, i32* inttoptr (i32 4764028 to i32*), align 4
  %v2_409da7 = load i1, i1* %cf.global-to-local, align 1
  %v3_409da7 = zext i1 %v2_409da7 to i32
  %v4_409da7 = add i32 %v1_409da7, %v0_409da7
  %v5_409da7 = add i32 %v4_409da7, %v3_409da7
  store i32 %v5_409da7, i32* %edx.global-to-local, align 4
  %v0_409dad = load i32, i32* %esi.global-to-local, align 4
  %v1_409dad = or i32 %v0_409dad, -71
  store i32 %v1_409dad, i32* %esi.global-to-local, align 4
  %v0_409db0 = load i32, i32* inttoptr (i32 4763950 to i32*), align 4
  %v1_409db0 = xor i32 %v0_409db0, 64
  store i32 %v1_409db0, i32* inttoptr (i32 4763950 to i32*), align 4
  store i32 1, i32* %ecx.global-to-local, align 4
  %v1_409dbc = load i32, i32* inttoptr (i32 4764086 to i32*), align 4
  %v4_409dbc = add i32 %v1_409dbc, 1
  %v16_409dbc = icmp eq i32 %v4_409dbc, 0
  store i1 %v16_409dbc, i1* %cf.global-to-local, align 1
  store i32 %v4_409dbc, i32* %ecx.global-to-local, align 4
  %v0_409dc2 = load i8, i8* inttoptr (i32 4763842 to i8*), align 2
  %v1_409dc2 = add i8 %v0_409dc2, -66
  store i8 %v1_409dc2, i8* inttoptr (i32 4763842 to i8*), align 2
  %v0_409dc9 = load i32, i32* %edi.global-to-local, align 4
  %v2_409dc9 = sub i32 %v0_409dc9, %v4_409dbc
  %v7_409dc9 = icmp ult i32 %v0_409dc9, %v4_409dbc
  store i32 %v2_409dc9, i32* %edi.global-to-local, align 4
  %v0_409dcb = load i32, i32* %esi.global-to-local, align 4
  %v1_409dcb = load i32, i32* %ebx.global-to-local, align 4
  %v3_409dcb = zext i1 %v7_409dc9 to i32
  %v4_409dcb = add i32 %v3_409dcb, %v0_409dcb
  %v5_409dcb = sub i32 %v4_409dcb, %v1_409dcb
  store i32 %v5_409dcb, i32* %esi.global-to-local, align 4
  %v0_409dcd = load i32, i32* inttoptr (i32 4763929 to i32*), align 4
  %v1_409dcd = or i32 %v0_409dcd, 180
  store i32 %v1_409dcd, i32* inttoptr (i32 4763929 to i32*), align 4
  store i32 0, i32* %edi.global-to-local, align 4
  %v0_409dd9 = load i32, i32* %edx.global-to-local, align 4
  %v1_409dd9 = trunc i32 %v0_409dd9 to i8
  %v4_409dd9 = add i32 %v0_409dd9, 167
  %v23_409dd9 = icmp ugt i8 %v1_409dd9, 88
  store i1 %v23_409dd9, i1* %cf.global-to-local, align 1
  %v25_409dd9 = and i32 %v4_409dd9, 255
  %v27_409dd9 = and i32 %v0_409dd9, -256
  %v28_409dd9 = or i32 %v25_409dd9, %v27_409dd9
  store i32 %v28_409dd9, i32* %edx.global-to-local, align 4
  %v0_409ddc = load i8, i8* inttoptr (i32 4764082 to i8*), align 2
  %v1_409ddc = add i8 %v0_409ddc, 125
  store i8 %v1_409ddc, i8* inttoptr (i32 4764082 to i8*), align 2
  store i32 11, i32* %eax.global-to-local, align 4
  store i1 false, i1* %cf.global-to-local, align 1
  %v6_409df4 = call i1 @IsBadStringPtrA(i8* getelementptr inbounds ([12 x i8], [12 x i8]* @global_var_48b6b4.5, i32 0, i32 0), i32 11)
  %v7_409df4 = sext i1 %v6_409df4 to i32
  store i32 %v7_409df4, i32* %eax.global-to-local, align 4
  store i1 false, i1* %cf.global-to-local, align 1
  %v2_409dfa = icmp eq i1 %v6_409df4, false
  %v1_409dfd = icmp eq i1 %v2_409dfa, false
  call void @__pseudo_cond_branch(i1 %v1_409dfd, i32 ptrtoint (i16** @global_var_406dd5.3 to i32))
  %v0_409e03 = load i32, i32* inttoptr (i32 4764081 to i32*), align 4
  %v1_409e03 = load i32, i32* %ebx.global-to-local, align 4
  %v2_409e03 = add i32 %v1_409e03, %v0_409e03
  %v7_409e03 = icmp ult i32 %v2_409e03, %v0_409e03
  store i32 %v2_409e03, i32* inttoptr (i32 4764081 to i32*), align 4
  %v2_409e09 = zext i1 %v7_409e03 to i32
  store i32 %v2_409e09, i32* %edi.global-to-local, align 4
  %v1_409e0b = or i32 %v2_409e03, 150
  store i32 %v1_409e0b, i32* inttoptr (i32 4764081 to i32*), align 4
  %v1_409e1a = load i32, i32* %ebx.global-to-local, align 4
  %v2_409e1a = add i32 %v1_409e1a, 1
  store i32 %v2_409e1a, i32* %edx.global-to-local, align 4
  %v5_409e1c = sub i32 %v7_409df4, %v1_409e1a
  %v21_409e1c = and i32 %v5_409e1c, 255
  %v24_409e1c = select i1 %v6_409df4, i32 -256, i32 0
  %v25_409e1c = or i32 %v21_409e1c, %v24_409e1c
  store i32 %v25_409e1c, i32* %eax.global-to-local, align 4
  %v0_409e1e = load i32, i32* inttoptr (i32 4763662 to i32*), align 4
  %v1_409e1e = xor i32 %v0_409e1e, 88
  store i32 %v1_409e1e, i32* inttoptr (i32 4763662 to i32*), align 4
  %v0_409e25 = load i32, i32* inttoptr (i32 4763812 to i32*), align 4
  %v1_409e25 = load i32, i32* %edx.global-to-local, align 4
  %v2_409e25 = add i32 %v1_409e25, %v0_409e25
  store i32 %v2_409e25, i32* inttoptr (i32 4763812 to i32*), align 4
  %v0_409e2b = load i32, i32* inttoptr (i32 4763852 to i32*), align 4
  %v2_409e2b = add i32 %v1_409e25, %v0_409e2b
  store i32 %v2_409e2b, i32* inttoptr (i32 4763852 to i32*), align 4
  store i32 163, i32* inttoptr (i32 4763698 to i32*), align 4
  %v0_409e3b = load i32, i32* inttoptr (i32 4763965 to i32*), align 4
  %v1_409e3b = load i32, i32* %esi.global-to-local, align 4
  %v2_409e3b = or i32 %v1_409e3b, %v0_409e3b
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v2_409e3b, i32* inttoptr (i32 4763965 to i32*), align 4
  %v0_409e41 = load i8, i8* inttoptr (i32 4763833 to i8*), align 1
  %v1_409e41 = load i32, i32* %eax.global-to-local, align 4
  %v2_409e41 = udiv i32 %v1_409e41, 256
  %v3_409e41 = trunc i32 %v2_409e41 to i8
  %v4_409e41 = add i8 %v3_409e41, %v0_409e41
  store i8 %v4_409e41, i8* inttoptr (i32 4763833 to i8*), align 1
  %v0_409e47 = load i32, i32* %ecx.global-to-local, align 4
  %v1_409e47 = and i32 %v0_409e47, -256
  %v2_409e49 = load i32, i32* %eax.global-to-local, align 4
  %v3_409e49 = trunc i32 %v2_409e49 to i8
  %v4_409e49 = add i8 %v3_409e49, 1
  %v9_409e49 = icmp eq i8 %v4_409e49, 0
  %v19_409e49 = zext i8 %v4_409e49 to i32
  %v22_409e49 = or i32 %v19_409e49, %v1_409e47
  store i32 %v22_409e49, i32* %ecx.global-to-local, align 4
  %v2_409e4b = zext i1 %v9_409e49 to i32
  %v3_409e4b = add i32 %v2_409e49, -54
  %v4_409e4b = add i32 %v3_409e4b, %v2_409e4b
  %v22_409e4b = icmp ule i32 %v4_409e4b, %v2_409e49
  %v23_409e4b = icmp ugt i32 %v2_409e49, 53
  %v24_409e4b = select i1 %v9_409e49, i1 %v22_409e4b, i1 %v23_409e4b
  %v1_409e4e = load i32, i32* %edi.global-to-local, align 4
  %v3_409e4e = zext i1 %v24_409e4b to i32
  %v4_409e4e = add i32 %v4_409e4b, %v1_409e4e
  %v5_409e4e = add i32 %v4_409e4e, %v3_409e4e
  store i32 %v5_409e4e, i32* %eax.global-to-local, align 4
  %v1_409e50 = load i32, i32* inttoptr (i32 4763786 to i32*), align 4
  %v2_409e50 = sub i32 %v22_409e49, %v1_409e50
  %v3_409e5628 = mul i32 %v5_409e4e, 256
  %tmp105 = and i32 %v3_409e5628, 65280
  %v14_409e56 = xor i32 %tmp105, %v2_409e50
  store i32 %v14_409e56, i32* %ecx.global-to-local, align 4
  %v0_409e58 = load i32, i32* %ebx.global-to-local, align 4
  %v1_409e58 = load i32, i32* inttoptr (i32 4763914 to i32*), align 4
  %v2_409e58 = or i32 %v1_409e58, %v0_409e58
  store i32 %v2_409e58, i32* %ebx.global-to-local, align 4
  %v1_409e5e = load i32, i32* inttoptr (i32 4764013 to i32*), align 4
  %v2_409e5e = or i32 %v1_409e5e, %v5_409e4e
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v2_409e5e, i32* %eax.global-to-local, align 4
  store i32 191, i32* inttoptr (i32 4763969 to i32*), align 4
  call void @__pseudo_call(i32 4234870)
  %v0_409e76 = load i32, i32* %eax.global-to-local, align 4
  %v1_409e76 = add i32 %v0_409e76, -102
  store i32 %v1_409e76, i32* %eax.global-to-local, align 4
  %v0_409e79 = load i32, i32* %edx.global-to-local, align 4
  %v2_409e79 = xor i32 %v0_409e79, %v1_409e76
  store i32 %v2_409e79, i32* %edx.global-to-local, align 4
  %v0_409e7b = load i32, i32* %esi.global-to-local, align 4
  %v1_409e7b = load i32, i32* %ecx.global-to-local, align 4
  %v2_409e7b = add i32 %v1_409e7b, %v0_409e7b
  store i32 %v2_409e7b, i32* %esi.global-to-local, align 4
  %v1_409e7d = load i32, i32* inttoptr (i32 4763855 to i32*), align 4
  %v2_409e7d = or i32 %v1_409e7d, %v1_409e7b
  store i32 %v2_409e7d, i32* %ecx.global-to-local, align 4
  %v0_409e83 = load i32, i32* %edi.global-to-local, align 4
  %v2_409e83 = add i32 %v0_409e83, %v2_409e7d
  store i32 %v2_409e83, i32* %edi.global-to-local, align 4
  %v0_409e85 = load i32, i32* inttoptr (i32 4764106 to i32*), align 4
  %v2_409e85 = add i32 %v0_409e85, %v2_409e83
  store i32 %v2_409e85, i32* inttoptr (i32 4764106 to i32*), align 4
  %v1_409e8b = xor i32 %v2_409e83, 116
  store i32 %v1_409e8b, i32* %edi.global-to-local, align 4
  %v0_409e8e = load i32, i32* inttoptr (i32 4763988 to i32*), align 4
  %v3_409e8e = add i32 %v0_409e8e, -112
  %v11_409e8e = icmp ult i32 %v0_409e8e, 112
  store i32 %v3_409e8e, i32* inttoptr (i32 4763988 to i32*), align 4
  %v0_409e95 = load i32, i32* inttoptr (i32 4764099 to i32*), align 4
  %v3_409e95 = zext i1 %v11_409e8e to i32
  %v4_409e95 = add i32 %v1_409e8b, %v0_409e95
  %v5_409e95 = add i32 %v4_409e95, %v3_409e95
  %v24_409e95 = icmp ule i32 %v5_409e95, %v0_409e95
  %v25_409e95 = icmp ult i32 %v4_409e95, %v0_409e95
  %v26_409e95 = select i1 %v11_409e8e, i1 %v24_409e95, i1 %v25_409e95
  store i32 %v5_409e95, i32* inttoptr (i32 4764099 to i32*), align 4
  %v0_409e9b = load i32, i32* %ecx.global-to-local, align 4
  %v1_409e9b = load i32, i32* inttoptr (i32 4763664 to i32*), align 16
  %v3_409e9b = zext i1 %v26_409e95 to i32
  %v4_409e9b = add i32 %v1_409e9b, %v0_409e9b
  %v5_409e9b = add i32 %v3_409e9b, %v4_409e9b
  %v24_409e9b = icmp ule i32 %v5_409e9b, %v0_409e9b
  %v25_409e9b = icmp ult i32 %v4_409e9b, %v0_409e9b
  %v26_409e9b = select i1 %v26_409e95, i1 %v24_409e9b, i1 %v25_409e9b
  store i32 %v5_409e9b, i32* %ecx.global-to-local, align 4
  %v0_409ea1 = load i32, i32* %eax.global-to-local, align 4
  %v1_409ea1 = trunc i32 %v0_409ea1 to i8
  %v3_409ea1 = udiv i32 %v5_409e9b, 256
  %v4_409ea1 = trunc i32 %v3_409ea1 to i8
  %v6_409ea1 = zext i1 %v26_409e9b to i8
  %v7_409ea1 = add i8 %v4_409ea1, %v1_409ea1
  %v8_409ea1 = add i8 %v7_409ea1, %v6_409ea1
  %v26_409ea1 = icmp ule i8 %v8_409ea1, %v1_409ea1
  %v27_409ea1 = icmp ult i8 %v7_409ea1, %v1_409ea1
  %v28_409ea1 = select i1 %v26_409e9b, i1 %v26_409ea1, i1 %v27_409ea1
  store i1 %v28_409ea1, i1* %cf.global-to-local, align 1
  %v29_409ea1 = zext i8 %v8_409ea1 to i32
  %v31_409ea1 = and i32 %v0_409ea1, -256
  %v32_409ea1 = or i32 %v29_409ea1, %v31_409ea1
  store i32 %v32_409ea1, i32* %eax.global-to-local, align 4
  %v0_409ea3 = load i8, i8* inttoptr (i32 4764012 to i8*), align 4
  %v1_409ea3 = add i8 %v0_409ea3, -23
  store i8 %v1_409ea3, i8* inttoptr (i32 4764012 to i8*), align 4
  %v1_409eaa = or i32 %v29_409ea1, -112
  %v0_409ead = load i32, i32* %ecx.global-to-local, align 4
  %v3_409ead = add i32 %v0_409ead, -118
  store i32 %v3_409ead, i32* %ecx.global-to-local, align 4
  %v1_409eb0 = add nsw i32 %v1_409eaa, 10
  %v5_409eb0 = icmp ult i32 %v1_409eaa, -10
  store i1 %v5_409eb0, i1* %cf.global-to-local, align 1
  %v12_409eb0 = trunc i32 %v1_409eb0 to i8
  store i32 %v1_409eb0, i32* %eax.global-to-local, align 4
  %v1_409eb3 = inttoptr i32 %v1_409eb0 to i8*
  %v2_409eb3 = load i8, i8* %v1_409eb3, align 1
  %v5_409eb3 = add i8 %v2_409eb3, %v12_409eb0
  store i8 %v5_409eb3, i8* %v1_409eb3, align 1
  store i32 30, i32* inttoptr (i32 4763799 to i32*), align 4
  %v0_409ebf = load i32, i32* %ebx.global-to-local, align 4
  %v1_409ebf30 = add i32 %v0_409ebf, 44544
  %v19_409ebf = and i32 %v1_409ebf30, 65280
  %v20_409ebf = and i32 %v0_409ebf, -65281
  %v21_409ebf = or i32 %v19_409ebf, %v20_409ebf
  store i32 %v21_409ebf, i32* %ebx.global-to-local, align 4
  %v0_409ec2 = load i32, i32* %esi.global-to-local, align 4
  %v1_409ec2 = xor i32 %v0_409ec2, 49
  store i32 %v1_409ec2, i32* %esi.global-to-local, align 4
  %v0_409ec5 = load i32, i32* inttoptr (i32 4764001 to i32*), align 4
  %v1_409ec5 = load i32, i32* %eax.global-to-local, align 4
  %v4_409ec5 = add i32 %v1_409ec5, %v0_409ec5
  store i32 %v4_409ec5, i32* inttoptr (i32 4764001 to i32*), align 4
  %v0_409ecb = load i32, i32* inttoptr (i32 4763985 to i32*), align 4
  %v1_409ecb = and i32 %v0_409ecb, 118
  store i32 %v1_409ecb, i32* inttoptr (i32 4763985 to i32*), align 4
  %v0_409ed2 = load i32, i32* inttoptr (i32 4763662 to i32*), align 4
  %v1_409ed2 = load i32, i32* %esi.global-to-local, align 4
  %v2_409ed2 = xor i32 %v1_409ed2, %v0_409ed2
  store i32 %v2_409ed2, i32* inttoptr (i32 4763662 to i32*), align 4
  %v0_409ed8 = load i32, i32* %ebx.global-to-local, align 4
  %v3_409ed8 = add i32 %v0_409ed8, 17
  %v0_409edb = load i32, i32* %eax.global-to-local, align 4
  %v2_409edb = mul i32 %v0_409edb, 2
  store i32 %v2_409edb, i32* %eax.global-to-local, align 4
  %v0_409edd = load i32, i32* %edi.global-to-local, align 4
  %v2_409edd = add i32 %v0_409edd, %v2_409edb
  store i32 %v2_409edd, i32* %edi.global-to-local, align 4
  %v1_409edf = and i32 %v3_409ed8, 45
  store i32 %v1_409edf, i32* %ebx.global-to-local, align 4
  %v0_409ee2 = load i32, i32* inttoptr (i32 4763851 to i32*), align 4
  %v1_409ee2 = load i32, i32* %esi.global-to-local, align 4
  %v2_409ee2 = xor i32 %v1_409ee2, %v0_409ee2
  store i32 %v2_409ee2, i32* inttoptr (i32 4763851 to i32*), align 4
  %v1_409eed = load i32, i32* %eax.global-to-local, align 4
  %v2_409eed = add i32 %v1_409eed, 1
  %v7_409eed = icmp eq i32 %v2_409eed, 0
  store i32 %v2_409eed, i32* %edx.global-to-local, align 4
  %v0_409eef = load i32, i32* inttoptr (i32 4763807 to i32*), align 4
  %v2_409eef = zext i1 %v7_409eed to i32
  %v3_409eef = add i32 %v0_409eef, 110
  %v4_409eef = add i32 %v3_409eef, %v2_409eef
  %v21_409eef = icmp ule i32 %v4_409eef, %v0_409eef
  %v22_409eef = icmp ugt i32 %v0_409eef, -111
  %v23_409eef = select i1 %v7_409eed, i1 %v21_409eef, i1 %v22_409eef
  store i32 %v4_409eef, i32* inttoptr (i32 4763807 to i32*), align 4
  %v0_409ef6 = load i32, i32* %ebx.global-to-local, align 4
  %v1_409ef6 = load i32, i32* inttoptr (i32 4764063 to i32*), align 4
  %v3_409ef6 = zext i1 %v23_409eef to i32
  %v4_409ef6 = add i32 %v1_409ef6, %v0_409ef6
  %v5_409ef6 = add i32 %v3_409ef6, %v4_409ef6
  %v24_409ef6 = icmp ule i32 %v5_409ef6, %v0_409ef6
  %v25_409ef6 = icmp ult i32 %v4_409ef6, %v0_409ef6
  %v26_409ef6 = select i1 %v23_409eef, i1 %v24_409ef6, i1 %v25_409ef6
  store i1 %v26_409ef6, i1* %cf.global-to-local, align 1
  store i32 %v5_409ef6, i32* %ebx.global-to-local, align 4
  %v0_409efc = load i32, i32* %edx.global-to-local, align 4
  %v1_409efc = udiv i32 %v0_409efc, 256
  %v2_409efc = trunc i32 %v1_409efc to i8
  %v3_409efc = load i8, i8* inttoptr (i32 4763701 to i8*), align 1
  %v4_409efc = sub i8 %v2_409efc, %v3_409efc
  %v19_409efc = zext i8 %v4_409efc to i32
  %v21_409efc = mul nuw nsw i32 %v19_409efc, 256
  %v22_409efc = and i32 %v0_409efc, -65281
  %v23_409efc = or i32 %v21_409efc, %v22_409efc
  %v1_409f02 = load i32, i32* %edi.global-to-local, align 4
  %v2_409f02 = sub i32 %v23_409efc, %v1_409f02
  store i32 %v2_409f02, i32* %edx.global-to-local, align 4
  %v0_409f04 = load i32, i32* inttoptr (i32 4763753 to i32*), align 4
  %v2_409f04 = xor i32 %v0_409f04, %v5_409ef6
  store i32 %v2_409f04, i32* inttoptr (i32 4763753 to i32*), align 4
  %v0_409f0a = load i32, i32* inttoptr (i32 4763801 to i32*), align 4
  %v1_409f0a = and i32 %v0_409f0a, 159
  store i32 %v1_409f0a, i32* inttoptr (i32 4763801 to i32*), align 4
  %v0_409f14 = load i32, i32* %ebx.global-to-local, align 4
  %v1_409f14 = load i32, i32* inttoptr (i32 4763929 to i32*), align 4
  %v4_409f14 = add i32 %v1_409f14, %v0_409f14
  store i32 %v4_409f14, i32* %ebx.global-to-local, align 4
  store i1 false, i1* %cf.global-to-local, align 1
  %v8_409f2c = call i1 @SetEnvironmentVariableW(i16* bitcast ([13 x i8]* @global_var_48b685.2 to i16*), i16* bitcast ([17 x i8]* @global_var_48b692.1 to i16*))
  %v9_409f2c = sext i1 %v8_409f2c to i32
  store i32 %v9_409f2c, i32* %eax.global-to-local, align 4
  %v0_409f32 = load i32, i32* %ecx.global-to-local, align 4
  %v1_409f32 = and i32 %v0_409f32, -65281
  %v20_409f34 = or i32 %v1_409f32, 61440
  store i32 %v20_409f34, i32* %ecx.global-to-local, align 4
  %v0_409f37 = load i32, i32* inttoptr (i32 4764076 to i32*), align 4
  %v1_409f37 = or i32 %v0_409f37, 166
  store i32 %v1_409f37, i32* inttoptr (i32 4764076 to i32*), align 4
  %v0_409f41 = load i32, i32* %edi.global-to-local, align 4
  %v1_409f41 = load i32, i32* inttoptr (i32 4764096 to i32*), align 64
  %v4_409f41 = add i32 %v1_409f41, %v0_409f41
  store i32 %v4_409f41, i32* %edi.global-to-local, align 4
  %v0_409f47 = load i32, i32* %esi.global-to-local, align 4
  %v1_409f47 = load i32, i32* inttoptr (i32 4764103 to i32*), align 4
  %v2_409f47 = or i32 %v1_409f47, %v0_409f47
  store i32 %v2_409f47, i32* %esi.global-to-local, align 4
  %v0_409f4d = load i32, i32* %ecx.global-to-local, align 4
  %v2_409f4d = xor i32 %v0_409f4d, %v4_409f41
  store i32 %v2_409f4d, i32* %ecx.global-to-local, align 4
  %v0_409f4f = load i32, i32* inttoptr (i32 4764015 to i32*), align 4
  %v2_409f4f = sub i32 %v0_409f4f, %v4_409f41
  store i32 %v2_409f4f, i32* inttoptr (i32 4764015 to i32*), align 4
  %v0_409f55 = load i32, i32* %esi.global-to-local, align 4
  %v1_409f55 = add i32 %v0_409f55, -15
  %v5_409f55 = icmp ult i32 %v0_409f55, 15
  store i32 %v1_409f55, i32* %esi.global-to-local, align 4
  %v0_409f58 = load i32, i32* inttoptr (i32 4763883 to i32*), align 4
  %v2_409f58 = zext i1 %v5_409f55 to i32
  %v3_409f58 = add i32 %v0_409f58, -11
  %v4_409f58 = add i32 %v3_409f58, %v2_409f58
  store i32 %v4_409f58, i32* inttoptr (i32 4763883 to i32*), align 4
  %v0_409f5f = load i32, i32* %edi.global-to-local, align 4
  %v1_409f5f = add i32 %v0_409f5f, 52
  %v5_409f5f = icmp ult i32 %v0_409f5f, -52
  store i32 %v1_409f5f, i32* %edi.global-to-local, align 4
  %v0_409f62 = load i32, i32* %ebx.global-to-local, align 4
  %v1_409f62 = load i32, i32* %esi.global-to-local, align 4
  %v3_409f62 = zext i1 %v5_409f5f to i32
  %v4_409f62 = add i32 %v3_409f62, %v0_409f62
  %v5_409f62 = sub i32 %v4_409f62, %v1_409f62
  store i32 %v5_409f62, i32* %ebx.global-to-local, align 4
  %v0_409f64 = load i32, i32* inttoptr (i32 4763660 to i32*), align 4
  %v2_409f64 = xor i32 %v0_409f64, %v1_409f62
  store i32 %v2_409f64, i32* inttoptr (i32 4763660 to i32*), align 4
  %v0_409f6a = load i32, i32* inttoptr (i32 4763927 to i32*), align 4
  %v3_409f6a = add i32 %v0_409f6a, 158
  %v22_409f6a = icmp ugt i32 %v0_409f6a, -159
  store i1 %v22_409f6a, i1* %cf.global-to-local, align 1
  store i32 %v3_409f6a, i32* inttoptr (i32 4763927 to i32*), align 4
  call void @__pseudo_call(i32 4235132)
  %v0_409f7c = load i32, i32* %ebx.global-to-local, align 4
  %v1_409f7f = trunc i32 %v0_409f7c to i8
  %v2_409f7f = load i32, i32* %ecx.global-to-local, align 4
  %v3_409f7f = udiv i32 %v2_409f7f, 256
  %v4_409f7f = trunc i32 %v3_409f7f to i8
  %v7_409f7f = add i8 %v4_409f7f, %v1_409f7f
  %v27_409f7f = icmp ult i8 %v7_409f7f, %v1_409f7f
  %v29_409f7f = zext i8 %v7_409f7f to i32
  %v31_409f7f = and i32 %v0_409f7c, -57856
  %v32_409f7f = or i32 %v29_409f7f, %v31_409f7f
  store i32 %v32_409f7f, i32* %ebx.global-to-local, align 4
  %v0_409f81 = load i32, i32* inttoptr (i32 4764095 to i32*), align 4
  %v1_409f81 = load i32, i32* %esi.global-to-local, align 4
  %v3_409f81 = zext i1 %v27_409f7f to i32
  %v4_409f81 = sub i32 %v0_409f81, %v1_409f81
  %v5_409f81 = add i32 %v3_409f81, %v4_409f81
  %v16_409f81 = sub i32 %v4_409f81, %v3_409f81
  %v17_409f81 = icmp ult i32 %v0_409f81, %v16_409f81
  %v18_409f81 = icmp ne i32 %v1_409f81, -1
  %v19_409f81 = or i1 %v18_409f81, %v17_409f81
  %v20_409f81 = icmp ult i32 %v0_409f81, %v1_409f81
  %v21_409f81 = select i1 %v27_409f7f, i1 %v19_409f81, i1 %v20_409f81
  store i32 %v5_409f81, i32* inttoptr (i32 4764095 to i32*), align 4
  %v1_409f87 = load i32, i32* inttoptr (i32 4763841 to i32*), align 4
  %v3_409f87 = zext i1 %v21_409f81 to i32
  %v4_409f87 = add i32 %v1_409f87, %v9_409f2c
  %v5_409f87 = add i32 %v4_409f87, %v3_409f87
  store i32 %v5_409f87, i32* %eax.global-to-local, align 4
  %v0_409f8d = load i32, i32* %edi.global-to-local, align 4
  %v1_409f8d = load i32, i32* inttoptr (i32 4763717 to i32*), align 4
  %v2_409f8d = sub i32 %v0_409f8d, %v1_409f8d
  %v7_409f8d = icmp ult i32 %v0_409f8d, %v1_409f8d
  store i32 %v2_409f8d, i32* %edi.global-to-local, align 4
  %v1_409f93 = load i32, i32* inttoptr (i32 4764042 to i32*), align 4
  %v3_409f93 = zext i1 %v7_409f8d to i32
  %v4_409f93 = add i32 %v3_409f93, %v1_409f93
  %v5_409f93 = add i32 %v4_409f93, %v5_409f87
  store i32 %v5_409f93, i32* %eax.global-to-local, align 4
  %v0_409f99 = load i32, i32* %ecx.global-to-local, align 4
  %v2_409f99 = mul i32 %v0_409f99, 2
  store i32 %v2_409f99, i32* %ecx.global-to-local, align 4
  %v0_409f9b = load i32, i32* inttoptr (i32 4763787 to i32*), align 4
  %v2_409f9b = xor i32 %v0_409f9b, %v2_409f99
  store i32 %v2_409f9b, i32* inttoptr (i32 4763787 to i32*), align 4
  store i32 19066, i32* %edx.global-to-local, align 4
  %v0_409fac = load i32, i32* inttoptr (i32 4763784 to i32*), align 8
  %v4_409fac = add i32 %v0_409fac, 195
  store i32 %v4_409fac, i32* inttoptr (i32 4763784 to i32*), align 8
  %v0_409fb6 = load i32, i32* %edi.global-to-local, align 4
  %v1_409fb6 = load i32, i32* %eax.global-to-local, align 4
  %v2_409fb6 = xor i32 %v1_409fb6, %v0_409fb6
  store i32 %v2_409fb6, i32* %edi.global-to-local, align 4
  %v0_409fb8 = load i32, i32* %edx.global-to-local, align 4
  %v1_409fb8 = load i32, i32* inttoptr (i32 4763714 to i32*), align 4
  %v4_409fb8 = add i32 %v1_409fb8, %v0_409fb8
  store i32 %v4_409fb8, i32* %edx.global-to-local, align 4
  %v0_409fbe = load i32, i32* inttoptr (i32 4764143 to i32*), align 4
  %v2_409fbe = add i32 %v0_409fbe, %v2_409fb6
  store i32 %v2_409fbe, i32* inttoptr (i32 4764143 to i32*), align 4
  %v0_409fc4 = load i32, i32* %edi.global-to-local, align 4
  %v1_409fc4 = xor i32 %v0_409fc4, -25
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v1_409fc4, i32* %edi.global-to-local, align 4
  %v0_409fc7 = load i32, i32* %eax.global-to-local, align 4
  %v1_409fc7 = inttoptr i32 %v0_409fc7 to i8*
  %v2_409fc7 = load i8, i8* %v1_409fc7, align 1
  %v4_409fc7 = trunc i32 %v0_409fc7 to i8
  %v5_409fc7 = add i8 %v4_409fc7, %v2_409fc7
  %v10_409fc7 = icmp ult i8 %v5_409fc7, %v2_409fc7
  store i1 %v10_409fc7, i1* %cf.global-to-local, align 1
  store i8 %v5_409fc7, i8* %v1_409fc7, align 1
  %v0_409fc9 = load i32, i32* %ecx.global-to-local, align 4
  %v1_409fc9 = inttoptr i32 %v0_409fc9 to i8*
  %v2_409fc9 = load i8, i8* %v1_409fc9, align 1
  %v3_409fc9 = load i32, i32* %edx.global-to-local, align 4
  %v4_409fc9 = udiv i32 %v3_409fc9, 256
  %v5_409fc9 = trunc i32 %v4_409fc9 to i8
  %v6_409fc9 = add i8 %v5_409fc9, %v2_409fc9
  store i8 %v6_409fc9, i8* %v1_409fc9, align 1
  %v5_409fcb = load i32, i32* %ebx.global-to-local, align 4
  %v0_409fce = load i32, i32* %eax.global-to-local, align 4
  %v2_409fce = add i32 %v0_409fce, 183
  %v16_409fce = and i32 %v2_409fce, 255
  %v18_409fce = and i32 %v0_409fce, -256
  %v19_409fce = or i32 %v16_409fce, %v18_409fce
  %v1_409fd0 = add i32 %v19_409fce, -1
  store i32 %v1_409fd0, i32* %eax.global-to-local, align 4
  %v4_409fd1 = add i32 %v1_409fd0, %v5_409fcb
  %v19_409fd1 = and i32 %v4_409fd1, 255
  %v21_409fd1 = and i32 %v5_409fcb, -65536
  %v22_409fd1 = or i32 %v19_409fd1, %v21_409fd1
  store i32 %v22_409fd1, i32* %ebx.global-to-local, align 4
  %v0_409fd3 = load i32, i32* inttoptr (i32 4763688 to i32*), align 8
  %v1_409fd3 = or i32 %v0_409fd3, 225
  store i32 %v1_409fd3, i32* inttoptr (i32 4763688 to i32*), align 8
  store i32 51, i32* %ecx.global-to-local, align 4
  %v0_409fe5 = load i32, i32* %edi.global-to-local, align 4
  %v3_409fe5 = add i32 %v0_409fe5, 46
  %v12_409fe5 = icmp ult i32 %v0_409fe5, -46
  store i1 %v12_409fe5, i1* %cf.global-to-local, align 1
  store i32 %v3_409fe5, i32* %edi.global-to-local, align 4
  %v0_409fe8 = load i8, i8* inttoptr (i32 4763764 to i8*), align 4
  %v1_409fe8 = add i8 %v0_409fe8, -66
  %v5_409fe8 = icmp ult i8 %v0_409fe8, 66
  store i1 %v5_409fe8, i1* %cf.global-to-local, align 1
  store i8 %v1_409fe8, i8* inttoptr (i32 4763764 to i8*), align 4
  store i32 1, i32* %edx.global-to-local, align 4
  %v1_409ff4 = load i32, i32* inttoptr (i32 4764065 to i32*), align 4
  %v3_409ff4 = zext i1 %v5_409fe8 to i32
  %v4_409ff4 = add i32 %v1_409ff4, 1
  %v5_409ff4 = add i32 %v3_409ff4, %v4_409ff4
  %v24_409ff4 = icmp ult i32 %v5_409ff4, 2
  %v25_409ff4 = icmp eq i32 %v4_409ff4, 0
  %v26_409ff4 = select i1 %v5_409fe8, i1 %v24_409ff4, i1 %v25_409ff4
  store i1 %v26_409ff4, i1* %cf.global-to-local, align 1
  store i32 %v5_409ff4, i32* %edx.global-to-local, align 4
  %v0_409ffa = load i8, i8* inttoptr (i32 4763971 to i8*), align 1
  %v1_409ffa = load i32, i32* %ecx.global-to-local, align 4
  %v2_409ffa = udiv i32 %v1_409ffa, 256
  %v3_409ffa = trunc i32 %v2_409ffa to i8
  %v4_409ffa = and i8 %v3_409ffa, %v0_409ffa
  store i8 %v4_409ffa, i8* inttoptr (i32 4763971 to i8*), align 1
  %v0_40a000 = load i32, i32* %ebx.global-to-local, align 4
  %v1_40a000 = add i32 %v0_40a000, 23
  %v5_40a000 = icmp ugt i32 %v0_40a000, -24
  %v2_40a003 = zext i1 %v5_40a000 to i32
  %v3_40a003 = add i32 %v0_40a000, 132
  %v4_40a003 = add i32 %v3_40a003, %v2_40a003
  %v21_40a003 = icmp ule i32 %v4_40a003, %v1_40a000
  %v22_40a003 = icmp ugt i32 %v1_40a000, -110
  %v23_40a003 = select i1 %v5_40a000, i1 %v21_40a003, i1 %v22_40a003
  %v0_40a006 = load i32, i32* %edi.global-to-local, align 4
  %v1_40a006 = load i32, i32* %edx.global-to-local, align 4
  %v3_40a006 = zext i1 %v23_40a003 to i32
  %v4_40a006 = sub i32 %v0_40a006, %v1_40a006
  %v5_40a006 = add i32 %v3_40a006, %v4_40a006
  store i32 %v5_40a006, i32* %edi.global-to-local, align 4
  %v2_40a008 = add i32 %v5_40a006, %v4_40a003
  %v7_40a008 = icmp ult i32 %v2_40a008, %v4_40a003
  store i32 %v2_40a008, i32* %ebx.global-to-local, align 4
  %v2_40a00a = zext i1 %v7_40a008 to i32
  store i32 %v2_40a00a, i32* %ecx.global-to-local, align 4
  %v0_40a00c = load i32, i32* inttoptr (i32 4763812 to i32*), align 4
  %v2_40a00c = add i32 %v0_40a00c, %v1_40a006
  %v7_40a00c = icmp ult i32 %v2_40a00c, %v0_40a00c
  store i1 %v7_40a00c, i1* %cf.global-to-local, align 1
  store i32 %v2_40a00c, i32* inttoptr (i32 4763812 to i32*), align 4
  %v1_40a012 = zext i1 %v7_40a008 to i8
  %v2_40a012 = load i8, i8* inttoptr (i32 4764071 to i8*), align 1
  %v4_40a012 = zext i1 %v7_40a00c to i8
  %v5_40a012 = add i8 %v1_40a012, %v2_40a012
  %v6_40a012 = add i8 %v5_40a012, %v4_40a012
  %v24_40a012 = icmp ule i8 %v6_40a012, %v1_40a012
  %v25_40a012 = icmp ult i8 %v5_40a012, %v1_40a012
  %v26_40a012 = select i1 %v7_40a00c, i1 %v24_40a012, i1 %v25_40a012
  store i1 %v26_40a012, i1* %cf.global-to-local, align 1
  %v27_40a012 = zext i8 %v6_40a012 to i32
  store i32 %v27_40a012, i32* %ecx.global-to-local, align 4
  %v0_40a018 = load i8, i8* inttoptr (i32 4763788 to i8*), align 4
  %v1_40a018 = add i8 %v0_40a018, -55
  store i8 %v1_40a018, i8* inttoptr (i32 4763788 to i8*), align 4
  %v0_40a01f = load i32, i32* inttoptr (i32 4763852 to i32*), align 4
  %v1_40a01f = or i32 %v0_40a01f, 34
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v1_40a01f, i32* inttoptr (i32 4763852 to i32*), align 4
  %v0_40a026 = load i32, i32* %edx.global-to-local, align 4
  %v1_40a026 = udiv i32 %v0_40a026, 256
  %v2_40a026 = trunc i32 %v1_40a026 to i8
  %v3_40a026 = load i8, i8* inttoptr (i32 4763913 to i8*), align 1
  %v6_40a026 = add i8 %v2_40a026, %v3_40a026
  %v28_40a026 = zext i8 %v6_40a026 to i32
  %v30_40a026 = mul nuw nsw i32 %v28_40a026, 256
  %v31_40a026 = and i32 %v0_40a026, -65281
  %v32_40a026 = or i32 %v30_40a026, %v31_40a026
  %v0_40a02c = load i32, i32* %eax.global-to-local, align 4
  %v2_40a02c = icmp ugt i32 %v0_40a02c, -113
  %v12_40a02f = icmp ult i32 %v32_40a026, 65
  %v13_40a02f = or i1 %v2_40a02c, %v12_40a02f
  %v2_40a032 = zext i1 %v13_40a02f to i32
  %v4_40a02f = select i1 %v2_40a02c, i32 -181, i32 -182
  %v3_40a032 = add i32 %v4_40a02f, %v32_40a026
  %v4_40a032 = add i32 %v3_40a032, %v2_40a032
  store i32 %v4_40a032, i32* %edx.global-to-local, align 4
  store i32 11, i32* %eax.global-to-local, align 4
  store i1 false, i1* %cf.global-to-local, align 1
  %v6_40a046 = call i1 @IsBadStringPtrA(i8* getelementptr inbounds ([12 x i8], [12 x i8]* @global_var_48b6b4.5, i32 0, i32 0), i32 11)
  %v7_40a046 = sext i1 %v6_40a046 to i32
  store i32 %v7_40a046, i32* %eax.global-to-local, align 4
  store i1 false, i1* %cf.global-to-local, align 1
  %v1_40a04c = icmp eq i1 %v6_40a046, false
  %v1_40a04e = icmp eq i1 %v1_40a04c, false
  call void @__pseudo_cond_branch(i1 %v1_40a04e, i32 ptrtoint (i16** @global_var_406dd5.3 to i32))
  %v0_40a054 = load i32, i32* inttoptr (i32 4764028 to i32*), align 4
  %v1_40a054 = load i32, i32* %esi.global-to-local, align 4
  %v2_40a054 = add i32 %v1_40a054, %v0_40a054
  store i32 %v2_40a054, i32* inttoptr (i32 4764028 to i32*), align 4
  store i32 108, i32* %ecx.global-to-local, align 4
  %v0_40a062 = load i32, i32* inttoptr (i32 4763717 to i32*), align 4
  %v4_40a062 = sub i32 %v0_40a062, %v7_40a046
  %v20_40a062 = icmp ult i32 %v0_40a062, %v7_40a046
  store i32 %v4_40a062, i32* inttoptr (i32 4763717 to i32*), align 4
  %v0_40a068 = load i32, i32* inttoptr (i32 4763975 to i32*), align 4
  %v1_40a068 = load i32, i32* %esi.global-to-local, align 4
  %v3_40a068 = zext i1 %v20_40a062 to i32
  %v4_40a068 = add i32 %v3_40a068, %v0_40a068
  %v5_40a068 = add i32 %v4_40a068, %v1_40a068
  store i32 %v5_40a068, i32* inttoptr (i32 4763975 to i32*), align 4
  %v0_40a06e = load i32, i32* %ebx.global-to-local, align 4
  %v1_40a06e = udiv i32 %v0_40a06e, 256
  %v2_40a06e = trunc i32 %v1_40a06e to i8
  %v4_40a06e = icmp ugt i8 %v2_40a06e, -81
  %v3_40a06e = mul nuw i32 %v1_40a06e, 256
  %v13_40a06e = add i32 %v3_40a06e, 20480
  %v15_40a06e = and i32 %v13_40a06e, 65280
  %v16_40a06e = and i32 %v0_40a06e, -65281
  %v17_40a06e = or i32 %v15_40a06e, %v16_40a06e
  store i32 %v17_40a06e, i32* %ebx.global-to-local, align 4
  %v0_40a071 = load i32, i32* inttoptr (i32 4764050 to i32*), align 4
  %v3_40a071 = zext i1 %v4_40a06e to i32
  %v7_40a046.neg = zext i1 %v6_40a046 to i32
  %v4_40a071 = add i32 %v0_40a071, %v7_40a046.neg
  %v5_40a071 = add i32 %v4_40a071, %v3_40a071
  store i32 %v5_40a071, i32* inttoptr (i32 4764050 to i32*), align 4
  %v0_40a077 = load i32, i32* %esi.global-to-local, align 4
  %v2_40a077 = sub i32 %v0_40a077, %v7_40a046
  %v1_40a079 = load i32, i32* %edi.global-to-local, align 4
  %v2_40a079 = sub i32 %v2_40a077, %v1_40a079
  %v7_40a079 = icmp ult i32 %v2_40a077, %v1_40a079
  store i32 %v2_40a079, i32* %esi.global-to-local, align 4
  %v0_40a07b = load i32, i32* inttoptr (i32 4764053 to i32*), align 4
  %v3_40a07b = zext i1 %v7_40a079 to i32
  %v4_40a07b = sub i32 %v0_40a07b, %v1_40a079
  %v5_40a07b = add i32 %v4_40a07b, %v3_40a07b
  %v16_40a07b = sub i32 %v4_40a07b, %v3_40a07b
  %v17_40a07b = icmp ult i32 %v0_40a07b, %v16_40a07b
  %v18_40a07b = icmp ne i32 %v1_40a079, -1
  %v19_40a07b = or i1 %v18_40a07b, %v17_40a07b
  %v20_40a07b = icmp ult i32 %v0_40a07b, %v1_40a079
  %v21_40a07b = select i1 %v7_40a079, i1 %v19_40a07b, i1 %v20_40a07b
  store i32 %v5_40a07b, i32* inttoptr (i32 4764053 to i32*), align 4
  %v0_40a081 = load i32, i32* %ebx.global-to-local, align 4
  %v1_40a081 = load i32, i32* inttoptr (i32 4764009 to i32*), align 4
  %v3_40a081 = zext i1 %v21_40a07b to i32
  %v4_40a081 = add i32 %v1_40a081, %v0_40a081
  %v5_40a081 = add i32 %v3_40a081, %v4_40a081
  %v24_40a081 = icmp ule i32 %v5_40a081, %v0_40a081
  %v25_40a081 = icmp ult i32 %v4_40a081, %v0_40a081
  %v26_40a081 = select i1 %v21_40a07b, i1 %v24_40a081, i1 %v25_40a081
  store i32 %v5_40a081, i32* %ebx.global-to-local, align 4
  %v0_40a087 = load i32, i32* inttoptr (i32 4763703 to i32*), align 4
  %v2_40a087 = zext i1 %v26_40a081 to i32
  %v3_40a087 = add i32 %v0_40a087, -194
  %v4_40a087 = add i32 %v3_40a087, %v2_40a087
  store i32 %v4_40a087, i32* inttoptr (i32 4763703 to i32*), align 4
  %v1_40a091 = load i32, i32* inttoptr (i32 4763975 to i32*), align 4
  %v2_40a091 = sub i32 %v7_40a046, %v1_40a091
  %v7_40a091 = icmp ult i32 %v7_40a046, %v1_40a091
  store i32 %v2_40a091, i32* %eax.global-to-local, align 4
  store i32 1, i32* %edx.global-to-local, align 4
  %v1_40a09c = load i32, i32* inttoptr (i32 4763989 to i32*), align 4
  %v3_40a09c = zext i1 %v7_40a091 to i32
  %v4_40a09c = add i32 %v1_40a09c, 1
  %v5_40a09c = add i32 %v4_40a09c, %v3_40a09c
  %v24_40a09c = icmp ult i32 %v5_40a09c, 2
  %v25_40a09c = icmp eq i32 %v4_40a09c, 0
  %v26_40a09c = select i1 %v7_40a091, i1 %v24_40a09c, i1 %v25_40a09c
  store i32 %v5_40a09c, i32* %edx.global-to-local, align 4
  %v0_40a0a2 = load i32, i32* %esi.global-to-local, align 4
  %v1_40a0a2 = load i32, i32* inttoptr (i32 4763846 to i32*), align 4
  %v3_40a0a2 = zext i1 %v26_40a09c to i32
  %v4_40a0a2 = add i32 %v1_40a0a2, %v0_40a0a2
  %v5_40a0a2 = add i32 %v4_40a0a2, %v3_40a0a2
  store i32 %v5_40a0a2, i32* %esi.global-to-local, align 4
  %v1_40a0a8 = load i32, i32* inttoptr (i32 4764156 to i32*), align 4
  %v2_40a0a8 = sub i32 %v5_40a0a2, %v1_40a0a8
  store i32 %v2_40a0a8, i32* %esi.global-to-local, align 4
  %v0_40a0ae = load i32, i32* inttoptr (i32 4763897 to i32*), align 4
  %v1_40a0ae = load i32, i32* %edi.global-to-local, align 4
  %v2_40a0ae = sub i32 %v0_40a0ae, %v1_40a0ae
  %v7_40a0ae = icmp ult i32 %v0_40a0ae, %v1_40a0ae
  store i32 %v2_40a0ae, i32* inttoptr (i32 4763897 to i32*), align 4
  %v0_40a0b4 = load i32, i32* %ecx.global-to-local, align 4
  %v1_40a0b4 = load i32, i32* inttoptr (i32 4764136 to i32*), align 8
  %v3_40a0b4 = zext i1 %v7_40a0ae to i32
  %v4_40a0b4 = add i32 %v3_40a0b4, %v0_40a0b4
  %v5_40a0b4 = add i32 %v4_40a0b4, %v1_40a0b4
  store i32 %v5_40a0b4, i32* %ecx.global-to-local, align 4
  %v0_40a0ba = load i32, i32* %edx.global-to-local, align 4
  %v1_40a0bd = add i32 %v0_40a0ba, -19
  store i32 %v1_40a0bd, i32* %edx.global-to-local, align 4
  %v0_40a0c0 = load i32, i32* inttoptr (i32 4764021 to i32*), align 4
  %v2_40a0c0 = sub i32 %v0_40a0c0, %v1_40a0bd
  %v7_40a0c0 = icmp ult i32 %v0_40a0c0, %v1_40a0bd
  store i1 %v7_40a0c0, i1* %cf.global-to-local, align 1
  store i32 %v2_40a0c0, i32* inttoptr (i32 4764021 to i32*), align 4
  call void @__pseudo_call(i32 4235470)
  %v0_40a0ce = load i32, i32* inttoptr (i32 4763695 to i32*), align 4
  %v1_40a0ce = load i1, i1* %cf.global-to-local, align 1
  %v2_40a0ce = zext i1 %v1_40a0ce to i32
  %v3_40a0ce = add i32 %v0_40a0ce, -157
  %v4_40a0ce = add i32 %v3_40a0ce, %v2_40a0ce
  %v12_40a0ce = icmp ult i32 %v0_40a0ce, 157
  %v13_40a0ce = or i1 %v12_40a0ce, %v1_40a0ce
  store i1 %v13_40a0ce, i1* %cf.global-to-local, align 1
  store i32 %v4_40a0ce, i32* inttoptr (i32 4763695 to i32*), align 4
  %v0_40a0d8 = load i8, i8* inttoptr (i32 4763943 to i8*), align 1
  %v1_40a0d8 = add i8 %v0_40a0d8, 98
  store i8 %v1_40a0d8, i8* inttoptr (i32 4763943 to i8*), align 1
  %v0_40a0df = load i32, i32* inttoptr (i32 4763917 to i32*), align 4
  %v1_40a0df = load i32, i32* %eax.global-to-local, align 4
  %v2_40a0df = sub i32 %v0_40a0df, %v1_40a0df
  store i32 %v2_40a0df, i32* inttoptr (i32 4763917 to i32*), align 4
  %v0_40a0e5 = load i32, i32* %edx.global-to-local, align 4
  %v11_40a0e5 = xor i32 %v0_40a0e5, 156
  store i32 %v11_40a0e5, i32* %edx.global-to-local, align 4
  %v0_40a0e8 = load i32, i32* inttoptr (i32 4764039 to i32*), align 4
  %v1_40a0e8 = load i32, i32* %eax.global-to-local, align 4
  %v2_40a0e8 = xor i32 %v1_40a0e8, %v0_40a0e8
  store i32 %v2_40a0e8, i32* inttoptr (i32 4764039 to i32*), align 4
  %v0_40a0ee = load i32, i32* inttoptr (i32 4764062 to i32*), align 4
  %v1_40a0ee = load i32, i32* %esi.global-to-local, align 4
  %v4_40a0ee = add i32 %v1_40a0ee, %v0_40a0ee
  %v25_40a0ee = icmp ult i32 %v4_40a0ee, %v0_40a0ee
  store i32 %v4_40a0ee, i32* inttoptr (i32 4764062 to i32*), align 4
  %v0_40a0f4 = load i32, i32* %ecx.global-to-local, align 4
  %v2_40a0f4 = zext i1 %v25_40a0ee to i32
  %v3_40a0f4 = add i32 %v0_40a0f4, 9
  %v4_40a0f4 = add i32 %v3_40a0f4, %v2_40a0f4
  %v12_40a0f4 = icmp ult i32 %v0_40a0f4, -9
  %v13_40a0f4 = or i1 %v25_40a0ee, %v12_40a0f4
  store i1 %v13_40a0f4, i1* %cf.global-to-local, align 1
  store i32 %v4_40a0f4, i32* %ecx.global-to-local, align 4
  %v0_40a0f7 = load i8, i8* inttoptr (i32 4763689 to i8*), align 1
  %v1_40a0f7 = load i32, i32* %edx.global-to-local, align 4
  %v2_40a0f7 = udiv i32 %v1_40a0f7, 256
  %v3_40a0f7 = trunc i32 %v2_40a0f7 to i8
  %v5_40a0f7 = zext i1 %v13_40a0f4 to i8
  %v6_40a0f7 = add i8 %v5_40a0f7, %v0_40a0f7
  %v7_40a0f7 = sub i8 %v6_40a0f7, %v3_40a0f7
  store i8 %v7_40a0f7, i8* inttoptr (i32 4763689 to i8*), align 1
  store i32 0, i32* %esi.global-to-local, align 4
  %v0_40a105 = load i32, i32* %eax.global-to-local, align 4
  %v1_40a105 = load i32, i32* %edx.global-to-local, align 4
  %v4_40a105 = add i32 %v1_40a105, %v0_40a105
  store i32 %v4_40a105, i32* %eax.global-to-local, align 4
  %v0_40a107 = load i32, i32* inttoptr (i32 4764069 to i32*), align 4
  %v2_40a107 = xor i32 %v0_40a107, %v4_40a105
  store i32 %v2_40a107, i32* inttoptr (i32 4764069 to i32*), align 4
  %v1_40a10d = load i32, i32* %ecx.global-to-local, align 4
  %v2_40a10d = add i32 %v1_40a10d, %v4_40a105
  store i32 %v2_40a10d, i32* %eax.global-to-local, align 4
  %v0_40a10f = load i32, i32* %edx.global-to-local, align 4
  %v1_40a10f = add i32 %v0_40a10f, -108
  %v5_40a10f = icmp ugt i32 %v0_40a10f, 107
  store i32 %v1_40a10f, i32* %edx.global-to-local, align 4
  %v0_40a112 = load i32, i32* %edi.global-to-local, align 4
  %v2_40a112 = zext i1 %v5_40a10f to i32
  %v3_40a112 = add i32 %v0_40a112, 118
  %v4_40a112 = add i32 %v3_40a112, %v2_40a112
  store i32 %v4_40a112, i32* %edi.global-to-local, align 4
  %v0_40a115 = load i32, i32* %ebx.global-to-local, align 4
  %v1_40a115 = load i32, i32* inttoptr (i32 4763659 to i32*), align 4
  %v2_40a115 = sub i32 %v0_40a115, %v1_40a115
  %v1_40a11b = xor i32 %v2_40a10d, 44
  %v4_40a11b = trunc i32 %v1_40a11b to i8
  store i32 %v1_40a11b, i32* %eax.global-to-local, align 4
  %v2_40a11e = mul i32 %v2_40a115, 2
  %v7_40a11e = icmp ult i32 %v2_40a11e, %v2_40a115
  store i1 %v7_40a11e, i1* %cf.global-to-local, align 1
  store i32 %v2_40a11e, i32* %ebx.global-to-local, align 4
  %v1_40a120 = inttoptr i32 %v1_40a11b to i8*
  %v2_40a120 = load i8, i8* %v1_40a120, align 1
  %v5_40a120 = add i8 %v2_40a120, %v4_40a11b
  %v10_40a120 = icmp ult i8 %v5_40a120, %v2_40a120
  store i1 %v10_40a120, i1* %cf.global-to-local, align 1
  store i8 %v5_40a120, i8* %v1_40a120, align 1
  %v0_40a122 = load i32, i32* %eax.global-to-local, align 4
  %v1_40a122 = inttoptr i32 %v0_40a122 to i8*
  %v2_40a122 = load i8, i8* %v1_40a122, align 1
  %v4_40a122 = trunc i32 %v0_40a122 to i8
  %v5_40a122 = add i8 %v4_40a122, %v2_40a122
  %v10_40a122 = icmp ult i8 %v5_40a122, %v2_40a122
  store i1 %v10_40a122, i1* %cf.global-to-local, align 1
  store i8 %v5_40a122, i8* %v1_40a122, align 1
  %v0_40a124 = load i32, i32* %eax.global-to-local, align 4
  %v1_40a124 = inttoptr i32 %v0_40a124 to i8*
  %v2_40a124 = load i8, i8* %v1_40a124, align 1
  %v4_40a124 = trunc i32 %v0_40a124 to i8
  %v5_40a124 = add i8 %v4_40a124, %v2_40a124
  %v10_40a124 = icmp ult i8 %v5_40a124, %v2_40a124
  store i1 %v10_40a124, i1* %cf.global-to-local, align 1
  store i8 %v5_40a124, i8* %v1_40a124, align 1
  %v0_40a126 = load i32, i32* %eax.global-to-local, align 4
  %v1_40a126 = inttoptr i32 %v0_40a126 to i8*
  %v2_40a126 = load i8, i8* %v1_40a126, align 1
  %v4_40a126 = trunc i32 %v0_40a126 to i8
  %v5_40a126 = add i8 %v4_40a126, %v2_40a126
  %v10_40a126 = icmp ult i8 %v5_40a126, %v2_40a126
  store i1 %v10_40a126, i1* %cf.global-to-local, align 1
  store i8 %v5_40a126, i8* %v1_40a126, align 1
  %v0_40a128 = load i32, i32* %eax.global-to-local, align 4
  %v1_40a128 = inttoptr i32 %v0_40a128 to i8*
  %v2_40a128 = load i8, i8* %v1_40a128, align 1
  %v4_40a128 = trunc i32 %v0_40a128 to i8
  %v5_40a128 = add i8 %v4_40a128, %v2_40a128
  %v10_40a128 = icmp ult i8 %v5_40a128, %v2_40a128
  store i1 %v10_40a128, i1* %cf.global-to-local, align 1
  store i8 %v5_40a128, i8* %v1_40a128, align 1
  %v0_40a12a = load i32, i32* %eax.global-to-local, align 4
  %v1_40a12a = inttoptr i32 %v0_40a12a to i8*
  %v2_40a12a = load i8, i8* %v1_40a12a, align 1
  %v4_40a12a = trunc i32 %v0_40a12a to i8
  %v5_40a12a = add i8 %v4_40a12a, %v2_40a12a
  %v10_40a12a = icmp ult i8 %v5_40a12a, %v2_40a12a
  store i1 %v10_40a12a, i1* %cf.global-to-local, align 1
  store i8 %v5_40a12a, i8* %v1_40a12a, align 1
  %v0_40a12c = load i32, i32* %eax.global-to-local, align 4
  %v1_40a12c = inttoptr i32 %v0_40a12c to i8*
  %v2_40a12c = load i8, i8* %v1_40a12c, align 1
  %v4_40a12c = trunc i32 %v0_40a12c to i8
  %v5_40a12c = add i8 %v4_40a12c, %v2_40a12c
  %v10_40a12c = icmp ult i8 %v5_40a12c, %v2_40a12c
  store i1 %v10_40a12c, i1* %cf.global-to-local, align 1
  store i8 %v5_40a12c, i8* %v1_40a12c, align 1
  %v0_40a12e = load i32, i32* inttoptr (i32 4763945 to i32*), align 4
  %v1_40a12e = load i1, i1* %cf.global-to-local, align 1
  %v2_40a12e = zext i1 %v1_40a12e to i32
  %v3_40a12e = add i32 %v0_40a12e, -93
  %v4_40a12e = add i32 %v3_40a12e, %v2_40a12e
  store i32 %v4_40a12e, i32* inttoptr (i32 4763945 to i32*), align 4
  store i32 128, i32* %ecx.global-to-local, align 4
  %v0_40a13d = load i32, i32* %eax.global-to-local, align 4
  %v1_40a13d = load i32, i32* %edi.global-to-local, align 4
  %v2_40a13d = sub i32 %v0_40a13d, %v1_40a13d
  %v7_40a13d = icmp ult i32 %v0_40a13d, %v1_40a13d
  store i32 %v2_40a13d, i32* %eax.global-to-local, align 4
  %v2_40a13f = zext i1 %v7_40a13d to i32
  %v3_40a13f = add i32 %v1_40a13d, -116
  %v4_40a13f = add i32 %v3_40a13f, %v2_40a13f
  store i32 %v4_40a13f, i32* %edi.global-to-local, align 4
  store i32 106, i32* %edx.global-to-local, align 4
  %v0_40a14a = load i32, i32* inttoptr (i32 4764147 to i32*), align 4
  %v3_40a14a = add i32 %v0_40a14a, 103
  store i32 %v3_40a14a, i32* inttoptr (i32 4764147 to i32*), align 4
  %v0_40a151 = load i32, i32* %ecx.global-to-local, align 4
  %v1_40a151 = load i32, i32* inttoptr (i32 4763923 to i32*), align 4
  %v2_40a151 = or i32 %v1_40a151, %v0_40a151
  store i32 %v2_40a151, i32* %ecx.global-to-local, align 4
  %v0_40a157 = load i32, i32* %eax.global-to-local, align 4
  %v1_40a157 = load i32, i32* inttoptr (i32 4763710 to i32*), align 4
  %v4_40a157 = add i32 %v1_40a157, %v0_40a157
  store i32 %v4_40a157, i32* %eax.global-to-local, align 4
  %v0_40a15d = load i32, i32* %edi.global-to-local, align 4
  %v1_40a15d = xor i32 %v0_40a15d, -53
  store i32 %v1_40a15d, i32* %edi.global-to-local, align 4
  %v0_40a160 = load i32, i32* %esi.global-to-local, align 4
  %v3_40a160 = add i32 %v0_40a160, 26
  %v12_40a160 = icmp ult i32 %v0_40a160, -26
  store i32 %v3_40a160, i32* %esi.global-to-local, align 4
  %v1_40a163 = load i32, i32* %ebx.global-to-local, align 4
  %v3_40a163 = zext i1 %v12_40a160 to i32
  %v4_40a163 = add i32 %v1_40a163, %v2_40a151
  %v5_40a163 = add i32 %v4_40a163, %v3_40a163
  %v24_40a163 = icmp ule i32 %v5_40a163, %v2_40a151
  %v25_40a163 = icmp ult i32 %v4_40a163, %v2_40a151
  %v26_40a163 = select i1 %v12_40a160, i1 %v24_40a163, i1 %v25_40a163
  store i1 %v26_40a163, i1* %cf.global-to-local, align 1
  store i32 %v5_40a163, i32* %ecx.global-to-local, align 4
  %v1_40a165 = udiv i32 %v5_40a163, 256
  %v2_40a165 = trunc i32 %v1_40a165 to i8
  %v3_40a165 = load i8, i8* inttoptr (i32 4764062 to i8*), align 2
  %v5_40a165 = zext i1 %v26_40a163 to i8
  %v6_40a165 = add i8 %v2_40a165, %v3_40a165
  %v7_40a165 = add i8 %v6_40a165, %v5_40a165
  %v28_40a165 = zext i8 %v7_40a165 to i32
  %v30_40a165 = mul nuw nsw i32 %v28_40a165, 256
  %v31_40a165 = and i32 %v5_40a163, -65281
  %v32_40a165 = or i32 %v30_40a165, %v31_40a165
  store i32 %v32_40a165, i32* %ecx.global-to-local, align 4
  %v1_40a16b = load i32, i32* inttoptr (i32 4763885 to i32*), align 4
  %v2_40a16b = or i32 %v32_40a165, %v1_40a16b
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v2_40a16b, i32* %ecx.global-to-local, align 4
  store i32 0, i32* %eax.global-to-local, align 4
  %v4_40a179 = call i32* @EncodePointer(i32* null)
  %v5_40a179 = ptrtoint i32* %v4_40a179 to i32
  %tmp107 = bitcast i32* %v4_40a179 to i8*
  store i32 %v5_40a179, i32* %eax.global-to-local, align 4
  store i32 1, i32* %edx.global-to-local, align 4
  %v1_40a184 = load i32, i32* inttoptr (i32 4764070 to i32*), align 4
  %v2_40a184 = load i1, i1* %cf.global-to-local, align 1
  %v3_40a184 = zext i1 %v2_40a184 to i32
  %v4_40a184 = add i32 %v1_40a184, 1
  %v5_40a184 = add i32 %v4_40a184, %v3_40a184
  store i32 %v5_40a184, i32* %edx.global-to-local, align 4
  %v0_40a18a = load i32, i32* %edi.global-to-local, align 4
  %v1_40a18d = or i32 %v0_40a18a, -17
  %v1_40a190 = add nsw i32 %v1_40a18d, 2
  store i32 %v1_40a190, i32* %edi.global-to-local, align 4
  %v0_40a193 = load i32, i32* %esi.global-to-local, align 4
  %v1_40a193 = add i32 %v0_40a193, -113
  store i32 %v1_40a193, i32* %esi.global-to-local, align 4
  store i32 83, i32* inttoptr (i32 4763703 to i32*), align 4
  %v3_40a1a5 = add i32 %v5_40a179, 1
  store i32 %v3_40a1a5, i32* %ecx.global-to-local, align 4
  %v0_40a1a7 = load i32, i32* %ebx.global-to-local, align 4
  %v2_40a1a7 = add i32 %v0_40a1a7, %v3_40a1a5
  %v7_40a1a7 = icmp ult i32 %v2_40a1a7, %v0_40a1a7
  store i32 %v2_40a1a7, i32* %ebx.global-to-local, align 4
  %v0_40a1a9 = load i32, i32* %esi.global-to-local, align 4
  %v1_40a1a9 = load i32, i32* inttoptr (i32 4763690 to i32*), align 4
  %v3_40a1a9 = zext i1 %v7_40a1a7 to i32
  %v4_40a1a9 = add i32 %v1_40a1a9, %v0_40a1a9
  %v5_40a1a9 = add i32 %v4_40a1a9, %v3_40a1a9
  %v24_40a1a9 = icmp ule i32 %v5_40a1a9, %v0_40a1a9
  %v25_40a1a9 = icmp ult i32 %v4_40a1a9, %v0_40a1a9
  %v26_40a1a9 = select i1 %v7_40a1a7, i1 %v24_40a1a9, i1 %v25_40a1a9
  store i32 %v5_40a1a9, i32* %esi.global-to-local, align 4
  %v0_40a1af = load i32, i32* inttoptr (i32 4763949 to i32*), align 4
  %v3_40a1af = select i1 %v26_40a1a9, i32 182, i32 181
  %v4_40a1af = add i32 %v3_40a1af, %v0_40a1af
  store i32 %v4_40a1af, i32* inttoptr (i32 4763949 to i32*), align 4
  %v0_40a1b9 = load i32, i32* inttoptr (i32 4763725 to i32*), align 4
  %v3_40a1b9 = add i32 %v0_40a1b9, %v5_40a179
  store i32 %v3_40a1b9, i32* inttoptr (i32 4763725 to i32*), align 4
  %v0_40a1bf = load i32, i32* inttoptr (i32 4764078 to i32*), align 4
  %v1_40a1bf = load i32, i32* %esi.global-to-local, align 4
  %v2_40a1bf = or i32 %v1_40a1bf, %v0_40a1bf
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v2_40a1bf, i32* inttoptr (i32 4764078 to i32*), align 4
  call void @__pseudo_call(i32 4235725)
  %v0_40a1cd = load i32, i32* %ecx.global-to-local, align 4
  %v1_40a1cd = trunc i32 %v0_40a1cd to i8
  %v2_40a1cd = load i8, i8* inttoptr (i32 4763837 to i8*), align 1
  %v3_40a1cd = load i1, i1* %cf.global-to-local, align 1
  %v4_40a1cd = zext i1 %v3_40a1cd to i8
  %v5_40a1cd = add i8 %v1_40a1cd, %v2_40a1cd
  %v6_40a1cd = add i8 %v4_40a1cd, %v5_40a1cd
  %v24_40a1cd = icmp ule i8 %v6_40a1cd, %v1_40a1cd
  %v25_40a1cd = icmp ult i8 %v5_40a1cd, %v1_40a1cd
  %v26_40a1cd = select i1 %v3_40a1cd, i1 %v24_40a1cd, i1 %v25_40a1cd
  store i1 %v26_40a1cd, i1* %cf.global-to-local, align 1
  %v27_40a1cd = zext i8 %v6_40a1cd to i32
  %v29_40a1cd = and i32 %v0_40a1cd, -256
  %v30_40a1cd = or i32 %v27_40a1cd, %v29_40a1cd
  store i32 %v30_40a1cd, i32* %ecx.global-to-local, align 4
  %v2_40a1d3 = load i8, i8* inttoptr (i32 4763741 to i8*), align 1
  %v4_40a1d3 = zext i1 %v26_40a1cd to i8
  %v5_40a1d3 = add i8 %v2_40a1d3, %v6_40a1cd
  %v6_40a1d3 = add i8 %v4_40a1d3, %v5_40a1d3
  %v24_40a1d3 = icmp ule i8 %v6_40a1d3, %v6_40a1cd
  %v25_40a1d3 = icmp ult i8 %v5_40a1d3, %v6_40a1cd
  %v26_40a1d3 = select i1 %v26_40a1cd, i1 %v24_40a1d3, i1 %v25_40a1d3
  %v27_40a1d3 = zext i8 %v6_40a1d3 to i32
  %v30_40a1d3 = or i32 %v27_40a1d3, %v29_40a1cd
  store i32 %v30_40a1d3, i32* %ecx.global-to-local, align 4
  %v0_40a1d9 = load i32, i32* inttoptr (i32 4763704 to i32*), align 8
  %v2_40a1d9 = zext i1 %v26_40a1d3 to i32
  %v3_40a1d9 = add i32 %v0_40a1d9, -235
  %v4_40a1d9 = add i32 %v3_40a1d9, %v2_40a1d9
  %v12_40a1d9 = icmp ult i32 %v0_40a1d9, 235
  %v13_40a1d9 = or i1 %v12_40a1d9, %v26_40a1d3
  store i1 %v13_40a1d9, i1* %cf.global-to-local, align 1
  store i32 %v4_40a1d9, i32* inttoptr (i32 4763704 to i32*), align 8
  %v0_40a1e3 = load i32, i32* %ebx.global-to-local, align 4
  %v1_40a1e3 = trunc i32 %v0_40a1e3 to i8
  %v2_40a1e3 = load i8, i8* inttoptr (i32 4763691 to i8*), align 1
  %v3_40a1e3 = sub i8 %v1_40a1e3, %v2_40a1e3
  %v8_40a1e3 = icmp ult i8 %v1_40a1e3, %v2_40a1e3
  %v18_40a1e3 = zext i8 %v3_40a1e3 to i32
  %v20_40a1e3 = and i32 %v0_40a1e3, -256
  %v21_40a1e3 = or i32 %v18_40a1e3, %v20_40a1e3
  store i32 %v21_40a1e3, i32* %ebx.global-to-local, align 4
  %v0_40a1e9 = load i32, i32* %edx.global-to-local, align 4
  %v1_40a1e9 = load i32, i32* %ecx.global-to-local, align 4
  %v3_40a1e9 = zext i1 %v8_40a1e3 to i32
  %v4_40a1e9 = sub i32 %v0_40a1e9, %v1_40a1e9
  %v5_40a1e9 = add i32 %v4_40a1e9, %v3_40a1e9
  %v16_40a1e9 = sub i32 %v4_40a1e9, %v3_40a1e9
  %v17_40a1e9 = icmp ult i32 %v0_40a1e9, %v16_40a1e9
  %v18_40a1e9 = icmp ne i32 %v1_40a1e9, -1
  %v19_40a1e9 = or i1 %v18_40a1e9, %v17_40a1e9
  %v20_40a1e9 = icmp ult i32 %v0_40a1e9, %v1_40a1e9
  %v21_40a1e9 = select i1 %v8_40a1e3, i1 %v19_40a1e9, i1 %v20_40a1e9
  store i32 %v5_40a1e9, i32* %edx.global-to-local, align 4
  %v0_40a1eb = load i32, i32* %edi.global-to-local, align 4
  %v2_40a1eb = zext i1 %v21_40a1e9 to i32
  %v3_40a1eb = add i32 %v0_40a1eb, 58
  %v1_40a1ee = add i32 %v1_40a1e9, 49
  %v2_40a1f1 = mul i32 %v1_40a1ee, 2
  %v7_40a1f1 = icmp ult i32 %v2_40a1f1, %v1_40a1ee
  store i32 %v2_40a1f1, i32* %ecx.global-to-local, align 4
  %v3_40a1f3 = zext i1 %v7_40a1f1 to i32
  %v4_40a1eb = sub i32 %v3_40a1eb, %v2_40a1f1
  %v4_40a1f3 = add i32 %v4_40a1eb, %v3_40a1f3
  %v5_40a1f3 = add i32 %v4_40a1f3, %v2_40a1eb
  store i32 %v5_40a1f3, i32* %edi.global-to-local, align 4
  %v0_40a1f5 = load i32, i32* inttoptr (i32 4763692 to i32*), align 4
  %v1_40a1f5 = load i32, i32* %esi.global-to-local, align 4
  %v2_40a1f5 = add i32 %v1_40a1f5, %v0_40a1f5
  store i32 %v2_40a1f5, i32* inttoptr (i32 4763692 to i32*), align 4
  %v0_40a1fb = load i32, i32* inttoptr (i32 4764016 to i32*), align 16
  %v3_40a1fb = or i32 %v0_40a1fb, %v5_40a179
  store i32 %v3_40a1fb, i32* inttoptr (i32 4764016 to i32*), align 16
  %v0_40a201 = load i32, i32* %ecx.global-to-local, align 4
  %v1_40a201 = udiv i32 %v0_40a201, 256
  %v2_40a201 = trunc i32 %v1_40a201 to i8
  %v7_40a201 = icmp ugt i8 %v2_40a201, -79
  %v3_40a201 = mul nuw i32 %v1_40a201, 256
  %v16_40a201 = add i32 %v3_40a201, 19968
  %v18_40a201 = and i32 %v16_40a201, 65280
  %v19_40a201 = and i32 %v0_40a201, -65281
  %v20_40a201 = or i32 %v18_40a201, %v19_40a201
  store i32 %v20_40a201, i32* %ecx.global-to-local, align 4
  %v1_40a204 = load i32, i32* inttoptr (i32 4763844 to i32*), align 4
  %v3_40a204 = zext i1 %v7_40a201 to i32
  %v4_40a204 = add i32 %v3_40a204, %v1_40a204
  %v5_40a204 = add i32 %v4_40a204, %v20_40a201
  %v0_40a20a = load i32, i32* %ebx.global-to-local, align 4
  %v1_40a20a31 = add i32 %v0_40a20a, 2048
  %v18_40a20a = and i32 %v1_40a20a31, 65280
  %v19_40a20a = and i32 %v0_40a20a, -65281
  %v20_40a20a = or i32 %v18_40a20a, %v19_40a20a
  store i32 %v20_40a20a, i32* %ebx.global-to-local, align 4
  %v0_40a20d = load i32, i32* %esi.global-to-local, align 4
  %v1_40a20d = or i32 %v0_40a20d, 1
  store i32 %v1_40a20d, i32* %esi.global-to-local, align 4
  %v1_40a210 = load i32, i32* %edi.global-to-local, align 4
  %v2_40a210 = xor i32 %v1_40a210, %v5_40a204
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v2_40a210, i32* %ecx.global-to-local, align 4
  %v0_40a212 = load i8, i8* inttoptr (i32 4763687 to i8*), align 1
  %v1_40a212 = add i8 %v0_40a212, 108
  store i8 %v1_40a212, i8* inttoptr (i32 4763687 to i8*), align 1
  %v0_40a219 = load i32, i32* %edx.global-to-local, align 4
  %v1_40a219 = load i32, i32* %edi.global-to-local, align 4
  %v2_40a219 = sub i32 %v0_40a219, %v1_40a219
  %v7_40a219 = icmp ult i32 %v0_40a219, %v1_40a219
  store i32 %v2_40a219, i32* %edx.global-to-local, align 4
  %v0_40a21b = load i32, i32* inttoptr (i32 4763889 to i32*), align 4
  %v2_40a21b = zext i1 %v7_40a219 to i32
  %v3_40a21b = add i32 %v0_40a21b, 162
  %v4_40a21b = add i32 %v3_40a21b, %v2_40a21b
  store i32 %v4_40a21b, i32* inttoptr (i32 4763889 to i32*), align 4
  %v0_40a225 = load i32, i32* %esi.global-to-local, align 4
  %v1_40a225 = load i32, i32* inttoptr (i32 4763895 to i32*), align 4
  %v2_40a225 = sub i32 %v0_40a225, %v1_40a225
  %v7_40a225 = icmp ult i32 %v0_40a225, %v1_40a225
  store i1 %v7_40a225, i1* %cf.global-to-local, align 1
  store i32 %v2_40a225, i32* %esi.global-to-local, align 4
  %v3_40a22b = load i8, i8* %tmp107, align 1
  %v6_40a22b = trunc i32 %v5_40a179 to i8
  %factor = mul i8 %v6_40a22b, 7
  %v7_40a237 = add i8 %v3_40a22b, %factor
  store i8 %v7_40a237, i8* %tmp107, align 1
  store i32 139, i32* inttoptr (i32 4763659 to i32*), align 4
  %v0_40a243 = load i32, i32* %edi.global-to-local, align 4
  %v3_40a243 = xor i32 %v0_40a243, %v5_40a179
  store i32 %v3_40a243, i32* %edi.global-to-local, align 4
  %v2_40a245 = add i32 %v5_40a179, -28
  %v6_40a245 = icmp ugt i32* %v4_40a179, inttoptr (i32 27 to i32*)
  store i32 %v2_40a245, i32* %eax.global-to-local, align 4
  %v0_40a248 = load i32, i32* inttoptr (i32 4763965 to i32*), align 4
  %v3_40a248 = select i1 %v6_40a245, i32 35, i32 34
  %v4_40a248 = add i32 %v3_40a248, %v0_40a248
  %v21_40a248 = icmp ule i32 %v4_40a248, %v0_40a248
  %v22_40a248 = icmp ugt i32 %v0_40a248, -35
  %v23_40a248 = select i1 %v6_40a245, i1 %v21_40a248, i1 %v22_40a248
  store i32 %v4_40a248, i32* inttoptr (i32 4763965 to i32*), align 4
  %v0_40a24f = load i32, i32* %edi.global-to-local, align 4
  %v2_40a24f = zext i1 %v23_40a248 to i32
  %v3_40a24f = add i32 %v0_40a24f, 103
  %v4_40a24f = add i32 %v3_40a24f, %v2_40a24f
  %v12_40a24f = icmp ult i32 %v0_40a24f, -103
  %v13_40a24f = or i1 %v12_40a24f, %v23_40a248
  %v7_40a252 = sext i1 %v13_40a24f to i32
  %v8_40a252 = icmp ult i32 %v4_40a24f, %v7_40a252
  %v9_40a252 = icmp ne i32 %v4_40a24f, -1
  %v10_40a252 = or i1 %v9_40a252, %v8_40a252
  %v11_40a252 = and i1 %v13_40a24f, %v10_40a252
  %v2_40a254 = zext i1 %v11_40a252 to i32
  store i32 %v2_40a254, i32* %edi.global-to-local, align 4
  store i32 1, i32* %edx.global-to-local, align 4
  %v1_40a25b = load i32, i32* inttoptr (i32 4763721 to i32*), align 4
  %v4_40a25b = add i32 %v1_40a25b, 1
  %v5_40a25b = add i32 %v4_40a25b, %v2_40a254
  store i32 %v5_40a25b, i32* %edx.global-to-local, align 4
  %v0_40a261 = load i32, i32* %ebx.global-to-local, align 4
  %v1_40a261 = or i32 %v0_40a261, 120
  %v3_40a261 = trunc i32 %v1_40a261 to i8
  store i32 %v1_40a261, i32* %ebx.global-to-local, align 4
  %v0_40a264 = load i32, i32* %eax.global-to-local, align 4
  %v1_40a264 = trunc i32 %v0_40a264 to i8
  %v4_40a264 = add i8 %v1_40a264, %v3_40a261
  %v9_40a264 = icmp ult i8 %v4_40a264, %v1_40a264
  store i1 %v9_40a264, i1* %cf.global-to-local, align 1
  %v19_40a264 = zext i8 %v4_40a264 to i32
  %v21_40a264 = and i32 %v0_40a264, -256
  %v22_40a264 = or i32 %v19_40a264, %v21_40a264
  store i32 %v22_40a264, i32* %eax.global-to-local, align 4
  %v0_40a266 = load i8, i8* inttoptr (i32 4764013 to i8*), align 1
  %v1_40a266 = add i8 %v0_40a266, -58
  store i8 %v1_40a266, i8* inttoptr (i32 4764013 to i8*), align 1
  %v1_40a26d = load i32, i32* %esi.global-to-local, align 4
  %v2_40a26d = xor i32 %v1_40a26d, %v22_40a264
  store i32 %v2_40a26d, i32* %eax.global-to-local, align 4
  %v0_40a26f = load i32, i32* inttoptr (i32 4763726 to i32*), align 4
  %v2_40a26f = or i32 %v0_40a26f, %v2_40a26d
  store i32 %v2_40a26f, i32* inttoptr (i32 4763726 to i32*), align 4
  %v0_40a275 = load i32, i32* inttoptr (i32 4763667 to i32*), align 4
  %v1_40a275 = and i32 %v0_40a275, 121
  store i32 %v1_40a275, i32* inttoptr (i32 4763667 to i32*), align 4
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 1048576, i32* %eax.global-to-local, align 4
  %v9_40a295 = call i32* @OpenJobObjectW(i32 1048576, i1 false, i16* bitcast ([13 x i8]* @global_var_48b6a3.4 to i16*))
  %v10_40a295 = ptrtoint i32* %v9_40a295 to i32
  store i32 %v10_40a295, i32* %eax.global-to-local, align 4
  store i1 false, i1* %cf.global-to-local, align 1
  %v1_40a29b = icmp eq i32* %v9_40a295, null
  %v1_40a29d = icmp eq i1 %v1_40a29b, false
  call void @__pseudo_cond_branch(i1 %v1_40a29d, i32 ptrtoint (i16** @global_var_406dd5.3 to i32))
  %v0_40a2a3 = load i32, i32* inttoptr (i32 4764138 to i32*), align 4
  %v1_40a2a3 = load i1, i1* %cf.global-to-local, align 1
  %v2_40a2a3 = zext i1 %v1_40a2a3 to i32
  %v3_40a2a3 = add i32 %v0_40a2a3, -18
  %v4_40a2a3 = add i32 %v3_40a2a3, %v2_40a2a3
  store i32 %v4_40a2a3, i32* inttoptr (i32 4764138 to i32*), align 4
  %v0_40a2aa = load i32, i32* inttoptr (i32 4764128 to i32*), align 32
  %v1_40a2aa = load i32, i32* %esi.global-to-local, align 4
  %v2_40a2aa = xor i32 %v1_40a2aa, %v0_40a2aa
  store i32 %v2_40a2aa, i32* inttoptr (i32 4764128 to i32*), align 32
  store i32 245, i32* inttoptr (i32 4763786 to i32*), align 4
  %v3_40a2ba = add i32 %v1_40a2aa, 94
  %v22_40a2ba = icmp ugt i32 %v1_40a2aa, -95
  store i1 %v22_40a2ba, i1* %cf.global-to-local, align 1
  store i32 %v3_40a2ba, i32* %esi.global-to-local, align 4
  %v0_40a2bd = load i32, i32* %ebx.global-to-local, align 4
  %v1_40a2bd = trunc i32 %v0_40a2bd to i8
  %v2_40a2bd = load i8, i8* inttoptr (i32 4764010 to i8*), align 2
  %v4_40a2bd = zext i1 %v22_40a2ba to i8
  %v5_40a2bd = add i8 %v2_40a2bd, %v4_40a2bd
  %v6_40a2bd = add i8 %v5_40a2bd, %v1_40a2bd
  %v27_40a2bd = zext i8 %v6_40a2bd to i32
  %v29_40a2bd = and i32 %v0_40a2bd, -256
  %v30_40a2bd = or i32 %v27_40a2bd, %v29_40a2bd
  %v1_40a2c3 = load i32, i32* %edi.global-to-local, align 4
  %v2_40a2c3 = sub i32 %v30_40a2bd, %v1_40a2c3
  store i32 %v2_40a2c3, i32* %ebx.global-to-local, align 4
  %v2_40a2ca = add i32 %v1_40a2aa, 95
  %v7_40a2ca = icmp eq i32 %v2_40a2ca, 0
  store i1 %v7_40a2ca, i1* %cf.global-to-local, align 1
  store i32 %v2_40a2ca, i32* %edx.global-to-local, align 4
  %v0_40a2cc = load i8, i8* inttoptr (i32 4763765 to i8*), align 1
  %v2_40a2cc = udiv i32 %v2_40a2ca, 256
  %v3_40a2cc = trunc i32 %v2_40a2cc to i8
  %v5_40a2cc = zext i1 %v7_40a2ca to i8
  %v6_40a2cc = add i8 %v5_40a2cc, %v3_40a2cc
  %v7_40a2cc = add i8 %v6_40a2cc, %v0_40a2cc
  store i8 %v7_40a2cc, i8* inttoptr (i32 4763765 to i8*), align 1
  %v2_40a2d2 = load i32, i32* %ebx.global-to-local, align 4
  %v3_40a2d232 = mul i32 %v2_40a2d2, 256
  %tmp109 = and i32 %v3_40a2d232, 65280
  %v14_40a2d2 = xor i32 %tmp109, %v10_40a295
  store i32 %v14_40a2d2, i32* %eax.global-to-local, align 4
  %v0_40a2d4 = load i32, i32* inttoptr (i32 4763865 to i32*), align 4
  %v3_40a2d4 = add i32 %v0_40a2d4, 158
  %v22_40a2d4 = icmp ugt i32 %v0_40a2d4, -159
  store i32 %v3_40a2d4, i32* inttoptr (i32 4763865 to i32*), align 4
  %v0_40a2de = load i32, i32* inttoptr (i32 4763782 to i32*), align 4
  %v3_40a2de = select i1 %v22_40a2d4, i32 76, i32 75
  %v4_40a2de = add i32 %v3_40a2de, %v0_40a2de
  %v21_40a2de = icmp ule i32 %v4_40a2de, %v0_40a2de
  %v22_40a2de = icmp ugt i32 %v0_40a2de, -76
  %v23_40a2de = select i1 %v22_40a2d4, i1 %v21_40a2de, i1 %v22_40a2de
  store i32 %v4_40a2de, i32* inttoptr (i32 4763782 to i32*), align 4
  %v0_40a2e5 = load i32, i32* %esi.global-to-local, align 4
  %v1_40a2e5 = load i32, i32* inttoptr (i32 4763861 to i32*), align 4
  %v3_40a2e5 = zext i1 %v23_40a2de to i32
  %v4_40a2e5 = add i32 %v1_40a2e5, %v0_40a2e5
  %v5_40a2e5 = add i32 %v4_40a2e5, %v3_40a2e5
  store i32 %v5_40a2e5, i32* %esi.global-to-local, align 4
  %v0_40a2eb = load i32, i32* %edx.global-to-local, align 4
  %v1_40a2eb = load i32, i32* inttoptr (i32 4763941 to i32*), align 4
  %v2_40a2eb = or i32 %v1_40a2eb, %v0_40a2eb
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v2_40a2eb, i32* %edx.global-to-local, align 4
  call void @__pseudo_call(i32 -1)
  %v0_40a2f9 = load i32, i32* inttoptr (i32 4763706 to i32*), align 4
  %v1_40a2f9 = and i32 %v0_40a2f9, 216
  store i32 %v1_40a2f9, i32* inttoptr (i32 4763706 to i32*), align 4
  %v0_40a303 = load i32, i32* %ebx.global-to-local, align 4
  %v1_40a303 = load i32, i32* %eax.global-to-local, align 4
  %v2_40a303 = add i32 %v1_40a303, %v0_40a303
  %v7_40a303 = icmp ult i32 %v2_40a303, %v0_40a303
  store i32 %v2_40a303, i32* %ebx.global-to-local, align 4
  %v0_40a305 = load i32, i32* inttoptr (i32 4763768 to i32*), align 8
  %v2_40a305 = zext i1 %v7_40a303 to i32
  %v3_40a305 = add i32 %v0_40a305, 245
  %v4_40a305 = add i32 %v3_40a305, %v2_40a305
  %v21_40a305 = icmp ule i32 %v4_40a305, %v0_40a305
  %v22_40a305 = icmp ugt i32 %v0_40a305, -246
  %v23_40a305 = select i1 %v7_40a303, i1 %v21_40a305, i1 %v22_40a305
  store i32 %v4_40a305, i32* inttoptr (i32 4763768 to i32*), align 8
  %v0_40a30f = load i32, i32* inttoptr (i32 4763688 to i32*), align 8
  %v3_40a30f = select i1 %v23_40a305, i32 89, i32 88
  %v4_40a30f = add i32 %v3_40a30f, %v0_40a30f
  %v21_40a30f = icmp ule i32 %v4_40a30f, %v0_40a30f
  %v22_40a30f = icmp ugt i32 %v0_40a30f, -89
  %v23_40a30f = select i1 %v23_40a305, i1 %v21_40a30f, i1 %v22_40a30f
  store i32 %v4_40a30f, i32* inttoptr (i32 4763688 to i32*), align 8
  %v0_40a316 = load i32, i32* inttoptr (i32 4763686 to i32*), align 4
  %v1_40a316 = load i32, i32* %esi.global-to-local, align 4
  %v3_40a316 = zext i1 %v23_40a30f to i32
  %v4_40a316 = add i32 %v1_40a316, %v0_40a316
  %v5_40a316 = add i32 %v4_40a316, %v3_40a316
  store i32 %v5_40a316, i32* inttoptr (i32 4763686 to i32*), align 4
  %v0_40a31c = load i32, i32* %ebx.global-to-local, align 4
  %v0_40a31f = load i32, i32* %eax.global-to-local, align 4
  %v1_40a31f = xor i32 %v0_40a31f, -98
  store i32 %v1_40a31f, i32* %eax.global-to-local, align 4
  %v1_40a322 = and i32 %v0_40a31c, 20
  %v0_40a325 = load i32, i32* %edx.global-to-local, align 4
  %v1_40a325 = add i32 %v0_40a325, -22
  store i32 %v1_40a325, i32* %edx.global-to-local, align 4
  %v2_40a32d = add i32 %v0_40a325, -21
  store i32 %v2_40a32d, i32* %ecx.global-to-local, align 4
  %v1_40a32f = load i32, i32* %esi.global-to-local, align 4
  %v2_40a32f = sub i32 %v1_40a322, %v1_40a32f
  store i32 %v2_40a32f, i32* %ebx.global-to-local, align 4
  %v0_40a331 = load i32, i32* inttoptr (i32 4763711 to i32*), align 4
  %v1_40a331 = load i32, i32* %edi.global-to-local, align 4
  %v2_40a331 = sub i32 %v0_40a331, %v1_40a331
  store i32 %v2_40a331, i32* inttoptr (i32 4763711 to i32*), align 4
  %v0_40a337 = load i32, i32* inttoptr (i32 4763726 to i32*), align 4
  %v2_40a337 = add i32 %v1_40a331, %v0_40a337
  %v7_40a337 = icmp ult i32 %v2_40a337, %v0_40a337
  store i32 %v2_40a337, i32* inttoptr (i32 4763726 to i32*), align 4
  %v0_40a33d = load i32, i32* %ebx.global-to-local, align 4
  %v2_40a33d = zext i1 %v7_40a337 to i32
  %v3_40a33d = add i32 %v0_40a33d, -40
  %v4_40a33d = add i32 %v3_40a33d, %v2_40a33d
  %v12_40a33d = icmp ult i32 %v0_40a33d, 40
  %v13_40a33d = or i1 %v7_40a337, %v12_40a33d
  store i1 %v13_40a33d, i1* %cf.global-to-local, align 1
  store i32 %v4_40a33d, i32* %ebx.global-to-local, align 4
  %v0_40a340 = load i32, i32* %eax.global-to-local, align 4
  %v1_40a340 = inttoptr i32 %v0_40a340 to i8*
  %v2_40a340 = load i8, i8* %v1_40a340, align 1
  %v4_40a340 = trunc i32 %v0_40a340 to i8
  %v5_40a340 = add i8 %v4_40a340, %v2_40a340
  %v10_40a340 = icmp ult i8 %v5_40a340, %v2_40a340
  store i1 %v10_40a340, i1* %cf.global-to-local, align 1
  store i8 %v5_40a340, i8* %v1_40a340, align 1
  %v0_40a342 = load i32, i32* %eax.global-to-local, align 4
  %v1_40a342 = inttoptr i32 %v0_40a342 to i8*
  %v2_40a342 = load i8, i8* %v1_40a342, align 1
  %v4_40a342 = trunc i32 %v0_40a342 to i8
  %v5_40a342 = add i8 %v4_40a342, %v2_40a342
  %v10_40a342 = icmp ult i8 %v5_40a342, %v2_40a342
  store i1 %v10_40a342, i1* %cf.global-to-local, align 1
  store i8 %v5_40a342, i8* %v1_40a342, align 1
  %v0_40a344 = load i32, i32* %eax.global-to-local, align 4
  %v1_40a344 = inttoptr i32 %v0_40a344 to i8*
  %v2_40a344 = load i8, i8* %v1_40a344, align 1
  %v4_40a344 = trunc i32 %v0_40a344 to i8
  %v5_40a344 = add i8 %v4_40a344, %v2_40a344
  %v10_40a344 = icmp ult i8 %v5_40a344, %v2_40a344
  store i1 %v10_40a344, i1* %cf.global-to-local, align 1
  store i8 %v5_40a344, i8* %v1_40a344, align 1
  %v0_40a346 = load i32, i32* %eax.global-to-local, align 4
  %v1_40a346 = inttoptr i32 %v0_40a346 to i8*
  %v2_40a346 = load i8, i8* %v1_40a346, align 1
  %v4_40a346 = trunc i32 %v0_40a346 to i8
  %v5_40a346 = add i8 %v4_40a346, %v2_40a346
  %v10_40a346 = icmp ult i8 %v5_40a346, %v2_40a346
  store i1 %v10_40a346, i1* %cf.global-to-local, align 1
  store i8 %v5_40a346, i8* %v1_40a346, align 1
  %v0_40a348 = load i32, i32* inttoptr (i32 4764094 to i32*), align 4
  %v1_40a348 = load i32, i32* %edi.global-to-local, align 4
  %v2_40a348 = load i1, i1* %cf.global-to-local, align 1
  %v3_40a348 = zext i1 %v2_40a348 to i32
  %v4_40a348 = add i32 %v1_40a348, %v0_40a348
  %v5_40a348 = add i32 %v3_40a348, %v4_40a348
  %v24_40a348 = icmp ule i32 %v5_40a348, %v0_40a348
  %v25_40a348 = icmp ult i32 %v4_40a348, %v0_40a348
  %v26_40a348 = select i1 %v2_40a348, i1 %v24_40a348, i1 %v25_40a348
  store i32 %v5_40a348, i32* inttoptr (i32 4764094 to i32*), align 4
  store i32 8, i32* inttoptr (i32 4763965 to i32*), align 4
  store i32 1, i32* %edx.global-to-local, align 4
  %v1_40a35d = load i32, i32* inttoptr (i32 4764093 to i32*), align 4
  %v3_40a35d = zext i1 %v26_40a348 to i32
  %v4_40a35d = add i32 %v1_40a35d, 1
  %v5_40a35d = add i32 %v4_40a35d, %v3_40a35d
  store i32 %v5_40a35d, i32* %edx.global-to-local, align 4
  %v0_40a363 = load i32, i32* inttoptr (i32 4763856 to i32*), align 16
  %v1_40a363 = load i32, i32* %esi.global-to-local, align 4
  %v2_40a363 = add i32 %v1_40a363, %v0_40a363
  %v7_40a363 = icmp ult i32 %v2_40a363, %v0_40a363
  store i32 %v2_40a363, i32* inttoptr (i32 4763856 to i32*), align 16
  %v0_40a369 = load i32, i32* %edi.global-to-local, align 4
  %v1_40a369 = load i32, i32* inttoptr (i32 4763686 to i32*), align 4
  %v3_40a369 = zext i1 %v7_40a363 to i32
  %v4_40a369 = add i32 %v1_40a369, %v0_40a369
  %v5_40a369 = add i32 %v4_40a369, %v3_40a369
  %v24_40a369 = icmp ule i32 %v5_40a369, %v0_40a369
  %v25_40a369 = icmp ult i32 %v4_40a369, %v0_40a369
  %v26_40a369 = select i1 %v7_40a363, i1 %v24_40a369, i1 %v25_40a369
  store i1 %v26_40a369, i1* %cf.global-to-local, align 1
  store i32 %v5_40a369, i32* %edi.global-to-local, align 4
  %v0_40a36f = load i32, i32* %eax.global-to-local, align 4
  %v1_40a36f = trunc i32 %v0_40a36f to i8
  %v2_40a36f = load i8, i8* inttoptr (i32 4763776 to i8*), align 128
  %v4_40a36f = zext i1 %v26_40a369 to i8
  %v5_40a36f = add i8 %v1_40a36f, %v2_40a36f
  %v6_40a36f = add i8 %v5_40a36f, %v4_40a36f
  %v27_40a36f = zext i8 %v6_40a36f to i32
  %v29_40a36f = and i32 %v0_40a36f, -256
  %v30_40a36f = or i32 %v27_40a36f, %v29_40a36f
  store i32 %v30_40a36f, i32* %eax.global-to-local, align 4
  %v1_40a37a = load i32, i32* %edx.global-to-local, align 4
  %v2_40a37a = add i32 %v1_40a37a, 1
  store i32 %v2_40a37a, i32* %ecx.global-to-local, align 4
  %v0_40a37c = load i32, i32* inttoptr (i32 4764143 to i32*), align 4
  %v1_40a37c = xor i32 %v0_40a37c, 77
  store i32 %v1_40a37c, i32* inttoptr (i32 4764143 to i32*), align 4
  %v0_40a383 = load i32, i32* %ebx.global-to-local, align 4
  %v1_40a383 = or i32 %v0_40a383, -35
  store i32 %v1_40a383, i32* %ebx.global-to-local, align 4
  %v0_40a386 = load i32, i32* inttoptr (i32 4764012 to i32*), align 4
  %v1_40a386 = load i32, i32* %edi.global-to-local, align 4
  %v2_40a386 = sub i32 %v0_40a386, %v1_40a386
  %v7_40a386 = icmp ult i32 %v0_40a386, %v1_40a386
  store i32 %v2_40a386, i32* inttoptr (i32 4764012 to i32*), align 4
  %v0_40a38c = load i32, i32* %edx.global-to-local, align 4
  %v1_40a38c = load i32, i32* inttoptr (i32 4764039 to i32*), align 4
  %v3_40a38c = zext i1 %v7_40a386 to i32
  %v4_40a38c = add i32 %v3_40a38c, %v0_40a38c
  %v5_40a38c = add i32 %v4_40a38c, %v1_40a38c
  store i32 %v5_40a38c, i32* %edx.global-to-local, align 4
  %v0_40a392 = load i32, i32* inttoptr (i32 4763871 to i32*), align 4
  %v1_40a392 = load i32, i32* %edi.global-to-local, align 4
  %v2_40a392 = or i32 %v1_40a392, %v0_40a392
  store i32 %v2_40a392, i32* inttoptr (i32 4763871 to i32*), align 4
  %v0_40a398 = load i32, i32* inttoptr (i32 4763931 to i32*), align 4
  %v3_40a398 = add i32 %v0_40a398, 96
  %v21_40a398 = icmp ugt i32 %v0_40a398, -97
  store i1 %v21_40a398, i1* %cf.global-to-local, align 1
  store i32 %v3_40a398, i32* inttoptr (i32 4763931 to i32*), align 4
  %v0_40a39f = load i8, i8* inttoptr (i32 4763736 to i8*), align 8
  %v1_40a39f = load i32, i32* %eax.global-to-local, align 4
  %v2_40a39f = udiv i32 %v1_40a39f, 256
  %v3_40a39f = trunc i32 %v2_40a39f to i8
  %v4_40a39f = or i8 %v3_40a39f, %v0_40a39f
  store i1 false, i1* %cf.global-to-local, align 1
  store i8 %v4_40a39f, i8* inttoptr (i32 4763736 to i8*), align 8
  %v0_40a3a5 = load i32, i32* %ebx.global-to-local, align 4
  %v1_40a3a5 = load i32, i32* inttoptr (i32 4764145 to i32*), align 4
  %v4_40a3a5 = add i32 %v1_40a3a5, %v0_40a3a5
  %v5_40a3a5 = add i32 %v1_40a3a5, %v0_40a3a5
  %v25_40a3a5 = icmp ult i32 %v4_40a3a5, %v0_40a3a5
  store i1 %v25_40a3a5, i1* %cf.global-to-local, align 1
  store i32 %v5_40a3a5, i32* %ebx.global-to-local, align 4
  store i32 0, i32* %eax.global-to-local, align 4
  %v4_40a3b3 = call i32* @EncodePointer(i32* null)
  %v5_40a3b3 = ptrtoint i32* %v4_40a3b3 to i32
  store i32 %v5_40a3b3, i32* %eax.global-to-local, align 4
  %v0_40a3b9 = load i32, i32* inttoptr (i32 4763721 to i32*), align 4
  %v1_40a3b9 = load i32, i32* %esi.global-to-local, align 4
  %v2_40a3b9 = and i32 %v1_40a3b9, %v0_40a3b9
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v2_40a3b9, i32* inttoptr (i32 4763721 to i32*), align 4
  %v0_40a3bf = load i8, i8* inttoptr (i32 4763824 to i8*), align 16
  %v1_40a3bf = load i32, i32* %ebx.global-to-local, align 4
  %v2_40a3bf = udiv i32 %v1_40a3bf, 256
  %v3_40a3bf = trunc i32 %v2_40a3bf to i8
  %v6_40a3bf = sub i8 %v0_40a3bf, %v3_40a3bf
  %v22_40a3bf = icmp ult i8 %v0_40a3bf, %v3_40a3bf
  store i1 %v22_40a3bf, i1* %cf.global-to-local, align 1
  store i8 %v6_40a3bf, i8* inttoptr (i32 4763824 to i8*), align 16
  %v0_40a3c5 = load i32, i32* %ebx.global-to-local, align 4
  %v1_40a3c5 = trunc i32 %v0_40a3c5 to i8
  %v2_40a3c5 = load i8, i8* inttoptr (i32 4763726 to i8*), align 2
  %v4_40a3c5 = zext i1 %v22_40a3bf to i8
  %v5_40a3c5 = add i8 %v1_40a3c5, %v2_40a3c5
  %v6_40a3c5 = add i8 %v4_40a3c5, %v5_40a3c5
  %v24_40a3c5 = icmp ule i8 %v6_40a3c5, %v1_40a3c5
  %v25_40a3c5 = icmp ult i8 %v5_40a3c5, %v1_40a3c5
  %v26_40a3c5 = select i1 %v22_40a3bf, i1 %v24_40a3c5, i1 %v25_40a3c5
  %v27_40a3c5 = zext i8 %v6_40a3c5 to i32
  %v29_40a3c5 = and i32 %v0_40a3c5, -256
  %v30_40a3c5 = or i32 %v27_40a3c5, %v29_40a3c5
  store i32 %v30_40a3c5, i32* %ebx.global-to-local, align 4
  %v0_40a3cb = load i32, i32* inttoptr (i32 4763652 to i32*), align 4
  %v3_40a3cb = zext i1 %v26_40a3c5 to i32
  %v4_40a3cb = add i32 %v0_40a3cb, %v5_40a3b3
  %v5_40a3cb = add i32 %v3_40a3cb, %v4_40a3cb
  %v24_40a3cb = icmp ule i32 %v5_40a3cb, %v0_40a3cb
  %v25_40a3cb = icmp ult i32 %v4_40a3cb, %v0_40a3cb
  %v26_40a3cb = select i1 %v26_40a3c5, i1 %v24_40a3cb, i1 %v25_40a3cb
  store i32 %v5_40a3cb, i32* inttoptr (i32 4763652 to i32*), align 4
  store i32 1, i32* %edx.global-to-local, align 4
  %v1_40a3d6 = load i32, i32* inttoptr (i32 4763721 to i32*), align 4
  %v3_40a3d6 = zext i1 %v26_40a3cb to i32
  %v4_40a3d6 = add i32 %v1_40a3d6, 1
  %v5_40a3d6 = add i32 %v3_40a3d6, %v4_40a3d6
  %v24_40a3d6 = icmp ult i32 %v5_40a3d6, 2
  %v25_40a3d6 = icmp eq i32 %v4_40a3d6, 0
  %v26_40a3d6 = select i1 %v26_40a3cb, i1 %v24_40a3d6, i1 %v25_40a3d6
  store i1 %v26_40a3d6, i1* %cf.global-to-local, align 1
  store i32 %v5_40a3d6, i32* %edx.global-to-local, align 4
  %v0_40a3dc = load i8, i8* inttoptr (i32 4763704 to i8*), align 8
  %v1_40a3dc = add i8 %v0_40a3dc, 94
  store i8 %v1_40a3dc, i8* inttoptr (i32 4763704 to i8*), align 8
  %v0_40a3e3 = load i32, i32* inttoptr (i32 4763879 to i32*), align 4
  %v1_40a3e3 = load i32, i32* %edi.global-to-local, align 4
  %v2_40a3e3 = sub i32 %v0_40a3e3, %v1_40a3e3
  store i32 %v2_40a3e3, i32* inttoptr (i32 4763879 to i32*), align 4
  %v0_40a3e9 = load i32, i32* inttoptr (i32 4763764 to i32*), align 4
  %v1_40a3e9 = load i32, i32* %esi.global-to-local, align 4
  %v2_40a3e9 = xor i32 %v1_40a3e9, %v0_40a3e9
  store i32 %v2_40a3e9, i32* inttoptr (i32 4763764 to i32*), align 4
  %v1_40a3ef = load i32, i32* %edi.global-to-local, align 4
  %v4_40a3ef = sub i32 %v5_40a3b3, %v1_40a3ef
  %v2_40a3f1 = mul i32 %v4_40a3ef, 2
  %v7_40a3f1 = icmp ult i32 %v2_40a3f1, %v4_40a3ef
  store i1 %v7_40a3f1, i1* %cf.global-to-local, align 1
  store i32 %v2_40a3f1, i32* %eax.global-to-local, align 4
  call void @__pseudo_call(i32 4236283)
  %v0_40a3fb = load i32, i32* inttoptr (i32 4764116 to i32*), align 4
  %v1_40a3fb = and i32 %v0_40a3fb, 130
  store i32 %v1_40a3fb, i32* inttoptr (i32 4764116 to i32*), align 4
  %v0_40a405 = load i32, i32* %eax.global-to-local, align 4
  %v1_40a405 = add i32 %v0_40a405, -67
  store i32 %v1_40a405, i32* %eax.global-to-local, align 4
  %v0_40a408 = load i32, i32* %ebx.global-to-local, align 4
  %tmp111 = and i32 %v1_40a405, 255
  %v12_40a408 = xor i32 %tmp111, %v0_40a408
  store i32 %v12_40a408, i32* %ebx.global-to-local, align 4
  %v0_40a40a = load i32, i32* inttoptr (i32 4763796 to i32*), align 4
  %v1_40a40a = load i32, i32* %edi.global-to-local, align 4
  %v2_40a40a = add i32 %v1_40a40a, %v0_40a40a
  store i32 %v2_40a40a, i32* inttoptr (i32 4763796 to i32*), align 4
  %v1_40a410 = load i32, i32* inttoptr (i32 4763769 to i32*), align 4
  %v2_40a410 = sub i32 %v1_40a40a, %v1_40a410
  store i32 %v2_40a410, i32* %edi.global-to-local, align 4
  %v0_40a416 = load i32, i32* %edx.global-to-local, align 4
  %v1_40a416 = load i32, i32* %eax.global-to-local, align 4
  %v2_40a416 = add i32 %v1_40a416, %v0_40a416
  %v0_40a418 = load i32, i32* %esi.global-to-local, align 4
  %v1_40a418 = add i32 %v0_40a418, -67
  store i32 %v1_40a418, i32* %esi.global-to-local, align 4
  store i32 -90, i32* %ecx.global-to-local, align 4
  %v1_40a423 = add i32 %v2_40a416, 31
  %v4_40a423 = icmp ugt i32 %v2_40a416, -32
  store i1 %v4_40a423, i1* %cf.global-to-local, align 1
  %v10_40a423 = trunc i32 %v1_40a423 to i8
  store i32 %v1_40a423, i32* %edx.global-to-local, align 4
  %v2_40a426 = load i8, i8* inttoptr (i32 4763955 to i8*), align 1
  %v4_40a426 = zext i1 %v4_40a423 to i8
  %v5_40a426 = add i8 %v2_40a426, %v10_40a423
  %v6_40a426 = add i8 %v5_40a426, %v4_40a426
  %v24_40a426 = icmp ule i8 %v6_40a426, %v10_40a423
  %v25_40a426 = icmp ult i8 %v5_40a426, %v10_40a423
  %v26_40a426 = select i1 %v4_40a423, i1 %v24_40a426, i1 %v25_40a426
  store i1 %v26_40a426, i1* %cf.global-to-local, align 1
  %v27_40a426 = zext i8 %v6_40a426 to i32
  %v29_40a426 = and i32 %v1_40a423, -256
  %v30_40a426 = or i32 %v27_40a426, %v29_40a426
  store i32 %v30_40a426, i32* %edx.global-to-local, align 4
  %v0_40a42c = load i32, i32* %ebx.global-to-local, align 4
  %v1_40a42c = trunc i32 %v0_40a42c to i8
  %v2_40a42c = load i8, i8* inttoptr (i32 4763756 to i8*), align 4
  %v4_40a42c = zext i1 %v26_40a426 to i8
  %v5_40a42c = add i8 %v1_40a42c, %v2_40a42c
  %v6_40a42c = add i8 %v5_40a42c, %v4_40a42c
  %v27_40a42c = zext i8 %v6_40a42c to i32
  %v29_40a42c = and i32 %v0_40a42c, -256
  %v30_40a42c = or i32 %v27_40a42c, %v29_40a42c
  store i32 %v30_40a42c, i32* %ebx.global-to-local, align 4
  %v0_40a432 = load i32, i32* inttoptr (i32 4763750 to i32*), align 4
  %v1_40a432 = or i32 %v0_40a432, 40
  store i32 %v1_40a432, i32* inttoptr (i32 4763750 to i32*), align 4
  %v0_40a439 = load i32, i32* %edi.global-to-local, align 4
  %v1_40a439 = load i32, i32* inttoptr (i32 4764127 to i32*), align 4
  %v2_40a439 = sub i32 %v0_40a439, %v1_40a439
  store i32 %v2_40a439, i32* %edi.global-to-local, align 4
  %v0_40a43f = load i32, i32* inttoptr (i32 4763794 to i32*), align 4
  %v1_40a43f = or i32 %v0_40a43f, 172
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v1_40a43f, i32* inttoptr (i32 4763794 to i32*), align 4
  %v0_40a449 = load i8, i8* inttoptr (i32 4764155 to i8*), align 1
  %v1_40a449 = load i32, i32* %eax.global-to-local, align 4
  %v2_40a449 = udiv i32 %v1_40a449, 256
  %v3_40a449 = trunc i32 %v2_40a449 to i8
  %v4_40a449 = sub i8 %v0_40a449, %v3_40a449
  %v9_40a449 = icmp ult i8 %v0_40a449, %v3_40a449
  store i1 %v9_40a449, i1* %cf.global-to-local, align 1
  store i8 %v4_40a449, i8* inttoptr (i32 4764155 to i8*), align 1
  %v0_40a44f = load i32, i32* %edx.global-to-local, align 4
  %v2_40a44f = zext i1 %v9_40a449 to i32
  %v3_40a44f = add i32 %v0_40a44f, 37
  %v4_40a44f = add i32 %v3_40a44f, %v2_40a44f
  store i32 %v4_40a44f, i32* %edx.global-to-local, align 4
  %v0_40a452 = load i32, i32* inttoptr (i32 4764129 to i32*), align 4
  %v2_40a452 = add i32 %v0_40a452, %v4_40a44f
  %v7_40a452 = icmp ult i32 %v2_40a452, %v0_40a452
  store i1 %v7_40a452, i1* %cf.global-to-local, align 1
  store i32 %v2_40a452, i32* inttoptr (i32 4764129 to i32*), align 4
  %v0_40a458 = load i32, i32* %ebx.global-to-local, align 4
  %v1_40a458 = add i32 %v0_40a458, 1219609373
  %v2_40a458 = inttoptr i32 %v1_40a458 to i8*
  %v3_40a458 = load i8, i8* %v2_40a458, align 1
  %v4_40a458 = load i32, i32* %eax.global-to-local, align 4
  %v5_40a458 = trunc i32 %v4_40a458 to i8
  %v6_40a458 = add i8 %v5_40a458, %v3_40a458
  %v11_40a458 = icmp ult i8 %v6_40a458, %v3_40a458
  store i1 %v11_40a458, i1* %cf.global-to-local, align 1
  store i8 %v6_40a458, i8* %v2_40a458, align 1
  %v0_40a45e = load i32, i32* %edx.global-to-local, align 4
  %v1_40a45e = add i32 %v0_40a45e, 49
  %v2_40a45e = inttoptr i32 %v1_40a45e to i8*
  %v3_40a45e = load i8, i8* %v2_40a45e, align 1
  %v4_40a45e = load i32, i32* %ecx.global-to-local, align 4
  %v5_40a45e = udiv i32 %v4_40a45e, 256
  %v6_40a45e = trunc i32 %v5_40a45e to i8
  %v7_40a45e = add i8 %v6_40a45e, %v3_40a45e
  %v12_40a45e = icmp ult i8 %v7_40a45e, %v3_40a45e
  store i1 %v12_40a45e, i1* %cf.global-to-local, align 1
  store i8 %v7_40a45e, i8* %v2_40a45e, align 1
  %v0_40a461 = load i32, i32* %eax.global-to-local, align 4
  %v1_40a461 = load i1, i1* %cf.global-to-local, align 1
  %v2_40a461 = zext i1 %v1_40a461 to i32
  %v3_40a461 = add i32 %v0_40a461, -4763875
  %v4_40a461 = add i32 %v3_40a461, %v2_40a461
  store i32 %v4_40a461, i32* %eax.global-to-local, align 4
  %v0_40a466 = load i32, i32* %ebx.global-to-local, align 4
  %v1_40a466 = load i32, i32* inttoptr (i32 4763697 to i32*), align 4
  %v2_40a466 = sub i32 %v0_40a466, %v1_40a466
  %v7_40a466 = icmp ult i32 %v0_40a466, %v1_40a466
  %v1_40a46c = udiv i32 %v4_40a461, 256
  %v2_40a46c = trunc i32 %v1_40a46c to i8
  %v4_40a46c = zext i1 %v7_40a466 to i8
  %v5_40a46c = add i8 %v2_40a46c, 88
  %v6_40a46c = add i8 %v5_40a46c, %v4_40a46c
  %v22_40a46c = icmp ule i8 %v6_40a46c, %v2_40a46c
  %v23_40a46c = icmp ugt i8 %v2_40a46c, -89
  %v24_40a46c = select i1 %v7_40a466, i1 %v22_40a46c, i1 %v23_40a46c
  %v25_40a46c = zext i8 %v6_40a46c to i32
  %v27_40a46c = mul nuw nsw i32 %v25_40a46c, 256
  %v28_40a46c = and i32 %v4_40a461, -65281
  %v29_40a46c = or i32 %v27_40a46c, %v28_40a46c
  store i32 %v29_40a46c, i32* %eax.global-to-local, align 4
  %v2_40a46f = zext i1 %v24_40a46c to i32
  %v7_40a46f = sext i1 %v24_40a46c to i32
  %v8_40a46f = icmp ult i32 %v2_40a466, %v7_40a46f
  %v9_40a46f = icmp ne i32 %v2_40a466, -1
  %v10_40a46f = or i1 %v9_40a46f, %v8_40a46f
  %v11_40a46f = and i1 %v24_40a46c, %v10_40a46f
  store i32 %v2_40a46f, i32* %ebx.global-to-local, align 4
  %v0_40a471 = load i32, i32* %edi.global-to-local, align 4
  %v2_40a471 = zext i1 %v11_40a46f to i32
  %v3_40a471 = add i32 %v0_40a471, -72
  %v4_40a471 = add i32 %v3_40a471, %v2_40a471
  store i32 %v4_40a471, i32* %edi.global-to-local, align 4
  %v0_40a474 = load i32, i32* inttoptr (i32 4763792 to i32*), align 16
  %v2_40a474 = xor i32 %v29_40a46c, %v0_40a474
  store i32 %v2_40a474, i32* inttoptr (i32 4763792 to i32*), align 16
  store i32 72, i32* %edx.global-to-local, align 4
  %v0_40a482 = load i32, i32* inttoptr (i32 4764069 to i32*), align 4
  %v1_40a482 = load i32, i32* %esi.global-to-local, align 4
  %v2_40a482 = add i32 %v1_40a482, %v0_40a482
  store i32 %v2_40a482, i32* inttoptr (i32 4764069 to i32*), align 4
  store i32 -17, i32* %edx.global-to-local, align 4
  %v4_40a496 = add i32 %v1_40a482, 28
  store i32 %v4_40a496, i32* %esi.global-to-local, align 4
  %v0_40a49a = load i32, i32* %ebx.global-to-local, align 4
  %v1_40a49a = and i32 %v0_40a49a, -42
  store i32 %v1_40a49a, i32* %ebx.global-to-local, align 4
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 -67, i32* %ecx.global-to-local, align 4
  %v0_40a4a0 = load i32, i32* %eax.global-to-local, align 4
  %v1_40a4a0 = trunc i32 %v0_40a4a0 to i8
  %v2_40a4a0 = load i8, i8* inttoptr (i32 4764130 to i8*), align 2
  %v8_40a4a0 = icmp ult i8 %v1_40a4a0, %v2_40a4a0
  %v0_40a4a6 = load i32, i32* %edi.global-to-local, align 4
  %v2_40a4a6 = zext i1 %v8_40a4a0 to i32
  %v3_40a4a6 = add i32 %v0_40a4a6, 42
  %v4_40a4a6 = add i32 %v3_40a4a6, %v2_40a4a6
  %v12_40a4a6 = icmp ult i32 %v0_40a4a6, -42
  %v13_40a4a6 = or i1 %v8_40a4a0, %v12_40a4a6
  store i1 %v13_40a4a6, i1* %cf.global-to-local, align 1
  store i32 %v4_40a4a6, i32* %edi.global-to-local, align 4
  store i32 0, i32* %eax.global-to-local, align 4
  %v4_40a4b1 = call i32* @EncodePointer(i32* null)
  %v5_40a4b1 = ptrtoint i32* %v4_40a4b1 to i32
  store i32 %v5_40a4b1, i32* %eax.global-to-local, align 4
  store i32 -107, i32* %ecx.global-to-local, align 4
  %v0_40a4bf = load i32, i32* %ebx.global-to-local, align 4
  %v3_40a4bf = add i32 %v0_40a4bf, -54
  %v23_40a4bf = icmp ugt i32 %v0_40a4bf, 53
  store i32 %v3_40a4bf, i32* %ebx.global-to-local, align 4
  store i32 1, i32* %edx.global-to-local, align 4
  %v1_40a4c7 = load i32, i32* inttoptr (i32 4763776 to i32*), align 128
  %v4_40a4c7 = select i1 %v23_40a4bf, i32 2, i32 1
  %v5_40a4c7 = add i32 %v4_40a4c7, %v1_40a4c7
  store i32 %v5_40a4c7, i32* %edx.global-to-local, align 4
  store i32 0, i32* %esi.global-to-local, align 4
  %v1_40a4cf = add i32 %v5_40a4b1, -107
  %v5_40a4cf = icmp ugt i32* %v4_40a4b1, inttoptr (i32 106 to i32*)
  store i32 %v1_40a4cf, i32* %eax.global-to-local, align 4
  %v1_40a4d2 = load i32, i32* inttoptr (i32 4764019 to i32*), align 4
  %v3_40a4d2 = zext i1 %v5_40a4cf to i32
  %v4_40a4d2 = add i32 %v3_40a4d2, %v1_40a4cf
  %v5_40a4d2 = add i32 %v4_40a4d2, %v1_40a4d2
  store i32 %v5_40a4d2, i32* %eax.global-to-local, align 4
  %v0_40a4d8 = load i32, i32* %edi.global-to-local, align 4
  %v2_40a4d8 = add i32 %v0_40a4d8, %v5_40a4c7
  store i32 %v2_40a4d8, i32* %edi.global-to-local, align 4
  %v1_40a4da = add i32 %v5_40a4c7, 95
  %v2_40a4dd = add i32 %v3_40a4bf, %v1_40a4da
  %v7_40a4dd = icmp ult i32 %v2_40a4dd, %v1_40a4da
  store i32 %v2_40a4dd, i32* %edx.global-to-local, align 4
  %v0_40a4df = load i32, i32* inttoptr (i32 4763943 to i32*), align 4
  %v3_40a4df = zext i1 %v7_40a4dd to i32
  %v4_40a4df = sub i32 %v0_40a4df, %v3_40a4bf
  %v5_40a4df = add i32 %v3_40a4df, %v4_40a4df
  %v16_40a4df = sub i32 %v4_40a4df, %v3_40a4df
  %v17_40a4df = icmp ult i32 %v0_40a4df, %v16_40a4df
  %v18_40a4df = icmp ne i32 %v3_40a4bf, -1
  %v19_40a4df = or i1 %v18_40a4df, %v17_40a4df
  %v20_40a4df = icmp ult i32 %v0_40a4df, %v3_40a4bf
  %v21_40a4df = select i1 %v7_40a4dd, i1 %v19_40a4df, i1 %v20_40a4df
  store i32 %v5_40a4df, i32* inttoptr (i32 4763943 to i32*), align 4
  %v0_40a4e5 = load i32, i32* %edx.global-to-local, align 4
  %v3_40a4e5 = zext i1 %v21_40a4df to i32
  %v4_40a4e5 = mul i32 %v0_40a4e5, 2
  %v5_40a4e5 = or i32 %v3_40a4e5, %v4_40a4e5
  %v24_40a4e5 = icmp ule i32 %v5_40a4e5, %v0_40a4e5
  %v25_40a4e5 = icmp ult i32 %v4_40a4e5, %v0_40a4e5
  %v26_40a4e5 = select i1 %v21_40a4df, i1 %v24_40a4e5, i1 %v25_40a4e5
  store i1 %v26_40a4e5, i1* %cf.global-to-local, align 1
  store i32 %v5_40a4e5, i32* %edx.global-to-local, align 4
  %v0_40a4e7 = load i8, i8* inttoptr (i32 4764026 to i8*), align 2
  %v1_40a4e7 = load i32, i32* %ebx.global-to-local, align 4
  %v2_40a4e7 = trunc i32 %v1_40a4e7 to i8
  %v4_40a4e7 = zext i1 %v26_40a4e5 to i8
  %v5_40a4e7 = add i8 %v2_40a4e7, %v0_40a4e7
  %v6_40a4e7 = add i8 %v4_40a4e7, %v5_40a4e7
  %v24_40a4e7 = icmp ule i8 %v6_40a4e7, %v0_40a4e7
  %v25_40a4e7 = icmp ult i8 %v5_40a4e7, %v0_40a4e7
  %v26_40a4e7 = select i1 %v26_40a4e5, i1 %v24_40a4e7, i1 %v25_40a4e7
  store i1 %v26_40a4e7, i1* %cf.global-to-local, align 1
  store i8 %v6_40a4e7, i8* inttoptr (i32 4764026 to i8*), align 2
  %v0_40a4ed = load i32, i32* inttoptr (i32 4764153 to i32*), align 4
  %v2_40a4ed = zext i1 %v26_40a4e7 to i32
  %v3_40a4ed = add i32 %v0_40a4ed, -189
  %v4_40a4ed = add i32 %v3_40a4ed, %v2_40a4ed
  store i32 %v4_40a4ed, i32* inttoptr (i32 4764153 to i32*), align 4
  %v0_40a4f7 = load i32, i32* %eax.global-to-local, align 4
  %v1_40a4f7 = load i32, i32* %edx.global-to-local, align 4
  %v2_40a4f7 = add i32 %v1_40a4f7, %v0_40a4f7
  %v7_40a4f7 = icmp ult i32 %v2_40a4f7, %v0_40a4f7
  store i32 %v2_40a4f7, i32* %eax.global-to-local, align 4
  %v0_40a4f9 = load i32, i32* inttoptr (i32 4763927 to i32*), align 4
  %v2_40a4f9 = zext i1 %v7_40a4f7 to i32
  %v3_40a4f9 = add i32 %v0_40a4f9, -164
  %v4_40a4f9 = add i32 %v3_40a4f9, %v2_40a4f9
  %v12_40a4f9 = icmp ult i32 %v0_40a4f9, 164
  %v13_40a4f9 = or i1 %v7_40a4f7, %v12_40a4f9
  store i1 %v13_40a4f9, i1* %cf.global-to-local, align 1
  store i32 %v4_40a4f9, i32* inttoptr (i32 4763927 to i32*), align 4
  call void @__pseudo_call(i32 4236555)
  %v0_40a50b = load i32, i32* %ecx.global-to-local, align 4
  %v1_40a50b = load i32, i32* inttoptr (i32 4764063 to i32*), align 4
  %v2_40a50b = load i1, i1* %cf.global-to-local, align 1
  %v3_40a50b = zext i1 %v2_40a50b to i32
  %v4_40a50b = add i32 %v1_40a50b, %v0_40a50b
  %v5_40a50b = add i32 %v3_40a50b, %v4_40a50b
  %v24_40a50b = icmp ule i32 %v5_40a50b, %v0_40a50b
  %v25_40a50b = icmp ult i32 %v4_40a50b, %v0_40a50b
  %v26_40a50b = select i1 %v2_40a50b, i1 %v24_40a50b, i1 %v25_40a50b
  store i32 %v5_40a50b, i32* %ecx.global-to-local, align 4
  %v0_40a511 = load i32, i32* %ebx.global-to-local, align 4
  %v3_40a511 = zext i1 %v26_40a50b to i32
  %v4_40a511 = mul i32 %v0_40a511, 2
  %v5_40a511 = or i32 %v3_40a511, %v4_40a511
  store i32 %v5_40a511, i32* %ebx.global-to-local, align 4
  %v1_40a513 = load i32, i32* inttoptr (i32 4763965 to i32*), align 4
  %v2_40a513 = sub i32 %v5_40a50b, %v1_40a513
  store i32 %v2_40a513, i32* %ecx.global-to-local, align 4
  %v0_40a519 = load i32, i32* inttoptr (i32 4763978 to i32*), align 4
  %v1_40a519 = or i32 %v0_40a519, 108
  store i32 %v1_40a519, i32* inttoptr (i32 4763978 to i32*), align 4
  %v0_40a520 = load i32, i32* %eax.global-to-local, align 4
  %v1_40a520 = load i32, i32* inttoptr (i32 4763909 to i32*), align 4
  %v4_40a520 = add i32 %v1_40a520, %v0_40a520
  store i32 %v4_40a520, i32* %eax.global-to-local, align 4
  %v0_40a526 = load i32, i32* %esi.global-to-local, align 4
  %v1_40a526 = load i32, i32* inttoptr (i32 4764026 to i32*), align 4
  %v2_40a526 = or i32 %v1_40a526, %v0_40a526
  %v1_40a52c = xor i32 %v2_40a526, 60
  store i32 %v1_40a52c, i32* %esi.global-to-local, align 4
  %v0_40a52f = load i32, i32* inttoptr (i32 4764051 to i32*), align 4
  %v1_40a52f = load i32, i32* %ebx.global-to-local, align 4
  %v2_40a52f = add i32 %v1_40a52f, %v0_40a52f
  %v7_40a52f = icmp ult i32 %v2_40a52f, %v0_40a52f
  store i1 %v7_40a52f, i1* %cf.global-to-local, align 1
  store i32 %v2_40a52f, i32* inttoptr (i32 4764051 to i32*), align 4
  %v0_40a535 = load i32, i32* %edx.global-to-local, align 4
  %v1_40a535 = trunc i32 %v0_40a535 to i8
  %v2_40a535 = load i8, i8* inttoptr (i32 4763939 to i8*), align 1
  %v4_40a535 = zext i1 %v7_40a52f to i8
  %v5_40a535 = add i8 %v1_40a535, %v2_40a535
  %v6_40a535 = add i8 %v5_40a535, %v4_40a535
  %v24_40a535 = icmp ule i8 %v6_40a535, %v1_40a535
  %v25_40a535 = icmp ult i8 %v5_40a535, %v1_40a535
  %v26_40a535 = select i1 %v7_40a52f, i1 %v24_40a535, i1 %v25_40a535
  %v27_40a535 = zext i8 %v6_40a535 to i32
  %v29_40a535 = and i32 %v0_40a535, -256
  %v30_40a535 = or i32 %v27_40a535, %v29_40a535
  store i32 %v30_40a535, i32* %edx.global-to-local, align 4
  store i32 6, i32* inttoptr (i32 4763835 to i32*), align 4
  %v1_40a545 = load i32, i32* inttoptr (i32 4763705 to i32*), align 4
  %v3_40a545 = zext i1 %v26_40a535 to i32
  %v4_40a545 = add i32 %v1_40a545, %v30_40a535
  %v5_40a545 = add i32 %v4_40a545, %v3_40a545
  store i32 %v5_40a545, i32* %edx.global-to-local, align 4
  %v0_40a54b = load i32, i32* %ebx.global-to-local, align 4
  %v1_40a54b = load i32, i32* inttoptr (i32 4763965 to i32*), align 4
  %v2_40a54b = or i32 %v1_40a54b, %v0_40a54b
  store i32 %v2_40a54b, i32* %ebx.global-to-local, align 4
  %v0_40a551 = load i32, i32* inttoptr (i32 4764134 to i32*), align 4
  %v1_40a551 = load i32, i32* %eax.global-to-local, align 4
  %v2_40a551 = or i32 %v1_40a551, %v0_40a551
  store i32 %v2_40a551, i32* inttoptr (i32 4764134 to i32*), align 4
  %v2_40a557 = mul i32 %v2_40a54b, 2
  store i32 %v2_40a557, i32* %ebx.global-to-local, align 4
  %v0_40a559 = load i32, i32* inttoptr (i32 4763806 to i32*), align 4
  %v1_40a559 = load i32, i32* %esi.global-to-local, align 4
  %v2_40a559 = xor i32 %v1_40a559, %v0_40a559
  store i32 %v2_40a559, i32* inttoptr (i32 4763806 to i32*), align 4
  %v0_40a55f = load i32, i32* inttoptr (i32 4764123 to i32*), align 4
  %v1_40a55f = xor i32 %v0_40a55f, 123
  store i32 %v1_40a55f, i32* inttoptr (i32 4764123 to i32*), align 4
  %v0_40a566 = load i32, i32* %eax.global-to-local, align 4
  %v1_40a566 = or i32 %v0_40a566, -118
  %v2_40a566 = trunc i32 %v1_40a566 to i8
  store i32 %v1_40a566, i32* %eax.global-to-local, align 4
  %v0_40a569 = load i32, i32* %esi.global-to-local, align 4
  %v1_40a569 = load i32, i32* inttoptr (i32 4764139 to i32*), align 4
  %v2_40a569 = or i32 %v1_40a569, %v0_40a569
  store i32 %v2_40a569, i32* %esi.global-to-local, align 4
  %v0_40a56f = load i32, i32* %ecx.global-to-local, align 4
  %v1_40a56f = load i32, i32* %edx.global-to-local, align 4
  %tmp112 = and i32 %v1_40a56f, 65280
  %v13_40a56f = xor i32 %tmp112, %v0_40a56f
  store i32 %v13_40a56f, i32* %ecx.global-to-local, align 4
  %v4_40a571 = add i8 %v2_40a566, -119
  store i1 false, i1* %cf.global-to-local, align 1
  %v26_40a571 = zext i8 %v4_40a571 to i32
  %v29_40a571 = or i32 %v26_40a571, -256
  store i32 %v29_40a571, i32* %eax.global-to-local, align 4
  %v1_40a573 = inttoptr i32 %v29_40a571 to i8*
  %v2_40a573 = load i8, i8* %v1_40a573, align 1
  %v5_40a573 = add i8 %v2_40a573, %v4_40a571
  %v10_40a573 = icmp ult i8 %v5_40a573, %v2_40a573
  store i1 %v10_40a573, i1* %cf.global-to-local, align 1
  store i8 %v5_40a573, i8* %v1_40a573, align 1
  %v0_40a575 = load i32, i32* %eax.global-to-local, align 4
  %v1_40a575 = inttoptr i32 %v0_40a575 to i8*
  %v2_40a575 = load i8, i8* %v1_40a575, align 1
  %v4_40a575 = trunc i32 %v0_40a575 to i8
  %v5_40a575 = add i8 %v4_40a575, %v2_40a575
  %v10_40a575 = icmp ult i8 %v5_40a575, %v2_40a575
  store i1 %v10_40a575, i1* %cf.global-to-local, align 1
  store i8 %v5_40a575, i8* %v1_40a575, align 1
  %v0_40a577 = load i32, i32* %eax.global-to-local, align 4
  %v1_40a577 = inttoptr i32 %v0_40a577 to i8*
  %v2_40a577 = load i8, i8* %v1_40a577, align 1
  %v4_40a577 = trunc i32 %v0_40a577 to i8
  %v5_40a577 = add i8 %v4_40a577, %v2_40a577
  %v10_40a577 = icmp ult i8 %v5_40a577, %v2_40a577
  store i1 %v10_40a577, i1* %cf.global-to-local, align 1
  store i8 %v5_40a577, i8* %v1_40a577, align 1
  %v0_40a579 = load i32, i32* %eax.global-to-local, align 4
  %v1_40a579 = inttoptr i32 %v0_40a579 to i8*
  %v2_40a579 = load i8, i8* %v1_40a579, align 1
  %v4_40a579 = trunc i32 %v0_40a579 to i8
  %v5_40a579 = add i8 %v4_40a579, %v2_40a579
  %v10_40a579 = icmp ult i8 %v5_40a579, %v2_40a579
  store i1 %v10_40a579, i1* %cf.global-to-local, align 1
  store i8 %v5_40a579, i8* %v1_40a579, align 1
  %v0_40a57b = load i32, i32* %eax.global-to-local, align 4
  %v1_40a57b = inttoptr i32 %v0_40a57b to i8*
  %v2_40a57b = load i8, i8* %v1_40a57b, align 1
  %v4_40a57b = trunc i32 %v0_40a57b to i8
  %v5_40a57b = add i8 %v4_40a57b, %v2_40a57b
  %v10_40a57b = icmp ult i8 %v5_40a57b, %v2_40a57b
  store i1 %v10_40a57b, i1* %cf.global-to-local, align 1
  store i8 %v5_40a57b, i8* %v1_40a57b, align 1
  %v0_40a57d = load i32, i32* %ecx.global-to-local, align 4
  %v1_40a57d = inttoptr i32 %v0_40a57d to i8*
  %v2_40a57d = load i8, i8* %v1_40a57d, align 1
  %v3_40a57d = load i32, i32* %edx.global-to-local, align 4
  %v4_40a57d = trunc i32 %v3_40a57d to i8
  %v5_40a57d = add i8 %v4_40a57d, %v2_40a57d
  %v10_40a57d = icmp ult i8 %v5_40a57d, %v2_40a57d
  store i1 %v10_40a57d, i1* %cf.global-to-local, align 1
  store i8 %v5_40a57d, i8* %v1_40a57d, align 1
  %v0_40a57f = load i32, i32* %ecx.global-to-local, align 4
  %v1_40a57f = inttoptr i32 %v0_40a57f to i32*
  %v2_40a57f = load i32, i32* %v1_40a57f, align 4
  %v3_40a57f = sitofp i32 %v2_40a57f to x86_fp80
  store x86_fp80 %v3_40a57f, x86_fp80* %st0.global-to-local, align 4
  %v0_40a581 = load i8, i8* inttoptr (i32 4763775 to i8*), align 1
  %v1_40a581 = load i32, i32* %eax.global-to-local, align 4
  %v2_40a581 = trunc i32 %v1_40a581 to i8
  %v3_40a581 = or i8 %v2_40a581, %v0_40a581
  store i8 %v3_40a581, i8* inttoptr (i32 4763775 to i8*), align 1
  %v0_40a588 = load i32, i32* inttoptr (i32 4763725 to i32*), align 4
  %v1_40a588 = load i32, i32* %ebx.global-to-local, align 4
  %v2_40a588 = add i32 %v1_40a588, %v0_40a588
  %v7_40a588 = icmp ult i32 %v2_40a588, %v0_40a588
  store i32 %v2_40a588, i32* inttoptr (i32 4763725 to i32*), align 4
  %v0_40a58e = load i32, i32* inttoptr (i32 4763864 to i32*), align 8
  %v1_40a58e = load i32, i32* %eax.global-to-local, align 4
  %v3_40a58e = zext i1 %v7_40a588 to i32
  %v4_40a58e = add i32 %v1_40a58e, %v0_40a58e
  %v5_40a58e = add i32 %v4_40a58e, %v3_40a58e
  store i32 %v5_40a58e, i32* inttoptr (i32 4763864 to i32*), align 8
  %v0_40a594 = load i32, i32* inttoptr (i32 4764061 to i32*), align 4
  %v1_40a594 = or i32 %v0_40a594, 222
  store i32 %v1_40a594, i32* inttoptr (i32 4764061 to i32*), align 4
  %v0_40a59e = load i32, i32* inttoptr (i32 4763821 to i32*), align 4
  %v3_40a59e = add i32 %v0_40a59e, -153
  store i32 %v3_40a59e, i32* inttoptr (i32 4763821 to i32*), align 4
  %v0_40a5a8 = load i32, i32* %eax.global-to-local, align 4
  %v1_40a5a8 = add i32 %v0_40a5a8, 54
  store i32 %v1_40a5a8, i32* %eax.global-to-local, align 4
  store i32 74, i32* %edx.global-to-local, align 4
  %v0_40a5b3 = load i32, i32* %ecx.global-to-local, align 4
  %v1_40a5b3 = and i32 %v0_40a5b3, -65281
  %v3_40a5b5 = load i32, i32* %ebx.global-to-local, align 4
  %v4_40a5b5 = trunc i32 %v3_40a5b5 to i8
  %v5_40a5b5 = add i8 %v4_40a5b5, 1
  %v10_40a5b5 = icmp eq i8 %v5_40a5b5, 0
  %v20_40a5b5 = zext i8 %v5_40a5b5 to i32
  %v22_40a5b5 = mul nuw nsw i32 %v20_40a5b5, 256
  %v24_40a5b5 = or i32 %v22_40a5b5, %v1_40a5b3
  store i32 %v24_40a5b5, i32* %ecx.global-to-local, align 4
  %v2_40a5b7 = zext i1 %v10_40a5b5 to i32
  %v3_40a5b7 = add i32 %v3_40a5b5, 104
  %v4_40a5b7 = add i32 %v3_40a5b7, %v2_40a5b7
  store i32 %v4_40a5b7, i32* %ebx.global-to-local, align 4
  %v0_40a5ba = load i32, i32* inttoptr (i32 4763703 to i32*), align 4
  %v1_40a5ba = load i32, i32* %esi.global-to-local, align 4
  %v2_40a5ba = sub i32 %v0_40a5ba, %v1_40a5ba
  %v7_40a5ba = icmp ult i32 %v0_40a5ba, %v1_40a5ba
  store i32 %v2_40a5ba, i32* inttoptr (i32 4763703 to i32*), align 4
  %v0_40a5c0 = load i32, i32* inttoptr (i32 4763846 to i32*), align 4
  %v2_40a5c0 = zext i1 %v7_40a5ba to i32
  %v3_40a5c0 = add i32 %v0_40a5c0, 197
  %v4_40a5c0 = add i32 %v3_40a5c0, %v2_40a5c0
  store i32 %v4_40a5c0, i32* inttoptr (i32 4763846 to i32*), align 4
  %v0_40a5ca = load i32, i32* inttoptr (i32 4763917 to i32*), align 4
  %v1_40a5ca = or i32 %v0_40a5ca, 202
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v1_40a5ca, i32* inttoptr (i32 4763917 to i32*), align 4
  %v0_40a5d4 = load i32, i32* %ebx.global-to-local, align 4
  %v1_40a5d4 = udiv i32 %v0_40a5d4, 256
  %v2_40a5d4 = trunc i32 %v1_40a5d4 to i8
  %v3_40a5d4 = load i8, i8* inttoptr (i32 4763924 to i8*), align 4
  %v4_40a5d4 = sub i8 %v2_40a5d4, %v3_40a5d4
  %v9_40a5d4 = icmp ult i8 %v2_40a5d4, %v3_40a5d4
  %v19_40a5d4 = zext i8 %v4_40a5d4 to i32
  %v21_40a5d4 = mul nuw nsw i32 %v19_40a5d4, 256
  %v22_40a5d4 = and i32 %v0_40a5d4, -65281
  %v23_40a5d4 = or i32 %v21_40a5d4, %v22_40a5d4
  store i32 %v23_40a5d4, i32* %ebx.global-to-local, align 4
  %v0_40a5da = load i32, i32* %ecx.global-to-local, align 4
  %v1_40a5da = load i32, i32* %edx.global-to-local, align 4
  %v3_40a5da = zext i1 %v9_40a5d4 to i32
  %v4_40a5da = add i32 %v1_40a5da, %v0_40a5da
  %v5_40a5da = add i32 %v4_40a5da, %v3_40a5da
  %v24_40a5da = icmp ule i32 %v5_40a5da, %v0_40a5da
  %v25_40a5da = icmp ult i32 %v4_40a5da, %v0_40a5da
  %v26_40a5da = select i1 %v9_40a5d4, i1 %v24_40a5da, i1 %v25_40a5da
  store i32 %v5_40a5da, i32* %ecx.global-to-local, align 4
  %v1_40a5dc = load i32, i32* %eax.global-to-local, align 4
  %v3_40a5dc = zext i1 %v26_40a5da to i32
  %v4_40a5dc = add i32 %v1_40a5dc, %v1_40a5da
  %v5_40a5dc = add i32 %v3_40a5dc, %v4_40a5dc
  %v24_40a5dc = icmp ule i32 %v5_40a5dc, %v1_40a5da
  %v25_40a5dc = icmp ult i32 %v4_40a5dc, %v1_40a5da
  %v26_40a5dc = select i1 %v26_40a5da, i1 %v24_40a5dc, i1 %v25_40a5dc
  store i1 %v26_40a5dc, i1* %cf.global-to-local, align 1
  store i32 %v5_40a5dc, i32* %edx.global-to-local, align 4
  %v1_40a5de = trunc i32 %v0_40a5d4 to i8
  %v2_40a5de = load i8, i8* inttoptr (i32 4763986 to i8*), align 2
  %v4_40a5de = zext i1 %v26_40a5dc to i8
  %v5_40a5de = add i8 %v2_40a5de, %v1_40a5de
  %v6_40a5de = add i8 %v5_40a5de, %v4_40a5de
  %v27_40a5de = zext i8 %v6_40a5de to i32
  %v29_40a5de = and i32 %v23_40a5d4, -256
  %v30_40a5de = or i32 %v27_40a5de, %v29_40a5de
  store i32 %v30_40a5de, i32* %ebx.global-to-local, align 4
  %v0_40a5e4 = load i32, i32* inttoptr (i32 4764011 to i32*), align 4
  %v2_40a5e4 = sub i32 %v0_40a5e4, %v30_40a5de
  store i32 %v2_40a5e4, i32* inttoptr (i32 4764011 to i32*), align 4
  %v0_40a5ea = load i32, i32* %esi.global-to-local, align 4
  %v1_40a5ea = load i32, i32* %edi.global-to-local, align 4
  %v2_40a5ea = xor i32 %v1_40a5ea, %v0_40a5ea
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v2_40a5ea, i32* %esi.global-to-local, align 4
  store i32 0, i32* %eax.global-to-local, align 4
  %v5_40a5f4 = call i32* @EncodePointer(i32* null)
  %v6_40a5f4 = ptrtoint i32* %v5_40a5f4 to i32
  store i32 %v6_40a5f4, i32* %eax.global-to-local, align 4
  store i32 1, i32* %ecx.global-to-local, align 4
  %v1_40a5ff = load i32, i32* inttoptr (i32 4763714 to i32*), align 4
  %v2_40a5ff = load i1, i1* %cf.global-to-local, align 1
  %v3_40a5ff = zext i1 %v2_40a5ff to i32
  %v4_40a5ff = add i32 %v1_40a5ff, 1
  %v5_40a5ff = add i32 %v3_40a5ff, %v4_40a5ff
  %v24_40a5ff = icmp ult i32 %v5_40a5ff, 2
  %v25_40a5ff = icmp eq i32 %v4_40a5ff, 0
  %v26_40a5ff = select i1 %v2_40a5ff, i1 %v24_40a5ff, i1 %v25_40a5ff
  store i32 %v5_40a5ff, i32* %ecx.global-to-local, align 4
  %v0_40a605 = load i32, i32* inttoptr (i32 4764143 to i32*), align 4
  %v3_40a605 = select i1 %v26_40a5ff, i32 212, i32 211
  %v4_40a605 = add i32 %v3_40a605, %v0_40a605
  %v21_40a605 = icmp ule i32 %v4_40a605, %v0_40a605
  %v22_40a605 = icmp ugt i32 %v0_40a605, -212
  %v23_40a605 = select i1 %v26_40a5ff, i1 %v21_40a605, i1 %v22_40a605
  store i32 %v4_40a605, i32* inttoptr (i32 4764143 to i32*), align 4
  store i32 1, i32* %edx.global-to-local, align 4
  %v1_40a614 = load i32, i32* inttoptr (i32 4764013 to i32*), align 4
  %v3_40a614 = zext i1 %v23_40a605 to i32
  %v4_40a614 = add i32 %v1_40a614, 1
  %v5_40a614 = add i32 %v4_40a614, %v3_40a614
  store i32 %v5_40a614, i32* %edx.global-to-local, align 4
  %v0_40a61a = load i32, i32* inttoptr (i32 4763817 to i32*), align 4
  %v1_40a61a = load i32, i32* %ecx.global-to-local, align 4
  %v2_40a61a = xor i32 %v1_40a61a, %v0_40a61a
  store i32 %v2_40a61a, i32* inttoptr (i32 4763817 to i32*), align 4
  %v0_40a620 = load i32, i32* inttoptr (i32 4763864 to i32*), align 8
  %v3_40a620 = add i32 %v0_40a620, -233
  store i32 %v3_40a620, i32* inttoptr (i32 4763864 to i32*), align 8
  %v0_40a62a = load i32, i32* %edi.global-to-local, align 4
  %v1_40a62a = xor i32 %v0_40a62a, -100
  store i32 %v1_40a62a, i32* %edi.global-to-local, align 4
  %v0_40a62d = load i32, i32* inttoptr (i32 4763964 to i32*), align 4
  %v2_40a62d = or i32 %v0_40a62d, %v6_40a5f4
  store i32 %v2_40a62d, i32* inttoptr (i32 4763964 to i32*), align 4
  %v0_40a633 = load i32, i32* %esi.global-to-local, align 4
  %v1_40a633 = load i32, i32* inttoptr (i32 4763784 to i32*), align 8
  %v4_40a633 = add i32 %v1_40a633, %v0_40a633
  store i32 %v4_40a633, i32* %esi.global-to-local, align 4
  %v0_40a639 = load i32, i32* %ebx.global-to-local, align 4
  %v1_40a639 = add i32 %v0_40a639, -53
  store i32 %v1_40a639, i32* %ebx.global-to-local, align 4
  %v0_40a63c = load i32, i32* inttoptr (i32 4763999 to i32*), align 4
  %v2_40a63c = or i32 %v0_40a63c, %v1_40a639
  store i32 %v2_40a63c, i32* inttoptr (i32 4763999 to i32*), align 4
  %v0_40a642 = load i32, i32* %ecx.global-to-local, align 4
  %v2_40a642 = add i32 %v0_40a642, 146
  %v15_40a642 = and i32 %v2_40a642, 255
  %v17_40a642 = and i32 %v0_40a642, -256
  %v18_40a642 = or i32 %v15_40a642, %v17_40a642
  %v1_40a645 = load i32, i32* %edx.global-to-local, align 4
  %v2_40a645 = add i32 %v18_40a642, %v1_40a645
  store i32 %v2_40a645, i32* %ecx.global-to-local, align 4
  %v0_40a647 = load i32, i32* inttoptr (i32 4763986 to i32*), align 4
  %v2_40a647 = or i32 %v0_40a647, %v6_40a5f4
  store i32 %v2_40a647, i32* inttoptr (i32 4763986 to i32*), align 4
  %v0_40a64d = load i32, i32* inttoptr (i32 4763758 to i32*), align 4
  %v1_40a64d = load i32, i32* %edx.global-to-local, align 4
  %v2_40a64d = and i32 %v1_40a64d, %v0_40a64d
  store i32 %v2_40a64d, i32* inttoptr (i32 4763758 to i32*), align 4
  %v0_40a653 = load i32, i32* %ecx.global-to-local, align 4
  %v1_40a653 = load i32, i32* inttoptr (i32 4763886 to i32*), align 4
  %v4_40a653 = add i32 %v1_40a653, %v0_40a653
  store i32 %v4_40a653, i32* %ecx.global-to-local, align 4
  %v0_40a659 = load i32, i32* %edi.global-to-local, align 4
  %v1_40a659 = load i32, i32* inttoptr (i32 4763761 to i32*), align 4
  %v2_40a659 = sub i32 %v0_40a659, %v1_40a659
  %v7_40a659 = icmp ult i32 %v0_40a659, %v1_40a659
  store i1 %v7_40a659, i1* %cf.global-to-local, align 1
  store i32 %v2_40a659, i32* %edi.global-to-local, align 4
  call void @__pseudo_call(i32 ptrtoint (i32* @global_var_40a667.22 to i32))
  %v0_40a667 = load i32, i32* %ecx.global-to-local, align 4
  %v1_40a667 = load i32, i32* %esi.global-to-local, align 4
  %v2_40a667 = load i1, i1* %cf.global-to-local, align 1
  %v3_40a667 = zext i1 %v2_40a667 to i32
  %v4_40a667 = sub i32 %v0_40a667, %v1_40a667
  %v5_40a667 = add i32 %v3_40a667, %v4_40a667
  %v16_40a667 = sub i32 %v4_40a667, %v3_40a667
  %v17_40a667 = icmp ult i32 %v0_40a667, %v16_40a667
  %v18_40a667 = icmp ne i32 %v1_40a667, -1
  %v19_40a667 = or i1 %v18_40a667, %v17_40a667
  %v20_40a667 = icmp ult i32 %v0_40a667, %v1_40a667
  %v21_40a667 = select i1 %v2_40a667, i1 %v19_40a667, i1 %v20_40a667
  store i1 %v21_40a667, i1* %cf.global-to-local, align 1
  store i32 %v5_40a667, i32* %ecx.global-to-local, align 4
  %v0_40a669 = load i32, i32* %edx.global-to-local, align 4
  %v1_40a669 = udiv i32 %v0_40a669, 256
  %v2_40a669 = trunc i32 %v1_40a669 to i8
  %v3_40a669 = load i8, i8* inttoptr (i32 4763889 to i8*), align 1
  %v5_40a669 = zext i1 %v21_40a667 to i8
  %v6_40a669 = add i8 %v2_40a669, %v3_40a669
  %v7_40a669 = add i8 %v6_40a669, %v5_40a669
  %v25_40a669 = icmp ule i8 %v7_40a669, %v2_40a669
  %v26_40a669 = icmp ult i8 %v6_40a669, %v2_40a669
  %v27_40a669 = select i1 %v21_40a667, i1 %v25_40a669, i1 %v26_40a669
  %v28_40a669 = zext i8 %v7_40a669 to i32
  %v30_40a669 = mul nuw nsw i32 %v28_40a669, 256
  %v31_40a669 = and i32 %v0_40a669, -65281
  %v32_40a669 = or i32 %v30_40a669, %v31_40a669
  %v2_40a66f = zext i1 %v27_40a669 to i32
  %v3_40a66f = add i32 %v32_40a669, 55
  %v4_40a66f = add i32 %v3_40a66f, %v2_40a66f
  %v21_40a66f = icmp ule i32 %v4_40a66f, %v32_40a669
  %v22_40a66f = icmp ugt i32 %v32_40a669, -56
  %v23_40a66f = select i1 %v27_40a669, i1 %v21_40a66f, i1 %v22_40a66f
  store i32 %v4_40a66f, i32* %edx.global-to-local, align 4
  %v3_40a672 = zext i1 %v23_40a66f to i32
  %v4_40a672 = add i32 %v1_40a667, %v6_40a5f4
  %v5_40a672 = add i32 %v3_40a672, %v4_40a672
  %v24_40a672 = icmp ule i32 %v5_40a672, %v6_40a5f4
  %v25_40a672 = icmp ult i32 %v4_40a672, %v6_40a5f4
  %v26_40a672 = select i1 %v23_40a66f, i1 %v24_40a672, i1 %v25_40a672
  store i32 %v5_40a672, i32* %eax.global-to-local, align 4
  %v1_40a674 = load i32, i32* inttoptr (i32 4763996 to i32*), align 4
  %v3_40a674 = zext i1 %v26_40a672 to i32
  %v4_40a674 = add i32 %v4_40a66f, %v1_40a674
  %v5_40a674 = add i32 %v3_40a674, %v4_40a674
  %v24_40a674 = icmp ule i32 %v5_40a674, %v4_40a66f
  %v25_40a674 = icmp ult i32 %v4_40a674, %v4_40a66f
  %v26_40a674 = select i1 %v26_40a672, i1 %v24_40a674, i1 %v25_40a674
  store i1 %v26_40a674, i1* %cf.global-to-local, align 1
  store i32 %v5_40a674, i32* %edx.global-to-local, align 4
  %v0_40a67a = load i32, i32* %ebx.global-to-local, align 4
  %v1_40a67a = trunc i32 %v0_40a67a to i8
  %v2_40a67a = load i8, i8* inttoptr (i32 4764001 to i8*), align 1
  %v3_40a67a = sub i8 %v1_40a67a, %v2_40a67a
  %v8_40a67a = icmp ult i8 %v1_40a67a, %v2_40a67a
  %v18_40a67a = zext i8 %v3_40a67a to i32
  %v20_40a67a = and i32 %v0_40a67a, -256
  %v21_40a67a = or i32 %v18_40a67a, %v20_40a67a
  store i32 %v21_40a67a, i32* %ebx.global-to-local, align 4
  %v2_40a680 = zext i1 %v8_40a67a to i32
  %v3_40a680 = add i32 %v1_40a667, -59
  %v4_40a680 = add i32 %v3_40a680, %v2_40a680
  store i32 %v4_40a680, i32* %esi.global-to-local, align 4
  %v0_40a683 = load i32, i32* inttoptr (i32 4763952 to i32*), align 16
  %v2_40a683 = xor i32 %v5_40a674, %v0_40a683
  store i32 %v2_40a683, i32* inttoptr (i32 4763952 to i32*), align 16
  %v0_40a689 = load i32, i32* inttoptr (i32 4763812 to i32*), align 4
  %v1_40a689 = load i32, i32* %eax.global-to-local, align 4
  %v4_40a689 = add i32 %v1_40a689, %v0_40a689
  store i32 %v4_40a689, i32* inttoptr (i32 4763812 to i32*), align 4
  %v0_40a68f = load i32, i32* inttoptr (i32 4763862 to i32*), align 4
  %v1_40a68f = load i32, i32* %edi.global-to-local, align 4
  %v2_40a68f = sub i32 %v0_40a68f, %v1_40a68f
  store i32 %v2_40a68f, i32* inttoptr (i32 4763862 to i32*), align 4
  %v0_40a695 = load i32, i32* %ecx.global-to-local, align 4
  %v1_40a69534 = add i32 %v0_40a695, 20992
  %v19_40a695 = and i32 %v1_40a69534, 65280
  %v20_40a695 = and i32 %v0_40a695, -65281
  %v21_40a695 = or i32 %v19_40a695, %v20_40a695
  store i32 %v21_40a695, i32* %ecx.global-to-local, align 4
  %v0_40a698 = load i32, i32* inttoptr (i32 4764123 to i32*), align 4
  %v1_40a698 = load i32, i32* %edi.global-to-local, align 4
  %v2_40a698 = and i32 %v1_40a698, %v0_40a698
  store i32 %v2_40a698, i32* inttoptr (i32 4764123 to i32*), align 4
  %v1_40a69e = load i32, i32* inttoptr (i32 4764044 to i32*), align 4
  %v2_40a69e = sub i32 %v1_40a698, %v1_40a69e
  %v7_40a69e = icmp ult i32 %v1_40a698, %v1_40a69e
  store i1 %v7_40a69e, i1* %cf.global-to-local, align 1
  store i32 %v2_40a69e, i32* %edi.global-to-local, align 4
  %v0_40a6a4 = load i32, i32* %eax.global-to-local, align 4
  %v1_40a6a4 = inttoptr i32 %v0_40a6a4 to i8*
  %v2_40a6a4 = load i8, i8* %v1_40a6a4, align 1
  %v4_40a6a4 = trunc i32 %v0_40a6a4 to i8
  %v5_40a6a4 = add i8 %v4_40a6a4, %v2_40a6a4
  %v10_40a6a4 = icmp ult i8 %v5_40a6a4, %v2_40a6a4
  store i1 %v10_40a6a4, i1* %cf.global-to-local, align 1
  store i8 %v5_40a6a4, i8* %v1_40a6a4, align 1
  %v0_40a6a6 = load i32, i32* %eax.global-to-local, align 4
  %v1_40a6a6 = inttoptr i32 %v0_40a6a6 to i8*
  %v2_40a6a6 = load i8, i8* %v1_40a6a6, align 1
  %v4_40a6a6 = trunc i32 %v0_40a6a6 to i8
  %v5_40a6a6 = add i8 %v4_40a6a6, %v2_40a6a6
  %v10_40a6a6 = icmp ult i8 %v5_40a6a6, %v2_40a6a6
  store i1 %v10_40a6a6, i1* %cf.global-to-local, align 1
  store i8 %v5_40a6a6, i8* %v1_40a6a6, align 1
  %v0_40a6a8 = load i32, i32* %eax.global-to-local, align 4
  %v1_40a6a8 = inttoptr i32 %v0_40a6a8 to i8*
  %v2_40a6a8 = load i8, i8* %v1_40a6a8, align 1
  %v4_40a6a8 = trunc i32 %v0_40a6a8 to i8
  %v5_40a6a8 = add i8 %v4_40a6a8, %v2_40a6a8
  %v10_40a6a8 = icmp ult i8 %v5_40a6a8, %v2_40a6a8
  store i1 %v10_40a6a8, i1* %cf.global-to-local, align 1
  store i8 %v5_40a6a8, i8* %v1_40a6a8, align 1
  %v0_40a6aa = load i32, i32* %ebx.global-to-local, align 4
  %v1_40a6aa = add i32 %v0_40a6aa, 1219606053
  %v2_40a6aa = inttoptr i32 %v1_40a6aa to i8*
  %v3_40a6aa = load i8, i8* %v2_40a6aa, align 1
  %v4_40a6aa = load i32, i32* %eax.global-to-local, align 4
  %v5_40a6aa = trunc i32 %v4_40a6aa to i8
  %v6_40a6aa = add i8 %v5_40a6aa, %v3_40a6aa
  %v11_40a6aa = icmp ult i8 %v6_40a6aa, %v3_40a6aa
  store i1 %v11_40a6aa, i1* %cf.global-to-local, align 1
  store i8 %v6_40a6aa, i8* %v2_40a6aa, align 1
  %v0_40a6b0 = load i8, i8* inttoptr (i32 -1014774271 to i8*), align 1
  %v1_40a6b0 = load i32, i32* %ebx.global-to-local, align 4
  %v2_40a6b0 = udiv i32 %v1_40a6b0, 256
  %v3_40a6b0 = trunc i32 %v2_40a6b0 to i8
  %v4_40a6b0 = add i8 %v3_40a6b0, %v0_40a6b0
  %v9_40a6b0 = icmp ult i8 %v4_40a6b0, %v0_40a6b0
  store i1 %v9_40a6b0, i1* %cf.global-to-local, align 1
  store i8 %v4_40a6b0, i8* inttoptr (i32 -1014774271 to i8*), align 1
  %v0_40a6b6 = load i32, i32* %esi.global-to-local, align 4
  %v1_40a6b6 = inttoptr i32 %v0_40a6b6 to i8*
  %v2_40a6b6 = load i8, i8* %v1_40a6b6, align 1
  %v3_40a6b6 = zext i8 %v2_40a6b6 to i32
  %v4_40a6b6 = load i32, i32* %eax.global-to-local, align 4
  %v5_40a6b6 = and i32 %v4_40a6b6, -256
  %v6_40a6b6 = or i32 %v5_40a6b6, %v3_40a6b6
  store i32 %v6_40a6b6, i32* %eax.global-to-local, align 4
  %v8_40a6b6 = load i1, i1* @df, align 1
  %v9_40a6b6 = select i1 %v8_40a6b6, i32 -1, i32 1
  %v10_40a6b6 = add i32 %v9_40a6b6, %v0_40a6b6
  store i32 %v10_40a6b6, i32* %esi.global-to-local, align 4
  %v0_40a6b7 = load i32, i32* inttoptr (i32 4763885 to i32*), align 4
  %v1_40a6b7 = load i1, i1* %cf.global-to-local, align 1
  %v2_40a6b7 = zext i1 %v1_40a6b7 to i32
  %v3_40a6b7 = add i32 %v0_40a6b7, 28
  %v4_40a6b7 = add i32 %v3_40a6b7, %v2_40a6b7
  store i32 %v4_40a6b7, i32* inttoptr (i32 4763885 to i32*), align 4
  %v0_40a6be = load i32, i32* inttoptr (i32 4763887 to i32*), align 4
  %v1_40a6be = load i32, i32* %edi.global-to-local, align 4
  %v2_40a6be = and i32 %v1_40a6be, %v0_40a6be
  store i32 %v2_40a6be, i32* inttoptr (i32 4763887 to i32*), align 4
  %v1_40a6c4 = load i32, i32* inttoptr (i32 4763893 to i32*), align 4
  %v2_40a6c4 = sub i32 %v1_40a6be, %v1_40a6c4
  %v7_40a6c4 = icmp ult i32 %v1_40a6be, %v1_40a6c4
  store i32 %v2_40a6c4, i32* %edi.global-to-local, align 4
  store i32 1, i32* %ecx.global-to-local, align 4
  %v1_40a6cf = load i32, i32* inttoptr (i32 4763925 to i32*), align 4
  %v4_40a6cf = select i1 %v7_40a6c4, i32 2, i32 1
  %v5_40a6cf = add i32 %v4_40a6cf, %v1_40a6cf
  store i32 %v5_40a6cf, i32* %ecx.global-to-local, align 4
  %v0_40a6d5 = load i32, i32* inttoptr (i32 4763690 to i32*), align 4
  %v2_40a6d5 = sub i32 %v0_40a6d5, %v2_40a6c4
  store i32 %v2_40a6d5, i32* inttoptr (i32 4763690 to i32*), align 4
  %v0_40a6db = load i32, i32* %edi.global-to-local, align 4
  %v1_40a6db = or i32 %v0_40a6db, -90
  store i32 %v1_40a6db, i32* %edi.global-to-local, align 4
  %v0_40a6de = load i32, i32* %ecx.global-to-local, align 4
  %v1_40a6de = load i32, i32* inttoptr (i32 4763807 to i32*), align 4
  %v4_40a6de = add i32 %v1_40a6de, %v0_40a6de
  %v25_40a6de = icmp ult i32 %v4_40a6de, %v0_40a6de
  store i32 %v4_40a6de, i32* %ecx.global-to-local, align 4
  store i32 202, i32* inttoptr (i32 4764021 to i32*), align 4
  %v0_40a6ee = load i32, i32* %ebx.global-to-local, align 4
  %v1_40a6ee = load i32, i32* inttoptr (i32 4763750 to i32*), align 4
  %v3_40a6ee = zext i1 %v25_40a6de to i32
  %v4_40a6ee = add i32 %v1_40a6ee, %v0_40a6ee
  %v5_40a6ee = add i32 %v4_40a6ee, %v3_40a6ee
  %v24_40a6ee = icmp ule i32 %v5_40a6ee, %v0_40a6ee
  %v25_40a6ee = icmp ult i32 %v4_40a6ee, %v0_40a6ee
  %v26_40a6ee = select i1 %v25_40a6de, i1 %v24_40a6ee, i1 %v25_40a6ee
  store i32 %v5_40a6ee, i32* %ebx.global-to-local, align 4
  store i32 1, i32* %edx.global-to-local, align 4
  %v1_40a6f9 = load i32, i32* inttoptr (i32 4764014 to i32*), align 4
  %v3_40a6f9 = zext i1 %v26_40a6ee to i32
  %v4_40a6f9 = add i32 %v1_40a6f9, 1
  %v5_40a6f9 = add i32 %v3_40a6f9, %v4_40a6f9
  %v24_40a6f9 = icmp ult i32 %v5_40a6f9, 2
  %v25_40a6f9 = icmp eq i32 %v4_40a6f9, 0
  %v26_40a6f9 = select i1 %v26_40a6ee, i1 %v24_40a6f9, i1 %v25_40a6f9
  store i32 %v5_40a6f9, i32* %edx.global-to-local, align 4
  %v0_40a6ff = load i32, i32* %edi.global-to-local, align 4
  %v3_40a6ff = zext i1 %v26_40a6f9 to i32
  %v4_40a6ff = sub i32 %v0_40a6ff, %v5_40a6f9
  %v5_40a6ff = add i32 %v3_40a6ff, %v4_40a6ff
  %v1_40a701 = add i32 %v5_40a6ff, -127
  %v5_40a701 = icmp ult i32 %v5_40a6ff, 127
  store i32 %v1_40a701, i32* %edi.global-to-local, align 4
  %v0_40a704 = load i32, i32* %eax.global-to-local, align 4
  %v1_40a704 = load i32, i32* inttoptr (i32 4763915 to i32*), align 4
  %v3_40a704 = zext i1 %v5_40a701 to i32
  %v4_40a704 = add i32 %v1_40a704, %v0_40a704
  %v5_40a704 = add i32 %v3_40a704, %v4_40a704
  %v24_40a704 = icmp ule i32 %v5_40a704, %v0_40a704
  %v25_40a704 = icmp ult i32 %v4_40a704, %v0_40a704
  %v26_40a704 = select i1 %v5_40a701, i1 %v24_40a704, i1 %v25_40a704
  store i32 %v5_40a704, i32* %eax.global-to-local, align 4
  %v0_40a70a = load i32, i32* inttoptr (i32 4763807 to i32*), align 4
  %v2_40a70a = zext i1 %v26_40a704 to i32
  %v3_40a70a = add i32 %v0_40a70a, -88
  %v4_40a70a = add i32 %v3_40a70a, %v2_40a70a
  %v12_40a70a = icmp ult i32 %v0_40a70a, 88
  %v13_40a70a = or i1 %v12_40a70a, %v26_40a704
  store i32 %v4_40a70a, i32* inttoptr (i32 4763807 to i32*), align 4
  %v0_40a711 = load i32, i32* inttoptr (i32 4763849 to i32*), align 4
  %v2_40a711 = zext i1 %v13_40a70a to i32
  %v3_40a711 = add i32 %v0_40a711, 238
  %v4_40a711 = add i32 %v3_40a711, %v2_40a711
  store i32 %v4_40a711, i32* inttoptr (i32 4763849 to i32*), align 4
  %v0_40a71b = load i32, i32* %edi.global-to-local, align 4
  %v1_40a71b = load i32, i32* %eax.global-to-local, align 4
  %v2_40a71b = xor i32 %v1_40a71b, %v0_40a71b
  store i32 %v2_40a71b, i32* %edi.global-to-local, align 4
  %v0_40a71d = load i32, i32* %edx.global-to-local, align 4
  %v1_40a71d = load i32, i32* inttoptr (i32 4763762 to i32*), align 4
  %v4_40a71d = add i32 %v1_40a71d, %v0_40a71d
  %v25_40a71d = icmp ult i32 %v4_40a71d, %v0_40a71d
  store i1 %v25_40a71d, i1* %cf.global-to-local, align 1
  store i32 %v4_40a71d, i32* %edx.global-to-local, align 4
  store i32 0, i32* %eax.global-to-local, align 4
  %v4_40a72b = call i32* @EncodePointer(i32* null)
  %v5_40a72b = ptrtoint i32* %v4_40a72b to i32
  store i32 %v5_40a72b, i32* %eax.global-to-local, align 4
  %v0_40a731 = load i32, i32* inttoptr (i32 4763949 to i32*), align 4
  %v1_40a731 = load i32, i32* %esi.global-to-local, align 4
  %v2_40a731 = load i1, i1* %cf.global-to-local, align 1
  %v3_40a731 = zext i1 %v2_40a731 to i32
  %v4_40a731 = add i32 %v1_40a731, %v0_40a731
  %v5_40a731 = add i32 %v4_40a731, %v3_40a731
  store i32 %v5_40a731, i32* inttoptr (i32 4763949 to i32*), align 4
  %v0_40a737 = load i32, i32* %edi.global-to-local, align 4
  %v1_40a737 = xor i32 %v0_40a737, 19
  store i32 %v1_40a737, i32* %edi.global-to-local, align 4
  store i32 1, i32* %ecx.global-to-local, align 4
  %v1_40a73f = load i32, i32* inttoptr (i32 4763710 to i32*), align 4
  %v4_40a73f = add i32 %v1_40a73f, 1
  store i32 %v4_40a73f, i32* %ecx.global-to-local, align 4
  %v0_40a745 = load i32, i32* inttoptr (i32 4763834 to i32*), align 4
  %v2_40a745 = add i32 %v0_40a745, %v4_40a73f
  %v7_40a745 = icmp ult i32 %v2_40a745, %v0_40a745
  store i32 %v2_40a745, i32* inttoptr (i32 4763834 to i32*), align 4
  store i32 1, i32* %edx.global-to-local, align 4
  %v1_40a750 = load i32, i32* inttoptr (i32 4763938 to i32*), align 4
  %v3_40a750 = zext i1 %v7_40a745 to i32
  %v4_40a750 = add i32 %v1_40a750, 1
  %v5_40a750 = add i32 %v4_40a750, %v3_40a750
  store i32 %v5_40a750, i32* %edx.global-to-local, align 4
  %v0_40a756 = load i32, i32* inttoptr (i32 4763975 to i32*), align 4
  %v1_40a756 = or i32 %v0_40a756, 227
  store i32 %v1_40a756, i32* inttoptr (i32 4763975 to i32*), align 4
  %v4_40a760 = sub i32 %v5_40a750, %v5_40a72b
  store i32 %v4_40a760, i32* %edx.global-to-local, align 4
  %v0_40a762 = load i32, i32* inttoptr (i32 4763764 to i32*), align 4
  %v1_40a762 = or i32 %v0_40a762, 80
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v1_40a762, i32* inttoptr (i32 4763764 to i32*), align 4
  %v1_40a769 = udiv i32 %v4_40a760, 256
  %v2_40a769 = trunc i32 %v1_40a769 to i8
  %v3_40a769 = load i8, i8* inttoptr (i32 4763706 to i8*), align 2
  %v6_40a769 = add i8 %v2_40a769, %v3_40a769
  %v26_40a769 = icmp ult i8 %v6_40a769, %v2_40a769
  %v28_40a769 = zext i8 %v6_40a769 to i32
  %v30_40a769 = mul nuw nsw i32 %v28_40a769, 256
  %v31_40a769 = and i32 %v4_40a760, -65281
  %v32_40a769 = or i32 %v30_40a769, %v31_40a769
  store i32 %v32_40a769, i32* %edx.global-to-local, align 4
  %v0_40a76f = load i32, i32* %esi.global-to-local, align 4
  %v2_40a76f = zext i1 %v26_40a769 to i32
  %v3_40a76f = add i32 %v0_40a76f, -88
  %v4_40a76f = add i32 %v3_40a76f, %v2_40a76f
  store i32 %v4_40a76f, i32* %esi.global-to-local, align 4
  store i32 0, i32* %eax.global-to-local, align 4
  %v0_40a774 = load i32, i32* inttoptr (i32 4763894 to i32*), align 4
  %v1_40a774 = and i32 %v0_40a774, 240
  store i32 %v1_40a774, i32* inttoptr (i32 4763894 to i32*), align 4
  %v0_40a77e = load i32, i32* inttoptr (i32 4763727 to i32*), align 4
  %v1_40a77e = load i32, i32* %edx.global-to-local, align 4
  %v2_40a77e = add i32 %v1_40a77e, %v0_40a77e
  store i32 %v2_40a77e, i32* inttoptr (i32 4763727 to i32*), align 4
  %v0_40a784 = load i32, i32* %esi.global-to-local, align 4
  %v1_40a784 = load i32, i32* inttoptr (i32 4763949 to i32*), align 4
  %v2_40a784 = sub i32 %v0_40a784, %v1_40a784
  store i32 %v2_40a784, i32* %esi.global-to-local, align 4
  %v0_40a78a = load i32, i32* %ecx.global-to-local, align 4
  %v1_40a78a = load i32, i32* inttoptr (i32 4764114 to i32*), align 4
  %v2_40a78a = or i32 %v1_40a78a, %v0_40a78a
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v2_40a78a, i32* %ecx.global-to-local, align 4
  call void @__pseudo_call(i32 4237208)
  %v0_40a798 = load i32, i32* inttoptr (i32 4763858 to i32*), align 4
  %v1_40a798 = load i32, i32* %edx.global-to-local, align 4
  %v2_40a798 = and i32 %v1_40a798, %v0_40a798
  store i32 %v2_40a798, i32* inttoptr (i32 4763858 to i32*), align 4
  %v0_40a79e = load i32, i32* %edi.global-to-local, align 4
  %v1_40a79e = load i32, i32* inttoptr (i32 4763906 to i32*), align 4
  %v2_40a79e = or i32 %v1_40a79e, %v0_40a79e
  store i32 %v2_40a79e, i32* %edi.global-to-local, align 4
  %v0_40a7a4 = load i32, i32* %ecx.global-to-local, align 4
  %v1_40a7a4 = and i32 %v0_40a7a4, 11
  store i32 %v1_40a7a4, i32* %ecx.global-to-local, align 4
  %v0_40a7a7 = load i32, i32* %esi.global-to-local, align 4
  %v1_40a7a7 = load i32, i32* %eax.global-to-local, align 4
  %v4_40a7a7 = add i32 %v1_40a7a7, %v0_40a7a7
  store i32 %v4_40a7a7, i32* %esi.global-to-local, align 4
  %v0_40a7a9 = load i32, i32* inttoptr (i32 4764086 to i32*), align 4
  %v2_40a7a9 = add i32 %v0_40a7a9, %v1_40a7a7
  store i32 %v2_40a7a9, i32* inttoptr (i32 4764086 to i32*), align 4
  %v1_40a7af = or i32 %v4_40a7a7, -38
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v1_40a7af, i32* %esi.global-to-local, align 4
  %v0_40a7b2 = load i8, i8* inttoptr (i32 4763989 to i8*), align 1
  %v1_40a7b2 = load i32, i32* %edx.global-to-local, align 4
  %v2_40a7b2 = udiv i32 %v1_40a7b2, 256
  %v3_40a7b2 = trunc i32 %v2_40a7b2 to i8
  %v4_40a7b2 = xor i8 %v3_40a7b2, %v0_40a7b2
  store i8 %v4_40a7b2, i8* inttoptr (i32 4763989 to i8*), align 1
  %v0_40a7b8 = load i32, i32* inttoptr (i32 4763911 to i32*), align 4
  %v1_40a7b8 = load i32, i32* %esi.global-to-local, align 4
  %v2_40a7b8 = add i32 %v1_40a7b8, %v0_40a7b8
  %v7_40a7b8 = icmp ult i32 %v2_40a7b8, %v0_40a7b8
  store i32 %v2_40a7b8, i32* inttoptr (i32 4763911 to i32*), align 4
  %v0_40a7be = load i32, i32* %edx.global-to-local, align 4
  %v1_40a7be = load i32, i32* inttoptr (i32 4764061 to i32*), align 4
  %v3_40a7be = zext i1 %v7_40a7b8 to i32
  %v4_40a7be = add i32 %v1_40a7be, %v0_40a7be
  %v5_40a7be = add i32 %v4_40a7be, %v3_40a7be
  store i32 %v5_40a7be, i32* %edx.global-to-local, align 4
  %v0_40a7c4 = load i32, i32* %ebx.global-to-local, align 4
  %v1_40a7c4 = add i32 %v0_40a7c4, -115
  store i32 %v1_40a7c4, i32* %ebx.global-to-local, align 4
  %v0_40a7c7 = load i32, i32* inttoptr (i32 4764077 to i32*), align 4
  %v1_40a7c7 = load i32, i32* %eax.global-to-local, align 4
  %v2_40a7c7 = sub i32 %v0_40a7c7, %v1_40a7c7
  %v7_40a7c7 = icmp ult i32 %v0_40a7c7, %v1_40a7c7
  store i32 %v2_40a7c7, i32* inttoptr (i32 4764077 to i32*), align 4
  %v0_40a7cd = load i32, i32* inttoptr (i32 4763959 to i32*), align 4
  %v3_40a7cd = zext i1 %v7_40a7c7 to i32
  %v4_40a7cd = add i32 %v3_40a7cd, %v0_40a7cd
  %v5_40a7cd = add i32 %v4_40a7cd, %v1_40a7c7
  store i32 %v5_40a7cd, i32* inttoptr (i32 4763959 to i32*), align 4
  %v0_40a7d3 = load i32, i32* inttoptr (i32 4763673 to i32*), align 4
  %v1_40a7d3 = xor i32 %v0_40a7d3, 35
  store i32 %v1_40a7d3, i32* inttoptr (i32 4763673 to i32*), align 4
  %v0_40a7da = load i32, i32* inttoptr (i32 4764047 to i32*), align 4
  %v3_40a7da = add i32 %v0_40a7da, 205
  %v22_40a7da = icmp ugt i32 %v0_40a7da, -206
  store i1 %v22_40a7da, i1* %cf.global-to-local, align 1
  store i32 %v3_40a7da, i32* inttoptr (i32 4764047 to i32*), align 4
  %v0_40a7e4 = load i32, i32* %eax.global-to-local, align 4
  %v1_40a7e4 = inttoptr i32 %v0_40a7e4 to i8*
  %v2_40a7e4 = load i8, i8* %v1_40a7e4, align 1
  %v4_40a7e4 = trunc i32 %v0_40a7e4 to i8
  %v5_40a7e4 = add i8 %v4_40a7e4, %v2_40a7e4
  %v10_40a7e4 = icmp ult i8 %v5_40a7e4, %v2_40a7e4
  store i1 %v10_40a7e4, i1* %cf.global-to-local, align 1
  store i8 %v5_40a7e4, i8* %v1_40a7e4, align 1
  %v0_40a7e6 = load i32, i32* %eax.global-to-local, align 4
  %v1_40a7e6 = inttoptr i32 %v0_40a7e6 to i8*
  %v2_40a7e6 = load i8, i8* %v1_40a7e6, align 1
  %v4_40a7e6 = trunc i32 %v0_40a7e6 to i8
  %v5_40a7e6 = add i8 %v4_40a7e6, %v2_40a7e6
  %v10_40a7e6 = icmp ult i8 %v5_40a7e6, %v2_40a7e6
  store i1 %v10_40a7e6, i1* %cf.global-to-local, align 1
  store i8 %v5_40a7e6, i8* %v1_40a7e6, align 1
  %v0_40a7e8 = load i32, i32* %eax.global-to-local, align 4
  %v1_40a7e8 = inttoptr i32 %v0_40a7e8 to i8*
  %v2_40a7e8 = load i8, i8* %v1_40a7e8, align 1
  %v4_40a7e8 = trunc i32 %v0_40a7e8 to i8
  %v5_40a7e8 = add i8 %v4_40a7e8, %v2_40a7e8
  %v10_40a7e8 = icmp ult i8 %v5_40a7e8, %v2_40a7e8
  store i1 %v10_40a7e8, i1* %cf.global-to-local, align 1
  store i8 %v5_40a7e8, i8* %v1_40a7e8, align 1
  %v0_40a7ea = load i32, i32* %eax.global-to-local, align 4
  %v1_40a7ea = inttoptr i32 %v0_40a7ea to i8*
  %v2_40a7ea = load i8, i8* %v1_40a7ea, align 1
  %v4_40a7ea = trunc i32 %v0_40a7ea to i8
  %v5_40a7ea = add i8 %v4_40a7ea, %v2_40a7ea
  %v10_40a7ea = icmp ult i8 %v5_40a7ea, %v2_40a7ea
  store i1 %v10_40a7ea, i1* %cf.global-to-local, align 1
  store i8 %v5_40a7ea, i8* %v1_40a7ea, align 1
  %v0_40a7ec = load i32, i32* %eax.global-to-local, align 4
  %v1_40a7ec = inttoptr i32 %v0_40a7ec to i8*
  %v2_40a7ec = load i8, i8* %v1_40a7ec, align 1
  %v4_40a7ec = trunc i32 %v0_40a7ec to i8
  %v5_40a7ec = add i8 %v4_40a7ec, %v2_40a7ec
  %v10_40a7ec = icmp ult i8 %v5_40a7ec, %v2_40a7ec
  store i1 %v10_40a7ec, i1* %cf.global-to-local, align 1
  store i8 %v5_40a7ec, i8* %v1_40a7ec, align 1
  %v0_40a7ee = load i32, i32* %esi.global-to-local, align 4
  %v1_40a7ee = load i32, i32* inttoptr (i32 4763699 to i32*), align 4
  %v2_40a7ee = load i1, i1* %cf.global-to-local, align 1
  %v3_40a7ee = zext i1 %v2_40a7ee to i32
  %v4_40a7ee = add i32 %v1_40a7ee, %v0_40a7ee
  %v5_40a7ee = add i32 %v4_40a7ee, %v3_40a7ee
  store i32 %v5_40a7ee, i32* %esi.global-to-local, align 4
  %v0_40a7f4 = load i32, i32* inttoptr (i32 4763744 to i32*), align 32
  %v1_40a7f4 = or i32 %v0_40a7f4, 12
  store i32 %v1_40a7f4, i32* inttoptr (i32 4763744 to i32*), align 32
  %v0_40a7fb = load i32, i32* inttoptr (i32 4763674 to i32*), align 4
  %v1_40a7fb = load i32, i32* %ebx.global-to-local, align 4
  %v2_40a7fb = sub i32 %v0_40a7fb, %v1_40a7fb
  %v7_40a7fb = icmp ult i32 %v0_40a7fb, %v1_40a7fb
  store i1 %v7_40a7fb, i1* %cf.global-to-local, align 1
  store i32 %v2_40a7fb, i32* inttoptr (i32 4763674 to i32*), align 4
  %v0_40a801 = load i8, i8* inttoptr (i32 4763963 to i8*), align 1
  %v1_40a801 = add i8 %v0_40a801, -126
  %v5_40a801 = icmp ult i8 %v0_40a801, 126
  store i1 %v5_40a801, i1* %cf.global-to-local, align 1
  store i8 %v1_40a801, i8* inttoptr (i32 4763963 to i8*), align 1
  %v0_40a808 = load i32, i32* inttoptr (i32 4763737 to i32*), align 4
  %v1_40a808 = load i32, i32* %ebx.global-to-local, align 4
  %v3_40a808 = zext i1 %v5_40a801 to i32
  %v4_40a808 = add i32 %v1_40a808, %v0_40a808
  %v5_40a808 = add i32 %v4_40a808, %v3_40a808
  store i32 %v5_40a808, i32* inttoptr (i32 4763737 to i32*), align 4
  %v0_40a80e = load i32, i32* %edi.global-to-local, align 4
  %v1_40a80e = load i32, i32* inttoptr (i32 4764086 to i32*), align 4
  %v2_40a80e = sub i32 %v0_40a80e, %v1_40a80e
  store i32 %v2_40a80e, i32* %edi.global-to-local, align 4
  %v0_40a814 = load i32, i32* %edx.global-to-local, align 4
  %v1_40a814 = and i32 %v0_40a814, -256
  %v19_40a816 = or i32 %v1_40a814, 194
  store i32 %v19_40a816, i32* %edx.global-to-local, align 4
  %v0_40a819 = load i32, i32* %ebx.global-to-local, align 4
  %v1_40a819 = load i32, i32* inttoptr (i32 4763923 to i32*), align 4
  %v2_40a819 = or i32 %v1_40a819, %v0_40a819
  store i32 %v2_40a819, i32* %ebx.global-to-local, align 4
  %v0_40a81f = load i32, i32* inttoptr (i32 4763775 to i32*), align 4
  %v2_40a81f = and i32 %v0_40a81f, %v2_40a80e
  store i32 %v2_40a81f, i32* inttoptr (i32 4763775 to i32*), align 4
  %v0_40a825 = load i32, i32* inttoptr (i32 4763748 to i32*), align 4
  %v2_40a825 = add i32 %v2_40a819, %v0_40a825
  store i32 %v2_40a825, i32* inttoptr (i32 4763748 to i32*), align 4
  store i32 -95, i32* %ecx.global-to-local, align 4
  %v0_40a833 = load i32, i32* %ebx.global-to-local, align 4
  %v1_40a833 = udiv i32 %v0_40a833, 256
  %v2_40a833 = trunc i32 %v1_40a833 to i8
  %v7_40a833 = icmp ult i8 %v2_40a833, -108
  %v3_40a833 = mul nuw i32 %v1_40a833, 256
  %v17_40a833 = add i32 %v3_40a833, 27648
  %v19_40a833 = and i32 %v17_40a833, 65280
  %v20_40a833 = and i32 %v0_40a833, -65281
  %v21_40a833 = or i32 %v19_40a833, %v20_40a833
  store i32 %v21_40a833, i32* %ebx.global-to-local, align 4
  %v0_40a836 = load i32, i32* %eax.global-to-local, align 4
  %v1_40a836 = load i32, i32* inttoptr (i32 4763788 to i32*), align 4
  %v3_40a836 = zext i1 %v7_40a833 to i32
  %v4_40a836 = add i32 %v1_40a836, %v0_40a836
  %v5_40a836 = add i32 %v4_40a836, %v3_40a836
  store i32 %v5_40a836, i32* %eax.global-to-local, align 4
  %v0_40a83c = load i32, i32* inttoptr (i32 4763668 to i32*), align 4
  %v1_40a83c = xor i32 %v0_40a83c, 9
  store i32 %v1_40a83c, i32* inttoptr (i32 4763668 to i32*), align 4
  %v0_40a843 = load i32, i32* %ecx.global-to-local, align 4
  %v1_40a843 = add i32 %v0_40a843, 43
  store i32 %v1_40a843, i32* %ecx.global-to-local, align 4
  %v0_40a846 = load i32, i32* %esi.global-to-local, align 4
  %v1_40a846 = load i32, i32* %edi.global-to-local, align 4
  %v2_40a846 = sub i32 %v0_40a846, %v1_40a846
  %v7_40a846 = icmp ult i32 %v0_40a846, %v1_40a846
  store i1 %v7_40a846, i1* %cf.global-to-local, align 1
  store i32 %v2_40a846, i32* %esi.global-to-local, align 4
  %v0_40a848 = load i8, i8* inttoptr (i32 4764093 to i8*), align 1
  %v1_40a848 = load i32, i32* %edx.global-to-local, align 4
  %v2_40a848 = udiv i32 %v1_40a848, 256
  %v3_40a848 = trunc i32 %v2_40a848 to i8
  %v4_40a848 = and i8 %v3_40a848, %v0_40a848
  store i8 %v4_40a848, i8* inttoptr (i32 4764093 to i8*), align 1
  store i1 false, i1* %cf.global-to-local, align 1
  %v8_40a860 = call i1 @SetEnvironmentVariableW(i16* bitcast ([13 x i8]* @global_var_48b685.2 to i16*), i16* bitcast ([17 x i8]* @global_var_48b692.1 to i16*))
  %v9_40a860 = sext i1 %v8_40a860 to i32
  %v12_40a860 = sext i1 %v8_40a860 to i8
  store i32 %v9_40a860, i32* %eax.global-to-local, align 4
  %v0_40a866 = load i32, i32* inttoptr (i32 4764119 to i32*), align 4
  %v1_40a866 = xor i32 %v0_40a866, 25
  store i32 %v1_40a866, i32* inttoptr (i32 4764119 to i32*), align 4
  store i32 1, i32* %edx.global-to-local, align 4
  %v1_40a872 = load i32, i32* inttoptr (i32 4763916 to i32*), align 4
  %v4_40a872 = add i32 %v1_40a872, 1
  %v16_40a872 = icmp eq i32 %v4_40a872, 0
  store i1 %v16_40a872, i1* %cf.global-to-local, align 1
  store i32 %v4_40a872, i32* %edx.global-to-local, align 4
  store i32 71, i32* inttoptr (i32 4763818 to i32*), align 4
  %v3_40a882 = load i8, i8* inttoptr (i32 4763855 to i8*), align 1
  %v5_40a882 = zext i1 %v16_40a872 to i8
  %v6_40a882 = add i8 %v3_40a882, %v12_40a860
  %v7_40a882 = add i8 %v6_40a882, %v5_40a882
  %v25_40a882 = icmp ule i8 %v7_40a882, %v12_40a860
  %v26_40a882 = icmp ult i8 %v6_40a882, %v12_40a860
  %v27_40a882 = select i1 %v16_40a872, i1 %v25_40a882, i1 %v26_40a882
  %v28_40a882 = zext i8 %v7_40a882 to i32
  %v31_40a882 = select i1 %v8_40a860, i32 -256, i32 0
  %v32_40a882 = or i32 %v28_40a882, %v31_40a882
  store i32 %v32_40a882, i32* %eax.global-to-local, align 4
  %v0_40a888 = load i32, i32* inttoptr (i32 4763671 to i32*), align 4
  %v1_40a888 = load i32, i32* %ebx.global-to-local, align 4
  %v3_40a888 = zext i1 %v27_40a882 to i32
  %v4_40a888 = sub i32 %v0_40a888, %v1_40a888
  %v5_40a888 = add i32 %v4_40a888, %v3_40a888
  store i32 %v5_40a888, i32* inttoptr (i32 4763671 to i32*), align 4
  %v0_40a88e = load i32, i32* %edi.global-to-local, align 4
  %v1_40a88e = load i32, i32* %eax.global-to-local, align 4
  %v2_40a88e = xor i32 %v1_40a88e, %v0_40a88e
  store i32 %v2_40a88e, i32* %edi.global-to-local, align 4
  %v1_40a890 = load i32, i32* inttoptr (i32 4763696 to i32*), align 16
  %v2_40a890 = sub i32 %v2_40a88e, %v1_40a890
  store i32 %v2_40a890, i32* %edi.global-to-local, align 4
  %v2_40a896 = add i32 %v1_40a88e, 161
  %v16_40a896 = and i32 %v2_40a896, 255
  %v18_40a896 = and i32 %v1_40a88e, -256
  %v19_40a896 = or i32 %v16_40a896, %v18_40a896
  store i32 %v19_40a896, i32* %eax.global-to-local, align 4
  %v0_40a898 = load i32, i32* %edx.global-to-local, align 4
  %v1_40a898 = and i32 %v0_40a898, 47
  store i32 %v1_40a898, i32* %edx.global-to-local, align 4
  %v0_40a89b = load i32, i32* inttoptr (i32 4763939 to i32*), align 4
  %v3_40a89b = add i32 %v0_40a89b, 226
  store i32 %v3_40a89b, i32* inttoptr (i32 4763939 to i32*), align 4
  %v0_40a8a5 = load i32, i32* %eax.global-to-local, align 4
  %v1_40a8a5 = add i32 %v0_40a8a5, -84
  store i32 %v1_40a8a5, i32* %eax.global-to-local, align 4
  %v0_40a8a8 = load i32, i32* %ebx.global-to-local, align 4
  %v1_40a8a8 = load i32, i32* %esi.global-to-local, align 4
  %v2_40a8a8 = add i32 %v1_40a8a8, %v0_40a8a8
  store i32 %v2_40a8a8, i32* %ebx.global-to-local, align 4
  %v0_40a8aa = load i32, i32* inttoptr (i32 4763821 to i32*), align 4
  %v1_40a8aa = xor i32 %v0_40a8aa, 78
  store i32 %v1_40a8aa, i32* inttoptr (i32 4763821 to i32*), align 4
  %v0_40a8b1 = load i32, i32* %eax.global-to-local, align 4
  %v3_40a8b1 = load i32, i32* %edx.global-to-local, align 4
  %v4_40a8b1 = and i32 %v3_40a8b1, 65280
  %v1_40a8b136 = add i32 %v4_40a8b1, %v0_40a8b1
  %v23_40a8b1 = and i32 %v1_40a8b136, 65280
  %v24_40a8b1 = and i32 %v0_40a8b1, -65281
  %v25_40a8b1 = or i32 %v23_40a8b1, %v24_40a8b1
  store i32 %v25_40a8b1, i32* %eax.global-to-local, align 4
  %v0_40a8b3 = load i32, i32* inttoptr (i32 4763911 to i32*), align 4
  %v1_40a8b3 = load i32, i32* %edi.global-to-local, align 4
  %v2_40a8b3 = add i32 %v1_40a8b3, %v0_40a8b3
  store i32 %v2_40a8b3, i32* inttoptr (i32 4763911 to i32*), align 4
  %v0_40a8b9 = load i32, i32* %esi.global-to-local, align 4
  %v2_40a8b9 = add i32 %v1_40a8b3, %v0_40a8b9
  %v1_40a8bb = load i32, i32* %eax.global-to-local, align 4
  %v2_40a8bb = add i32 %v2_40a8b9, %v1_40a8bb
  store i32 %v2_40a8bb, i32* %esi.global-to-local, align 4
  %v0_40a8bd = load i32, i32* inttoptr (i32 4763816 to i32*), align 8
  %v2_40a8bd = or i32 %v0_40a8bd, %v1_40a8b3
  store i32 %v2_40a8bd, i32* inttoptr (i32 4763816 to i32*), align 8
  %v0_40a8c3 = load i32, i32* inttoptr (i32 4764050 to i32*), align 4
  %v1_40a8c3 = load i32, i32* %ebx.global-to-local, align 4
  %v4_40a8c3 = sub i32 %v0_40a8c3, %v1_40a8c3
  store i32 %v4_40a8c3, i32* inttoptr (i32 4764050 to i32*), align 4
  %v0_40a8c9 = load i32, i32* inttoptr (i32 4764116 to i32*), align 4
  %v2_40a8c9 = sub i32 %v0_40a8c9, %v1_40a8c3
  %v7_40a8c9 = icmp ult i32 %v0_40a8c9, %v1_40a8c3
  store i1 %v7_40a8c9, i1* %cf.global-to-local, align 1
  store i32 %v2_40a8c9, i32* inttoptr (i32 4764116 to i32*), align 4
  call void @__pseudo_call(i32 4237527)
  %v0_40a8d7 = load i32, i32* inttoptr (i32 4764006 to i32*), align 4
  %v1_40a8d7 = load i32, i32* %edi.global-to-local, align 4
  %v2_40a8d7 = or i32 %v1_40a8d7, %v0_40a8d7
  store i32 %v2_40a8d7, i32* inttoptr (i32 4764006 to i32*), align 4
  %v0_40a8dd = load i32, i32* %ebx.global-to-local, align 4
  %v2_40a8dd = sub i32 %v0_40a8dd, %v1_40a8d7
  store i32 %v2_40a8dd, i32* %ebx.global-to-local, align 4
  %v0_40a8df = load i32, i32* %eax.global-to-local, align 4
  %v1_40a8df = add i32 %v0_40a8df, 115
  store i32 %v1_40a8df, i32* %eax.global-to-local, align 4
  %v1_40a8e7 = load i32, i32* %esi.global-to-local, align 4
  %v2_40a8e7 = add i32 %v1_40a8e7, 1
  %v7_40a8e7 = icmp eq i32 %v2_40a8e7, 0
  store i1 %v7_40a8e7, i1* %cf.global-to-local, align 1
  store i32 %v2_40a8e7, i32* %ecx.global-to-local, align 4
  %v0_40a8e9 = load i8, i8* inttoptr (i32 4764097 to i8*), align 1
  %v2_40a8e9 = udiv i32 %v1_40a8df, 256
  %v3_40a8e9 = trunc i32 %v2_40a8e9 to i8
  %v4_40a8e9 = add i8 %v0_40a8e9, %v3_40a8e9
  %v9_40a8e9 = icmp ult i8 %v4_40a8e9, %v0_40a8e9
  store i1 %v9_40a8e9, i1* %cf.global-to-local, align 1
  store i8 %v4_40a8e9, i8* inttoptr (i32 4764097 to i8*), align 1
  %v0_40a8ef = load i8, i8* inttoptr (i32 4763913 to i8*), align 1
  %v1_40a8ef = load i32, i32* %eax.global-to-local, align 4
  %v2_40a8ef = udiv i32 %v1_40a8ef, 256
  %v3_40a8ef = trunc i32 %v2_40a8ef to i8
  %v4_40a8ef = add i8 %v3_40a8ef, %v0_40a8ef
  store i8 %v4_40a8ef, i8* inttoptr (i32 4763913 to i8*), align 1
  %v0_40a8f5 = load i32, i32* %ecx.global-to-local, align 4
  %v1_40a8f5 = load i32, i32* inttoptr (i32 4763680 to i32*), align 32
  %v2_40a8f5 = sub i32 %v0_40a8f5, %v1_40a8f5
  store i32 %v2_40a8f5, i32* %ecx.global-to-local, align 4
  %v0_40a8fb = load i32, i32* %esi.global-to-local, align 4
  %v1_40a8fb = load i32, i32* %edi.global-to-local, align 4
  %v2_40a8fb = xor i32 %v1_40a8fb, %v0_40a8fb
  store i32 %v2_40a8fb, i32* %esi.global-to-local, align 4
  %v0_40a8fd = load i32, i32* %eax.global-to-local, align 4
  %v1_40a8fd = load i32, i32* inttoptr (i32 4763941 to i32*), align 4
  %v2_40a8fd = sub i32 %v0_40a8fd, %v1_40a8fd
  store i32 %v2_40a8fd, i32* %eax.global-to-local, align 4
  %v0_40a903 = load i32, i32* %edx.global-to-local, align 4
  %v1_40a903 = load i32, i32* inttoptr (i32 4764076 to i32*), align 4
  %v2_40a903 = or i32 %v1_40a903, %v0_40a903
  store i32 %v2_40a903, i32* %edx.global-to-local, align 4
  %v2_40a909 = xor i32 %v2_40a903, %v2_40a8fd
  store i32 %v2_40a909, i32* %eax.global-to-local, align 4
  %v0_40a90b = load i32, i32* inttoptr (i32 4763877 to i32*), align 4
  %v2_40a90b = xor i32 %v0_40a90b, %v2_40a909
  store i32 %v2_40a90b, i32* inttoptr (i32 4763877 to i32*), align 4
  %v0_40a911 = load i32, i32* %esi.global-to-local, align 4
  %v1_40a911 = load i32, i32* %ecx.global-to-local, align 4
  %v4_40a911 = add i32 %v1_40a911, %v0_40a911
  store i32 %v4_40a911, i32* %esi.global-to-local, align 4
  store i32 0, i32* %eax.global-to-local, align 4
  store i32 124, i32* inttoptr (i32 4764042 to i32*), align 4
  %v0_40a91f = load i32, i32* inttoptr (i32 4764038 to i32*), align 4
  %v3_40a91f = add i32 %v0_40a91f, 108
  %v22_40a91f = icmp ugt i32 %v0_40a91f, -109
  store i1 %v22_40a91f, i1* %cf.global-to-local, align 1
  store i32 %v3_40a91f, i32* inttoptr (i32 4764038 to i32*), align 4
  %v0_40a926 = load i32, i32* %eax.global-to-local, align 4
  %v1_40a926 = inttoptr i32 %v0_40a926 to i8*
  %v2_40a926 = load i8, i8* %v1_40a926, align 1
  %v4_40a926 = trunc i32 %v0_40a926 to i8
  %v5_40a926 = add i8 %v4_40a926, %v2_40a926
  %v10_40a926 = icmp ult i8 %v5_40a926, %v2_40a926
  store i1 %v10_40a926, i1* %cf.global-to-local, align 1
  store i8 %v5_40a926, i8* %v1_40a926, align 1
  %v0_40a928 = load i32, i32* %eax.global-to-local, align 4
  %v1_40a928 = inttoptr i32 %v0_40a928 to i8*
  %v2_40a928 = load i8, i8* %v1_40a928, align 1
  %v4_40a928 = trunc i32 %v0_40a928 to i8
  %v5_40a928 = add i8 %v4_40a928, %v2_40a928
  %v10_40a928 = icmp ult i8 %v5_40a928, %v2_40a928
  store i1 %v10_40a928, i1* %cf.global-to-local, align 1
  store i8 %v5_40a928, i8* %v1_40a928, align 1
  %v0_40a92a = load i32, i32* %eax.global-to-local, align 4
  %v1_40a92a = inttoptr i32 %v0_40a92a to i8*
  %v2_40a92a = load i8, i8* %v1_40a92a, align 1
  %v4_40a92a = trunc i32 %v0_40a92a to i8
  %v5_40a92a = add i8 %v4_40a92a, %v2_40a92a
  %v10_40a92a = icmp ult i8 %v5_40a92a, %v2_40a92a
  store i1 %v10_40a92a, i1* %cf.global-to-local, align 1
  store i8 %v5_40a92a, i8* %v1_40a92a, align 1
  %v0_40a92c = load i32, i32* %eax.global-to-local, align 4
  %v1_40a92c = inttoptr i32 %v0_40a92c to i8*
  %v2_40a92c = load i8, i8* %v1_40a92c, align 1
  %v4_40a92c = trunc i32 %v0_40a92c to i8
  %v5_40a92c = add i8 %v4_40a92c, %v2_40a92c
  %v10_40a92c = icmp ult i8 %v5_40a92c, %v2_40a92c
  store i1 %v10_40a92c, i1* %cf.global-to-local, align 1
  store i8 %v5_40a92c, i8* %v1_40a92c, align 1
  %v0_40a92e = load i32, i32* %ecx.global-to-local, align 4
  %v1_40a92e = inttoptr i32 %v0_40a92e to i8*
  %v2_40a92e = load i8, i8* %v1_40a92e, align 1
  %v3_40a92e = load i32, i32* %ebx.global-to-local, align 4
  %v4_40a92e = trunc i32 %v3_40a92e to i8
  %v5_40a92e = add i8 %v4_40a92e, %v2_40a92e
  store i8 %v5_40a92e, i8* %v1_40a92e, align 1
  %v1_40a930 = load x86_fp80, x86_fp80* %st0.global-to-local, align 4
  %v2_40a930 = fptosi x86_fp80 %v1_40a930 to i16
  %v3_40a930 = load i32, i32* %ebx.global-to-local, align 4
  %v4_40a930 = inttoptr i32 %v3_40a930 to i16*
  store i16 %v2_40a930, i16* %v4_40a930, align 2
  %v0_40a937 = load i32, i32* inttoptr (i32 4763897 to i32*), align 4
  %v1_40a937 = and i32 %v0_40a937, 101
  store i32 %v1_40a937, i32* inttoptr (i32 4763897 to i32*), align 4
  %v0_40a93e = load i32, i32* inttoptr (i32 4764127 to i32*), align 4
  %v1_40a93e = load i32, i32* %esi.global-to-local, align 4
  %v4_40a93e = add i32 %v1_40a93e, %v0_40a93e
  store i32 %v4_40a93e, i32* inttoptr (i32 4764127 to i32*), align 4
  %v0_40a944 = load i32, i32* %eax.global-to-local, align 4
  %v1_40a944 = add i32 %v0_40a944, 102
  %v1_40a947 = load i32, i32* %edi.global-to-local, align 4
  %v2_40a947 = add i32 %v1_40a947, %v1_40a944
  %v7_40a947 = icmp ult i32 %v2_40a947, %v1_40a944
  store i1 %v7_40a947, i1* %cf.global-to-local, align 1
  store i32 %v2_40a947, i32* %eax.global-to-local, align 4
  %v0_40a949 = load i8, i8* inttoptr (i32 4764123 to i8*), align 1
  %v2_40a949 = udiv i32 %v2_40a947, 256
  %v3_40a949 = trunc i32 %v2_40a949 to i8
  %v5_40a949 = zext i1 %v7_40a947 to i8
  %v6_40a949 = add i8 %v0_40a949, %v3_40a949
  %v7_40a949 = add i8 %v6_40a949, %v5_40a949
  %v25_40a949 = icmp ule i8 %v7_40a949, %v0_40a949
  %v26_40a949 = icmp ult i8 %v6_40a949, %v0_40a949
  %v27_40a949 = select i1 %v7_40a947, i1 %v25_40a949, i1 %v26_40a949
  store i1 %v27_40a949, i1* %cf.global-to-local, align 1
  store i8 %v7_40a949, i8* inttoptr (i32 4764123 to i8*), align 1
  %v0_40a94f = load i32, i32* %ebx.global-to-local, align 4
  %v2_40a94f = zext i1 %v27_40a949 to i32
  %v3_40a94f = add i32 %v0_40a94f, 32
  %v4_40a94f = add i32 %v3_40a94f, %v2_40a94f
  store i32 %v4_40a94f, i32* %ebx.global-to-local, align 4
  %v0_40a952 = load i32, i32* %eax.global-to-local, align 4
  %v1_40a952 = add i32 %v0_40a952, 84
  store i32 %v1_40a952, i32* %eax.global-to-local, align 4
  %v0_40a955 = load i32, i32* %esi.global-to-local, align 4
  %v2_40a955 = mul i32 %v0_40a955, 2
  %v7_40a955 = icmp ult i32 %v2_40a955, %v0_40a955
  store i32 %v2_40a955, i32* %esi.global-to-local, align 4
  %v0_40a957 = load i32, i32* inttoptr (i32 4764090 to i32*), align 4
  %v3_40a957 = zext i1 %v7_40a955 to i32
  %v4_40a957 = sub i32 %v0_40a957, %v2_40a955
  %v5_40a957 = add i32 %v4_40a957, %v3_40a957
  store i32 %v5_40a957, i32* inttoptr (i32 4764090 to i32*), align 4
  %v0_40a95d = load i32, i32* inttoptr (i32 4763687 to i32*), align 4
  %v1_40a95d = load i32, i32* %eax.global-to-local, align 4
  %v2_40a95d = or i32 %v1_40a95d, %v0_40a95d
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v2_40a95d, i32* inttoptr (i32 4763687 to i32*), align 4
  store i32 0, i32* %eax.global-to-local, align 4
  %v4_40a96b = call i32* @EncodePointer(i32* null)
  %v5_40a96b = ptrtoint i32* %v4_40a96b to i32
  store i32 %v5_40a96b, i32* %eax.global-to-local, align 4
  %v0_40a971 = load i32, i32* %edi.global-to-local, align 4
  %v1_40a971 = load i32, i32* inttoptr (i32 4764146 to i32*), align 4
  %v2_40a971 = load i1, i1* %cf.global-to-local, align 1
  %v3_40a971 = zext i1 %v2_40a971 to i32
  %v4_40a971 = add i32 %v1_40a971, %v0_40a971
  %v5_40a971 = add i32 %v4_40a971, %v3_40a971
  store i32 %v5_40a971, i32* %edi.global-to-local, align 4
  store i32 74, i32* %ecx.global-to-local, align 4
  %v0_40a97f = load i32, i32* inttoptr (i32 4764126 to i32*), align 4
  %v1_40a97f = xor i32 %v0_40a97f, 61
  store i32 %v1_40a97f, i32* inttoptr (i32 4764126 to i32*), align 4
  %v1_40a986 = add i32 %v5_40a971, 82
  store i32 %v1_40a986, i32* %edi.global-to-local, align 4
  %v0_40a989 = load i32, i32* inttoptr (i32 4763845 to i32*), align 4
  %v1_40a989 = or i32 %v0_40a989, 142
  store i32 %v1_40a989, i32* inttoptr (i32 4763845 to i32*), align 4
  %v0_40a993 = load i32, i32* inttoptr (i32 4763740 to i32*), align 4
  %v1_40a993 = load i32, i32* %ebx.global-to-local, align 4
  %v2_40a993 = xor i32 %v1_40a993, %v0_40a993
  store i32 %v2_40a993, i32* inttoptr (i32 4763740 to i32*), align 4
  %v0_40a999 = load i32, i32* inttoptr (i32 4763979 to i32*), align 4
  %v3_40a999 = add i32 %v0_40a999, 129
  %v22_40a999 = icmp ugt i32 %v0_40a999, -130
  store i32 %v3_40a999, i32* inttoptr (i32 4763979 to i32*), align 4
  %v0_40a9a3 = load i32, i32* inttoptr (i32 4764063 to i32*), align 4
  %v3_40a9a3 = select i1 %v22_40a999, i32 9, i32 8
  %v4_40a9a3 = add i32 %v3_40a9a3, %v0_40a9a3
  store i32 %v4_40a9a3, i32* inttoptr (i32 4764063 to i32*), align 4
  %v0_40a9aa = load i32, i32* %ebx.global-to-local, align 4
  %v1_40a9aa = add i32 %v0_40a9aa, -101
  store i32 %v1_40a9aa, i32* %ebx.global-to-local, align 4
  %v1_40a9ad = load i32, i32* inttoptr (i32 4763932 to i32*), align 4
  %v2_40a9ad = sub i32 %v1_40a9aa, %v1_40a9ad
  store i32 %v2_40a9ad, i32* %ebx.global-to-local, align 4
  %v0_40a9b3 = load i32, i32* %ecx.global-to-local, align 4
  %v1_40a9b3 = load i32, i32* %esi.global-to-local, align 4
  %v2_40a9b3 = xor i32 %v1_40a9b3, %v0_40a9b3
  store i32 %v2_40a9b3, i32* %ecx.global-to-local, align 4
  %v0_40a9b5 = load i32, i32* inttoptr (i32 4764140 to i32*), align 4
  %v4_40a9b5 = add i32 %v0_40a9b5, %v2_40a9b3
  store i32 %v4_40a9b5, i32* inttoptr (i32 4764140 to i32*), align 4
  %v0_40a9bb = load i32, i32* %ebx.global-to-local, align 4
  %v1_40a9bb = add i32 %v0_40a9bb, 65
  %v5_40a9bb = icmp ugt i32 %v0_40a9bb, -66
  store i32 %v1_40a9bb, i32* %ebx.global-to-local, align 4
  %v0_40a9be = load i32, i32* %ecx.global-to-local, align 4
  %v1_40a9be = load i32, i32* inttoptr (i32 4763715 to i32*), align 4
  %v3_40a9be = zext i1 %v5_40a9bb to i32
  %v4_40a9be = add i32 %v1_40a9be, %v0_40a9be
  %v5_40a9be = add i32 %v4_40a9be, %v3_40a9be
  %v24_40a9be = icmp ule i32 %v5_40a9be, %v0_40a9be
  %v25_40a9be = icmp ult i32 %v4_40a9be, %v0_40a9be
  %v26_40a9be = select i1 %v5_40a9bb, i1 %v24_40a9be, i1 %v25_40a9be
  store i1 %v26_40a9be, i1* %cf.global-to-local, align 1
  store i32 %v5_40a9be, i32* %ecx.global-to-local, align 4
  call void @__pseudo_call(i32 4237772)
  %v0_40a9cc = load i32, i32* %ebx.global-to-local, align 4
  %v1_40a9cc = udiv i32 %v0_40a9cc, 256
  %v2_40a9cc = trunc i32 %v1_40a9cc to i8
  %v3_40a9cc = load i8, i8* inttoptr (i32 4763708 to i8*), align 4
  %v4_40a9cc = load i1, i1* %cf.global-to-local, align 1
  %v5_40a9cc = zext i1 %v4_40a9cc to i8
  %v6_40a9cc = add i8 %v2_40a9cc, %v3_40a9cc
  %v7_40a9cc = add i8 %v6_40a9cc, %v5_40a9cc
  %v25_40a9cc = icmp ule i8 %v7_40a9cc, %v2_40a9cc
  %v26_40a9cc = icmp ult i8 %v6_40a9cc, %v2_40a9cc
  %v27_40a9cc = select i1 %v4_40a9cc, i1 %v25_40a9cc, i1 %v26_40a9cc
  %v28_40a9cc = zext i8 %v7_40a9cc to i32
  %v30_40a9cc = mul nuw nsw i32 %v28_40a9cc, 256
  %v31_40a9cc = and i32 %v0_40a9cc, -65281
  %v32_40a9cc = or i32 %v30_40a9cc, %v31_40a9cc
  store i32 %v32_40a9cc, i32* %ebx.global-to-local, align 4
  %v1_40a9d2 = load i32, i32* inttoptr (i32 4763934 to i32*), align 4
  %v3_40a9d2 = zext i1 %v27_40a9cc to i32
  %v4_40a9d2 = add i32 %v1_40a9d2, %v5_40a96b
  %v5_40a9d2 = add i32 %v4_40a9d2, %v3_40a9d2
  store i32 %v5_40a9d2, i32* %eax.global-to-local, align 4
  %v1_40a9d8 = load i32, i32* %ecx.global-to-local, align 4
  %v2_40a9d8 = add i32 %v32_40a9cc, %v1_40a9d8
  store i32 %v2_40a9d8, i32* %ebx.global-to-local, align 4
  %v0_40a9da = load i32, i32* inttoptr (i32 4763828 to i32*), align 4
  %v1_40a9da = xor i32 %v0_40a9da, 114
  store i32 %v1_40a9da, i32* inttoptr (i32 4763828 to i32*), align 4
  %v0_40a9e1 = load i32, i32* inttoptr (i32 4764103 to i32*), align 4
  %v4_40a9e1 = sub i32 %v0_40a9e1, %v2_40a9d8
  %v20_40a9e1 = icmp ult i32 %v0_40a9e1, %v2_40a9d8
  store i32 %v4_40a9e1, i32* inttoptr (i32 4764103 to i32*), align 4
  %v0_40a9e7 = load i32, i32* %eax.global-to-local, align 4
  %v1_40a9e7 = load i32, i32* inttoptr (i32 4763737 to i32*), align 4
  %v3_40a9e7 = zext i1 %v20_40a9e1 to i32
  %v4_40a9e7 = add i32 %v3_40a9e7, %v0_40a9e7
  %v5_40a9e7 = add i32 %v4_40a9e7, %v1_40a9e7
  store i32 %v5_40a9e7, i32* %eax.global-to-local, align 4
  %v0_40a9ed = load i32, i32* %edi.global-to-local, align 4
  %v1_40a9ed = load i32, i32* inttoptr (i32 4763681 to i32*), align 4
  %v2_40a9ed = or i32 %v1_40a9ed, %v0_40a9ed
  store i32 %v2_40a9ed, i32* %edi.global-to-local, align 4
  %v1_40a9f8 = load i32, i32* %ebx.global-to-local, align 4
  %v2_40a9f8 = add i32 %v1_40a9f8, 1
  store i32 %v2_40a9f8, i32* %edx.global-to-local, align 4
  %v0_40a9fa = load i32, i32* %ecx.global-to-local, align 4
  %v1_40a9fa = add i32 %v0_40a9fa, 13
  store i32 %v1_40a9fa, i32* %ecx.global-to-local, align 4
  %v0_40a9fd = load i32, i32* %esi.global-to-local, align 4
  %v2_40a9fd = xor i32 %v0_40a9fd, %v1_40a9fa
  store i32 %v2_40a9fd, i32* %esi.global-to-local, align 4
  %v0_40a9ff = load i32, i32* inttoptr (i32 4763717 to i32*), align 4
  %v2_40a9ff = add i32 %v0_40a9ff, %v2_40a9f8
  %v7_40a9ff = icmp ult i32 %v2_40a9ff, %v0_40a9ff
  store i32 %v2_40a9ff, i32* inttoptr (i32 4763717 to i32*), align 4
  %v0_40aa05 = load i32, i32* %edi.global-to-local, align 4
  %v1_40aa05 = load i32, i32* %eax.global-to-local, align 4
  %v3_40aa05 = zext i1 %v7_40a9ff to i32
  %v4_40aa05 = sub i32 %v0_40aa05, %v1_40aa05
  %v5_40aa05 = add i32 %v4_40aa05, %v3_40aa05
  store i32 %v5_40aa05, i32* %edi.global-to-local, align 4
  %v0_40aa07 = load i32, i32* %esi.global-to-local, align 4
  %v2_40aa07 = mul i32 %v0_40aa07, 2
  %v2_40aa09 = xor i32 %v2_40aa07, %v1_40aa05
  store i32 %v2_40aa09, i32* %esi.global-to-local, align 4
  %v0_40aa0b = load i32, i32* %edx.global-to-local, align 4
  %v3_40aa0b = add i32 %v0_40aa0b, -67
  store i32 %v3_40aa0b, i32* %edx.global-to-local, align 4
  %v0_40aa0e = load i32, i32* inttoptr (i32 4764093 to i32*), align 4
  %v2_40aa0e = xor i32 %v0_40aa0e, %v5_40aa05
  store i32 %v2_40aa0e, i32* inttoptr (i32 4764093 to i32*), align 4
  %v0_40aa14 = load i32, i32* inttoptr (i32 4763710 to i32*), align 4
  %v3_40aa14 = add i32 %v0_40aa14, -80
  store i32 %v3_40aa14, i32* inttoptr (i32 4763710 to i32*), align 4
  %v0_40aa1b = load i32, i32* %eax.global-to-local, align 4
  %v1_40aa1b = load i32, i32* %edi.global-to-local, align 4
  %v2_40aa1b = xor i32 %v1_40aa1b, %v0_40aa1b
  store i32 %v2_40aa1b, i32* %eax.global-to-local, align 4
  %v0_40aa1d = load i32, i32* inttoptr (i32 4763966 to i32*), align 4
  %v3_40aa1d = add i32 %v0_40aa1d, 59
  store i32 %v3_40aa1d, i32* inttoptr (i32 4763966 to i32*), align 4
  %v1_40aa24 = add i32 %v1_40aa1b, -1
  %v5_40aa24 = icmp eq i32 %v1_40aa1b, 0
  store i1 %v5_40aa24, i1* %cf.global-to-local, align 1
  store i32 %v1_40aa24, i32* %edi.global-to-local, align 4
  %v0_40aa27 = load i32, i32* %eax.global-to-local, align 4
  %v1_40aa27 = inttoptr i32 %v0_40aa27 to i8*
  %v2_40aa27 = load i8, i8* %v1_40aa27, align 1
  %v4_40aa27 = trunc i32 %v0_40aa27 to i8
  %v5_40aa27 = add i8 %v4_40aa27, %v2_40aa27
  %v10_40aa27 = icmp ult i8 %v5_40aa27, %v2_40aa27
  store i1 %v10_40aa27, i1* %cf.global-to-local, align 1
  store i8 %v5_40aa27, i8* %v1_40aa27, align 1
  %v0_40aa29 = load i32, i32* %eax.global-to-local, align 4
  %v1_40aa29 = inttoptr i32 %v0_40aa29 to i8*
  %v2_40aa29 = load i8, i8* %v1_40aa29, align 1
  %v4_40aa29 = trunc i32 %v0_40aa29 to i8
  %v5_40aa29 = add i8 %v4_40aa29, %v2_40aa29
  %v10_40aa29 = icmp ult i8 %v5_40aa29, %v2_40aa29
  store i1 %v10_40aa29, i1* %cf.global-to-local, align 1
  store i8 %v5_40aa29, i8* %v1_40aa29, align 1
  %v0_40aa2b = load i32, i32* %eax.global-to-local, align 4
  %v1_40aa2b = inttoptr i32 %v0_40aa2b to i8*
  %v2_40aa2b = load i8, i8* %v1_40aa2b, align 1
  %v4_40aa2b = trunc i32 %v0_40aa2b to i8
  %v5_40aa2b = add i8 %v4_40aa2b, %v2_40aa2b
  %v10_40aa2b = icmp ult i8 %v5_40aa2b, %v2_40aa2b
  store i1 %v10_40aa2b, i1* %cf.global-to-local, align 1
  store i8 %v5_40aa2b, i8* %v1_40aa2b, align 1
  %v0_40aa2d = load i32, i32* %eax.global-to-local, align 4
  %v1_40aa2d = inttoptr i32 %v0_40aa2d to i8*
  %v2_40aa2d = load i8, i8* %v1_40aa2d, align 1
  %v4_40aa2d = trunc i32 %v0_40aa2d to i8
  %v5_40aa2d = add i8 %v4_40aa2d, %v2_40aa2d
  %v10_40aa2d = icmp ult i8 %v5_40aa2d, %v2_40aa2d
  store i1 %v10_40aa2d, i1* %cf.global-to-local, align 1
  store i8 %v5_40aa2d, i8* %v1_40aa2d, align 1
  %v0_40aa2f = load i32, i32* %edx.global-to-local, align 4
  %v1_40aa2f = inttoptr i32 %v0_40aa2f to i8*
  %v2_40aa2f = load i8, i8* %v1_40aa2f, align 1
  %v3_40aa2f = load i32, i32* %ecx.global-to-local, align 4
  %v4_40aa2f = udiv i32 %v3_40aa2f, 256
  %v5_40aa2f = trunc i32 %v4_40aa2f to i8
  %v6_40aa2f = add i8 %v5_40aa2f, %v2_40aa2f
  store i8 %v6_40aa2f, i8* %v1_40aa2f, align 1
  %v0_40aa31 = load i32, i32* %eax.global-to-local, align 4
  %v1_40aa31 = add i32 %v0_40aa31, 4764131
  store i32 %v1_40aa31, i32* %eax.global-to-local, align 4
  %v0_40aa36 = load i32, i32* inttoptr (i32 4763776 to i32*), align 128
  %v2_40aa36 = or i32 %v0_40aa36, %v1_40aa31
  store i32 %v2_40aa36, i32* inttoptr (i32 4763776 to i32*), align 128
  %v0_40aa3c = load i32, i32* inttoptr (i32 4763703 to i32*), align 4
  %v1_40aa3c = or i32 %v0_40aa3c, 90
  store i32 %v1_40aa3c, i32* inttoptr (i32 4763703 to i32*), align 4
  %v0_40aa43 = load i32, i32* inttoptr (i32 4764063 to i32*), align 4
  %v1_40aa43 = load i32, i32* %ebx.global-to-local, align 4
  %v2_40aa43 = add i32 %v1_40aa43, %v0_40aa43
  store i32 %v2_40aa43, i32* inttoptr (i32 4764063 to i32*), align 4
  store i32 -125, i32* %ecx.global-to-local, align 4
  %v0_40aa51 = load i32, i32* inttoptr (i32 4764025 to i32*), align 4
  %v1_40aa51 = load i32, i32* %eax.global-to-local, align 4
  %v2_40aa51 = sub i32 %v0_40aa51, %v1_40aa51
  store i32 %v2_40aa51, i32* inttoptr (i32 4764025 to i32*), align 4
  %v0_40aa57 = load i32, i32* inttoptr (i32 4764039 to i32*), align 4
  %v1_40aa57 = xor i32 %v0_40aa57, 84
  store i32 %v1_40aa57, i32* inttoptr (i32 4764039 to i32*), align 4
  %v0_40aa5e = load i32, i32* %ecx.global-to-local, align 4
  %v3_40aa5e = load i32, i32* %ebx.global-to-local, align 4
  %v4_40aa5e = and i32 %v3_40aa5e, 65280
  %v1_40aa5e38 = add i32 %v4_40aa5e, %v0_40aa5e
  %v23_40aa5e = and i32 %v1_40aa5e38, 65280
  %v24_40aa5e = and i32 %v0_40aa5e, -65281
  %v25_40aa5e = or i32 %v23_40aa5e, %v24_40aa5e
  store i32 %v25_40aa5e, i32* %ecx.global-to-local, align 4
  %v0_40aa60 = load i32, i32* inttoptr (i32 4763864 to i32*), align 8
  %v1_40aa60 = and i32 %v0_40aa60, 96
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v1_40aa60, i32* inttoptr (i32 4763864 to i32*), align 8
  %v0_40aa67 = load i8, i8* inttoptr (i32 4763701 to i8*), align 1
  %v2_40aa67 = udiv i32 %v25_40aa5e, 256
  %v3_40aa67 = trunc i32 %v2_40aa67 to i8
  %v4_40aa67 = xor i8 %v3_40aa67, %v0_40aa67
  store i8 %v4_40aa67, i8* inttoptr (i32 4763701 to i8*), align 1
  %v0_40aa6d = load i32, i32* %edi.global-to-local, align 4
  %v1_40aa6d = load i32, i32* %esi.global-to-local, align 4
  %v2_40aa6d = add i32 %v1_40aa6d, %v0_40aa6d
  %v7_40aa6d = icmp ult i32 %v2_40aa6d, %v0_40aa6d
  store i32 %v2_40aa6d, i32* %edi.global-to-local, align 4
  %v0_40aa6f = load i32, i32* inttoptr (i32 4763720 to i32*), align 8
  %v2_40aa6f = zext i1 %v7_40aa6d to i32
  %v3_40aa6f = add i32 %v0_40aa6f, -205
  %v4_40aa6f = add i32 %v3_40aa6f, %v2_40aa6f
  store i32 %v4_40aa6f, i32* inttoptr (i32 4763720 to i32*), align 8
  store i1 false, i1* %cf.global-to-local, align 1
  %v8_40aa8b = call i1 @SetEnvironmentVariableW(i16* bitcast ([13 x i8]* @global_var_48b685.2 to i16*), i16* bitcast ([17 x i8]* @global_var_48b692.1 to i16*))
  %v9_40aa8b = sext i1 %v8_40aa8b to i32
  store i32 %v9_40aa8b, i32* %eax.global-to-local, align 4
  %v1_40aa96 = load i32, i32* %ebx.global-to-local, align 4
  %v2_40aa96 = add i32 %v1_40aa96, 1
  %v7_40aa96 = icmp eq i32 %v2_40aa96, 0
  store i32 %v2_40aa96, i32* %ecx.global-to-local, align 4
  %v1_40aa98 = load i32, i32* inttoptr (i32 4763875 to i32*), align 4
  %v3_40aa98 = zext i1 %v7_40aa96 to i32
  %v4_40aa98 = add i32 %v1_40aa98, %v1_40aa96
  %v5_40aa98 = add i32 %v3_40aa98, %v4_40aa98
  %v24_40aa98 = icmp ule i32 %v5_40aa98, %v1_40aa96
  %v25_40aa98 = icmp ult i32 %v4_40aa98, %v1_40aa96
  %v26_40aa98 = select i1 %v7_40aa96, i1 %v24_40aa98, i1 %v25_40aa98
  store i32 %v5_40aa98, i32* %ebx.global-to-local, align 4
  %v0_40aa9e = load i32, i32* inttoptr (i32 4763899 to i32*), align 4
  %v2_40aa9e = zext i1 %v26_40aa98 to i32
  %v3_40aa9e = add i32 %v0_40aa9e, -75
  %v4_40aa9e = add i32 %v3_40aa9e, %v2_40aa9e
  %v12_40aa9e = icmp ult i32 %v0_40aa9e, 75
  %v13_40aa9e = or i1 %v12_40aa9e, %v26_40aa98
  store i32 %v4_40aa9e, i32* inttoptr (i32 4763899 to i32*), align 4
  %v0_40aaa5 = load i32, i32* inttoptr (i32 4763748 to i32*), align 4
  %v2_40aaa5 = zext i1 %v13_40aa9e to i32
  %v3_40aaa5 = add i32 %v0_40aaa5, 91
  %v4_40aaa5 = add i32 %v3_40aaa5, %v2_40aaa5
  %v21_40aaa5 = icmp ule i32 %v4_40aaa5, %v0_40aaa5
  %v22_40aaa5 = icmp ugt i32 %v0_40aaa5, -92
  %v23_40aaa5 = select i1 %v13_40aa9e, i1 %v21_40aaa5, i1 %v22_40aaa5
  store i32 %v4_40aaa5, i32* inttoptr (i32 4763748 to i32*), align 4
  %v0_40aaac = load i32, i32* %esi.global-to-local, align 4
  %v3_40aaac = select i1 %v23_40aaa5, i32 -118, i32 -119
  %v4_40aaac = add i32 %v3_40aaac, %v0_40aaac
  %v22_40aaac = icmp ule i32 %v4_40aaac, %v0_40aaac
  %v23_40aaac = icmp ugt i32 %v0_40aaac, 118
  %v24_40aaac = select i1 %v23_40aaa5, i1 %v22_40aaac, i1 %v23_40aaac
  store i1 %v24_40aaac, i1* %cf.global-to-local, align 1
  store i32 %v4_40aaac, i32* %esi.global-to-local, align 4
  %v0_40aaaf = load i8, i8* inttoptr (i32 4763757 to i8*), align 1
  %v1_40aaaf = load i32, i32* %ebx.global-to-local, align 4
  %v2_40aaaf = trunc i32 %v1_40aaaf to i8
  %v3_40aaaf = add i8 %v2_40aaaf, %v0_40aaaf
  %v8_40aaaf = icmp ult i8 %v3_40aaaf, %v0_40aaaf
  store i1 %v8_40aaaf, i1* %cf.global-to-local, align 1
  store i8 %v3_40aaaf, i8* inttoptr (i32 4763757 to i8*), align 1
  %v0_40aab5 = load i32, i32* inttoptr (i32 4763766 to i32*), align 4
  %v2_40aab5 = zext i1 %v8_40aaaf to i32
  %v3_40aab5 = add i32 %v0_40aab5, -245
  %v4_40aab5 = add i32 %v3_40aab5, %v2_40aab5
  store i32 %v4_40aab5, i32* inttoptr (i32 4763766 to i32*), align 4
  %v0_40aabf = load i32, i32* %esi.global-to-local, align 4
  %v1_40aabf = add i32 %v0_40aabf, 15
  %v4_40aabf = icmp ugt i32 %v0_40aabf, -16
  store i1 %v4_40aabf, i1* %cf.global-to-local, align 1
  store i32 %v1_40aabf, i32* %esi.global-to-local, align 4
  %v0_40aac2 = load i8, i8* inttoptr (i32 4763888 to i8*), align 16
  %v1_40aac2 = add i8 %v0_40aac2, -122
  store i8 %v1_40aac2, i8* inttoptr (i32 4763888 to i8*), align 16
  %v0_40aac9 = load i32, i32* inttoptr (i32 4763777 to i32*), align 4
  %v3_40aac9 = add i32 %v0_40aac9, %v9_40aa8b
  store i32 %v3_40aac9, i32* inttoptr (i32 4763777 to i32*), align 4
  %v0_40aacf = load i32, i32* %edx.global-to-local, align 4
  %v1_40aacf = and i32 %v0_40aacf, -256
  %v18_40aad1 = or i32 %v1_40aacf, 42
  store i32 %v18_40aad1, i32* %edx.global-to-local, align 4
  %v0_40aad4 = load i32, i32* %ecx.global-to-local, align 4
  %v1_40aad4 = add i32 %v0_40aad4, 66
  %v5_40aad4 = icmp ugt i32 %v0_40aad4, -67
  store i32 %v1_40aad4, i32* %ecx.global-to-local, align 4
  %v0_40aad7 = load i32, i32* %edi.global-to-local, align 4
  %v1_40aad7 = load i32, i32* %esi.global-to-local, align 4
  %v3_40aad7 = zext i1 %v5_40aad4 to i32
  %v4_40aad7 = add i32 %v0_40aad7, 91
  %v5_40aad7 = add i32 %v4_40aad7, %v3_40aad7
  %v1_40aad9 = add i32 %v5_40aad7, %v1_40aad7
  store i32 %v1_40aad9, i32* %edi.global-to-local, align 4
  %v0_40aadc = load i32, i32* inttoptr (i32 4763725 to i32*), align 4
  %v2_40aadc = add i32 %v1_40aad9, %v0_40aadc
  store i32 %v2_40aadc, i32* inttoptr (i32 4763725 to i32*), align 4
  %v0_40aae2 = load i32, i32* %ebx.global-to-local, align 4
  %v1_40aae2 = load i32, i32* inttoptr (i32 4763965 to i32*), align 4
  %v2_40aae2 = or i32 %v1_40aae2, %v0_40aae2
  store i32 %v2_40aae2, i32* %ebx.global-to-local, align 4
  store i32 191, i32* inttoptr (i32 4763696 to i32*), align 16
  %v1_40aaf2 = load i32, i32* inttoptr (i32 4764023 to i32*), align 4
  %v4_40aaf2 = add i32 %v1_40aaf2, %v2_40aae2
  %v18_40aaf2 = trunc i32 %v4_40aaf2 to i8
  store i32 %v4_40aaf2, i32* %ebx.global-to-local, align 4
  %v0_40aaf8 = load i32, i32* %edx.global-to-local, align 4
  %v1_40aaf8 = load i32, i32* inttoptr (i32 4763867 to i32*), align 4
  %v2_40aaf8 = or i32 %v1_40aaf8, %v0_40aaf8
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v2_40aaf8, i32* %edx.global-to-local, align 4
  %v2_40aafe = load i8, i8* inttoptr (i32 4764125 to i8*), align 1
  %v3_40aafe = or i8 %v2_40aafe, %v18_40aaf2
  store i1 false, i1* %cf.global-to-local, align 1
  %v9_40aafe = zext i8 %v3_40aafe to i32
  %v11_40aafe = and i32 %v4_40aaf2, -256
  %v12_40aafe = or i32 %v9_40aafe, %v11_40aafe
  store i32 %v12_40aafe, i32* %ebx.global-to-local, align 4
  call void @__pseudo_call(i32 4238092)
  %v0_40ab0c = load i32, i32* %ecx.global-to-local, align 4
  %v1_40ab0c = load i32, i32* %ebx.global-to-local, align 4
  %v2_40ab0c = add i32 %v1_40ab0c, %v0_40ab0c
  %v14_40ab0c = trunc i32 %v2_40ab0c to i8
  store i32 %v2_40ab0c, i32* %ecx.global-to-local, align 4
  %v0_40ab0e = load i32, i32* %edx.global-to-local, align 4
  %v2_40ab0e = sub i32 %v0_40ab0e, %v2_40ab0c
  %v1_40ab10 = udiv i32 %v2_40ab0e, 256
  %v2_40ab10 = trunc i32 %v1_40ab10 to i8
  %v5_40ab10 = sub i32 %v1_40ab10, %v2_40ab0c
  %v10_40ab10 = icmp ult i8 %v2_40ab10, %v14_40ab0c
  store i1 %v10_40ab10, i1* %cf.global-to-local, align 1
  %v21_40ab10 = mul i32 %v5_40ab10, 256
  %v23_40ab10 = and i32 %v21_40ab10, 65280
  %v24_40ab10 = and i32 %v2_40ab0e, -65281
  %v25_40ab10 = or i32 %v23_40ab10, %v24_40ab10
  store i32 %v25_40ab10, i32* %edx.global-to-local, align 4
  %v0_40ab12 = load i8, i8* inttoptr (i32 4763714 to i8*), align 2
  %v4_40ab12 = zext i1 %v10_40ab10 to i8
  %v5_40ab12 = sub i8 %v0_40ab12, %v14_40ab0c
  %v6_40ab12 = add i8 %v4_40ab12, %v5_40ab12
  %v17_40ab12 = sub i8 %v5_40ab12, %v4_40ab12
  %v18_40ab12 = icmp ult i8 %v0_40ab12, %v17_40ab12
  %v19_40ab12 = icmp ne i8 %v14_40ab0c, -1
  %v20_40ab12 = or i1 %v19_40ab12, %v18_40ab12
  %v21_40ab12 = icmp ult i8 %v0_40ab12, %v14_40ab0c
  %v22_40ab12 = select i1 %v10_40ab10, i1 %v20_40ab12, i1 %v21_40ab12
  store i1 %v22_40ab12, i1* %cf.global-to-local, align 1
  store i8 %v6_40ab12, i8* inttoptr (i32 4763714 to i8*), align 2
  %v0_40ab18 = load i32, i32* inttoptr (i32 4763654 to i32*), align 4
  %v2_40ab18 = zext i1 %v22_40ab12 to i32
  %v3_40ab18 = add i32 %v0_40ab18, 233
  %v4_40ab18 = add i32 %v3_40ab18, %v2_40ab18
  %v21_40ab18 = icmp ule i32 %v4_40ab18, %v0_40ab18
  %v22_40ab18 = icmp ugt i32 %v0_40ab18, -234
  %v23_40ab18 = select i1 %v22_40ab12, i1 %v21_40ab18, i1 %v22_40ab18
  store i32 %v4_40ab18, i32* inttoptr (i32 4763654 to i32*), align 4
  %v0_40ab22 = load i32, i32* inttoptr (i32 4763778 to i32*), align 4
  %v3_40ab22 = select i1 %v23_40ab18, i32 209, i32 208
  %v4_40ab22 = add i32 %v3_40ab22, %v0_40ab22
  store i32 %v4_40ab22, i32* inttoptr (i32 4763778 to i32*), align 4
  %v0_40ab2c = load i32, i32* %ecx.global-to-local, align 4
  %v1_40ab2c = xor i32 %v0_40ab2c, 14
  store i32 %v1_40ab2c, i32* %ecx.global-to-local, align 4
  %v0_40ab2f = load i32, i32* inttoptr (i32 4764028 to i32*), align 4
  %v3_40ab2f = add i32 %v0_40ab2f, 101
  %v22_40ab2f = icmp ugt i32 %v0_40ab2f, -102
  store i32 %v3_40ab2f, i32* inttoptr (i32 4764028 to i32*), align 4
  %v0_40ab36 = load i32, i32* inttoptr (i32 4763772 to i32*), align 4
  %v1_40ab36 = load i32, i32* %esi.global-to-local, align 4
  %v3_40ab36 = zext i1 %v22_40ab2f to i32
  %v4_40ab36 = add i32 %v3_40ab36, %v0_40ab36
  %v5_40ab36 = add i32 %v4_40ab36, %v1_40ab36
  store i32 %v5_40ab36, i32* inttoptr (i32 4763772 to i32*), align 4
  %v4_40ab3c = mul nsw i32 %v9_40aa8b, 2
  %v9_40ab3c = icmp ult i32 %v4_40ab3c, %v9_40aa8b
  store i32 %v4_40ab3c, i32* %eax.global-to-local, align 4
  %v0_40ab3e = load i32, i32* %edx.global-to-local, align 4
  %v1_40ab3e = load i32, i32* inttoptr (i32 4763934 to i32*), align 4
  %v3_40ab3e = zext i1 %v9_40ab3c to i32
  %v4_40ab3e = add i32 %v1_40ab3e, %v0_40ab3e
  %v5_40ab3e = add i32 %v4_40ab3e, %v3_40ab3e
  %v24_40ab3e = icmp ule i32 %v5_40ab3e, %v0_40ab3e
  %v25_40ab3e = icmp ult i32 %v4_40ab3e, %v0_40ab3e
  %v26_40ab3e = select i1 %v9_40ab3c, i1 %v24_40ab3e, i1 %v25_40ab3e
  store i32 %v5_40ab3e, i32* %edx.global-to-local, align 4
  %v0_40ab44 = load i32, i32* inttoptr (i32 4763725 to i32*), align 4
  %v1_40ab44 = load i32, i32* %esi.global-to-local, align 4
  %v3_40ab44 = zext i1 %v26_40ab3e to i32
  %v4_40ab44 = add i32 %v1_40ab44, %v0_40ab44
  %v5_40ab44 = add i32 %v3_40ab44, %v4_40ab44
  %v24_40ab44 = icmp ule i32 %v5_40ab44, %v0_40ab44
  %v25_40ab44 = icmp ult i32 %v4_40ab44, %v0_40ab44
  %v26_40ab44 = select i1 %v26_40ab3e, i1 %v24_40ab44, i1 %v25_40ab44
  store i1 %v26_40ab44, i1* %cf.global-to-local, align 1
  store i32 %v5_40ab44, i32* inttoptr (i32 4763725 to i32*), align 4
  %v0_40ab4a = load i32, i32* %eax.global-to-local, align 4
  %v1_40ab4a = inttoptr i32 %v0_40ab4a to i8*
  %v2_40ab4a = load i8, i8* %v1_40ab4a, align 1
  %v4_40ab4a = trunc i32 %v0_40ab4a to i8
  %v5_40ab4a = add i8 %v4_40ab4a, %v2_40ab4a
  %v10_40ab4a = icmp ult i8 %v5_40ab4a, %v2_40ab4a
  store i1 %v10_40ab4a, i1* %cf.global-to-local, align 1
  store i8 %v5_40ab4a, i8* %v1_40ab4a, align 1
  %v0_40ab4c = load i32, i32* %eax.global-to-local, align 4
  %v1_40ab4c = inttoptr i32 %v0_40ab4c to i8*
  %v2_40ab4c = load i8, i8* %v1_40ab4c, align 1
  %v4_40ab4c = trunc i32 %v0_40ab4c to i8
  %v5_40ab4c = add i8 %v4_40ab4c, %v2_40ab4c
  %v10_40ab4c = icmp ult i8 %v5_40ab4c, %v2_40ab4c
  store i1 %v10_40ab4c, i1* %cf.global-to-local, align 1
  store i8 %v5_40ab4c, i8* %v1_40ab4c, align 1
  %v0_40ab4e = load i32, i32* %eax.global-to-local, align 4
  %v1_40ab4e = inttoptr i32 %v0_40ab4e to i8*
  %v2_40ab4e = load i8, i8* %v1_40ab4e, align 1
  %v4_40ab4e = trunc i32 %v0_40ab4e to i8
  %v5_40ab4e = add i8 %v4_40ab4e, %v2_40ab4e
  %v10_40ab4e = icmp ult i8 %v5_40ab4e, %v2_40ab4e
  store i1 %v10_40ab4e, i1* %cf.global-to-local, align 1
  store i8 %v5_40ab4e, i8* %v1_40ab4e, align 1
  %v0_40ab50 = load i32, i32* %eax.global-to-local, align 4
  %v1_40ab50 = inttoptr i32 %v0_40ab50 to i8*
  %v2_40ab50 = load i8, i8* %v1_40ab50, align 1
  %v4_40ab50 = trunc i32 %v0_40ab50 to i8
  %v5_40ab50 = add i8 %v4_40ab50, %v2_40ab50
  %v10_40ab50 = icmp ult i8 %v5_40ab50, %v2_40ab50
  store i1 %v10_40ab50, i1* %cf.global-to-local, align 1
  store i8 %v5_40ab50, i8* %v1_40ab50, align 1
  %v0_40ab52 = load i32, i32* %eax.global-to-local, align 4
  %v1_40ab52 = inttoptr i32 %v0_40ab52 to i8*
  %v2_40ab52 = load i8, i8* %v1_40ab52, align 1
  %v4_40ab52 = trunc i32 %v0_40ab52 to i8
  %v5_40ab52 = add i8 %v4_40ab52, %v2_40ab52
  %v10_40ab52 = icmp ult i8 %v5_40ab52, %v2_40ab52
  store i1 %v10_40ab52, i1* %cf.global-to-local, align 1
  store i8 %v5_40ab52, i8* %v1_40ab52, align 1
  %v0_40ab54 = load i32, i32* %ecx.global-to-local, align 4
  %v1_40ab54 = inttoptr i32 %v0_40ab54 to i8*
  %v2_40ab54 = load i8, i8* %v1_40ab54, align 1
  %v3_40ab54 = load i32, i32* %eax.global-to-local, align 4
  %v4_40ab54 = trunc i32 %v3_40ab54 to i8
  %v5_40ab54 = add i8 %v4_40ab54, %v2_40ab54
  store i8 %v5_40ab54, i8* %v1_40ab54, align 1
  %v0_40ab56 = load i32, i32* %eax.global-to-local, align 4
  %v1_40ab56 = xor i32 %v0_40ab56, 4763821
  store i32 %v1_40ab56, i32* %eax.global-to-local, align 4
  %v1_40ab60 = load i32, i32* %esi.global-to-local, align 4
  %v2_40ab60 = add i32 %v1_40ab60, 1
  store i32 %v2_40ab60, i32* %edx.global-to-local, align 4
  %v0_40ab62 = load i32, i32* inttoptr (i32 4763887 to i32*), align 4
  %v1_40ab62 = load i32, i32* %ebx.global-to-local, align 4
  %v2_40ab62 = sub i32 %v0_40ab62, %v1_40ab62
  store i32 %v2_40ab62, i32* inttoptr (i32 4763887 to i32*), align 4
  %v1_40ab68 = load i32, i32* inttoptr (i32 4763994 to i32*), align 4
  %v2_40ab68 = or i32 %v1_40ab68, %v1_40ab62
  store i32 %v2_40ab68, i32* %ebx.global-to-local, align 4
  %v0_40ab6e = load i32, i32* inttoptr (i32 4763715 to i32*), align 4
  %v1_40ab6e = and i32 %v0_40ab6e, 7
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v1_40ab6e, i32* inttoptr (i32 4763715 to i32*), align 4
  %v0_40ab75 = load i32, i32* %eax.global-to-local, align 4
  %v1_40ab75 = udiv i32 %v0_40ab75, 256
  %v2_40ab75 = trunc i32 %v1_40ab75 to i8
  %v3_40ab75 = load i8, i8* inttoptr (i32 4764130 to i8*), align 2
  %v4_40ab75 = or i8 %v2_40ab75, %v3_40ab75
  %v10_40ab75 = zext i8 %v4_40ab75 to i32
  %v12_40ab75 = mul nuw nsw i32 %v10_40ab75, 256
  %v13_40ab75 = and i32 %v0_40ab75, -65281
  %v14_40ab75 = or i32 %v12_40ab75, %v13_40ab75
  store i32 %v14_40ab75, i32* %eax.global-to-local, align 4
  %v0_40ab7b = load i32, i32* %esi.global-to-local, align 4
  %v1_40ab7b = load i32, i32* inttoptr (i32 4763780 to i32*), align 4
  %v2_40ab7b = sub i32 %v0_40ab7b, %v1_40ab7b
  store i32 %v2_40ab7b, i32* %esi.global-to-local, align 4
  %v0_40ab81 = load i32, i32* inttoptr (i32 4764124 to i32*), align 4
  %v2_40ab81 = xor i32 %v0_40ab81, %v2_40ab7b
  store i32 %v2_40ab81, i32* inttoptr (i32 4764124 to i32*), align 4
  %v3_40ab87 = add i32 %v2_40ab7b, 124
  %v1_40ab8a = load i32, i32* %ebx.global-to-local, align 4
  %v2_40ab8a = add i32 %v1_40ab8a, %v3_40ab87
  %v7_40ab8a = icmp ult i32 %v2_40ab8a, %v3_40ab87
  store i32 %v2_40ab8a, i32* %esi.global-to-local, align 4
  %v2_40ab8c = zext i1 %v7_40ab8a to i32
  %v3_40ab8c = add i32 %v1_40ab8a, -37
  %v4_40ab8c = add i32 %v3_40ab8c, %v2_40ab8c
  store i32 %v4_40ab8c, i32* %ebx.global-to-local, align 4
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 -3, i32* %ecx.global-to-local, align 4
  %v0_40ab97 = load i8, i8* inttoptr (i32 4763780 to i8*), align 4
  %v1_40ab97 = load i32, i32* %edx.global-to-local, align 4
  %v2_40ab97 = udiv i32 %v1_40ab97, 256
  %v3_40ab97 = trunc i32 %v2_40ab97 to i8
  %v4_40ab97 = or i8 %v3_40ab97, %v0_40ab97
  store i1 false, i1* %cf.global-to-local, align 1
  store i8 %v4_40ab97, i8* inttoptr (i32 4763780 to i8*), align 4
  %v0_40ab9d = load i32, i32* inttoptr (i32 4763664 to i32*), align 16
  %v1_40ab9d = load i32, i32* %esi.global-to-local, align 4
  %v4_40ab9d = sub i32 %v0_40ab9d, %v1_40ab9d
  store i32 %v4_40ab9d, i32* inttoptr (i32 4763664 to i32*), align 16
  %v0_40aba3 = load i32, i32* %edi.global-to-local, align 4
  %v1_40aba3 = load i32, i32* inttoptr (i32 4763839 to i32*), align 4
  %v2_40aba3 = sub i32 %v0_40aba3, %v1_40aba3
  %v7_40aba3 = icmp ult i32 %v0_40aba3, %v1_40aba3
  store i1 %v7_40aba3, i1* %cf.global-to-local, align 1
  store i32 %v2_40aba3, i32* %edi.global-to-local, align 4
  store i32 0, i32* %eax.global-to-local, align 4
  %v5_40abb1 = call i32* @EncodePointer(i32* null)
  %v6_40abb1 = ptrtoint i32* %v5_40abb1 to i32
  store i32 %v6_40abb1, i32* %eax.global-to-local, align 4
  store i32 -53, i32* %ecx.global-to-local, align 4
  store i32 -2, i32* %edx.global-to-local, align 4
  %v0_40abc7 = load i32, i32* %edi.global-to-local, align 4
  %v2_40abc7 = add i32 %v0_40abc7, %v6_40abb1
  store i32 %v2_40abc7, i32* %edi.global-to-local, align 4
  %v0_40abc9 = load i32, i32* inttoptr (i32 4763711 to i32*), align 4
  %v2_40abc9 = and i32 %v0_40abc9, -53
  store i32 %v2_40abc9, i32* inttoptr (i32 4763711 to i32*), align 4
  %v1_40abcf = load i32, i32* inttoptr (i32 4763903 to i32*), align 4
  %v4_40abcf = add i32 %v1_40abcf, %v6_40abb1
  %v0_40abd5 = load i32, i32* %ecx.global-to-local, align 4
  %v1_40abd5 = xor i32 %v0_40abd5, 18
  store i32 %v1_40abd5, i32* %ecx.global-to-local, align 4
  %v4_40abd8 = add i32 %v1_40abd5, %v4_40abcf
  %v25_40abd8 = icmp ult i32 %v4_40abd8, %v4_40abcf
  store i32 %v4_40abd8, i32* %eax.global-to-local, align 4
  %v0_40abda = load i32, i32* inttoptr (i32 4764112 to i32*), align 16
  %v3_40abda = select i1 %v25_40abd8, i32 64, i32 63
  %v4_40abda = add i32 %v3_40abda, %v0_40abda
  %v21_40abda = icmp ule i32 %v4_40abda, %v0_40abda
  %v22_40abda = icmp ugt i32 %v0_40abda, -64
  %v23_40abda = select i1 %v25_40abd8, i1 %v21_40abda, i1 %v22_40abda
  store i32 %v4_40abda, i32* inttoptr (i32 4764112 to i32*), align 16
  %v0_40abe1 = load i32, i32* inttoptr (i32 4763670 to i32*), align 4
  %v1_40abe1 = load i32, i32* %edi.global-to-local, align 4
  %v3_40abe1 = zext i1 %v23_40abda to i32
  %v4_40abe1 = add i32 %v1_40abe1, %v0_40abe1
  %v5_40abe1 = add i32 %v4_40abe1, %v3_40abe1
  store i32 %v5_40abe1, i32* inttoptr (i32 4763670 to i32*), align 4
  %v0_40abe7 = load i32, i32* %ecx.global-to-local, align 4
  %v1_40abe7 = xor i32 %v0_40abe7, 46
  store i32 %v1_40abe7, i32* %ecx.global-to-local, align 4
  %v0_40abea = load i32, i32* %ebx.global-to-local, align 4
  %v1_40abea = add i32 %v0_40abea, 87
  %v5_40abea = icmp ugt i32 %v0_40abea, -88
  store i32 %v1_40abea, i32* %ebx.global-to-local, align 4
  %v0_40abed = load i32, i32* inttoptr (i32 4764018 to i32*), align 4
  %v2_40abed = zext i1 %v5_40abea to i32
  %v3_40abed = add i32 %v0_40abed, 205
  %v4_40abed = add i32 %v3_40abed, %v2_40abed
  store i32 %v4_40abed, i32* inttoptr (i32 4764018 to i32*), align 4
  store i32 181, i32* inttoptr (i32 4763782 to i32*), align 4
  %v0_40ac01 = load i32, i32* %edx.global-to-local, align 4
  %v1_40ac01 = add i32 %v0_40ac01, -28
  store i32 %v1_40ac01, i32* %edx.global-to-local, align 4
  %v0_40ac04 = load i32, i32* %edi.global-to-local, align 4
  %v2_40ac04 = mul i32 %v0_40ac04, 2
  %v1_40ac06 = load i32, i32* %eax.global-to-local, align 4
  %v2_40ac06 = add i32 %v1_40ac06, %v2_40ac04
  %v1_40ac08 = add i32 %v2_40ac06, -3
  %v5_40ac08 = icmp ugt i32 %v2_40ac06, 2
  store i1 %v5_40ac08, i1* %cf.global-to-local, align 1
  store i32 %v1_40ac08, i32* %edi.global-to-local, align 4
  call void @__pseudo_call(i32 4238355)
  store i32 0, i32* %ebx.global-to-local, align 4
  %v0_40ac17 = load i32, i32* %edx.global-to-local, align 4
  %v1_40ac17 = xor i32 %v0_40ac17, -44
  store i32 %v1_40ac17, i32* %edx.global-to-local, align 4
  %v0_40ac1a = load i32, i32* inttoptr (i32 4763940 to i32*), align 4
  %v1_40ac1a = or i32 %v0_40ac1a, 219
  store i32 %v1_40ac1a, i32* inttoptr (i32 4763940 to i32*), align 4
  %v0_40ac24 = load i32, i32* inttoptr (i32 4764028 to i32*), align 4
  %v3_40ac24 = add i32 %v0_40ac24, 239
  store i32 %v3_40ac24, i32* inttoptr (i32 4764028 to i32*), align 4
  %v0_40ac2e = load i32, i32* %edx.global-to-local, align 4
  %v1_40ac2e = load i32, i32* %edi.global-to-local, align 4
  %v2_40ac2e = add i32 %v1_40ac2e, %v0_40ac2e
  %v7_40ac2e = icmp ult i32 %v2_40ac2e, %v0_40ac2e
  store i32 %v2_40ac2e, i32* %edx.global-to-local, align 4
  %v0_40ac30 = load i32, i32* %ebx.global-to-local, align 4
  %v1_40ac30 = load i32, i32* inttoptr (i32 4764039 to i32*), align 4
  %v3_40ac30 = zext i1 %v7_40ac2e to i32
  %v4_40ac30 = add i32 %v1_40ac30, %v0_40ac30
  %v5_40ac30 = add i32 %v4_40ac30, %v3_40ac30
  store i32 %v5_40ac30, i32* %ebx.global-to-local, align 4
  %v1_40ac36 = or i32 %v2_40ac2e, 109
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v1_40ac36, i32* %edx.global-to-local, align 4
  %v0_40ac39 = load i32, i32* %eax.global-to-local, align 4
  %v1_40ac39 = udiv i32 %v0_40ac39, 256
  %v2_40ac39 = trunc i32 %v1_40ac39 to i8
  %v3_40ac39 = load i8, i8* inttoptr (i32 4763737 to i8*), align 1
  %v6_40ac39 = add i8 %v2_40ac39, %v3_40ac39
  %v28_40ac39 = zext i8 %v6_40ac39 to i32
  %v30_40ac39 = mul nuw nsw i32 %v28_40ac39, 256
  %v31_40ac39 = and i32 %v0_40ac39, -65281
  %v32_40ac39 = or i32 %v30_40ac39, %v31_40ac39
  store i32 %v32_40ac39, i32* %eax.global-to-local, align 4
  %v0_40ac3f = load i32, i32* inttoptr (i32 4764143 to i32*), align 4
  %v1_40ac3f = and i32 %v0_40ac3f, 118
  store i32 %v1_40ac3f, i32* inttoptr (i32 4764143 to i32*), align 4
  %v0_40ac46 = load i32, i32* %edx.global-to-local, align 4
  %v1_40ac46 = load i32, i32* inttoptr (i32 4763686 to i32*), align 4
  %v4_40ac46 = add i32 %v1_40ac46, %v0_40ac46
  store i32 %v4_40ac46, i32* %edx.global-to-local, align 4
  %v0_40ac4c = load i32, i32* %eax.global-to-local, align 4
  %v1_40ac4c = load i32, i32* %esi.global-to-local, align 4
  %v2_40ac4c = xor i32 %v1_40ac4c, %v0_40ac4c
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v2_40ac4c, i32* %eax.global-to-local, align 4
  %v0_40ac4e = load i8, i8* inttoptr (i32 4764001 to i8*), align 1
  %v1_40ac4e = add i8 %v0_40ac4e, -56
  %v5_40ac4e = icmp ult i8 %v0_40ac4e, 56
  store i1 %v5_40ac4e, i1* %cf.global-to-local, align 1
  store i8 %v1_40ac4e, i8* inttoptr (i32 4764001 to i8*), align 1
  %v0_40ac55 = load i32, i32* %ecx.global-to-local, align 4
  %v1_40ac55 = inttoptr i32 %v0_40ac55 to i8*
  %v2_40ac55 = load i8, i8* %v1_40ac55, align 1
  %v3_40ac55 = load i32, i32* %eax.global-to-local, align 4
  %v4_40ac55 = trunc i32 %v3_40ac55 to i8
  %v5_40ac55 = add i8 %v4_40ac55, %v2_40ac55
  %v10_40ac55 = icmp ult i8 %v5_40ac55, %v2_40ac55
  store i1 %v10_40ac55, i1* %cf.global-to-local, align 1
  store i8 %v5_40ac55, i8* %v1_40ac55, align 1
  %v0_40ac5d = load i32, i32* inttoptr (i32 4764084 to i32*), align 4
  %v1_40ac5d = load i32, i32* %ebx.global-to-local, align 4
  %v2_40ac5d = load i1, i1* %cf.global-to-local, align 1
  %v3_40ac5d = zext i1 %v2_40ac5d to i32
  %v4_40ac5d = sub i32 %v0_40ac5d, %v1_40ac5d
  %v5_40ac5d = add i32 %v4_40ac5d, %v3_40ac5d
  store i32 %v5_40ac5d, i32* inttoptr (i32 4764084 to i32*), align 4
  %v0_40ac63 = load i32, i32* inttoptr (i32 4764158 to i32*), align 4
  %v1_40ac63 = load i32, i32* %edi.global-to-local, align 4
  %v2_40ac63 = or i32 %v1_40ac63, %v0_40ac63
  store i32 %v2_40ac63, i32* inttoptr (i32 4764158 to i32*), align 4
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 -53, i32* %ecx.global-to-local, align 4
  %v2_40ac71 = load i8, i8* inttoptr (i32 4763960 to i8*), align 8
  store i1 false, i1* %cf.global-to-local, align 1
  %v9_40ac71 = zext i8 %v2_40ac71 to i32
  %v12_40ac71 = or i32 %v9_40ac71, -53
  store i32 %v12_40ac71, i32* %ecx.global-to-local, align 4
  %v0_40ac77 = load i8, i8* inttoptr (i32 4763693 to i8*), align 1
  %v1_40ac77 = add i8 %v0_40ac77, 82
  %v5_40ac77 = icmp ult i8 %v0_40ac77, -82
  store i1 %v5_40ac77, i1* %cf.global-to-local, align 1
  store i8 %v1_40ac77, i8* inttoptr (i32 4763693 to i8*), align 1
  %v0_40ac7e = load i32, i32* %eax.global-to-local, align 4
  %v1_40ac7e = udiv i32 %v0_40ac7e, 256
  %v2_40ac7e = trunc i32 %v1_40ac7e to i8
  %v4_40ac7e = zext i1 %v5_40ac77 to i8
  %v5_40ac7e = add i8 %v2_40ac7e, 2
  %v6_40ac7e = add i8 %v5_40ac7e, %v4_40ac7e
  %v22_40ac7e = icmp ule i8 %v6_40ac7e, %v2_40ac7e
  %v23_40ac7e = icmp ugt i8 %v2_40ac7e, -3
  %v24_40ac7e = select i1 %v5_40ac77, i1 %v22_40ac7e, i1 %v23_40ac7e
  store i1 %v24_40ac7e, i1* %cf.global-to-local, align 1
  %v25_40ac7e = zext i8 %v6_40ac7e to i32
  %v27_40ac7e = mul nuw nsw i32 %v25_40ac7e, 256
  %v28_40ac7e = and i32 %v0_40ac7e, -65281
  %v29_40ac7e = or i32 %v27_40ac7e, %v28_40ac7e
  store i32 %v29_40ac7e, i32* %eax.global-to-local, align 4
  %v0_40ac81 = load i32, i32* %ecx.global-to-local, align 4
  %v1_40ac81 = trunc i32 %v0_40ac81 to i8
  %v2_40ac81 = load i8, i8* inttoptr (i32 4763889 to i8*), align 1
  %v3_40ac81 = sub i8 %v1_40ac81, %v2_40ac81
  %v8_40ac81 = icmp ult i8 %v1_40ac81, %v2_40ac81
  %v18_40ac81 = zext i8 %v3_40ac81 to i32
  %v20_40ac81 = and i32 %v0_40ac81, -256
  %v21_40ac81 = or i32 %v18_40ac81, %v20_40ac81
  store i32 %v21_40ac81, i32* %ecx.global-to-local, align 4
  %v0_40ac87 = load i32, i32* %edi.global-to-local, align 4
  %v1_40ac87 = load i32, i32* %edx.global-to-local, align 4
  %v3_40ac87 = zext i1 %v8_40ac81 to i32
  %v4_40ac87 = add i32 %v1_40ac87, %v0_40ac87
  %v5_40ac87 = add i32 %v4_40ac87, %v3_40ac87
  %v24_40ac87 = icmp ule i32 %v5_40ac87, %v0_40ac87
  %v25_40ac87 = icmp ult i32 %v4_40ac87, %v0_40ac87
  %v26_40ac87 = select i1 %v8_40ac81, i1 %v24_40ac87, i1 %v25_40ac87
  store i1 %v26_40ac87, i1* %cf.global-to-local, align 1
  store i32 %v5_40ac87, i32* %edi.global-to-local, align 4
  store i32 0, i32* %eax.global-to-local, align 4
  %v4_40ac91 = call i32* @EncodePointer(i32* null)
  %v5_40ac91 = ptrtoint i32* %v4_40ac91 to i32
  store i32 %v5_40ac91, i32* %eax.global-to-local, align 4
  %v1_40ac9c = load i32, i32* %edi.global-to-local, align 4
  %v2_40ac9c = add i32 %v1_40ac9c, 1
  store i32 %v2_40ac9c, i32* %ecx.global-to-local, align 4
  %v0_40ac9e = load i32, i32* inttoptr (i32 4763769 to i32*), align 4
  %v1_40ac9e = load i32, i32* %ebx.global-to-local, align 4
  %v2_40ac9e = and i32 %v1_40ac9e, %v0_40ac9e
  store i32 %v2_40ac9e, i32* inttoptr (i32 4763769 to i32*), align 4
  %v0_40aca4 = load i32, i32* inttoptr (i32 4763763 to i32*), align 4
  %v2_40aca4 = add i32 %v1_40ac9e, %v0_40aca4
  store i32 %v2_40aca4, i32* inttoptr (i32 4763763 to i32*), align 4
  %v1_40acaa = xor i32 %v5_40ac91, 88
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v1_40acaa, i32* %eax.global-to-local, align 4
  %v0_40acad = load i32, i32* %ebx.global-to-local, align 4
  %v1_40acad = trunc i32 %v0_40acad to i8
  %v2_40acad = load i8, i8* inttoptr (i32 4763957 to i8*), align 1
  %v3_40acad = or i8 %v1_40acad, %v2_40acad
  %v9_40acad = zext i8 %v3_40acad to i32
  %v11_40acad = and i32 %v0_40acad, -256
  %v12_40acad = or i32 %v9_40acad, %v11_40acad
  store i32 %v12_40acad, i32* %ebx.global-to-local, align 4
  %v0_40acb3 = load i32, i32* inttoptr (i32 4764100 to i32*), align 4
  %v1_40acb3 = and i32 %v0_40acb3, 106
  store i32 %v1_40acb3, i32* inttoptr (i32 4764100 to i32*), align 4
  %v0_40acba = load i32, i32* inttoptr (i32 4764096 to i32*), align 64
  %v1_40acba = or i32 %v0_40acba, 168
  store i32 %v1_40acba, i32* inttoptr (i32 4764096 to i32*), align 64
  %v0_40acc4 = load i32, i32* %ebx.global-to-local, align 4
  %v1_40acc4 = load i32, i32* inttoptr (i32 4764090 to i32*), align 4
  %v4_40acc4 = add i32 %v1_40acc4, %v0_40acc4
  %v25_40acc4 = icmp ult i32 %v4_40acc4, %v0_40acc4
  store i32 %v4_40acc4, i32* %ebx.global-to-local, align 4
  %v0_40acca = load i32, i32* %esi.global-to-local, align 4
  %v3_40acca = select i1 %v25_40acc4, i32 -34, i32 -35
  %v4_40acca = add i32 %v3_40acca, %v0_40acca
  %v22_40acca = icmp ule i32 %v4_40acca, %v0_40acca
  %v23_40acca = icmp ugt i32 %v0_40acca, 34
  %v24_40acca = select i1 %v25_40acc4, i1 %v22_40acca, i1 %v23_40acca
  store i32 %v4_40acca, i32* %esi.global-to-local, align 4
  %v1_40accd = load i32, i32* inttoptr (i32 4763952 to i32*), align 16
  %v3_40accd = zext i1 %v24_40acca to i32
  %v4_40accd = add i32 %v1_40accd, %v4_40acca
  %v5_40accd = add i32 %v3_40accd, %v4_40accd
  %v24_40accd = icmp ule i32 %v5_40accd, %v4_40acca
  %v25_40accd = icmp ult i32 %v4_40accd, %v4_40acca
  %v26_40accd = select i1 %v24_40acca, i1 %v24_40accd, i1 %v25_40accd
  store i1 %v26_40accd, i1* %cf.global-to-local, align 1
  store i32 %v5_40accd, i32* %esi.global-to-local, align 4
  call void @__pseudo_call(i32 4238555)
  %v0_40acdb = load i32, i32* %ecx.global-to-local, align 4
  %v1_40acdb = add i32 %v0_40acdb, 28
  %v5_40acdb = icmp ult i32 %v0_40acdb, -28
  store i32 %v1_40acdb, i32* %ecx.global-to-local, align 4
  %v0_40acde = load i32, i32* %eax.global-to-local, align 4
  %v1_40acde = udiv i32 %v0_40acde, 256
  %v2_40acde = trunc i32 %v1_40acde to i8
  %v5_40acde = select i1 %v5_40acdb, i32 231, i32 230
  %v6_40acde = add nuw nsw i32 %v5_40acde, %v1_40acde
  %v14_40acde = icmp ult i8 %v2_40acde, 26
  %v15_40acde = or i1 %v5_40acdb, %v14_40acde
  store i1 %v15_40acde, i1* %cf.global-to-local, align 1
  %v27_40acde = mul i32 %v6_40acde, 256
  %v29_40acde = and i32 %v27_40acde, 65280
  %v30_40acde = and i32 %v0_40acde, -65281
  %v31_40acde = or i32 %v29_40acde, %v30_40acde
  store i32 %v31_40acde, i32* %eax.global-to-local, align 4
  %v0_40ace1 = load i8, i8* inttoptr (i32 4763718 to i8*), align 2
  %v1_40ace1 = add i8 %v0_40ace1, 78
  %v5_40ace1 = icmp ult i8 %v0_40ace1, -78
  store i1 %v5_40ace1, i1* %cf.global-to-local, align 1
  store i8 %v1_40ace1, i8* inttoptr (i32 4763718 to i8*), align 2
  %v0_40ace8 = load i32, i32* %edi.global-to-local, align 4
  %v1_40ace8 = load i32, i32* inttoptr (i32 4763809 to i32*), align 4
  %v3_40ace8 = zext i1 %v5_40ace1 to i32
  %v4_40ace8 = add i32 %v1_40ace8, %v0_40ace8
  %v5_40ace8 = add i32 %v4_40ace8, %v3_40ace8
  store i32 %v5_40ace8, i32* %edi.global-to-local, align 4
  %v0_40acee = load i32, i32* %ebx.global-to-local, align 4
  %v1_40acee = add i32 %v0_40acee, 4
  store i32 %v1_40acee, i32* %ebx.global-to-local, align 4
  %v1_40acf1 = load i32, i32* inttoptr (i32 4763982 to i32*), align 4
  %v2_40acf1 = or i32 %v1_40acf1, %v1_40acee
  store i32 %v2_40acf1, i32* %ebx.global-to-local, align 4
  %v1_40acf7 = add i32 %v5_40ace8, 104
  %v5_40acf7 = icmp ugt i32 %v5_40ace8, -105
  store i32 %v1_40acf7, i32* %edi.global-to-local, align 4
  %v0_40acfa = load i32, i32* inttoptr (i32 4763682 to i32*), align 4
  %v3_40acfa = select i1 %v5_40acf7, i32 -175, i32 -176
  %v4_40acfa = add i32 %v3_40acfa, %v0_40acfa
  store i32 %v4_40acfa, i32* inttoptr (i32 4763682 to i32*), align 4
  %v0_40ad04 = load i32, i32* inttoptr (i32 4763807 to i32*), align 4
  %v1_40ad04 = or i32 %v0_40ad04, 67
  store i32 %v1_40ad04, i32* inttoptr (i32 4763807 to i32*), align 4
  %v0_40ad0b = load i32, i32* %eax.global-to-local, align 4
  %tmp115 = mul i32 %v0_40ad0b, 2
  %v23_40ad0b = and i32 %tmp115, 65024
  %v24_40ad0b = and i32 %v0_40ad0b, -65281
  %v25_40ad0b = or i32 %v23_40ad0b, %v24_40ad0b
  store i32 %v25_40ad0b, i32* %eax.global-to-local, align 4
  %v0_40ad0d = load i32, i32* inttoptr (i32 4763863 to i32*), align 4
  %v1_40ad0d = load i32, i32* %edi.global-to-local, align 4
  %v2_40ad0d = and i32 %v1_40ad0d, %v0_40ad0d
  store i32 %v2_40ad0d, i32* inttoptr (i32 4763863 to i32*), align 4
  %v1_40ad13 = add i32 %v25_40ad0b, 122
  store i1 true, i1* %cf.global-to-local, align 1
  %v12_40ad13 = trunc i32 %v1_40ad13 to i8
  store i32 %v1_40ad13, i32* %eax.global-to-local, align 4
  %v2_40ad16 = load i8, i8* inttoptr (i32 4763912 to i8*), align 8
  %v5_40ad16 = add i8 %v12_40ad13, 1
  %v6_40ad16 = add i8 %v5_40ad16, %v2_40ad16
  %v27_40ad16 = zext i8 %v6_40ad16 to i32
  %v29_40ad16 = and i32 %v1_40ad13, -256
  %v30_40ad16 = or i32 %v27_40ad16, %v29_40ad16
  store i32 %v30_40ad16, i32* %eax.global-to-local, align 4
  %v0_40ad1c = load i32, i32* %ecx.global-to-local, align 4
  %v1_40ad1c = add i32 %v0_40ad1c, -77
  %v5_40ad1c = icmp ugt i32 %v0_40ad1c, 76
  store i32 %v1_40ad1c, i32* %ecx.global-to-local, align 4
  %v0_40ad1f = load i32, i32* inttoptr (i32 4764012 to i32*), align 4
  %v2_40ad1f = zext i1 %v5_40ad1c to i32
  %v3_40ad1f = add i32 %v0_40ad1f, -128
  %v4_40ad1f = add i32 %v3_40ad1f, %v2_40ad1f
  store i32 %v4_40ad1f, i32* inttoptr (i32 4764012 to i32*), align 4
  store i32 33, i32* %edx.global-to-local, align 4
  %v0_40ad2e = load i32, i32* inttoptr (i32 4763916 to i32*), align 4
  %v3_40ad2e = add i32 %v0_40ad2e, 242
  store i32 %v3_40ad2e, i32* inttoptr (i32 4763916 to i32*), align 4
  %v0_40ad38 = load i32, i32* inttoptr (i32 4764052 to i32*), align 4
  %v1_40ad38 = load i32, i32* %esi.global-to-local, align 4
  %v2_40ad38 = and i32 %v1_40ad38, %v0_40ad38
  store i32 %v2_40ad38, i32* inttoptr (i32 4764052 to i32*), align 4
  %v0_40ad3e = load i32, i32* %eax.global-to-local, align 4
  %v1_40ad3e = load i32, i32* %ecx.global-to-local, align 4
  %v4_40ad3e = add i32 %v1_40ad3e, %v0_40ad3e
  %v18_40ad3e = trunc i32 %v4_40ad3e to i8
  %v25_40ad3e = icmp ult i32 %v4_40ad3e, %v0_40ad3e
  store i1 %v25_40ad3e, i1* %cf.global-to-local, align 1
  store i32 %v4_40ad3e, i32* %eax.global-to-local, align 4
  %v1_40ad40 = inttoptr i32 %v4_40ad3e to i8*
  %v2_40ad40 = load i8, i8* %v1_40ad40, align 1
  %v5_40ad40 = add i8 %v2_40ad40, %v18_40ad3e
  %v10_40ad40 = icmp ult i8 %v5_40ad40, %v2_40ad40
  store i1 %v10_40ad40, i1* %cf.global-to-local, align 1
  store i8 %v5_40ad40, i8* %v1_40ad40, align 1
  %v0_40ad42 = load i32, i32* %eax.global-to-local, align 4
  %v1_40ad42 = inttoptr i32 %v0_40ad42 to i8*
  %v2_40ad42 = load i8, i8* %v1_40ad42, align 1
  %v4_40ad42 = trunc i32 %v0_40ad42 to i8
  %v5_40ad42 = add i8 %v4_40ad42, %v2_40ad42
  %v10_40ad42 = icmp ult i8 %v5_40ad42, %v2_40ad42
  store i1 %v10_40ad42, i1* %cf.global-to-local, align 1
  store i8 %v5_40ad42, i8* %v1_40ad42, align 1
  %v0_40ad44 = load i32, i32* %eax.global-to-local, align 4
  %v1_40ad44 = inttoptr i32 %v0_40ad44 to i8*
  %v2_40ad44 = load i8, i8* %v1_40ad44, align 1
  %v4_40ad44 = trunc i32 %v0_40ad44 to i8
  %v5_40ad44 = add i8 %v4_40ad44, %v2_40ad44
  %v10_40ad44 = icmp ult i8 %v5_40ad44, %v2_40ad44
  store i1 %v10_40ad44, i1* %cf.global-to-local, align 1
  store i8 %v5_40ad44, i8* %v1_40ad44, align 1
  %v0_40ad46 = load i32, i32* %eax.global-to-local, align 4
  %v1_40ad46 = inttoptr i32 %v0_40ad46 to i8*
  %v2_40ad46 = load i8, i8* %v1_40ad46, align 1
  %v4_40ad46 = trunc i32 %v0_40ad46 to i8
  %v5_40ad46 = add i8 %v4_40ad46, %v2_40ad46
  %v10_40ad46 = icmp ult i8 %v5_40ad46, %v2_40ad46
  store i1 %v10_40ad46, i1* %cf.global-to-local, align 1
  store i8 %v5_40ad46, i8* %v1_40ad46, align 1
  %v0_40ad48 = load i32, i32* %eax.global-to-local, align 4
  %v1_40ad48 = inttoptr i32 %v0_40ad48 to i8*
  %v2_40ad48 = load i8, i8* %v1_40ad48, align 1
  %v4_40ad48 = trunc i32 %v0_40ad48 to i8
  %v5_40ad48 = add i8 %v4_40ad48, %v2_40ad48
  %v10_40ad48 = icmp ult i8 %v5_40ad48, %v2_40ad48
  store i1 %v10_40ad48, i1* %cf.global-to-local, align 1
  store i8 %v5_40ad48, i8* %v1_40ad48, align 1
  %v0_40ad4a = load i32, i32* %ecx.global-to-local, align 4
  %v1_40ad4a = add i32 %v0_40ad4a, 1219585813
  %v2_40ad4a = inttoptr i32 %v1_40ad4a to i8*
  %v3_40ad4a = load i8, i8* %v2_40ad4a, align 1
  %v4_40ad4a = load i32, i32* %eax.global-to-local, align 4
  %v5_40ad4a = trunc i32 %v4_40ad4a to i8
  %v6_40ad4a = add i8 %v5_40ad4a, %v3_40ad4a
  %v11_40ad4a = icmp ult i8 %v6_40ad4a, %v3_40ad4a
  store i1 %v11_40ad4a, i1* %cf.global-to-local, align 1
  store i8 %v6_40ad4a, i8* %v2_40ad4a, align 1
  %v0_40ad50 = load i32, i32* %esi.global-to-local, align 4
  %v1_40ad50 = add i32 %v0_40ad50, 16777216
  %v2_40ad50 = inttoptr i32 %v1_40ad50 to i8*
  %v3_40ad50 = load i8, i8* %v2_40ad50, align 1
  %v4_40ad50 = load i32, i32* %eax.global-to-local, align 4
  %v5_40ad50 = udiv i32 %v4_40ad50, 256
  %v6_40ad50 = trunc i32 %v5_40ad50 to i8
  %v7_40ad50 = add i8 %v6_40ad50, %v3_40ad50
  store i8 %v7_40ad50, i8* %v2_40ad50, align 1
  %v0_40ad56 = load i32, i32* %eax.global-to-local, align 4
  %v1_40ad56 = add i32 %v0_40ad56, 4763753
  %v5_40ad56 = icmp ugt i32 %v0_40ad56, -4763754
  store i32 %v1_40ad56, i32* %eax.global-to-local, align 4
  %v0_40ad5b = load i32, i32* inttoptr (i32 4764143 to i32*), align 4
  %v3_40ad5b = zext i1 %v5_40ad56 to i32
  %v1_40ad56.neg = sub i32 -4763753, %v0_40ad56
  %v4_40ad5b = add i32 %v0_40ad5b, %v1_40ad56.neg
  %v5_40ad5b = add i32 %v4_40ad5b, %v3_40ad5b
  store i32 %v5_40ad5b, i32* inttoptr (i32 4764143 to i32*), align 4
  %v0_40ad61 = load i32, i32* inttoptr (i32 4763779 to i32*), align 4
  %v1_40ad61 = load i32, i32* %eax.global-to-local, align 4
  %v2_40ad61 = or i32 %v1_40ad61, %v0_40ad61
  store i32 %v2_40ad61, i32* inttoptr (i32 4763779 to i32*), align 4
  %v0_40ad67 = load i32, i32* inttoptr (i32 4764032 to i32*), align 128
  %v3_40ad67 = add i32 %v0_40ad67, 133
  %v22_40ad67 = icmp ugt i32 %v0_40ad67, -134
  store i32 %v3_40ad67, i32* inttoptr (i32 4764032 to i32*), align 128
  store i32 1, i32* %edx.global-to-local, align 4
  %v1_40ad76 = load i32, i32* inttoptr (i32 4764152 to i32*), align 8
  %v3_40ad76 = zext i1 %v22_40ad67 to i32
  %v4_40ad76 = add i32 %v1_40ad76, 1
  %v5_40ad76 = add i32 %v4_40ad76, %v3_40ad76
  %v24_40ad76 = icmp ult i32 %v5_40ad76, 2
  %v25_40ad76 = icmp eq i32 %v4_40ad76, 0
  %v26_40ad76 = select i1 %v22_40ad67, i1 %v24_40ad76, i1 %v25_40ad76
  store i32 %v5_40ad76, i32* %edx.global-to-local, align 4
  %v0_40ad7c = load i32, i32* %eax.global-to-local, align 4
  %v1_40ad7c = load i32, i32* inttoptr (i32 4764049 to i32*), align 4
  %v3_40ad7c = zext i1 %v26_40ad76 to i32
  %v4_40ad7c = add i32 %v1_40ad7c, %v0_40ad7c
  %v5_40ad7c = add i32 %v4_40ad7c, %v3_40ad7c
  store i32 %v5_40ad7c, i32* %eax.global-to-local, align 4
  %v0_40ad82 = load i32, i32* inttoptr (i32 4764035 to i32*), align 4
  %v1_40ad82 = xor i32 %v0_40ad82, 166
  store i32 %v1_40ad82, i32* inttoptr (i32 4764035 to i32*), align 4
  %v0_40ad8c = load i32, i32* inttoptr (i32 4763810 to i32*), align 4
  %v1_40ad8c = or i32 %v0_40ad8c, 120
  store i32 %v1_40ad8c, i32* inttoptr (i32 4763810 to i32*), align 4
  %v0_40ad93 = load i32, i32* %ebx.global-to-local, align 4
  %v1_40ad93 = load i32, i32* inttoptr (i32 4763670 to i32*), align 4
  %v2_40ad93 = sub i32 %v0_40ad93, %v1_40ad93
  %v7_40ad93 = icmp ult i32 %v0_40ad93, %v1_40ad93
  store i1 %v7_40ad93, i1* %cf.global-to-local, align 1
  store i32 %v2_40ad93, i32* %ebx.global-to-local, align 4
  %v0_40ad99 = load i8, i8* inttoptr (i32 4763953 to i8*), align 1
  %v1_40ad99 = load i32, i32* %edx.global-to-local, align 4
  %v2_40ad99 = trunc i32 %v1_40ad99 to i8
  %v3_40ad99 = xor i8 %v2_40ad99, %v0_40ad99
  store i1 false, i1* %cf.global-to-local, align 1
  store i8 %v3_40ad99, i8* inttoptr (i32 4763953 to i8*), align 1
  %v0_40ad9f = load i32, i32* inttoptr (i32 4763945 to i32*), align 4
  %v1_40ad9f = load i32, i32* %ebx.global-to-local, align 4
  %v4_40ad9f = sub i32 %v0_40ad9f, %v1_40ad9f
  %v20_40ad9f = icmp ult i32 %v0_40ad9f, %v1_40ad9f
  store i32 %v4_40ad9f, i32* inttoptr (i32 4763945 to i32*), align 4
  %v0_40ada5 = load i32, i32* %edi.global-to-local, align 4
  %v2_40ada5 = zext i1 %v20_40ad9f to i32
  %v3_40ada5 = add i32 %v0_40ada5, 79
  %v4_40ada5 = add i32 %v3_40ada5, %v2_40ada5
  %v12_40ada5 = icmp ult i32 %v0_40ada5, -79
  %v13_40ada5 = or i1 %v12_40ada5, %v20_40ad9f
  store i32 %v4_40ada5, i32* %edi.global-to-local, align 4
  %v0_40ada8 = load i32, i32* %eax.global-to-local, align 4
  %v2_40ada8 = zext i1 %v13_40ada5 to i32
  %v3_40ada8 = add i32 %v0_40ada8, -78
  %v4_40ada8 = add i32 %v3_40ada8, %v2_40ada8
  %v23_40adab = load i32, i32* %ebx.global-to-local, align 4
  %v25_40adab = and i32 %v23_40adab, -65281
  %v2_40adad = add i32 %v4_40ada8, %v25_40adab
  store i32 %v2_40adad, i32* %ebx.global-to-local, align 4
  %v2_40adaf = add i32 %v2_40adad, %v4_40ada8
  %v7_40adaf = icmp ult i32 %v2_40adaf, %v4_40ada8
  store i32 %v2_40adaf, i32* %eax.global-to-local, align 4
  %v0_40adb1 = load i32, i32* %edx.global-to-local, align 4
  %v1_40adb1 = trunc i32 %v0_40adb1 to i8
  %v3_40adb1 = udiv i32 %v2_40adad, 256
  %v4_40adb1 = trunc i32 %v3_40adb1 to i8
  %v6_40adb1 = zext i1 %v7_40adaf to i8
  %v7_40adb1 = sub i8 %v1_40adb1, %v4_40adb1
  %v8_40adb1 = add i8 %v7_40adb1, %v6_40adb1
  %v19_40adb1 = sub i8 %v7_40adb1, %v6_40adb1
  %v20_40adb1 = icmp ult i8 %v1_40adb1, %v19_40adb1
  %v21_40adb1 = icmp ne i8 %v4_40adb1, -1
  %v22_40adb1 = or i1 %v21_40adb1, %v20_40adb1
  %v23_40adb1 = icmp ult i8 %v1_40adb1, %v4_40adb1
  %v24_40adb1 = select i1 %v7_40adaf, i1 %v22_40adb1, i1 %v23_40adb1
  store i1 %v24_40adb1, i1* %cf.global-to-local, align 1
  %v38_40adb1 = zext i8 %v8_40adb1 to i32
  %v40_40adb1 = and i32 %v0_40adb1, -256
  %v41_40adb1 = or i32 %v38_40adb1, %v40_40adb1
  store i32 %v41_40adb1, i32* %edx.global-to-local, align 4
  %v0_40adb3 = load i8, i8* inttoptr (i32 4763724 to i8*), align 4
  %v1_40adb3 = add i8 %v0_40adb3, 125
  store i8 %v1_40adb3, i8* inttoptr (i32 4763724 to i8*), align 4
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 1048576, i32* %eax.global-to-local, align 4
  %v10_40add3 = call i32* @OpenJobObjectW(i32 1048576, i1 false, i16* bitcast ([13 x i8]* @global_var_48b6a3.4 to i16*))
  %v11_40add3 = ptrtoint i32* %v10_40add3 to i32
  store i32 %v11_40add3, i32* %eax.global-to-local, align 4
  store i1 false, i1* %cf.global-to-local, align 1
  %v1_40add9 = icmp eq i32* %v10_40add3, null
  %v3_40add9 = trunc i32 %v11_40add3 to i8
  %v1_40addc = icmp eq i1 %v1_40add9, false
  call void @__pseudo_cond_branch(i1 %v1_40addc, i32 ptrtoint (i16** @global_var_406dd5.3 to i32))
  %v2_40ade7 = add i32 %v11_40add3, 1
  %v7_40ade7 = icmp eq i32 %v2_40ade7, 0
  store i1 %v7_40ade7, i1* %cf.global-to-local, align 1
  store i32 %v2_40ade7, i32* %edx.global-to-local, align 4
  %v1_40ade9 = udiv i32 %v11_40add3, 256
  %v2_40ade9 = trunc i32 %v1_40ade9 to i8
  %v3_40ade9 = load i8, i8* inttoptr (i32 4763675 to i8*), align 1
  %v4_40ade9 = or i8 %v3_40ade9, %v2_40ade9
  store i1 false, i1* %cf.global-to-local, align 1
  %v10_40ade9 = zext i8 %v4_40ade9 to i32
  %v12_40ade9 = mul nuw nsw i32 %v10_40ade9, 256
  %v13_40ade9 = and i32 %v11_40add3, -65281
  %v14_40ade9 = or i32 %v12_40ade9, %v13_40ade9
  store i32 %v14_40ade9, i32* %eax.global-to-local, align 4
  %v2_40adef = load i8, i8* inttoptr (i32 4763751 to i8*), align 1
  %v3_40adef = or i8 %v2_40adef, %v3_40add9
  %v9_40adef = zext i8 %v3_40adef to i32
  %v11_40adef = and i32 %v14_40ade9, -256
  %v12_40adef = or i32 %v11_40adef, %v9_40adef
  store i32 %v12_40adef, i32* %eax.global-to-local, align 4
  %v0_40adfd = load i32, i32* %ebx.global-to-local, align 4
  %v2_40adfd = add i32 %v0_40adfd, -59
  %v7_40adfd = icmp ugt i32 %v0_40adfd, 58
  store i32 %v2_40adfd, i32* %ebx.global-to-local, align 4
  %v4_40adff = select i1 %v7_40adfd, i32 40, i32 39
  store i32 %v4_40adff, i32* %ecx.global-to-local, align 4
  %v0_40ae02 = load i32, i32* inttoptr (i32 4763913 to i32*), align 4
  %v2_40adfd.neg = sub i32 59, %v0_40adfd
  %v4_40ae02 = add i32 %v2_40adfd.neg, 1
  %v5_40ae02 = add i32 %v4_40ae02, %v0_40ae02
  store i32 %v5_40ae02, i32* inttoptr (i32 4763913 to i32*), align 4
  %v1_40ae08 = load i32, i32* %edi.global-to-local, align 4
  %v2_40ae08 = sub i32 %v4_40adff, %v1_40ae08
  %v7_40ae08 = icmp ult i32 %v4_40adff, %v1_40ae08
  store i32 %v2_40ae08, i32* %ecx.global-to-local, align 4
  %v0_40ae0a = load i32, i32* %esi.global-to-local, align 4
  %v1_40ae0a = load i32, i32* inttoptr (i32 4764119 to i32*), align 4
  %v3_40ae0a = zext i1 %v7_40ae08 to i32
  %v4_40ae0a = add i32 %v1_40ae0a, %v0_40ae0a
  %v5_40ae0a = add i32 %v4_40ae0a, %v3_40ae0a
  %v24_40ae0a = icmp ule i32 %v5_40ae0a, %v0_40ae0a
  %v25_40ae0a = icmp ult i32 %v4_40ae0a, %v0_40ae0a
  %v26_40ae0a = select i1 %v7_40ae08, i1 %v24_40ae0a, i1 %v25_40ae0a
  store i32 %v5_40ae0a, i32* %esi.global-to-local, align 4
  %v0_40ae10 = load i32, i32* %edx.global-to-local, align 4
  %v1_40ae10 = load i32, i32* inttoptr (i32 4763996 to i32*), align 4
  %v3_40ae10 = zext i1 %v26_40ae0a to i32
  %v4_40ae10 = add i32 %v1_40ae10, %v0_40ae10
  %v5_40ae10 = add i32 %v4_40ae10, %v3_40ae10
  store i32 %v5_40ae10, i32* %edx.global-to-local, align 4
  %v1_40ae16 = load i32, i32* inttoptr (i32 4763936 to i32*), align 32
  %v2_40ae16 = or i32 %v5_40ae10, %v1_40ae16
  store i32 %v2_40ae16, i32* %edx.global-to-local, align 4
  %v1_40ae1c = load i32, i32* inttoptr (i32 4763674 to i32*), align 4
  %v2_40ae1c = sub i32 %v1_40ae08, %v1_40ae1c
  %v7_40ae1c = icmp ult i32 %v1_40ae08, %v1_40ae1c
  store i1 %v7_40ae1c, i1* %cf.global-to-local, align 1
  store i32 %v2_40ae1c, i32* %edi.global-to-local, align 4
  call void @__pseudo_call(i32 0)
  %v0_40ae2a = load i32, i32* %eax.global-to-local, align 4
  %v1_40ae2a = load i32, i32* inttoptr (i32 4763656 to i32*), align 8
  %v2_40ae2a = load i1, i1* %cf.global-to-local, align 1
  %v3_40ae2a = zext i1 %v2_40ae2a to i32
  %v4_40ae2a = add i32 %v1_40ae2a, %v0_40ae2a
  %v5_40ae2a = add i32 %v3_40ae2a, %v4_40ae2a
  %v24_40ae2a = icmp ule i32 %v5_40ae2a, %v0_40ae2a
  %v25_40ae2a = icmp ult i32 %v4_40ae2a, %v0_40ae2a
  %v26_40ae2a = select i1 %v2_40ae2a, i1 %v24_40ae2a, i1 %v25_40ae2a
  %v2_40ae30 = zext i1 %v26_40ae2a to i32
  %v3_40ae30 = add i32 %v5_40ae2a, -76
  %v4_40ae30 = add i32 %v3_40ae30, %v2_40ae30
  %v22_40ae30 = icmp ule i32 %v4_40ae30, %v5_40ae2a
  %v23_40ae30 = icmp ugt i32 %v5_40ae2a, 75
  %v24_40ae30 = select i1 %v26_40ae2a, i1 %v22_40ae30, i1 %v23_40ae30
  store i32 %v4_40ae30, i32* %eax.global-to-local, align 4
  %v0_40ae33 = load i32, i32* inttoptr (i32 4763855 to i32*), align 4
  %v3_40ae33 = select i1 %v24_40ae30, i32 48, i32 47
  %v4_40ae33 = add i32 %v3_40ae33, %v0_40ae33
  store i32 %v4_40ae33, i32* inttoptr (i32 4763855 to i32*), align 4
  %v0_40ae3a = load i32, i32* inttoptr (i32 4764130 to i32*), align 4
  %v1_40ae3a = load i32, i32* %ebx.global-to-local, align 4
  %v2_40ae3a = or i32 %v1_40ae3a, %v0_40ae3a
  store i32 %v2_40ae3a, i32* inttoptr (i32 4764130 to i32*), align 4
  %v0_40ae40 = load i32, i32* inttoptr (i32 4763700 to i32*), align 4
  %v1_40ae40 = and i32 %v0_40ae40, 192
  store i32 %v1_40ae40, i32* inttoptr (i32 4763700 to i32*), align 4
  %v0_40ae4a = load i32, i32* %ecx.global-to-local, align 4
  %v2_40ae4a = load i32, i32* %eax.global-to-local, align 4
  %v3_40ae4a39 = mul i32 %v2_40ae4a, 256
  %tmp117 = and i32 %v3_40ae4a39, 65280
  %v14_40ae4a = xor i32 %tmp117, %v0_40ae4a
  store i32 %v14_40ae4a, i32* %ecx.global-to-local, align 4
  %v1_40ae4c = load i32, i32* %edx.global-to-local, align 4
  %v2_40ae4c = sub i32 %v2_40ae4a, %v1_40ae4c
  store i32 %v2_40ae4c, i32* %eax.global-to-local, align 4
  %v0_40ae4e = load i32, i32* %edi.global-to-local, align 4
  %v1_40ae4e = load i32, i32* %ebx.global-to-local, align 4
  %v2_40ae4e = xor i32 %v1_40ae4e, %v0_40ae4e
  store i32 %v2_40ae4e, i32* %edi.global-to-local, align 4
  %v0_40ae50 = load i32, i32* inttoptr (i32 4763979 to i32*), align 4
  %v2_40ae50 = add i32 %v0_40ae50, %v1_40ae4e
  store i32 %v2_40ae50, i32* inttoptr (i32 4763979 to i32*), align 4
  %v0_40ae56 = load i32, i32* %ecx.global-to-local, align 4
  %v2_40ae56 = mul i32 %v0_40ae56, 2
  %v7_40ae56 = icmp ult i32 %v2_40ae56, %v0_40ae56
  store i32 %v2_40ae56, i32* %ecx.global-to-local, align 4
  %v0_40ae58 = load i32, i32* inttoptr (i32 4764103 to i32*), align 4
  %v2_40ae58 = zext i1 %v7_40ae56 to i32
  %v3_40ae58 = add i32 %v0_40ae58, -64
  %v4_40ae58 = add i32 %v3_40ae58, %v2_40ae58
  %v11_40ae58 = icmp ult i32 %v0_40ae58, 64
  %v12_40ae58 = or i1 %v7_40ae56, %v11_40ae58
  store i32 %v4_40ae58, i32* inttoptr (i32 4764103 to i32*), align 4
  %v0_40ae5f = load i32, i32* %eax.global-to-local, align 4
  %v1_40ae5f = load i32, i32* inttoptr (i32 4763911 to i32*), align 4
  %v3_40ae5f = zext i1 %v12_40ae58 to i32
  %v4_40ae5f = add i32 %v1_40ae5f, %v0_40ae5f
  %v5_40ae5f = add i32 %v4_40ae5f, %v3_40ae5f
  %v18_40ae5f = trunc i32 %v5_40ae5f to i8
  store i32 %v5_40ae5f, i32* %eax.global-to-local, align 4
  %v0_40ae65 = load i32, i32* %edi.global-to-local, align 4
  %v1_40ae65 = xor i32 %v0_40ae65, 126
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v1_40ae65, i32* %edi.global-to-local, align 4
  %v1_40ae68 = inttoptr i32 %v5_40ae5f to i8*
  %v2_40ae68 = load i8, i8* %v1_40ae68, align 1
  %v5_40ae68 = add i8 %v2_40ae68, %v18_40ae5f
  %v10_40ae68 = icmp ult i8 %v5_40ae68, %v2_40ae68
  store i1 %v10_40ae68, i1* %cf.global-to-local, align 1
  store i8 %v5_40ae68, i8* %v1_40ae68, align 1
  %v0_40ae6a = load i32, i32* %eax.global-to-local, align 4
  %v1_40ae6a = inttoptr i32 %v0_40ae6a to i8*
  %v2_40ae6a = load i8, i8* %v1_40ae6a, align 1
  %v4_40ae6a = trunc i32 %v0_40ae6a to i8
  %v5_40ae6a = add i8 %v4_40ae6a, %v2_40ae6a
  %v10_40ae6a = icmp ult i8 %v5_40ae6a, %v2_40ae6a
  store i1 %v10_40ae6a, i1* %cf.global-to-local, align 1
  store i8 %v5_40ae6a, i8* %v1_40ae6a, align 1
  %v0_40ae6c = load i32, i32* %eax.global-to-local, align 4
  %v1_40ae6c = inttoptr i32 %v0_40ae6c to i8*
  %v2_40ae6c = load i8, i8* %v1_40ae6c, align 1
  %v4_40ae6c = trunc i32 %v0_40ae6c to i8
  %v5_40ae6c = add i8 %v4_40ae6c, %v2_40ae6c
  %v10_40ae6c = icmp ult i8 %v5_40ae6c, %v2_40ae6c
  store i1 %v10_40ae6c, i1* %cf.global-to-local, align 1
  store i8 %v5_40ae6c, i8* %v1_40ae6c, align 1
  %v0_40ae6e = load i32, i32* %eax.global-to-local, align 4
  %v1_40ae6e = inttoptr i32 %v0_40ae6e to i8*
  %v2_40ae6e = load i8, i8* %v1_40ae6e, align 1
  %v4_40ae6e = trunc i32 %v0_40ae6e to i8
  %v5_40ae6e = add i8 %v4_40ae6e, %v2_40ae6e
  %v10_40ae6e = icmp ult i8 %v5_40ae6e, %v2_40ae6e
  store i1 %v10_40ae6e, i1* %cf.global-to-local, align 1
  store i8 %v5_40ae6e, i8* %v1_40ae6e, align 1
  %v0_40ae70 = load i32, i32* %eax.global-to-local, align 4
  %v1_40ae70 = inttoptr i32 %v0_40ae70 to i8*
  %v2_40ae70 = load i8, i8* %v1_40ae70, align 1
  %v4_40ae70 = trunc i32 %v0_40ae70 to i8
  %v5_40ae70 = add i8 %v4_40ae70, %v2_40ae70
  %v10_40ae70 = icmp ult i8 %v5_40ae70, %v2_40ae70
  store i1 %v10_40ae70, i1* %cf.global-to-local, align 1
  store i8 %v5_40ae70, i8* %v1_40ae70, align 1
  %v0_40ae72 = load i32, i32* %eax.global-to-local, align 4
  %v1_40ae72 = inttoptr i32 %v0_40ae72 to i8*
  %v2_40ae72 = load i8, i8* %v1_40ae72, align 1
  %v4_40ae72 = trunc i32 %v0_40ae72 to i8
  %v5_40ae72 = add i8 %v4_40ae72, %v2_40ae72
  %v10_40ae72 = icmp ult i8 %v5_40ae72, %v2_40ae72
  store i1 %v10_40ae72, i1* %cf.global-to-local, align 1
  store i8 %v5_40ae72, i8* %v1_40ae72, align 1
  %v0_40ae74 = load i32, i32* %eax.global-to-local, align 4
  %v1_40ae74 = inttoptr i32 %v0_40ae74 to i8*
  %v2_40ae74 = load i8, i8* %v1_40ae74, align 1
  %v4_40ae74 = trunc i32 %v0_40ae74 to i8
  %v5_40ae74 = add i8 %v4_40ae74, %v2_40ae74
  %v10_40ae74 = icmp ult i8 %v5_40ae74, %v2_40ae74
  store i1 %v10_40ae74, i1* %cf.global-to-local, align 1
  store i8 %v5_40ae74, i8* %v1_40ae74, align 1
  store i32 1, i32* %edx.global-to-local, align 4
  %v1_40ae7b = load i32, i32* inttoptr (i32 4764068 to i32*), align 4
  %v2_40ae7b = load i1, i1* %cf.global-to-local, align 1
  %v3_40ae7b = zext i1 %v2_40ae7b to i32
  %v4_40ae7b = add i32 %v1_40ae7b, 1
  %v5_40ae7b = add i32 %v3_40ae7b, %v4_40ae7b
  %v24_40ae7b = icmp ult i32 %v5_40ae7b, 2
  %v25_40ae7b = icmp eq i32 %v4_40ae7b, 0
  %v26_40ae7b = select i1 %v2_40ae7b, i1 %v24_40ae7b, i1 %v25_40ae7b
  store i1 %v26_40ae7b, i1* %cf.global-to-local, align 1
  store i32 %v5_40ae7b, i32* %edx.global-to-local, align 4
  %v0_40ae81 = load i8, i8* inttoptr (i32 4764066 to i8*), align 2
  %v1_40ae81 = add i8 %v0_40ae81, -44
  store i8 %v1_40ae81, i8* inttoptr (i32 4764066 to i8*), align 2
  %v0_40ae88 = load i32, i32* %esi.global-to-local, align 4
  %v1_40ae88 = or i32 %v0_40ae88, -10
  %v1_40ae8b = load i32, i32* %eax.global-to-local, align 4
  %v4_40ae8b = sub i32 %v1_40ae88, %v1_40ae8b
  %v20_40ae8b = icmp ult i32 %v1_40ae88, %v1_40ae8b
  store i32 %v4_40ae8b, i32* %esi.global-to-local, align 4
  %v0_40ae8d = load i32, i32* %edx.global-to-local, align 4
  %v1_40ae8d = load i32, i32* inttoptr (i32 4763667 to i32*), align 4
  %v3_40ae8d = zext i1 %v20_40ae8b to i32
  store i32 0, i32* %edi.global-to-local, align 4
  store i32 %v4_40ae8b, i32* %esi.global-to-local, align 4
  %v4_40ae8d = add i32 %v0_40ae8d, %v4_40ae8b
  %v5_40ae8d = add i32 %v4_40ae8d, %v3_40ae8d
  %v4_40ae97 = add i32 %v5_40ae8d, %v1_40ae8d
  store i32 %v4_40ae97, i32* %edx.global-to-local, align 4
  %v0_40ae99 = load i32, i32* inttoptr (i32 4764060 to i32*), align 4
  %v2_40ae99 = sub i32 %v0_40ae99, %v1_40ae8b
  %v7_40ae99 = icmp ult i32 %v0_40ae99, %v1_40ae8b
  store i1 %v7_40ae99, i1* %cf.global-to-local, align 1
  store i32 %v2_40ae99, i32* inttoptr (i32 4764060 to i32*), align 4
  %v0_40ae9f = load i32, i32* %eax.global-to-local, align 4
  %v1_40ae9f = udiv i32 %v0_40ae9f, 256
  %v2_40ae9f = trunc i32 %v1_40ae9f to i8
  %v3_40ae9f = load i8, i8* inttoptr (i32 4763754 to i8*), align 2
  %v4_40ae9f = or i8 %v2_40ae9f, %v3_40ae9f
  %v10_40ae9f = zext i8 %v4_40ae9f to i32
  %v12_40ae9f = mul nuw nsw i32 %v10_40ae9f, 256
  %v13_40ae9f = and i32 %v0_40ae9f, -65281
  %v14_40ae9f = or i32 %v12_40ae9f, %v13_40ae9f
  store i32 %v14_40ae9f, i32* %eax.global-to-local, align 4
  %v1_40aeaa = load i32, i32* %ebx.global-to-local, align 4
  %v2_40aeaa = add i32 %v1_40aeaa, 1
  store i32 %v2_40aeaa, i32* %ecx.global-to-local, align 4
  %v0_40aeac = load i32, i32* inttoptr (i32 4763680 to i32*), align 32
  %v1_40aeac = and i32 %v0_40aeac, 148
  store i32 %v1_40aeac, i32* inttoptr (i32 4763680 to i32*), align 32
  %v1_40aeb6 = load i32, i32* inttoptr (i32 4763972 to i32*), align 4
  %v4_40aeb6 = add i32 %v1_40aeb6, %v1_40aeaa
  store i32 %v4_40aeb6, i32* %ebx.global-to-local, align 4
  %v0_40aebc = load i32, i32* %esi.global-to-local, align 4
  %v1_40aebc = and i32 %v0_40aebc, 70
  store i32 %v1_40aebc, i32* %esi.global-to-local, align 4
  %v0_40aebf = load i32, i32* %eax.global-to-local, align 4
  %v1_40aebf = add i32 %v0_40aebf, -91
  store i32 %v1_40aebf, i32* %eax.global-to-local, align 4
  store i1 false, i1* %cf.global-to-local, align 1
  %v8_40aed4 = call i1 @SetEnvironmentVariableW(i16* bitcast ([13 x i8]* @global_var_48b685.2 to i16*), i16* bitcast ([17 x i8]* @global_var_48b692.1 to i16*))
  %v9_40aed4 = sext i1 %v8_40aed4 to i32
  store i32 %v9_40aed4, i32* %eax.global-to-local, align 4
  %v0_40aeda = load i32, i32* %ebx.global-to-local, align 4
  %v1_40aeda = add i32 %v0_40aeda, 123
  %v5_40aeda = icmp ugt i32 %v0_40aeda, -124
  store i32 %v1_40aeda, i32* %ebx.global-to-local, align 4
  store i32 1, i32* %ecx.global-to-local, align 4
  %v1_40aee2 = load i32, i32* inttoptr (i32 4763659 to i32*), align 4
  %v4_40aee2 = select i1 %v5_40aeda, i32 2, i32 1
  %v5_40aee2 = add i32 %v4_40aee2, %v1_40aee2
  store i32 %v5_40aee2, i32* %ecx.global-to-local, align 4
  %v1_40aee8 = load i32, i32* inttoptr (i32 4764004 to i32*), align 4
  %v2_40aee8 = or i32 %v1_40aee8, %v5_40aee2
  store i32 %v2_40aee8, i32* %ecx.global-to-local, align 4
  %v1_40aeee = add nsw i32 %v9_40aed4, 110
  %v5_40aeee15 = icmp ne i1 %v8_40aed4, true
  %v1_40aef1 = load i32, i32* %edi.global-to-local, align 4
  %v3_40aef1 = zext i1 %v5_40aeee15 to i32
  %v4_40aef1 = add i32 %v1_40aef1, %v1_40aeee
  %v5_40aef1 = add i32 %v4_40aef1, %v3_40aef1
  %v24_40aef1 = icmp ule i32 %v5_40aef1, %v1_40aeee
  %v25_40aef1 = icmp ult i32 %v4_40aef1, %v1_40aeee
  %v26_40aef1 = select i1 %v5_40aeee15, i1 %v24_40aef1, i1 %v25_40aef1
  store i32 %v5_40aef1, i32* %eax.global-to-local, align 4
  %v0_40aef3 = load i32, i32* inttoptr (i32 4763845 to i32*), align 4
  %v3_40aef3 = zext i1 %v26_40aef1 to i32
  %v4_40aef3 = add i32 %v0_40aef3, %v2_40aee8
  %v5_40aef3 = add i32 %v3_40aef3, %v4_40aef3
  %v24_40aef3 = icmp ule i32 %v5_40aef3, %v0_40aef3
  %v25_40aef3 = icmp ult i32 %v4_40aef3, %v0_40aef3
  %v26_40aef3 = select i1 %v26_40aef1, i1 %v24_40aef3, i1 %v25_40aef3
  store i1 %v26_40aef3, i1* %cf.global-to-local, align 1
  store i32 %v5_40aef3, i32* inttoptr (i32 4763845 to i32*), align 4
  %v0_40aef9 = load i32, i32* %eax.global-to-local, align 4
  %v1_40aef9 = trunc i32 %v0_40aef9 to i8
  %v2_40aef9 = load i8, i8* inttoptr (i32 4763828 to i8*), align 4
  %v4_40aef9 = zext i1 %v26_40aef3 to i8
  %v5_40aef9 = add i8 %v1_40aef9, %v2_40aef9
  %v6_40aef9 = add i8 %v4_40aef9, %v5_40aef9
  %v24_40aef9 = icmp ule i8 %v6_40aef9, %v1_40aef9
  %v25_40aef9 = icmp ult i8 %v5_40aef9, %v1_40aef9
  %v26_40aef9 = select i1 %v26_40aef3, i1 %v24_40aef9, i1 %v25_40aef9
  %v27_40aef9 = zext i8 %v6_40aef9 to i32
  %v29_40aef9 = and i32 %v0_40aef9, -256
  %v30_40aef9 = or i32 %v27_40aef9, %v29_40aef9
  store i32 %v30_40aef9, i32* %eax.global-to-local, align 4
  %v0_40aeff = load i32, i32* %esi.global-to-local, align 4
  %v1_40aeff = load i32, i32* inttoptr (i32 4764159 to i32*), align 4
  %v3_40aeff = zext i1 %v26_40aef9 to i32
  %v4_40aeff = add i32 %v1_40aeff, %v0_40aeff
  %v5_40aeff = add i32 %v3_40aeff, %v4_40aeff
  %v24_40aeff = icmp ule i32 %v5_40aeff, %v0_40aeff
  %v25_40aeff = icmp ult i32 %v4_40aeff, %v0_40aeff
  %v26_40aeff = select i1 %v26_40aef9, i1 %v24_40aeff, i1 %v25_40aeff
  store i1 %v26_40aeff, i1* %cf.global-to-local, align 1
  store i32 %v5_40aeff, i32* %esi.global-to-local, align 4
  %v0_40af05 = load i8, i8* inttoptr (i32 4763915 to i8*), align 1
  %v1_40af05 = load i32, i32* %ecx.global-to-local, align 4
  %v2_40af05 = udiv i32 %v1_40af05, 256
  %v3_40af05 = trunc i32 %v2_40af05 to i8
  %v4_40af05 = sub i8 %v0_40af05, %v3_40af05
  %v9_40af05 = icmp ult i8 %v0_40af05, %v3_40af05
  store i1 %v9_40af05, i1* %cf.global-to-local, align 1
  store i8 %v4_40af05, i8* inttoptr (i32 4763915 to i8*), align 1
  %v0_40af0b = load i32, i32* inttoptr (i32 4764108 to i32*), align 4
  %v1_40af0b = load i32, i32* %esi.global-to-local, align 4
  %v3_40af0b = zext i1 %v9_40af05 to i32
  %v4_40af0b = sub i32 %v0_40af0b, %v1_40af0b
  %v5_40af0b = add i32 %v4_40af0b, %v3_40af0b
  store i32 %v5_40af0b, i32* inttoptr (i32 4764108 to i32*), align 4
  %v0_40af11 = load i32, i32* %ebx.global-to-local, align 4
  %v1_40af11 = load i32, i32* %ecx.global-to-local, align 4
  %v2_40af11 = add i32 %v1_40af11, %v0_40af11
  %v1_40af13 = load i32, i32* %esi.global-to-local, align 4
  %v2_40af13 = add i32 %v1_40af13, %v2_40af11
  %v7_40af13 = icmp ult i32 %v2_40af13, %v2_40af11
  store i32 %v2_40af13, i32* %ebx.global-to-local, align 4
  %v0_40af15 = load i32, i32* inttoptr (i32 4764031 to i32*), align 4
  %v2_40af15 = zext i1 %v7_40af13 to i32
  %v3_40af15 = add i32 %v0_40af15, 208
  %v4_40af15 = add i32 %v3_40af15, %v2_40af15
  %v20_40af15 = icmp ule i32 %v4_40af15, %v0_40af15
  %v21_40af15 = icmp ugt i32 %v0_40af15, -209
  %v22_40af15 = select i1 %v7_40af13, i1 %v20_40af15, i1 %v21_40af15
  store i1 %v22_40af15, i1* %cf.global-to-local, align 1
  store i32 %v4_40af15, i32* inttoptr (i32 4764031 to i32*), align 4
  call void @__pseudo_call(i32 4239143)
  store i32 51, i32* inttoptr (i32 4763978 to i32*), align 4
  %v0_40af31 = load i32, i32* %ebx.global-to-local, align 4
  %v1_40af31 = load i1, i1* %cf.global-to-local, align 1
  %v2_40af31 = zext i1 %v1_40af31 to i32
  %v3_40af31 = add i32 %v0_40af31, -16
  %v4_40af31 = add i32 %v3_40af31, %v2_40af31
  store i32 %v4_40af31, i32* %ebx.global-to-local, align 4
  %v0_40af34 = load i32, i32* inttoptr (i32 4763892 to i32*), align 4
  %v1_40af34 = load i32, i32* %edi.global-to-local, align 4
  %v2_40af34 = add i32 %v1_40af34, %v0_40af34
  store i32 %v2_40af34, i32* inttoptr (i32 4763892 to i32*), align 4
  %v0_40af3a = load i32, i32* %ecx.global-to-local, align 4
  %v1_40af3a = load i32, i32* inttoptr (i32 4763870 to i32*), align 4
  %v2_40af3a = sub i32 %v0_40af3a, %v1_40af3a
  %v7_40af3a = icmp ult i32 %v0_40af3a, %v1_40af3a
  store i32 %v2_40af3a, i32* %ecx.global-to-local, align 4
  %v0_40af40 = load i32, i32* inttoptr (i32 4763753 to i32*), align 4
  %v2_40af40 = zext i1 %v7_40af3a to i32
  %v3_40af40 = add i32 %v0_40af40, 247
  %v4_40af40 = add i32 %v3_40af40, %v2_40af40
  store i32 %v4_40af40, i32* inttoptr (i32 4763753 to i32*), align 4
  %v0_40af4a = load i32, i32* %esi.global-to-local, align 4
  %v1_40af4a = or i32 %v0_40af4a, 93
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v1_40af4a, i32* %esi.global-to-local, align 4
  %v0_40af4d = load i32, i32* %ebx.global-to-local, align 4
  %v1_40af4d = udiv i32 %v0_40af4d, 256
  %v2_40af4d = trunc i32 %v1_40af4d to i8
  %v3_40af4d = load i8, i8* inttoptr (i32 4763959 to i8*), align 1
  %v4_40af4d = sub i8 %v2_40af4d, %v3_40af4d
  %v19_40af4d = zext i8 %v4_40af4d to i32
  %v21_40af4d = mul nuw nsw i32 %v19_40af4d, 256
  %v22_40af4d = and i32 %v0_40af4d, -65281
  %v23_40af4d = or i32 %v21_40af4d, %v22_40af4d
  store i32 %v23_40af4d, i32* %ebx.global-to-local, align 4
  %v0_40af53 = load i32, i32* %edi.global-to-local, align 4
  %v2_40af53 = add i32 %v0_40af53, %v1_40af4a
  store i32 %v2_40af53, i32* %edi.global-to-local, align 4
  %v0_40af55 = load i32, i32* inttoptr (i32 4763974 to i32*), align 4
  %v1_40af55 = load i32, i32* %eax.global-to-local, align 4
  %v2_40af55 = add i32 %v1_40af55, %v0_40af55
  %v7_40af55 = icmp ult i32 %v2_40af55, %v0_40af55
  store i32 %v2_40af55, i32* inttoptr (i32 4763974 to i32*), align 4
  %v2_40af5b = zext i1 %v7_40af55 to i32
  %v3_40af5b = add i32 %v2_40af53, 80
  %v4_40af5b = add i32 %v3_40af5b, %v2_40af5b
  %v20_40af5b = icmp ule i32 %v4_40af5b, %v2_40af53
  %v21_40af5b = icmp ugt i32 %v2_40af53, -81
  %v22_40af5b = select i1 %v7_40af55, i1 %v20_40af5b, i1 %v21_40af5b
  store i1 %v22_40af5b, i1* %cf.global-to-local, align 1
  store i32 %v4_40af5b, i32* %edi.global-to-local, align 4
  %v0_40af5e = load i32, i32* %eax.global-to-local, align 4
  %v1_40af5e = inttoptr i32 %v0_40af5e to i8*
  %v2_40af5e = load i8, i8* %v1_40af5e, align 1
  %v4_40af5e = trunc i32 %v0_40af5e to i8
  %v5_40af5e = add i8 %v4_40af5e, %v2_40af5e
  %v10_40af5e = icmp ult i8 %v5_40af5e, %v2_40af5e
  store i1 %v10_40af5e, i1* %cf.global-to-local, align 1
  store i8 %v5_40af5e, i8* %v1_40af5e, align 1
  %v0_40af60 = load i32, i32* %eax.global-to-local, align 4
  %v1_40af60 = inttoptr i32 %v0_40af60 to i8*
  %v2_40af60 = load i8, i8* %v1_40af60, align 1
  %v4_40af60 = trunc i32 %v0_40af60 to i8
  %v5_40af60 = add i8 %v4_40af60, %v2_40af60
  %v10_40af60 = icmp ult i8 %v5_40af60, %v2_40af60
  store i1 %v10_40af60, i1* %cf.global-to-local, align 1
  store i8 %v5_40af60, i8* %v1_40af60, align 1
  %v0_40af62 = load i32, i32* %eax.global-to-local, align 4
  %v1_40af62 = inttoptr i32 %v0_40af62 to i8*
  %v2_40af62 = load i8, i8* %v1_40af62, align 1
  %v4_40af62 = trunc i32 %v0_40af62 to i8
  %v5_40af62 = add i8 %v4_40af62, %v2_40af62
  %v10_40af62 = icmp ult i8 %v5_40af62, %v2_40af62
  store i1 %v10_40af62, i1* %cf.global-to-local, align 1
  store i8 %v5_40af62, i8* %v1_40af62, align 1
  %v0_40af64 = load i32, i32* %eax.global-to-local, align 4
  %v1_40af64 = inttoptr i32 %v0_40af64 to i8*
  %v2_40af64 = load i8, i8* %v1_40af64, align 1
  %v4_40af64 = trunc i32 %v0_40af64 to i8
  %v5_40af64 = add i8 %v4_40af64, %v2_40af64
  %v10_40af64 = icmp ult i8 %v5_40af64, %v2_40af64
  store i1 %v10_40af64, i1* %cf.global-to-local, align 1
  store i8 %v5_40af64, i8* %v1_40af64, align 1
  %v0_40af66 = load i32, i32* %ecx.global-to-local, align 4
  %v1_40af66 = inttoptr i32 %v0_40af66 to i8*
  %v2_40af66 = load i8, i8* %v1_40af66, align 1
  %v3_40af66 = load i32, i32* %eax.global-to-local, align 4
  %v4_40af66 = trunc i32 %v3_40af66 to i8
  %v5_40af66 = add i8 %v4_40af66, %v2_40af66
  %v10_40af66 = icmp ult i8 %v5_40af66, %v2_40af66
  store i1 %v10_40af66, i1* %cf.global-to-local, align 1
  store i8 %v5_40af66, i8* %v1_40af66, align 1
  %v0_40af68 = load i32, i32* %eax.global-to-local, align 4
  %v1_40af68 = load i1, i1* %cf.global-to-local, align 1
  %v2_40af68 = zext i1 %v1_40af68 to i32
  %v3_40af68 = add i32 %v0_40af68, -4763710
  %v4_40af68 = add i32 %v3_40af68, %v2_40af68
  %v12_40af68 = icmp ult i32 %v0_40af68, 4763710
  %v13_40af68 = or i1 %v12_40af68, %v1_40af68
  store i1 %v13_40af68, i1* %cf.global-to-local, align 1
  %v22_40af68 = trunc i32 %v4_40af68 to i8
  store i32 %v4_40af68, i32* %eax.global-to-local, align 4
  %v0_40af6d = load i8, i8* inttoptr (i32 4763979 to i8*), align 1
  %v3_40af6d = or i8 %v0_40af6d, %v22_40af68
  store i1 false, i1* %cf.global-to-local, align 1
  store i8 %v3_40af6d, i8* inttoptr (i32 4763979 to i8*), align 1
  %v0_40af73 = load i32, i32* inttoptr (i32 4763713 to i32*), align 4
  %v4_40af73 = add i32 %v0_40af73, -195
  store i32 %v4_40af73, i32* inttoptr (i32 4763713 to i32*), align 4
  %v0_40af7d = load i32, i32* %eax.global-to-local, align 4
  %v1_40af7d = add i32 %v0_40af7d, 61
  store i32 %v1_40af7d, i32* %eax.global-to-local, align 4
  %v0_40af80 = load i32, i32* %esi.global-to-local, align 4
  %v2_40af80 = add i32 %v0_40af80, %v1_40af7d
  store i32 %v2_40af80, i32* %esi.global-to-local, align 4
  %v0_40af82 = load i32, i32* inttoptr (i32 4763992 to i32*), align 8
  %v1_40af82 = load i32, i32* %edi.global-to-local, align 4
  %v2_40af82 = and i32 %v1_40af82, %v0_40af82
  store i32 %v2_40af82, i32* inttoptr (i32 4763992 to i32*), align 8
  %v0_40af88 = load i32, i32* %ebx.global-to-local, align 4
  %v1_40af88 = load i32, i32* inttoptr (i32 4764094 to i32*), align 4
  %v2_40af88 = sub i32 %v0_40af88, %v1_40af88
  %v7_40af88 = icmp ult i32 %v0_40af88, %v1_40af88
  %v1_40af8e = load i32, i32* %edi.global-to-local, align 4
  %v3_40af8e = zext i1 %v7_40af88 to i32
  %v4_40af8e = add i32 %v2_40af88, %v1_40af8e
  %v5_40af8e = add i32 %v4_40af8e, %v3_40af8e
  %v18_40af8e = trunc i32 %v5_40af8e to i8
  store i32 %v5_40af8e, i32* %ebx.global-to-local, align 4
  %v0_40af90 = load i32, i32* %eax.global-to-local, align 4
  %v1_40af90 = or i32 %v0_40af90, 29
  store i32 %v1_40af90, i32* %eax.global-to-local, align 4
  %v0_40af93 = load i32, i32* %esi.global-to-local, align 4
  %v3_40af93 = add i32 %v0_40af93, 49
  %v22_40af93 = icmp ugt i32 %v0_40af93, -50
  store i1 %v22_40af93, i1* %cf.global-to-local, align 1
  store i32 %v3_40af93, i32* %esi.global-to-local, align 4
  %v2_40af96 = load i8, i8* inttoptr (i32 4764071 to i8*), align 1
  %v4_40af96 = zext i1 %v22_40af93 to i8
  %v5_40af96 = add i8 %v4_40af96, %v18_40af8e
  %v6_40af96 = add i8 %v5_40af96, %v2_40af96
  %v27_40af96 = zext i8 %v6_40af96 to i32
  %v29_40af96 = and i32 %v5_40af8e, -256
  %v30_40af96 = or i32 %v27_40af96, %v29_40af96
  %v1_40af9c = add i32 %v1_40af90, -78
  store i32 %v1_40af9c, i32* %eax.global-to-local, align 4
  %v2_40af9f = add i32 %v30_40af96, %v1_40af8e
  store i32 %v2_40af9f, i32* %ebx.global-to-local, align 4
  %v1_40afa1 = and i32 %v3_40af93, 93
  store i32 %v1_40afa1, i32* %esi.global-to-local, align 4
  %v1_40afa4 = load i32, i32* inttoptr (i32 4763661 to i32*), align 4
  %v4_40afa4 = add i32 %v1_40afa4, %v1_40af8e
  store i32 %v4_40afa4, i32* %edi.global-to-local, align 4
  %v0_40afaa = load i32, i32* inttoptr (i32 4764104 to i32*), align 8
  %v2_40afaa = sub i32 %v0_40afaa, %v1_40afa1
  store i32 %v2_40afaa, i32* inttoptr (i32 4764104 to i32*), align 8
  %v1_40afb5 = load i32, i32* %esi.global-to-local, align 4
  %v2_40afb5 = add i32 %v1_40afb5, 1
  store i32 %v2_40afb5, i32* %edx.global-to-local, align 4
  store i32 %v2_40afb5, i32* %ecx.global-to-local, align 4
  %v0_40afbe = load i32, i32* %edi.global-to-local, align 4
  %v1_40afbe = load i32, i32* %eax.global-to-local, align 4
  %v2_40afbe = add i32 %v1_40afbe, %v0_40afbe
  %v7_40afbe = icmp ult i32 %v2_40afbe, %v0_40afbe
  store i32 %v2_40afbe, i32* %edi.global-to-local, align 4
  %v0_40afc0 = load i32, i32* inttoptr (i32 4764036 to i32*), align 4
  %v3_40afc0 = zext i1 %v7_40afbe to i32
  %v4_40afc0 = add i32 %v0_40afc0, %v2_40afbe
  %v5_40afc0 = add i32 %v4_40afc0, %v3_40afc0
  store i32 %v5_40afc0, i32* inttoptr (i32 4764036 to i32*), align 4
  store i1 false, i1* %cf.global-to-local, align 1
  %v8_40afd8 = call i1 @SetEnvironmentVariableW(i16* bitcast ([13 x i8]* @global_var_48b685.2 to i16*), i16* bitcast ([17 x i8]* @global_var_48b692.1 to i16*))
  %v9_40afd8 = sext i1 %v8_40afd8 to i32
  store i32 %v9_40afd8, i32* %eax.global-to-local, align 4
  %v0_40afde = load i32, i32* inttoptr (i32 4763671 to i32*), align 4
  %v1_40afde = and i32 %v0_40afde, 2
  store i32 %v1_40afde, i32* inttoptr (i32 4763671 to i32*), align 4
  store i32 37, i32* inttoptr (i32 4763732 to i32*), align 4
  %v0_40afef = load i32, i32* inttoptr (i32 4763721 to i32*), align 4
  %v1_40afef = load i32, i32* %esi.global-to-local, align 4
  %v4_40afef = add i32 %v1_40afef, %v0_40afef
  %v25_40afef = icmp ult i32 %v4_40afef, %v0_40afef
  store i1 %v25_40afef, i1* %cf.global-to-local, align 1
  store i32 %v4_40afef, i32* inttoptr (i32 4763721 to i32*), align 4
  %v0_40aff5 = load i32, i32* %ebx.global-to-local, align 4
  %v1_40aff5 = udiv i32 %v0_40aff5, 256
  %v2_40aff5 = trunc i32 %v1_40aff5 to i8
  %v3_40aff5 = load i8, i8* inttoptr (i32 4763769 to i8*), align 1
  %v4_40aff5 = sub i8 %v2_40aff5, %v3_40aff5
  %v9_40aff5 = icmp ult i8 %v2_40aff5, %v3_40aff5
  %v19_40aff5 = zext i8 %v4_40aff5 to i32
  %v21_40aff5 = mul nuw nsw i32 %v19_40aff5, 256
  %v22_40aff5 = and i32 %v0_40aff5, -65281
  %v23_40aff5 = or i32 %v21_40aff5, %v22_40aff5
  store i32 %v23_40aff5, i32* %ebx.global-to-local, align 4
  %v1_40affb = load i32, i32* inttoptr (i32 4763743 to i32*), align 4
  %v3_40affb = zext i1 %v9_40aff5 to i32
  %v4_40affb = add i32 %v1_40affb, %v9_40afd8
  %v5_40affb = add i32 %v4_40affb, %v3_40affb
  store i32 %v5_40affb, i32* %eax.global-to-local, align 4
  %v0_40b001 = load i32, i32* inttoptr (i32 4763712 to i32*), align 64
  %v1_40b001 = xor i32 %v0_40b001, 135
  store i32 %v1_40b001, i32* inttoptr (i32 4763712 to i32*), align 64
  store i32 0, i32* %esi.global-to-local, align 4
  %v0_40b00d = load i32, i32* inttoptr (i32 4763899 to i32*), align 4
  %v3_40b00d = add i32 %v0_40b00d, 154
  store i32 %v3_40b00d, i32* inttoptr (i32 4763899 to i32*), align 4
  %v0_40b017 = load i32, i32* inttoptr (i32 4763855 to i32*), align 4
  %v1_40b017 = load i32, i32* %ebx.global-to-local, align 4
  %v2_40b017 = and i32 %v1_40b017, %v0_40b017
  store i32 %v2_40b017, i32* inttoptr (i32 4763855 to i32*), align 4
  %v0_40b01d = load i32, i32* %esi.global-to-local, align 4
  %v1_40b01d = xor i32 %v0_40b01d, -127
  store i32 %v1_40b01d, i32* %esi.global-to-local, align 4
  store i32 0, i32* %eax.global-to-local, align 4
  %v0_40b022 = load i32, i32* inttoptr (i32 4763972 to i32*), align 4
  %v1_40b022 = xor i32 %v0_40b022, 208
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v1_40b022, i32* inttoptr (i32 4763972 to i32*), align 4
  call void @__pseudo_call(i32 4239412)
  %v0_40b034 = load i32, i32* %eax.global-to-local, align 4
  %v1_40b034 = add i32 %v0_40b034, 63
  %v5_40b034 = icmp ult i32 %v0_40b034, -63
  store i32 %v1_40b034, i32* %eax.global-to-local, align 4
  store i32 1, i32* %edx.global-to-local, align 4
  %v1_40b03c = load i32, i32* inttoptr (i32 4763847 to i32*), align 4
  %v3_40b03c = zext i1 %v5_40b034 to i32
  %v4_40b03c = add i32 %v1_40b03c, 1
  %v5_40b03c = add i32 %v4_40b03c, %v3_40b03c
  %v24_40b03c = icmp ult i32 %v5_40b03c, 2
  %v25_40b03c = icmp eq i32 %v4_40b03c, 0
  %v26_40b03c = select i1 %v5_40b034, i1 %v24_40b03c, i1 %v25_40b03c
  store i1 %v26_40b03c, i1* %cf.global-to-local, align 1
  store i32 %v5_40b03c, i32* %edx.global-to-local, align 4
  %v0_40b042 = load i32, i32* %ebx.global-to-local, align 4
  %v1_40b042 = udiv i32 %v0_40b042, 256
  %v2_40b042 = trunc i32 %v1_40b042 to i8
  %v3_40b042 = load i8, i8* inttoptr (i32 4763835 to i8*), align 1
  %v4_40b042 = or i8 %v2_40b042, %v3_40b042
  store i1 false, i1* %cf.global-to-local, align 1
  %v10_40b042 = zext i8 %v4_40b042 to i32
  %v12_40b042 = mul nuw nsw i32 %v10_40b042, 256
  %v13_40b042 = and i32 %v0_40b042, -65281
  %v14_40b042 = or i32 %v12_40b042, %v13_40b042
  store i32 %v14_40b042, i32* %ebx.global-to-local, align 4
  %v1_40b048 = udiv i32 %v5_40b03c, 256
  %v2_40b048 = trunc i32 %v1_40b048 to i8
  %v3_40b048 = load i8, i8* inttoptr (i32 4764088 to i8*), align 8
  %v4_40b048 = sub i8 %v2_40b048, %v3_40b048
  %v19_40b048 = zext i8 %v4_40b048 to i32
  %v21_40b048 = mul nuw nsw i32 %v19_40b048, 256
  %v22_40b048 = and i32 %v5_40b03c, -65281
  %v23_40b048 = or i32 %v21_40b048, %v22_40b048
  store i32 %v23_40b048, i32* %edx.global-to-local, align 4
  %v0_40b04e = load i32, i32* %edi.global-to-local, align 4
  %v1_40b04e = add i32 %v0_40b04e, -56
  store i32 %v1_40b04e, i32* %edi.global-to-local, align 4
  %v1_40b051 = load i32, i32* inttoptr (i32 4763954 to i32*), align 4
  %v2_40b051 = sub i32 %v1_40b034, %v1_40b051
  %v3_40b057 = or i8 %v4_40b048, 76
  %v8_40b057 = zext i8 %v3_40b057 to i32
  %v10_40b057 = mul nuw nsw i32 %v8_40b057, 256
  %v12_40b057 = or i32 %v10_40b057, %v22_40b048
  store i32 %v12_40b057, i32* %edx.global-to-local, align 4
  %v3_40b05a = add i32 %v2_40b051, 48
  %v11_40b05a = icmp ult i32 %v2_40b051, -48
  store i32 %v3_40b05a, i32* %eax.global-to-local, align 4
  %v5_40b05d = select i1 %v11_40b05a, i8 114, i8 113
  %v6_40b05d = add i8 %v5_40b05d, %v4_40b042
  %v22_40b05d = icmp ule i8 %v6_40b05d, %v4_40b042
  %v23_40b05d = icmp ugt i8 %v4_40b042, -114
  %v24_40b05d = select i1 %v11_40b05a, i1 %v22_40b05d, i1 %v23_40b05d
  %v25_40b05d = zext i8 %v6_40b05d to i32
  %v27_40b05d = mul nuw nsw i32 %v25_40b05d, 256
  %v28_40b05d = and i32 %v0_40b042, -65281
  %v29_40b05d = or i32 %v27_40b05d, %v28_40b05d
  store i32 %v29_40b05d, i32* %ebx.global-to-local, align 4
  %v0_40b060 = load i32, i32* inttoptr (i32 4763802 to i32*), align 4
  %v2_40b060 = zext i1 %v24_40b05d to i32
  %v3_40b060 = add i32 %v0_40b060, -36
  %v4_40b060 = add i32 %v3_40b060, %v2_40b060
  store i32 %v4_40b060, i32* inttoptr (i32 4763802 to i32*), align 4
  %v0_40b067 = load i32, i32* inttoptr (i32 4763700 to i32*), align 4
  %v1_40b067 = load i32, i32* %eax.global-to-local, align 4
  %v2_40b067 = add i32 %v1_40b067, %v0_40b067
  store i32 %v2_40b067, i32* inttoptr (i32 4763700 to i32*), align 4
  %v0_40b06d = load i32, i32* %edi.global-to-local, align 4
  %v1_40b06d = xor i32 %v0_40b06d, -46
  store i32 %v1_40b06d, i32* %edi.global-to-local, align 4
  %v0_40b070 = load i32, i32* inttoptr (i32 4763813 to i32*), align 4
  %v1_40b070 = load i32, i32* %edx.global-to-local, align 4
  %v4_40b070 = sub i32 %v0_40b070, %v1_40b070
  %v20_40b070 = icmp ult i32 %v0_40b070, %v1_40b070
  store i32 %v4_40b070, i32* inttoptr (i32 4763813 to i32*), align 4
  %v0_40b076 = load i32, i32* inttoptr (i32 4763861 to i32*), align 4
  %v2_40b076 = zext i1 %v20_40b070 to i32
  %v3_40b076 = add i32 %v0_40b076, 126
  %v4_40b076 = add i32 %v3_40b076, %v2_40b076
  %v21_40b076 = icmp ule i32 %v4_40b076, %v0_40b076
  %v22_40b076 = icmp ugt i32 %v0_40b076, -127
  %v23_40b076 = select i1 %v20_40b070, i1 %v21_40b076, i1 %v22_40b076
  store i32 %v4_40b076, i32* inttoptr (i32 4763861 to i32*), align 4
  %v0_40b07d = load i32, i32* inttoptr (i32 4763665 to i32*), align 4
  %v1_40b07d = load i32, i32* %eax.global-to-local, align 4
  %v3_40b07d = zext i1 %v23_40b076 to i32
  %v4_40b07d = sub i32 %v0_40b07d, %v1_40b07d
  %v5_40b07d = add i32 %v3_40b07d, %v4_40b07d
  %v16_40b07d = sub i32 %v4_40b07d, %v3_40b07d
  %v17_40b07d = icmp ult i32 %v0_40b07d, %v16_40b07d
  %v18_40b07d = icmp ne i32 %v1_40b07d, -1
  %v19_40b07d = or i1 %v18_40b07d, %v17_40b07d
  %v20_40b07d = icmp ult i32 %v0_40b07d, %v1_40b07d
  %v21_40b07d = select i1 %v23_40b076, i1 %v19_40b07d, i1 %v20_40b07d
  store i32 %v5_40b07d, i32* inttoptr (i32 4763665 to i32*), align 4
  %v0_40b083 = load i32, i32* inttoptr (i32 4763695 to i32*), align 4
  %v2_40b083 = zext i1 %v21_40b07d to i32
  %v3_40b083 = add i32 %v0_40b083, -236
  %v4_40b083 = add i32 %v3_40b083, %v2_40b083
  store i32 %v4_40b083, i32* inttoptr (i32 4763695 to i32*), align 4
  %v0_40b08d = load i32, i32* %ebx.global-to-local, align 4
  %v1_40b08d = load i32, i32* %eax.global-to-local, align 4
  %v2_40b08d = sub i32 %v0_40b08d, %v1_40b08d
  %v7_40b08d = icmp ult i32 %v0_40b08d, %v1_40b08d
  store i1 %v7_40b08d, i1* %cf.global-to-local, align 1
  store i32 %v2_40b08d, i32* %ebx.global-to-local, align 4
  %v1_40b08f = inttoptr i32 %v1_40b08d to i8*
  %v2_40b08f = load i8, i8* %v1_40b08f, align 1
  %v4_40b08f = trunc i32 %v1_40b08d to i8
  %v5_40b08f = add i8 %v2_40b08f, %v4_40b08f
  %v10_40b08f = icmp ult i8 %v5_40b08f, %v2_40b08f
  store i1 %v10_40b08f, i1* %cf.global-to-local, align 1
  store i8 %v5_40b08f, i8* %v1_40b08f, align 1
  %v0_40b091 = load i32, i32* %eax.global-to-local, align 4
  %v1_40b091 = inttoptr i32 %v0_40b091 to i8*
  %v2_40b091 = load i8, i8* %v1_40b091, align 1
  %v4_40b091 = trunc i32 %v0_40b091 to i8
  %v5_40b091 = add i8 %v4_40b091, %v2_40b091
  %v10_40b091 = icmp ult i8 %v5_40b091, %v2_40b091
  store i1 %v10_40b091, i1* %cf.global-to-local, align 1
  store i8 %v5_40b091, i8* %v1_40b091, align 1
  %v0_40b093 = load i32, i32* %eax.global-to-local, align 4
  %v1_40b093 = inttoptr i32 %v0_40b093 to i8*
  %v2_40b093 = load i8, i8* %v1_40b093, align 1
  %v4_40b093 = trunc i32 %v0_40b093 to i8
  %v5_40b093 = add i8 %v4_40b093, %v2_40b093
  %v10_40b093 = icmp ult i8 %v5_40b093, %v2_40b093
  store i1 %v10_40b093, i1* %cf.global-to-local, align 1
  store i8 %v5_40b093, i8* %v1_40b093, align 1
  %v0_40b095 = load i32, i32* %eax.global-to-local, align 4
  %v1_40b095 = inttoptr i32 %v0_40b095 to i8*
  %v2_40b095 = load i8, i8* %v1_40b095, align 1
  %v4_40b095 = trunc i32 %v0_40b095 to i8
  %v5_40b095 = add i8 %v4_40b095, %v2_40b095
  %v10_40b095 = icmp ult i8 %v5_40b095, %v2_40b095
  store i1 %v10_40b095, i1* %cf.global-to-local, align 1
  store i8 %v5_40b095, i8* %v1_40b095, align 1
  %v0_40b097 = load i32, i32* %ecx.global-to-local, align 4
  %v1_40b097 = inttoptr i32 %v0_40b097 to i8*
  %v2_40b097 = load i8, i8* %v1_40b097, align 1
  %v3_40b097 = load i32, i32* %edx.global-to-local, align 4
  %v4_40b097 = udiv i32 %v3_40b097, 256
  %v5_40b097 = trunc i32 %v4_40b097 to i8
  %v6_40b097 = add i8 %v5_40b097, %v2_40b097
  store i8 %v6_40b097, i8* %v1_40b097, align 1
  %v5_40b099 = load i32, i32* %ebx.global-to-local, align 4
  %v0_40b09c = load i32, i32* %eax.global-to-local, align 4
  %v11_40b09c = xor i32 %v0_40b09c, 183
  %v1_40b09e = add i32 %v11_40b09c, -1
  %v10_40b09e = trunc i32 %v1_40b09e to i8
  store i32 %v1_40b09e, i32* %eax.global-to-local, align 4
  %v1_40b09f = trunc i32 %v5_40b099 to i8
  %v4_40b09f = add i8 %v10_40b09e, %v1_40b09f
  %v9_40b09f = icmp ult i8 %v4_40b09f, %v1_40b09f
  %v19_40b09f = zext i8 %v4_40b09f to i32
  %v21_40b09f = and i32 %v5_40b099, -65536
  %v22_40b09f = or i32 %v19_40b09f, %v21_40b09f
  store i32 %v22_40b09f, i32* %ebx.global-to-local, align 4
  %v0_40b0a1 = load i32, i32* inttoptr (i32 4763853 to i32*), align 4
  %v2_40b0a1 = zext i1 %v9_40b09f to i32
  %v3_40b0a1 = add i32 %v0_40b0a1, 197
  %v4_40b0a1 = add i32 %v3_40b0a1, %v2_40b0a1
  store i32 %v4_40b0a1, i32* inttoptr (i32 4763853 to i32*), align 4
  %v0_40b0ab = load i32, i32* inttoptr (i32 4763683 to i32*), align 4
  %v1_40b0ab = xor i32 %v0_40b0ab, 54
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v1_40b0ab, i32* inttoptr (i32 4763683 to i32*), align 4
  %v0_40b0b2 = load i8, i8* inttoptr (i32 4764105 to i8*), align 1
  %v1_40b0b2 = add i8 %v0_40b0b2, 36
  store i8 %v1_40b0b2, i8* inttoptr (i32 4764105 to i8*), align 1
  store i32 0, i32* %edx.global-to-local, align 4
  %v0_40b0c2 = load i32, i32* %esi.global-to-local, align 4
  store i32 -14, i32* %ecx.global-to-local, align 4
  %v1_40b0c2 = or i32 %v0_40b0c2, -41
  %v1_40b0cd = xor i32 %v1_40b0c2, 40
  store i32 %v1_40b0cd, i32* %esi.global-to-local, align 4
  store i32 49, i32* inttoptr (i32 4763927 to i32*), align 4
  %v0_40b0da = load i32, i32* %edx.global-to-local, align 4
  %v1_40b0da = load i32, i32* inttoptr (i32 4764125 to i32*), align 4
  %v2_40b0da = sub i32 %v0_40b0da, %v1_40b0da
  store i32 %v2_40b0da, i32* %edx.global-to-local, align 4
  %v0_40b0e0 = load i32, i32* %ebx.global-to-local, align 4
  %v1_40b0e0 = add i32 %v0_40b0e0, -126
  store i32 %v1_40b0e0, i32* %ebx.global-to-local, align 4
  %v0_40b0e3 = load i32, i32* inttoptr (i32 4764094 to i32*), align 4
  %v1_40b0e3 = xor i32 %v0_40b0e3, 125
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v1_40b0e3, i32* inttoptr (i32 4764094 to i32*), align 4
  %v0_40b0ea = load i8, i8* inttoptr (i32 4764016 to i8*), align 16
  %v1_40b0ea = load i32, i32* %edx.global-to-local, align 4
  %v2_40b0ea = trunc i32 %v1_40b0ea to i8
  %v3_40b0ea = xor i8 %v2_40b0ea, %v0_40b0ea
  store i8 %v3_40b0ea, i8* inttoptr (i32 4764016 to i8*), align 16
  %v0_40b0f0 = load i32, i32* %edi.global-to-local, align 4
  %v1_40b0f0 = add i32 %v0_40b0f0, -35
  store i32 %v1_40b0f0, i32* %edi.global-to-local, align 4
  %v0_40b0f3 = load i32, i32* inttoptr (i32 4763766 to i32*), align 4
  %v1_40b0f3 = or i32 %v0_40b0f3, 102
  store i32 %v1_40b0f3, i32* inttoptr (i32 4763766 to i32*), align 4
  %v1_40b0fa = or i32 %v1_40b0f0, 59
  store i32 %v1_40b0fa, i32* %edi.global-to-local, align 4
  store i32 30, i32* inttoptr (i32 4763953 to i32*), align 4
  %v0_40b107 = load i32, i32* %edx.global-to-local, align 4
  %v1_40b107 = add i32 %v0_40b107, -52
  store i32 %v1_40b107, i32* %edx.global-to-local, align 4
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 1048576, i32* %eax.global-to-local, align 4
  %v10_40b123 = call i32* @OpenJobObjectW(i32 1048576, i1 false, i16* bitcast ([13 x i8]* @global_var_48b6a3.4 to i16*))
  %v11_40b123 = ptrtoint i32* %v10_40b123 to i32
  %v14_40b123 = trunc i32 %v11_40b123 to i8
  store i32 %v11_40b123, i32* %eax.global-to-local, align 4
  %sext = mul i32 %v11_40b123, 16777216
  store i1 false, i1* %cf.global-to-local, align 1
  %v2_40b129 = icmp eq i32 %sext, 0
  %v1_40b12b = icmp eq i1 %v2_40b129, false
  call void @__pseudo_cond_branch(i1 %v1_40b12b, i32 ptrtoint (i16** @global_var_406dd5.3 to i32))
  %v0_40b131 = load i32, i32* inttoptr (i32 4763852 to i32*), align 4
  %v1_40b131 = load i32, i32* %edi.global-to-local, align 4
  %v2_40b131 = xor i32 %v1_40b131, %v0_40b131
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v2_40b131, i32* inttoptr (i32 4763852 to i32*), align 4
  %v3_40b137 = load i8, i8* inttoptr (i32 4763887 to i8*), align 1
  %v4_40b137 = sub i8 %v14_40b123, %v3_40b137
  %v9_40b137 = icmp ult i8 %v14_40b123, %v3_40b137
  store i1 %v9_40b137, i1* %cf.global-to-local, align 1
  %v19_40b137 = zext i8 %v4_40b137 to i32
  %v21_40b137 = sdiv i32 %sext, 16777216
  %v22_40b137 = and i32 %v21_40b137, -256
  %v23_40b137 = or i32 %v19_40b137, %v22_40b137
  store i32 %v23_40b137, i32* %eax.global-to-local, align 4
  %v0_40b13d = load i8, i8* inttoptr (i32 4763752 to i8*), align 8
  %v1_40b13d = load i32, i32* %ebx.global-to-local, align 4
  %v2_40b13d = trunc i32 %v1_40b13d to i8
  %v3_40b13d = xor i8 %v2_40b13d, %v0_40b13d
  store i1 false, i1* %cf.global-to-local, align 1
  store i8 %v3_40b13d, i8* inttoptr (i32 4763752 to i8*), align 8
  store i32 1, i32* %edx.global-to-local, align 4
  %v1_40b148 = load i32, i32* inttoptr (i32 4763843 to i32*), align 4
  %v5_40b148 = add i32 %v1_40b148, 1
  %v25_40b148 = icmp eq i32 %v1_40b148, -1
  store i32 %v5_40b148, i32* %edx.global-to-local, align 4
  %v0_40b14e = load i32, i32* %esi.global-to-local, align 4
  %v1_40b14e = load i32, i32* inttoptr (i32 4763691 to i32*), align 4
  %v3_40b14e = zext i1 %v25_40b148 to i32
  %v4_40b14e = add i32 %v1_40b14e, %v0_40b14e
  %v5_40b14e = add i32 %v4_40b14e, %v3_40b14e
  store i32 %v5_40b14e, i32* %esi.global-to-local, align 4
  %v0_40b154 = load i32, i32* inttoptr (i32 4763677 to i32*), align 4
  %v1_40b154 = load i32, i32* %eax.global-to-local, align 4
  %v2_40b154 = add i32 %v1_40b154, %v0_40b154
  store i32 %v2_40b154, i32* inttoptr (i32 4763677 to i32*), align 4
  %v0_40b15a = load i32, i32* %edi.global-to-local, align 4
  %v1_40b15a = add i32 %v0_40b15a, -55
  %v5_40b15a = icmp ugt i32 %v0_40b15a, 54
  store i1 %v5_40b15a, i1* %cf.global-to-local, align 1
  store i32 %v1_40b15a, i32* %edi.global-to-local, align 4
  %v0_40b15d = load i32, i32* %ebx.global-to-local, align 4
  %v1_40b15d = trunc i32 %v0_40b15d to i8
  %v2_40b15d = load i8, i8* inttoptr (i32 4763800 to i8*), align 8
  %v3_40b15d = sub i8 %v1_40b15d, %v2_40b15d
  %v18_40b15d = zext i8 %v3_40b15d to i32
  %v20_40b15d = and i32 %v0_40b15d, -256
  %v21_40b15d = or i32 %v18_40b15d, %v20_40b15d
  store i32 %v21_40b15d, i32* %ebx.global-to-local, align 4
  %v0_40b163 = load i32, i32* inttoptr (i32 4764046 to i32*), align 4
  %v1_40b163 = load i32, i32* %eax.global-to-local, align 4
  %v2_40b163 = xor i32 %v1_40b163, %v0_40b163
  store i32 %v2_40b163, i32* inttoptr (i32 4764046 to i32*), align 4
  %v1_40b16e = load i32, i32* %edi.global-to-local, align 4
  %v2_40b16e = add i32 %v1_40b16e, 1
  store i32 %v2_40b16e, i32* %ecx.global-to-local, align 4
  %v1_40b170 = add i32 %v1_40b163, -20
  %v5_40b170 = icmp ult i32 %v1_40b163, 20
  store i1 %v5_40b170, i1* %cf.global-to-local, align 1
  store i32 %v1_40b170, i32* %eax.global-to-local, align 4
  call void @__pseudo_call(i32 -1)
  %v0_40b17b = load i32, i32* %esi.global-to-local, align 4
  %v1_40b17b = add i32 %v0_40b17b, -98
  store i32 %v1_40b17b, i32* %esi.global-to-local, align 4
  %v1_40b17e = load i32, i32* inttoptr (i32 4764025 to i32*), align 4
  %v2_40b17e = or i32 %v1_40b17e, %v1_40b17b
  store i32 %v2_40b17e, i32* %esi.global-to-local, align 4
  %v0_40b184 = load i32, i32* inttoptr (i32 4764050 to i32*), align 4
  %v1_40b184 = load i32, i32* %edx.global-to-local, align 4
  %v4_40b184 = sub i32 %v0_40b184, %v1_40b184
  %v20_40b184 = icmp ult i32 %v0_40b184, %v1_40b184
  store i32 %v4_40b184, i32* inttoptr (i32 4764050 to i32*), align 4
  %v1_40b18c = select i1 %v20_40b184, i32 -121, i32 -122
  store i32 %v1_40b18c, i32* %ecx.global-to-local, align 4
  %v1_40b18f = load i32, i32* inttoptr (i32 4763956 to i32*), align 4
  %v4_40b18f = add i32 %v1_40b18f, %v1_40b18c
  store i32 %v4_40b18f, i32* %ecx.global-to-local, align 4
  %v0_40b195 = load i32, i32* inttoptr (i32 4764109 to i32*), align 4
  %v1_40b195 = xor i32 %v0_40b195, 204
  store i32 %v1_40b195, i32* inttoptr (i32 4764109 to i32*), align 4
  %v0_40b19f = load i32, i32* %esi.global-to-local, align 4
  %v1_40b19f = and i32 %v0_40b19f, 90
  store i32 %v1_40b19f, i32* %esi.global-to-local, align 4
  %v0_40b1a2 = load i32, i32* inttoptr (i32 4763851 to i32*), align 4
  %v1_40b1a2 = load i32, i32* %eax.global-to-local, align 4
  %v2_40b1a2 = add i32 %v1_40b1a2, %v0_40b1a2
  store i32 %v2_40b1a2, i32* inttoptr (i32 4763851 to i32*), align 4
  %v0_40b1a8 = load i32, i32* inttoptr (i32 4763664 to i32*), align 16
  %v1_40b1a8 = load i32, i32* %edi.global-to-local, align 4
  %v2_40b1a8 = xor i32 %v1_40b1a8, %v0_40b1a8
  store i32 %v2_40b1a8, i32* inttoptr (i32 4763664 to i32*), align 16
  %v0_40b1ae = load i32, i32* inttoptr (i32 4764003 to i32*), align 4
  %v3_40b1ae = add i32 %v0_40b1ae, 50
  store i32 %v3_40b1ae, i32* inttoptr (i32 4764003 to i32*), align 4
  %v0_40b1b5 = load i32, i32* %ebx.global-to-local, align 4
  %v1_40b1b5 = udiv i32 %v0_40b1b5, 256
  %v2_40b1b5 = trunc i32 %v1_40b1b5 to i8
  %v6_40b1b517 = mul nuw nsw i32 %v1_40b1b5, 2
  %v6_40b1b5 = trunc i32 %v6_40b1b517 to i8
  %v11_40b1b5 = icmp ult i8 %v6_40b1b5, %v2_40b1b5
  %v21_40b1b5 = mul i32 %v1_40b1b5, 512
  %v23_40b1b5 = and i32 %v21_40b1b5, 65024
  %v24_40b1b5 = and i32 %v0_40b1b5, -65281
  %v25_40b1b5 = or i32 %v23_40b1b5, %v24_40b1b5
  store i32 %v25_40b1b5, i32* %ebx.global-to-local, align 4
  %v0_40b1b7 = load i32, i32* %edi.global-to-local, align 4
  %v2_40b1b7 = zext i1 %v11_40b1b5 to i32
  %v3_40b1b7 = add i32 %v0_40b1b7, -91
  %v4_40b1b7 = add i32 %v3_40b1b7, %v2_40b1b7
  store i32 %v4_40b1b7, i32* %edi.global-to-local, align 4
  %v0_40b1ba = load i32, i32* inttoptr (i32 4763836 to i32*), align 4
  %v1_40b1ba = and i32 %v0_40b1ba, 56
  store i32 %v1_40b1ba, i32* inttoptr (i32 4763836 to i32*), align 4
  %v0_40b1c1 = load i32, i32* %edx.global-to-local, align 4
  %v1_40b1c1 = trunc i32 %v0_40b1c1 to i8
  %v2_40b1c1 = load i32, i32* %ecx.global-to-local, align 4
  %v3_40b1c1 = udiv i32 %v2_40b1c1, 256
  %v4_40b1c1 = trunc i32 %v3_40b1c1 to i8
  %v5_40b1c1 = add i8 %v4_40b1c1, %v1_40b1c1
  %v10_40b1c1 = icmp ult i8 %v5_40b1c1, %v1_40b1c1
  store i1 %v10_40b1c1, i1* %cf.global-to-local, align 1
  %v20_40b1c1 = zext i8 %v5_40b1c1 to i32
  %v22_40b1c1 = and i32 %v0_40b1c1, -256
  %v23_40b1c1 = or i32 %v20_40b1c1, %v22_40b1c1
  store i32 %v23_40b1c1, i32* %edx.global-to-local, align 4
  %v0_40b1c3 = load i32, i32* %eax.global-to-local, align 4
  %v1_40b1c3 = inttoptr i32 %v0_40b1c3 to i8*
  %v2_40b1c3 = load i8, i8* %v1_40b1c3, align 1
  %v4_40b1c3 = trunc i32 %v0_40b1c3 to i8
  %v5_40b1c3 = add i8 %v4_40b1c3, %v2_40b1c3
  %v10_40b1c3 = icmp ult i8 %v5_40b1c3, %v2_40b1c3
  store i1 %v10_40b1c3, i1* %cf.global-to-local, align 1
  store i8 %v5_40b1c3, i8* %v1_40b1c3, align 1
  %v0_40b1c5 = load i32, i32* %ebx.global-to-local, align 4
  %v1_40b1c5 = inttoptr i32 %v0_40b1c5 to i8*
  %v2_40b1c5 = load i8, i8* %v1_40b1c5, align 1
  %v3_40b1c5 = load i32, i32* %ecx.global-to-local, align 4
  %v4_40b1c5 = trunc i32 %v3_40b1c5 to i8
  %v5_40b1c5 = add i8 %v4_40b1c5, %v2_40b1c5
  store i8 %v5_40b1c5, i8* %v1_40b1c5, align 1
  %v0_40b1c7 = load i32, i32* %eax.global-to-local, align 4
  %v1_40b1c7 = add i32 %v0_40b1c7, 4763809
  %v5_40b1c7 = icmp ugt i32 %v0_40b1c7, -4763810
  store i32 %v1_40b1c7, i32* %eax.global-to-local, align 4
  %v0_40b1cc = load i32, i32* %esi.global-to-local, align 4
  %v1_40b1cc = load i32, i32* inttoptr (i32 4764121 to i32*), align 4
  %v3_40b1cc = zext i1 %v5_40b1c7 to i32
  %v4_40b1cc = add i32 %v3_40b1cc, %v0_40b1cc
  %v5_40b1cc = add i32 %v4_40b1cc, %v1_40b1cc
  store i32 %v5_40b1cc, i32* %esi.global-to-local, align 4
  %v0_40b1d2 = load i32, i32* inttoptr (i32 4763940 to i32*), align 4
  %v2_40b1d2 = sub i32 %v0_40b1d2, %v5_40b1cc
  %v7_40b1d2 = icmp ult i32 %v0_40b1d2, %v5_40b1cc
  store i32 %v2_40b1d2, i32* inttoptr (i32 4763940 to i32*), align 4
  store i32 1, i32* %edx.global-to-local, align 4
  %v1_40b1dd = load i32, i32* inttoptr (i32 4763697 to i32*), align 4
  %v4_40b1dd = select i1 %v7_40b1d2, i32 2, i32 1
  %v5_40b1dd = add i32 %v4_40b1dd, %v1_40b1dd
  store i32 %v5_40b1dd, i32* %edx.global-to-local, align 4
  %v0_40b1e3 = load i32, i32* inttoptr (i32 4764130 to i32*), align 4
  %v1_40b1e3 = xor i32 %v0_40b1e3, 186
  store i32 %v1_40b1e3, i32* inttoptr (i32 4764130 to i32*), align 4
  store i32 1, i32* %ecx.global-to-local, align 4
  %v1_40b1f2 = load i32, i32* inttoptr (i32 4763884 to i32*), align 4
  %v4_40b1f2 = add i32 %v1_40b1f2, 1
  %v16_40b1f2 = icmp eq i32 %v4_40b1f2, 0
  store i32 %v4_40b1f2, i32* %ecx.global-to-local, align 4
  %v0_40b1f8 = load i32, i32* %eax.global-to-local, align 4
  %v1_40b1f8 = load i32, i32* inttoptr (i32 4763735 to i32*), align 4
  %v3_40b1f8 = zext i1 %v16_40b1f2 to i32
  %v4_40b1f8 = add i32 %v1_40b1f8, %v0_40b1f8
  %v5_40b1f8 = add i32 %v4_40b1f8, %v3_40b1f8
  %v24_40b1f8 = icmp ule i32 %v5_40b1f8, %v0_40b1f8
  %v25_40b1f8 = icmp ult i32 %v4_40b1f8, %v0_40b1f8
  %v26_40b1f8 = select i1 %v16_40b1f2, i1 %v24_40b1f8, i1 %v25_40b1f8
  store i32 %v5_40b1f8, i32* %eax.global-to-local, align 4
  %v0_40b1fe = load i32, i32* %edi.global-to-local, align 4
  %v3_40b1fe = select i1 %v26_40b1f8, i32 -5, i32 -6
  %v4_40b1fe = add i32 %v3_40b1fe, %v0_40b1fe
  store i32 %v4_40b1fe, i32* %edi.global-to-local, align 4
  %v1_40b201 = add i32 %v1_40b1f2, 17
  %v2_40b201 = icmp ugt i32 %v4_40b1f2, -17
  %v2_40b204 = zext i1 %v2_40b201 to i32
  store i32 %v2_40b204, i32* %esi.global-to-local, align 4
  %v1_40b206 = xor i32 %v1_40b201, -128
  store i32 %v1_40b206, i32* %ecx.global-to-local, align 4
  %v0_40b209 = load i32, i32* inttoptr (i32 4763898 to i32*), align 4
  %v1_40b209 = load i32, i32* %ebx.global-to-local, align 4
  %v4_40b209 = sub i32 %v0_40b209, %v1_40b209
  store i32 %v4_40b209, i32* inttoptr (i32 4763898 to i32*), align 4
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 1048576, i32* %eax.global-to-local, align 4
  %v9_40b22a = call i32* @OpenJobObjectW(i32 1048576, i1 false, i16* bitcast ([13 x i8]* @global_var_48b6a3.4 to i16*))
  %v10_40b22a = ptrtoint i32* %v9_40b22a to i32
  %v13_40b22a = trunc i32 %v10_40b22a to i8
  store i32 %v10_40b22a, i32* %eax.global-to-local, align 4
  %sext7 = mul i32 %v10_40b22a, 16777216
  store i1 false, i1* %cf.global-to-local, align 1
  %v2_40b230 = icmp eq i32 %sext7, 0
  %v1_40b232 = icmp eq i1 %v2_40b230, false
  call void @__pseudo_cond_branch(i1 %v1_40b232, i32 ptrtoint (i16** @global_var_406dd5.3 to i32))
  %v0_40b238 = load i32, i32* %edi.global-to-local, align 4
  %v1_40b238 = load i32, i32* inttoptr (i32 4763928 to i32*), align 8
  %v2_40b238 = sub i32 %v0_40b238, %v1_40b238
  %v7_40b238 = icmp ult i32 %v0_40b238, %v1_40b238
  store i1 %v7_40b238, i1* %cf.global-to-local, align 1
  store i32 %v2_40b238, i32* %edi.global-to-local, align 4
  %v3_40b23e = load i8, i8* inttoptr (i32 4763941 to i8*), align 1
  %v4_40b23e = sub i8 %v13_40b22a, %v3_40b23e
  %v19_40b23e = zext i8 %v4_40b23e to i32
  %v21_40b23e = sdiv i32 %sext7, 16777216
  %v22_40b23e = and i32 %v21_40b23e, -256
  %v23_40b23e = or i32 %v19_40b23e, %v22_40b23e
  store i32 %v23_40b23e, i32* %eax.global-to-local, align 4
  %v0_40b244 = load i32, i32* inttoptr (i32 4763873 to i32*), align 4
  %v2_40b244 = xor i32 %v23_40b23e, %v0_40b244
  store i32 %v2_40b244, i32* inttoptr (i32 4763873 to i32*), align 4
  store i32 -4, i32* %ecx.global-to-local, align 4
  %v1_40b257 = load i32, i32* %edi.global-to-local, align 4
  %v2_40b257 = add i32 %v1_40b257, 1
  store i32 %v2_40b257, i32* %edx.global-to-local, align 4
  %v0_40b259 = load i32, i32* %eax.global-to-local, align 4
  %v2_40b259 = add i32 %v0_40b259, %v1_40b257
  %v7_40b259 = icmp ult i32 %v2_40b259, %v0_40b259
  store i32 %v2_40b259, i32* %eax.global-to-local, align 4
  %v0_40b25b = load i32, i32* inttoptr (i32 4763761 to i32*), align 4
  %v2_40b25b = zext i1 %v7_40b259 to i32
  %v3_40b25b = add i32 %v0_40b25b, 127
  %v4_40b25b = add i32 %v3_40b25b, %v2_40b25b
  store i32 %v4_40b25b, i32* inttoptr (i32 4763761 to i32*), align 4
  %v1_40b262 = load i32, i32* %edi.global-to-local, align 4
  %v2_40b262 = sub i32 %v2_40b259, %v1_40b262
  store i32 %v2_40b262, i32* %eax.global-to-local, align 4
  %v1_40b264 = load i32, i32* inttoptr (i32 4764090 to i32*), align 4
  %v2_40b264 = sub i32 %v1_40b262, %v1_40b264
  %v7_40b264 = icmp ult i32 %v1_40b262, %v1_40b264
  store i32 %v2_40b264, i32* %edi.global-to-local, align 4
  %v0_40b26a = load i32, i32* inttoptr (i32 4764061 to i32*), align 4
  %v1_40b26a = load i32, i32* %esi.global-to-local, align 4
  %v3_40b26a = zext i1 %v7_40b264 to i32
  %v4_40b26a = add i32 %v1_40b26a, %v0_40b26a
  %v5_40b26a = add i32 %v4_40b26a, %v3_40b26a
  %v24_40b26a = icmp ule i32 %v5_40b26a, %v0_40b26a
  %v25_40b26a = icmp ult i32 %v4_40b26a, %v0_40b26a
  %v26_40b26a = select i1 %v7_40b264, i1 %v24_40b26a, i1 %v25_40b26a
  store i32 %v5_40b26a, i32* inttoptr (i32 4764061 to i32*), align 4
  %v0_40b270 = load i32, i32* %edi.global-to-local, align 4
  %v3_40b270 = select i1 %v26_40b26a, i32 -45, i32 -46
  %v4_40b270 = add i32 %v3_40b270, %v0_40b270
  store i32 %v4_40b270, i32* %edi.global-to-local, align 4
  %v0_40b273 = load i32, i32* %ebx.global-to-local, align 4
  %v1_40b273 = xor i32 %v0_40b273, 16
  store i32 %v1_40b273, i32* %ebx.global-to-local, align 4
  %v0_40b276 = load i32, i32* %eax.global-to-local, align 4
  %v1_40b276 = load i32, i32* %edx.global-to-local, align 4
  %v2_40b276 = add i32 %v1_40b276, %v0_40b276
  %v7_40b276 = icmp ult i32 %v2_40b276, %v0_40b276
  store i32 %v2_40b276, i32* %eax.global-to-local, align 4
  %v1_40b278 = load i32, i32* inttoptr (i32 4764018 to i32*), align 4
  %v3_40b278 = zext i1 %v7_40b276 to i32
  %v4_40b278 = add i32 %v1_40b278, %v1_40b276
  %v5_40b278 = add i32 %v4_40b278, %v3_40b278
  %v18_40b278 = trunc i32 %v5_40b278 to i8
  store i32 %v5_40b278, i32* %edx.global-to-local, align 4
  %v0_40b27e = load i32, i32* %ecx.global-to-local, align 4
  %v1_40b27e = load i32, i32* inttoptr (i32 4763970 to i32*), align 4
  %v2_40b27e = sub i32 %v0_40b27e, %v1_40b27e
  %v7_40b27e = icmp ult i32 %v0_40b27e, %v1_40b27e
  store i32 %v2_40b27e, i32* %ecx.global-to-local, align 4
  %v1_40b284 = load i32, i32* inttoptr (i32 4763935 to i32*), align 4
  %v3_40b284 = zext i1 %v7_40b27e to i32
  %v4_40b284 = add i32 %v1_40b284, %v2_40b27e
  %v5_40b284 = add i32 %v4_40b284, %v3_40b284
  %v24_40b284 = icmp ule i32 %v5_40b284, %v2_40b27e
  %v25_40b284 = icmp ult i32 %v4_40b284, %v2_40b27e
  %v26_40b284 = select i1 %v7_40b27e, i1 %v24_40b284, i1 %v25_40b284
  store i1 %v26_40b284, i1* %cf.global-to-local, align 1
  store i32 %v5_40b284, i32* %ecx.global-to-local, align 4
  %v2_40b28a = load i8, i8* inttoptr (i32 4764063 to i8*), align 1
  %v3_40b28a = sub i8 %v18_40b278, %v2_40b28a
  %v18_40b28a = zext i8 %v3_40b28a to i32
  %v20_40b28a = and i32 %v5_40b278, -256
  %v21_40b28a = or i32 %v18_40b28a, %v20_40b28a
  store i32 %v21_40b28a, i32* %edx.global-to-local, align 4
  %v10_40b290 = or i32 %v5_40b284, 102
  store i32 %v10_40b290, i32* %ecx.global-to-local, align 4
  %v0_40b293 = load i32, i32* inttoptr (i32 4763930 to i32*), align 4
  %v1_40b293 = xor i32 %v0_40b293, 255
  store i32 %v1_40b293, i32* inttoptr (i32 4763930 to i32*), align 4
  %v0_40b29d = load i32, i32* %eax.global-to-local, align 4
  %v1_40b29d = load i32, i32* %esi.global-to-local, align 4
  %v2_40b29d = add i32 %v1_40b29d, %v0_40b29d
  %v7_40b29d = icmp ult i32 %v2_40b29d, %v0_40b29d
  store i1 %v7_40b29d, i1* %cf.global-to-local, align 1
  store i32 %v2_40b29d, i32* %eax.global-to-local, align 4
  call void @__pseudo_call(i32 -1)
  %v0_40b2a7 = load i32, i32* %ecx.global-to-local, align 4
  %v1_40b2a7 = add i32 %v0_40b2a7, 38
  store i32 %v1_40b2a7, i32* %ecx.global-to-local, align 4
  %v0_40b2aa = load i32, i32* %ebx.global-to-local, align 4
  %v1_40b2aa = load i32, i32* %edi.global-to-local, align 4
  %v2_40b2aa = sub i32 %v0_40b2aa, %v1_40b2aa
  %v7_40b2aa = icmp ult i32 %v0_40b2aa, %v1_40b2aa
  store i32 %v2_40b2aa, i32* %ebx.global-to-local, align 4
  %v0_40b2ac = load i32, i32* inttoptr (i32 4764153 to i32*), align 4
  %v2_40b2ac = zext i1 %v7_40b2aa to i32
  %v3_40b2ac = add i32 %v0_40b2ac, -174
  %v4_40b2ac = add i32 %v3_40b2ac, %v2_40b2ac
  store i32 %v4_40b2ac, i32* inttoptr (i32 4764153 to i32*), align 4
  %v0_40b2b6 = load i32, i32* %edx.global-to-local, align 4
  %v1_40b2b6 = xor i32 %v0_40b2b6, 54
  store i32 %v1_40b2b6, i32* %edx.global-to-local, align 4
  %v0_40b2b9 = load i32, i32* %ecx.global-to-local, align 4
  %v1_40b2b9 = load i32, i32* inttoptr (i32 4764037 to i32*), align 4
  %v4_40b2b9 = add i32 %v1_40b2b9, %v0_40b2b9
  %v25_40b2b9 = icmp ult i32 %v4_40b2b9, %v0_40b2b9
  store i32 %v4_40b2b9, i32* %ecx.global-to-local, align 4
  %v0_40b2bf = load i32, i32* %eax.global-to-local, align 4
  %v1_40b2bf = load i32, i32* inttoptr (i32 4763753 to i32*), align 4
  %v3_40b2bf = zext i1 %v25_40b2b9 to i32
  %v4_40b2bf = add i32 %v1_40b2bf, %v0_40b2bf
  %v5_40b2bf = add i32 %v4_40b2bf, %v3_40b2bf
  store i32 %v5_40b2bf, i32* %eax.global-to-local, align 4
  %v1_40b2c5 = xor i32 %v1_40b2bf, 149
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v1_40b2c5, i32* inttoptr (i32 4763753 to i32*), align 4
  %v0_40b2cf = load i32, i32* %edx.global-to-local, align 4
  %v1_40b2cf = udiv i32 %v0_40b2cf, 256
  %v2_40b2cf = trunc i32 %v1_40b2cf to i8
  %v3_40b2cf = load i8, i8* inttoptr (i32 4764020 to i8*), align 4
  %v6_40b2cf = add i8 %v2_40b2cf, %v3_40b2cf
  %v28_40b2cf = zext i8 %v6_40b2cf to i32
  %v30_40b2cf = mul nuw nsw i32 %v28_40b2cf, 256
  %v31_40b2cf = and i32 %v0_40b2cf, -65281
  %v32_40b2cf = or i32 %v30_40b2cf, %v31_40b2cf
  store i32 %v32_40b2cf, i32* %edx.global-to-local, align 4
  %v0_40b2d5 = load i32, i32* %eax.global-to-local, align 4
  %v1_40b2d5 = load i32, i32* %esi.global-to-local, align 4
  %v2_40b2d5 = add i32 %v1_40b2d5, %v0_40b2d5
  %v7_40b2d5 = icmp ult i32 %v2_40b2d5, %v0_40b2d5
  store i32 %v2_40b2d5, i32* %eax.global-to-local, align 4
  %v0_40b2d7 = load i32, i32* inttoptr (i32 4763667 to i32*), align 4
  %v2_40b2d7 = zext i1 %v7_40b2d5 to i32
  %v3_40b2d7 = add i32 %v0_40b2d7, 180
  %v4_40b2d7 = add i32 %v3_40b2d7, %v2_40b2d7
  store i32 %v4_40b2d7, i32* inttoptr (i32 4763667 to i32*), align 4
  %v0_40b2e1 = load i32, i32* inttoptr (i32 4763705 to i32*), align 4
  %v1_40b2e1 = and i32 %v0_40b2e1, 214
  store i32 %v1_40b2e1, i32* inttoptr (i32 4763705 to i32*), align 4
  %v0_40b2eb = load i32, i32* %eax.global-to-local, align 4
  %v1_40b2eb = trunc i32 %v0_40b2eb to i8
  %v4_40b2eb = add i32 %v0_40b2eb, 208
  %v12_40b2eb = icmp ult i8 %v1_40b2eb, 48
  %v25_40b2eb = and i32 %v4_40b2eb, 255
  %v27_40b2eb = and i32 %v0_40b2eb, -256
  %v28_40b2eb = or i32 %v25_40b2eb, %v27_40b2eb
  store i32 %v28_40b2eb, i32* %eax.global-to-local, align 4
  %v0_40b2ed = load i32, i32* inttoptr (i32 4763661 to i32*), align 4
  %v2_40b2ed = zext i1 %v12_40b2eb to i32
  %v3_40b2ed = add i32 %v0_40b2ed, -133
  %v4_40b2ed = add i32 %v3_40b2ed, %v2_40b2ed
  store i32 %v4_40b2ed, i32* inttoptr (i32 4763661 to i32*), align 4
  %v1_40b2f7 = add i32 %v28_40b2eb, 44
  %v5_40b2f7 = icmp ugt i32 %v28_40b2eb, -45
  store i1 %v5_40b2f7, i1* %cf.global-to-local, align 1
  %v11_40b2f7 = trunc i32 %v1_40b2f7 to i8
  store i32 %v1_40b2f7, i32* %eax.global-to-local, align 4
  %v1_40b2fa = inttoptr i32 %v1_40b2f7 to i8*
  %v2_40b2fa = load i8, i8* %v1_40b2fa, align 1
  %v5_40b2fa = add i8 %v2_40b2fa, %v11_40b2f7
  %v10_40b2fa = icmp ult i8 %v5_40b2fa, %v2_40b2fa
  store i1 %v10_40b2fa, i1* %cf.global-to-local, align 1
  store i8 %v5_40b2fa, i8* %v1_40b2fa, align 1
  %v0_40b2fc = load i32, i32* %eax.global-to-local, align 4
  %v1_40b2fc = inttoptr i32 %v0_40b2fc to i8*
  %v2_40b2fc = load i8, i8* %v1_40b2fc, align 1
  %v4_40b2fc = trunc i32 %v0_40b2fc to i8
  %v5_40b2fc = add i8 %v4_40b2fc, %v2_40b2fc
  %v10_40b2fc = icmp ult i8 %v5_40b2fc, %v2_40b2fc
  store i1 %v10_40b2fc, i1* %cf.global-to-local, align 1
  store i8 %v5_40b2fc, i8* %v1_40b2fc, align 1
  %v0_40b2fe = load i32, i32* %ecx.global-to-local, align 4
  %v1_40b2fe = inttoptr i32 %v0_40b2fe to i8*
  %v2_40b2fe = load i8, i8* %v1_40b2fe, align 1
  %v3_40b2fe = load i32, i32* %ebx.global-to-local, align 4
  %v4_40b2fe = trunc i32 %v3_40b2fe to i8
  %v5_40b2fe = add i8 %v4_40b2fe, %v2_40b2fe
  store i8 %v5_40b2fe, i8* %v1_40b2fe, align 1
  %v0_40b305 = load i32, i32* %esi.global-to-local, align 4
  %v1_40b305 = load i32, i32* inttoptr (i32 4763868 to i32*), align 4
  %v2_40b305 = sub i32 %v0_40b305, %v1_40b305
  store i32 %v2_40b305, i32* %esi.global-to-local, align 4
  %v0_40b30b = load i32, i32* inttoptr (i32 4763728 to i32*), align 16
  %v1_40b30b = and i32 %v0_40b30b, 228
  store i32 %v1_40b30b, i32* inttoptr (i32 4763728 to i32*), align 16
  %v0_40b315 = load i32, i32* %ebx.global-to-local, align 4
  %v1_40b315 = load i32, i32* inttoptr (i32 4763785 to i32*), align 4
  %v2_40b315 = sub i32 %v0_40b315, %v1_40b315
  store i32 %v2_40b315, i32* %ebx.global-to-local, align 4
  store i32 199, i32* inttoptr (i32 4764113 to i32*), align 4
  %v0_40b325 = load i32, i32* %edi.global-to-local, align 4
  %v2_40b325 = mul i32 %v0_40b325, 2
  store i32 %v2_40b325, i32* %edi.global-to-local, align 4
  store i32 7, i32* inttoptr (i32 4763825 to i32*), align 4
  %v0_40b331 = load i32, i32* inttoptr (i32 4764108 to i32*), align 4
  %v1_40b331 = load i32, i32* %ebx.global-to-local, align 4
  %v2_40b331 = xor i32 %v1_40b331, %v0_40b331
  store i32 %v2_40b331, i32* inttoptr (i32 4764108 to i32*), align 4
  %v0_40b337 = load i32, i32* %esi.global-to-local, align 4
  %v1_40b337 = load i32, i32* inttoptr (i32 4763682 to i32*), align 4
  %v4_40b337 = add i32 %v1_40b337, %v0_40b337
  store i32 %v4_40b337, i32* %esi.global-to-local, align 4
  %v0_40b33d = load i32, i32* %ecx.global-to-local, align 4
  %v1_40b33d = and i32 %v0_40b33d, -256
  %v18_40b33f = or i32 %v1_40b33d, 94
  store i32 %v18_40b33f, i32* %ecx.global-to-local, align 4
  %v0_40b342 = load i32, i32* inttoptr (i32 4763996 to i32*), align 4
  %v1_40b342 = load i32, i32* %ebx.global-to-local, align 4
  %v2_40b342 = sub i32 %v0_40b342, %v1_40b342
  store i32 %v2_40b342, i32* inttoptr (i32 4763996 to i32*), align 4
  %v0_40b348 = load i32, i32* inttoptr (i32 4763790 to i32*), align 4
  %v1_40b348 = load i32, i32* %esi.global-to-local, align 4
  %v2_40b348 = add i32 %v1_40b348, %v0_40b348
  %v7_40b348 = icmp ult i32 %v2_40b348, %v0_40b348
  store i32 %v2_40b348, i32* inttoptr (i32 4763790 to i32*), align 4
  %v0_40b34e = load i32, i32* %ecx.global-to-local, align 4
  %v1_40b34e = load i32, i32* inttoptr (i32 4763767 to i32*), align 4
  %v3_40b34e = zext i1 %v7_40b348 to i32
  %v4_40b34e = add i32 %v1_40b34e, %v0_40b34e
  %v5_40b34e = add i32 %v4_40b34e, %v3_40b34e
  %v24_40b34e = icmp ule i32 %v5_40b34e, %v0_40b34e
  %v25_40b34e = icmp ult i32 %v4_40b34e, %v0_40b34e
  %v26_40b34e = select i1 %v7_40b348, i1 %v24_40b34e, i1 %v25_40b34e
  store i32 %v5_40b34e, i32* %ecx.global-to-local, align 4
  %v0_40b354 = load i32, i32* %esi.global-to-local, align 4
  %v3_40b354 = select i1 %v26_40b34e, i32 -94, i32 -95
  %v4_40b354 = add i32 %v3_40b354, %v0_40b354
  %v22_40b354 = icmp ule i32 %v4_40b354, %v0_40b354
  %v23_40b354 = icmp ugt i32 %v0_40b354, 94
  %v24_40b354 = select i1 %v26_40b34e, i1 %v22_40b354, i1 %v23_40b354
  store i32 %v4_40b354, i32* %esi.global-to-local, align 4
  %v0_40b357 = load i32, i32* inttoptr (i32 4763939 to i32*), align 4
  %v3_40b357 = select i1 %v24_40b354, i32 157, i32 156
  %v4_40b357 = add i32 %v3_40b357, %v0_40b357
  %v21_40b357 = icmp ule i32 %v4_40b357, %v0_40b357
  %v22_40b357 = icmp ugt i32 %v0_40b357, -157
  %v23_40b357 = select i1 %v24_40b354, i1 %v21_40b357, i1 %v22_40b357
  store i32 %v4_40b357, i32* inttoptr (i32 4763939 to i32*), align 4
  %v0_40b361 = load i32, i32* %esi.global-to-local, align 4
  %v3_40b361 = select i1 %v23_40b357, i32 -9, i32 -10
  %v4_40b361 = add i32 %v3_40b361, %v0_40b361
  store i32 %v4_40b361, i32* %esi.global-to-local, align 4
  %v0_40b364 = load i32, i32* inttoptr (i32 4763975 to i32*), align 4
  %v2_40b364 = sub i32 %v0_40b364, %v4_40b361
  %v7_40b364 = icmp ult i32 %v0_40b364, %v4_40b361
  store i32 %v2_40b364, i32* inttoptr (i32 4763975 to i32*), align 4
  %v0_40b36a = load i32, i32* inttoptr (i32 4763904 to i32*), align 256
  %v2_40b36a = zext i1 %v7_40b364 to i32
  %v3_40b36a = add i32 %v0_40b36a, 165
  %v4_40b36a = add i32 %v3_40b36a, %v2_40b36a
  store i32 %v4_40b36a, i32* inttoptr (i32 4763904 to i32*), align 256
  store i32 11, i32* %eax.global-to-local, align 4
  store i1 false, i1* %cf.global-to-local, align 1
  %v6_40b385 = call i1 @IsBadStringPtrA(i8* getelementptr inbounds ([12 x i8], [12 x i8]* @global_var_48b6b4.5, i32 0, i32 0), i32 11)
  %v7_40b385 = sext i1 %v6_40b385 to i32
  store i32 %v7_40b385, i32* %eax.global-to-local, align 4
  store i1 false, i1* %cf.global-to-local, align 1
  %v1_40b38b = icmp eq i1 %v6_40b385, false
  %v1_40b38d = icmp eq i1 %v1_40b38b, false
  call void @__pseudo_cond_branch(i1 %v1_40b38d, i32 ptrtoint (i16** @global_var_406dd5.3 to i32))
  %v0_40b393 = load i32, i32* inttoptr (i32 4763864 to i32*), align 8
  %v1_40b393 = load i32, i32* %edi.global-to-local, align 4
  %v2_40b393 = load i1, i1* %cf.global-to-local, align 1
  %v3_40b393 = zext i1 %v2_40b393 to i32
  %v4_40b393 = sub i32 %v0_40b393, %v1_40b393
  %v5_40b393 = add i32 %v3_40b393, %v4_40b393
  %v16_40b393 = sub i32 %v4_40b393, %v3_40b393
  %v17_40b393 = icmp ult i32 %v0_40b393, %v16_40b393
  %v18_40b393 = icmp ne i32 %v1_40b393, -1
  %v19_40b393 = or i1 %v18_40b393, %v17_40b393
  %v20_40b393 = icmp ult i32 %v0_40b393, %v1_40b393
  %v21_40b393 = select i1 %v2_40b393, i1 %v19_40b393, i1 %v20_40b393
  store i32 %v5_40b393, i32* inttoptr (i32 4763864 to i32*), align 8
  %v0_40b399 = load i32, i32* %ebx.global-to-local, align 4
  %v1_40b399 = load i32, i32* inttoptr (i32 4763665 to i32*), align 4
  %v3_40b399 = zext i1 %v21_40b393 to i32
  %v4_40b399 = add i32 %v1_40b399, %v0_40b399
  %v5_40b399 = add i32 %v4_40b399, %v3_40b399
  %v0_40b39f = load i32, i32* %edx.global-to-local, align 4
  %v1_40b39f = and i32 %v0_40b39f, -256
  %v3_40b3a1 = udiv i32 %v5_40b399, 256
  %v4_40b3a1 = trunc i32 %v3_40b3a1 to i8
  %v5_40b3a1 = add i8 %v4_40b3a1, 1
  %v10_40b3a1 = icmp eq i8 %v5_40b3a1, 0
  %v20_40b3a1 = zext i8 %v5_40b3a1 to i32
  %v23_40b3a1 = or i32 %v20_40b3a1, %v1_40b39f
  store i32 %v23_40b3a1, i32* %edx.global-to-local, align 4
  %v2_40b3a3 = zext i1 %v10_40b3a1 to i32
  store i32 %v2_40b3a3, i32* %ebx.global-to-local, align 4
  %v1_40b3a5 = select i1 %v6_40b385, i32 -74, i32 0
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v1_40b3a5, i32* %eax.global-to-local, align 4
  %v1_40b3a8 = zext i1 %v10_40b3a1 to i8
  %v2_40b3a8 = load i8, i8* inttoptr (i32 4764116 to i8*), align 4
  %v5_40b3a8 = add i8 %v1_40b3a8, %v2_40b3a8
  %v25_40b3a8 = icmp ult i8 %v5_40b3a8, %v1_40b3a8
  store i1 %v25_40b3a8, i1* %cf.global-to-local, align 1
  %v27_40b3a8 = zext i8 %v5_40b3a8 to i32
  store i32 %v27_40b3a8, i32* %ebx.global-to-local, align 4
  %v2_40b3ae = load i8, i8* inttoptr (i32 4763810 to i8*), align 2
  %v3_40b3ae = sub i8 %v5_40b3a1, %v2_40b3ae
  %v8_40b3ae = icmp ult i8 %v5_40b3a1, %v2_40b3ae
  %v18_40b3ae = zext i8 %v3_40b3ae to i32
  %v21_40b3ae = or i32 %v18_40b3ae, %v1_40b39f
  store i32 %v21_40b3ae, i32* %edx.global-to-local, align 4
  store i32 255, i32* inttoptr (i32 4763916 to i32*), align 4
  %v0_40b3be = load i32, i32* inttoptr (i32 4763836 to i32*), align 4
  %v3_40b3be = select i1 %v8_40b3ae, i32 220, i32 219
  %v4_40b3be = add i32 %v3_40b3be, %v0_40b3be
  %v21_40b3be = icmp ule i32 %v4_40b3be, %v0_40b3be
  %v22_40b3be = icmp ugt i32 %v0_40b3be, -220
  %v23_40b3be = select i1 %v8_40b3ae, i1 %v21_40b3be, i1 %v22_40b3be
  store i32 %v4_40b3be, i32* inttoptr (i32 4763836 to i32*), align 4
  %v0_40b3c8 = load i32, i32* inttoptr (i32 4764041 to i32*), align 4
  %v1_40b3c8 = load i32, i32* %esi.global-to-local, align 4
  %v3_40b3c8 = zext i1 %v23_40b3be to i32
  %v4_40b3c8 = add i32 %v1_40b3c8, %v0_40b3c8
  %v5_40b3c8 = add i32 %v3_40b3c8, %v4_40b3c8
  %v24_40b3c8 = icmp ule i32 %v5_40b3c8, %v0_40b3c8
  %v25_40b3c8 = icmp ult i32 %v4_40b3c8, %v0_40b3c8
  %v26_40b3c8 = select i1 %v23_40b3be, i1 %v24_40b3c8, i1 %v25_40b3c8
  store i1 %v26_40b3c8, i1* %cf.global-to-local, align 1
  store i32 %v5_40b3c8, i32* inttoptr (i32 4764041 to i32*), align 4
  call void @__pseudo_call(i32 4240342)
  %v0_40b3d6 = load i32, i32* inttoptr (i32 4764108 to i32*), align 4
  %v1_40b3d6 = load i32, i32* %edi.global-to-local, align 4
  %v2_40b3d6 = load i1, i1* %cf.global-to-local, align 1
  %v3_40b3d6 = zext i1 %v2_40b3d6 to i32
  %v4_40b3d6 = sub i32 %v0_40b3d6, %v1_40b3d6
  %v5_40b3d6 = add i32 %v4_40b3d6, %v3_40b3d6
  store i32 %v5_40b3d6, i32* inttoptr (i32 4764108 to i32*), align 4
  %v0_40b3dc = load i32, i32* inttoptr (i32 4763799 to i32*), align 4
  %v1_40b3dc = load i32, i32* %eax.global-to-local, align 4
  %v2_40b3dc = and i32 %v1_40b3dc, %v0_40b3dc
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v2_40b3dc, i32* inttoptr (i32 4763799 to i32*), align 4
  %v1_40b3e2 = udiv i32 %v1_40b3dc, 256
  %v2_40b3e2 = trunc i32 %v1_40b3e2 to i8
  %v3_40b3e2 = load i8, i8* inttoptr (i32 4763898 to i8*), align 2
  %v6_40b3e2 = add i8 %v2_40b3e2, %v3_40b3e2
  %v28_40b3e2 = zext i8 %v6_40b3e2 to i32
  %v30_40b3e2 = mul nuw nsw i32 %v28_40b3e2, 256
  %v31_40b3e2 = and i32 %v1_40b3dc, -65281
  %v32_40b3e2 = or i32 %v30_40b3e2, %v31_40b3e2
  store i32 %v32_40b3e2, i32* %eax.global-to-local, align 4
  %v0_40b3e8 = load i32, i32* inttoptr (i32 4763986 to i32*), align 4
  %v1_40b3e8 = and i32 %v0_40b3e8, 44
  store i32 %v1_40b3e8, i32* inttoptr (i32 4763986 to i32*), align 4
  %v0_40b3ef = load i32, i32* %edi.global-to-local, align 4
  %v1_40b3ef = load i32, i32* inttoptr (i32 4763719 to i32*), align 4
  %v4_40b3ef = add i32 %v1_40b3ef, %v0_40b3ef
  %v25_40b3ef = icmp ult i32 %v4_40b3ef, %v0_40b3ef
  store i32 %v4_40b3ef, i32* %edi.global-to-local, align 4
  %v0_40b3f5 = load i32, i32* inttoptr (i32 4763909 to i32*), align 4
  %v2_40b3f5 = zext i1 %v25_40b3ef to i32
  %v3_40b3f5 = add i32 %v0_40b3f5, -52
  %v4_40b3f5 = add i32 %v3_40b3f5, %v2_40b3f5
  store i32 %v4_40b3f5, i32* inttoptr (i32 4763909 to i32*), align 4
  %v0_40b3fc = load i32, i32* inttoptr (i32 4763859 to i32*), align 4
  %v1_40b3fc = and i32 %v0_40b3fc, 243
  store i32 %v1_40b3fc, i32* inttoptr (i32 4763859 to i32*), align 4
  %v0_40b406 = load i32, i32* inttoptr (i32 4764146 to i32*), align 4
  %v3_40b406 = add i32 %v0_40b406, 157
  %v22_40b406 = icmp ugt i32 %v0_40b406, -158
  store i32 %v3_40b406, i32* inttoptr (i32 4764146 to i32*), align 4
  %v0_40b410 = load i32, i32* %esi.global-to-local, align 4
  %v1_40b410 = load i32, i32* %eax.global-to-local, align 4
  %v3_40b410 = zext i1 %v22_40b406 to i32
  %v4_40b410 = add i32 %v3_40b410, %v0_40b410
  %v5_40b410 = add i32 %v4_40b410, %v1_40b410
  store i32 %v5_40b410, i32* %esi.global-to-local, align 4
  store i32 117, i32* %ecx.global-to-local, align 4
  %v0_40b41a = load i32, i32* inttoptr (i32 4764128 to i32*), align 32
  %v1_40b41a = or i32 %v0_40b41a, 126
  store i32 %v1_40b41a, i32* inttoptr (i32 4764128 to i32*), align 32
  %v0_40b421 = load i32, i32* inttoptr (i32 4763942 to i32*), align 4
  %v1_40b421 = load i32, i32* %ebx.global-to-local, align 4
  %v2_40b421 = xor i32 %v1_40b421, %v0_40b421
  store i32 %v2_40b421, i32* inttoptr (i32 4763942 to i32*), align 4
  %v0_40b427 = load i32, i32* %edi.global-to-local, align 4
  %v1_40b427 = load i32, i32* inttoptr (i32 4764048 to i32*), align 16
  %v4_40b427 = add i32 %v1_40b427, %v0_40b427
  %v25_40b427 = icmp ult i32 %v4_40b427, %v0_40b427
  store i32 %v4_40b427, i32* %edi.global-to-local, align 4
  %v0_40b42d = load i32, i32* inttoptr (i32 4763787 to i32*), align 4
  %v3_40b42d = select i1 %v25_40b427, i32 14, i32 13
  %v4_40b42d = add i32 %v3_40b42d, %v0_40b42d
  %v21_40b42d = icmp ule i32 %v4_40b42d, %v0_40b42d
  %v22_40b42d = icmp ugt i32 %v0_40b42d, -14
  %v23_40b42d = select i1 %v25_40b427, i1 %v21_40b42d, i1 %v22_40b42d
  store i32 %v4_40b42d, i32* inttoptr (i32 4763787 to i32*), align 4
  %v0_40b434 = load i32, i32* %ebx.global-to-local, align 4
  %v1_40b434 = load i32, i32* %esi.global-to-local, align 4
  %v3_40b434 = zext i1 %v23_40b42d to i32
  %v4_40b434 = add i32 %v1_40b434, %v0_40b434
  %v5_40b434 = add i32 %v3_40b434, %v4_40b434
  %v24_40b434 = icmp ule i32 %v5_40b434, %v0_40b434
  %v25_40b434 = icmp ult i32 %v4_40b434, %v0_40b434
  %v26_40b434 = select i1 %v23_40b42d, i1 %v24_40b434, i1 %v25_40b434
  store i1 %v26_40b434, i1* %cf.global-to-local, align 1
  store i32 %v5_40b434, i32* %ebx.global-to-local, align 4
  %v0_40b436 = load i32, i32* %eax.global-to-local, align 4
  %v1_40b436 = inttoptr i32 %v0_40b436 to i8*
  %v2_40b436 = load i8, i8* %v1_40b436, align 1
  %v4_40b436 = trunc i32 %v0_40b436 to i8
  %v5_40b436 = add i8 %v4_40b436, %v2_40b436
  %v10_40b436 = icmp ult i8 %v5_40b436, %v2_40b436
  store i1 %v10_40b436, i1* %cf.global-to-local, align 1
  store i8 %v5_40b436, i8* %v1_40b436, align 1
  %v0_40b438 = load i32, i32* %eax.global-to-local, align 4
  %v1_40b438 = inttoptr i32 %v0_40b438 to i8*
  %v2_40b438 = load i8, i8* %v1_40b438, align 1
  %v4_40b438 = trunc i32 %v0_40b438 to i8
  %v5_40b438 = add i8 %v4_40b438, %v2_40b438
  %v10_40b438 = icmp ult i8 %v5_40b438, %v2_40b438
  store i1 %v10_40b438, i1* %cf.global-to-local, align 1
  store i8 %v5_40b438, i8* %v1_40b438, align 1
  %v0_40b43a = load i32, i32* %eax.global-to-local, align 4
  %v1_40b43a = inttoptr i32 %v0_40b43a to i8*
  %v2_40b43a = load i8, i8* %v1_40b43a, align 1
  %v4_40b43a = trunc i32 %v0_40b43a to i8
  %v5_40b43a = add i8 %v4_40b43a, %v2_40b43a
  %v10_40b43a = icmp ult i8 %v5_40b43a, %v2_40b43a
  store i1 %v10_40b43a, i1* %cf.global-to-local, align 1
  store i8 %v5_40b43a, i8* %v1_40b43a, align 1
  %v0_40b43c = load i32, i32* %eax.global-to-local, align 4
  %v1_40b43c = inttoptr i32 %v0_40b43c to i8*
  %v2_40b43c = load i8, i8* %v1_40b43c, align 1
  %v4_40b43c = trunc i32 %v0_40b43c to i8
  %v5_40b43c = add i8 %v4_40b43c, %v2_40b43c
  store i8 %v5_40b43c, i8* %v1_40b43c, align 1
  %v0_40b43e = load i32, i32* %ebx.global-to-local, align 4
  %v3_40b43e = load i32, i32* %eax.global-to-local, align 4
  %v5_40b43e41 = mul i32 %v3_40b43e, 256
  %v1_40b43e42 = add i32 %v5_40b43e41, %v0_40b43e
  %v22_40b43e = and i32 %v1_40b43e42, 65280
  %v23_40b43e = and i32 %v0_40b43e, -65281
  %v24_40b43e = or i32 %v22_40b43e, %v23_40b43e
  %v1_40b440 = load i32, i32* %esi.global-to-local, align 4
  %v2_40b440 = add i32 %v24_40b43e, %v1_40b440
  store i32 %v2_40b440, i32* %ebx.global-to-local, align 4
  %v1_40b442 = load i32, i32* inttoptr (i32 4764026 to i32*), align 4
  %v2_40b442 = sub i32 %v3_40b43e, %v1_40b442
  %v7_40b442 = icmp ult i32 %v3_40b43e, %v1_40b442
  store i1 %v7_40b442, i1* %cf.global-to-local, align 1
  %v14_40b442 = trunc i32 %v2_40b442 to i8
  store i32 %v2_40b442, i32* %eax.global-to-local, align 4
  %v2_40b448 = load i8, i8* inttoptr (i32 4764120 to i8*), align 8
  %v4_40b448 = zext i1 %v7_40b442 to i8
  %v5_40b448 = add i8 %v4_40b448, %v14_40b442
  %v6_40b448 = add i8 %v5_40b448, %v2_40b448
  %v27_40b448 = zext i8 %v6_40b448 to i32
  %v29_40b448 = and i32 %v2_40b442, -256
  %v30_40b448 = or i32 %v27_40b448, %v29_40b448
  store i32 %v30_40b448, i32* %eax.global-to-local, align 4
  %v2_40b453 = add i32 %v30_40b448, 1
  %v7_40b453 = icmp eq i32 %v2_40b453, 0
  store i32 %v2_40b453, i32* %ecx.global-to-local, align 4
  %v1_40b455 = load i32, i32* inttoptr (i32 4763896 to i32*), align 8
  %v3_40b455 = zext i1 %v7_40b453 to i32
  %v4_40b455 = add i32 %v1_40b455, %v1_40b440
  %v5_40b455 = add i32 %v4_40b455, %v3_40b455
  store i32 %v5_40b455, i32* %esi.global-to-local, align 4
  %v0_40b45b = load i32, i32* inttoptr (i32 4763663 to i32*), align 4
  %v2_40b45b = add i32 %v0_40b45b, %v2_40b453
  %v7_40b45b = icmp ult i32 %v2_40b45b, %v0_40b45b
  store i32 %v2_40b45b, i32* inttoptr (i32 4763663 to i32*), align 4
  %v1_40b461 = load i32, i32* inttoptr (i32 4763775 to i32*), align 4
  %v3_40b461 = zext i1 %v7_40b45b to i32
  %v4_40b461 = add i32 %v1_40b461, %v5_40b455
  %v5_40b461 = add i32 %v4_40b461, %v3_40b461
  store i32 %v5_40b461, i32* %esi.global-to-local, align 4
  %v0_40b467 = load i32, i32* inttoptr (i32 4763842 to i32*), align 4
  %v1_40b467 = and i32 %v0_40b467, 156
  store i32 %v1_40b467, i32* inttoptr (i32 4763842 to i32*), align 4
  %v0_40b471 = load i32, i32* inttoptr (i32 4763721 to i32*), align 4
  %v1_40b471 = load i32, i32* %edi.global-to-local, align 4
  %v2_40b471 = and i32 %v1_40b471, %v0_40b471
  store i32 %v2_40b471, i32* inttoptr (i32 4763721 to i32*), align 4
  %v0_40b477 = load i32, i32* inttoptr (i32 4764098 to i32*), align 4
  %v1_40b477 = or i32 %v0_40b477, 176
  store i32 %v1_40b477, i32* inttoptr (i32 4764098 to i32*), align 4
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 114, i32* %edx.global-to-local, align 4
  store i32 0, i32* %eax.global-to-local, align 4
  %v5_40b494 = call i32* @EncodePointer(i32* null)
  %v6_40b494 = ptrtoint i32* %v5_40b494 to i32
  store i32 %v6_40b494, i32* %eax.global-to-local, align 4
  %v3_40b49f = add i32 %v6_40b494, 1
  store i32 %v3_40b49f, i32* %ecx.global-to-local, align 4
  %v0_40b4a1 = load i32, i32* inttoptr (i32 4763901 to i32*), align 4
  %v1_40b4a1 = load i32, i32* %ebx.global-to-local, align 4
  %v2_40b4a1 = and i32 %v1_40b4a1, %v0_40b4a1
  store i32 %v2_40b4a1, i32* inttoptr (i32 4763901 to i32*), align 4
  %v0_40b4a7 = load i32, i32* inttoptr (i32 4764126 to i32*), align 4
  %v3_40b4a7 = or i32 %v0_40b4a7, %v6_40b494
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v3_40b4a7, i32* inttoptr (i32 4764126 to i32*), align 4
  %v0_40b4ad = load i8, i8* inttoptr (i32 4763769 to i8*), align 1
  %v1_40b4ad = load i32, i32* %ecx.global-to-local, align 4
  %v2_40b4ad = trunc i32 %v1_40b4ad to i8
  %v5_40b4ad = add i8 %v2_40b4ad, %v0_40b4ad
  store i8 %v5_40b4ad, i8* inttoptr (i32 4763769 to i8*), align 1
  %v0_40b4b3 = load i32, i32* inttoptr (i32 4763834 to i32*), align 4
  %v2_40b4b3 = or i32 %v1_40b4ad, %v0_40b4b3
  store i32 %v2_40b4b3, i32* inttoptr (i32 4763834 to i32*), align 4
  %v2_40b4b9 = load i32, i32* inttoptr (i32 4763966 to i32*), align 4
  %v5_40b4b9 = add i32 %v2_40b4b9, %v6_40b494
  %v26_40b4b9 = icmp ult i32 %v5_40b4b9, %v6_40b494
  store i32 %v5_40b4b9, i32* %eax.global-to-local, align 4
  %v0_40b4bf = load i32, i32* inttoptr (i32 4763929 to i32*), align 4
  %v1_40b4bf = load i32, i32* %edi.global-to-local, align 4
  %v3_40b4bf = zext i1 %v26_40b4b9 to i32
  %v4_40b4bf = sub i32 %v0_40b4bf, %v1_40b4bf
  %v5_40b4bf = add i32 %v4_40b4bf, %v3_40b4bf
  store i32 %v5_40b4bf, i32* inttoptr (i32 4763929 to i32*), align 4
  %v0_40b4c5 = load i32, i32* inttoptr (i32 4763654 to i32*), align 4
  %v1_40b4c5 = and i32 %v0_40b4c5, 41
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v1_40b4c5, i32* inttoptr (i32 4763654 to i32*), align 4
  %v0_40b4cc = load i8, i8* inttoptr (i32 4764043 to i8*), align 1
  %v1_40b4cc = load i32, i32* %eax.global-to-local, align 4
  %v2_40b4cc = trunc i32 %v1_40b4cc to i8
  %v5_40b4cc = add i8 %v2_40b4cc, %v0_40b4cc
  %v25_40b4cc = icmp ult i8 %v5_40b4cc, %v0_40b4cc
  store i1 %v25_40b4cc, i1* %cf.global-to-local, align 1
  store i8 %v5_40b4cc, i8* inttoptr (i32 4764043 to i8*), align 1
  %v0_40b4d2 = load i32, i32* inttoptr (i32 4763884 to i32*), align 4
  %v2_40b4d2 = zext i1 %v25_40b4cc to i32
  %v3_40b4d2 = add i32 %v0_40b4d2, -80
  %v4_40b4d2 = add i32 %v3_40b4d2, %v2_40b4d2
  store i32 %v4_40b4d2, i32* inttoptr (i32 4763884 to i32*), align 4
  %v0_40b4d9 = load i32, i32* %edx.global-to-local, align 4
  %v1_40b4d9 = and i32 %v0_40b4d9, -65281
  %v18_40b4db = or i32 %v1_40b4d9, 37120
  store i32 %v18_40b4db, i32* %edx.global-to-local, align 4
  %v0_40b4de = load i32, i32* %edi.global-to-local, align 4
  %v1_40b4de = and i32 %v0_40b4de, -60
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v1_40b4de, i32* %edi.global-to-local, align 4
  %v0_40b4e1 = load i8, i8* inttoptr (i32 4764038 to i8*), align 2
  %v1_40b4e1 = load i32, i32* %ebx.global-to-local, align 4
  %v2_40b4e1 = trunc i32 %v1_40b4e1 to i8
  %v3_40b4e1 = or i8 %v2_40b4e1, %v0_40b4e1
  store i8 %v3_40b4e1, i8* inttoptr (i32 4764038 to i8*), align 2
  store i32 28, i32* inttoptr (i32 4763943 to i32*), align 4
  %v1_40b4f1 = load i32, i32* %edi.global-to-local, align 4
  %v2_40b4f1 = add i32 %v1_40b4f1, %v1_40b4e1
  store i32 %v2_40b4f1, i32* %ebx.global-to-local, align 4
  %v1_40b4f3 = load i32, i32* %ecx.global-to-local, align 4
  %v2_40b4f3 = add i32 %v1_40b4f3, %v1_40b4f1
  %v7_40b4f3 = icmp ult i32 %v2_40b4f3, %v1_40b4f1
  store i32 %v2_40b4f3, i32* %edi.global-to-local, align 4
  %v0_40b4f5 = load i32, i32* inttoptr (i32 4764081 to i32*), align 4
  %v2_40b4f5 = zext i1 %v7_40b4f3 to i32
  %v3_40b4f5 = add i32 %v0_40b4f5, 70
  %v4_40b4f5 = add i32 %v3_40b4f5, %v2_40b4f5
  store i32 %v4_40b4f5, i32* inttoptr (i32 4764081 to i32*), align 4
  %v0_40b4fc = load i32, i32* %eax.global-to-local, align 4
  %v1_40b4fc = or i32 %v0_40b4fc, -3
  store i32 %v1_40b4fc, i32* %eax.global-to-local, align 4
  %v0_40b4ff = load i32, i32* %esi.global-to-local, align 4
  %v1_40b4ff = add i32 %v0_40b4ff, 66
  %v5_40b4ff = icmp ugt i32 %v0_40b4ff, -67
  store i1 %v5_40b4ff, i1* %cf.global-to-local, align 1
  store i32 %v1_40b4ff, i32* %esi.global-to-local, align 4
  call void @__pseudo_call(i32 4240650)
  %v0_40b50a = load i32, i32* inttoptr (i32 4764101 to i32*), align 4
  %v1_40b50a = load i32, i32* %edx.global-to-local, align 4
  %v2_40b50a = and i32 %v1_40b50a, %v0_40b50a
  store i32 %v2_40b50a, i32* inttoptr (i32 4764101 to i32*), align 4
  %v0_40b510 = load i32, i32* inttoptr (i32 4763775 to i32*), align 4
  %v1_40b510 = load i32, i32* %ebx.global-to-local, align 4
  %v2_40b510 = xor i32 %v1_40b510, %v0_40b510
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v2_40b510, i32* inttoptr (i32 4763775 to i32*), align 4
  %v0_40b516 = load i8, i8* inttoptr (i32 4764147 to i8*), align 1
  %v1_40b516 = add i8 %v0_40b516, -22
  store i8 %v1_40b516, i8* inttoptr (i32 4764147 to i8*), align 1
  %v0_40b51d = load i32, i32* %eax.global-to-local, align 4
  %v1_40b51d = or i32 %v0_40b51d, -71
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v1_40b51d, i32* %eax.global-to-local, align 4
  %v0_40b520 = load i32, i32* %edx.global-to-local, align 4
  %v1_40b520 = udiv i32 %v0_40b520, 256
  %v2_40b520 = trunc i32 %v1_40b520 to i8
  %v3_40b520 = load i8, i8* inttoptr (i32 4763893 to i8*), align 1
  %v6_40b520 = add i8 %v2_40b520, %v3_40b520
  %v26_40b520 = icmp ult i8 %v6_40b520, %v2_40b520
  %v28_40b520 = zext i8 %v6_40b520 to i32
  %v30_40b520 = mul nuw nsw i32 %v28_40b520, 256
  %v31_40b520 = and i32 %v0_40b520, -65281
  %v32_40b520 = or i32 %v30_40b520, %v31_40b520
  store i32 %v32_40b520, i32* %edx.global-to-local, align 4
  %v0_40b526 = load i32, i32* %ecx.global-to-local, align 4
  %v1_40b526 = load i32, i32* inttoptr (i32 4763806 to i32*), align 4
  %v3_40b526 = zext i1 %v26_40b520 to i32
  %v4_40b526 = add i32 %v1_40b526, %v0_40b526
  %v5_40b526 = add i32 %v4_40b526, %v3_40b526
  store i32 %v5_40b526, i32* %ecx.global-to-local, align 4
  %v0_40b52c = load i32, i32* inttoptr (i32 4764105 to i32*), align 4
  %v1_40b52c = load i32, i32* %edi.global-to-local, align 4
  %v2_40b52c = and i32 %v1_40b52c, %v0_40b52c
  store i32 %v2_40b52c, i32* inttoptr (i32 4764105 to i32*), align 4
  %v0_40b532 = load i32, i32* %esi.global-to-local, align 4
  %v2_40b532 = add i32 %v5_40b526, %v0_40b532
  store i32 %v2_40b532, i32* %esi.global-to-local, align 4
  %v2_40b534 = add i32 %v1_40b52c, %v5_40b526
  store i32 %v2_40b534, i32* %ecx.global-to-local, align 4
  %v0_40b536 = load i32, i32* inttoptr (i32 4764054 to i32*), align 4
  %v2_40b536 = or i32 %v0_40b536, %v2_40b534
  store i32 %v2_40b536, i32* inttoptr (i32 4764054 to i32*), align 4
  %v0_40b53c = load i32, i32* inttoptr (i32 4764016 to i32*), align 16
  %v1_40b53c = or i32 %v0_40b53c, 6
  store i32 %v1_40b53c, i32* inttoptr (i32 4764016 to i32*), align 16
  %v0_40b543 = load i32, i32* inttoptr (i32 4763950 to i32*), align 4
  %v1_40b543 = and i32 %v0_40b543, 141
  store i32 %v1_40b543, i32* inttoptr (i32 4763950 to i32*), align 4
  %v0_40b54d = load i32, i32* %ebx.global-to-local, align 4
  %v1_40b54d = add i32 %v0_40b54d, -34
  %v5_40b54d = icmp ugt i32 %v0_40b54d, 33
  store i1 %v5_40b54d, i1* %cf.global-to-local, align 1
  store i32 %v1_40b54d, i32* %ebx.global-to-local, align 4
  %v0_40b550 = load i32, i32* %eax.global-to-local, align 4
  %v1_40b550 = inttoptr i32 %v0_40b550 to i8*
  %v2_40b550 = load i8, i8* %v1_40b550, align 1
  %v4_40b550 = trunc i32 %v0_40b550 to i8
  %v5_40b550 = add i8 %v4_40b550, %v2_40b550
  %v10_40b550 = icmp ult i8 %v5_40b550, %v2_40b550
  store i1 %v10_40b550, i1* %cf.global-to-local, align 1
  store i8 %v5_40b550, i8* %v1_40b550, align 1
  %v0_40b552 = load i32, i32* %ecx.global-to-local, align 4
  %v1_40b552 = inttoptr i32 %v0_40b552 to i8*
  %v2_40b552 = load i8, i8* %v1_40b552, align 1
  %v3_40b552 = load i32, i32* %edx.global-to-local, align 4
  %v4_40b552 = udiv i32 %v3_40b552, 256
  %v5_40b552 = trunc i32 %v4_40b552 to i8
  %v6_40b552 = add i8 %v5_40b552, %v2_40b552
  store i8 %v6_40b552, i8* %v1_40b552, align 1
  %v0_40b556 = load i32, i32* %eax.global-to-local, align 4
  %v1_40b556 = xor i32 %v0_40b556, 4764025
  store i32 %v1_40b556, i32* %eax.global-to-local, align 4
  %v1_40b560 = load i32, i32* %edi.global-to-local, align 4
  %v2_40b560 = add i32 %v1_40b560, 1
  store i32 %v2_40b560, i32* %ecx.global-to-local, align 4
  %v0_40b562 = load i32, i32* %ebx.global-to-local, align 4
  %v1_40b562 = add i32 %v0_40b562, -109
  store i32 %v1_40b562, i32* %ebx.global-to-local, align 4
  %v0_40b565 = load i32, i32* inttoptr (i32 4763764 to i32*), align 4
  %v1_40b565 = load i32, i32* %esi.global-to-local, align 4
  %v2_40b565 = xor i32 %v1_40b565, %v0_40b565
  store i32 %v2_40b565, i32* inttoptr (i32 4763764 to i32*), align 4
  store i32 9, i32* inttoptr (i32 4763784 to i32*), align 8
  %v0_40b575 = load i32, i32* inttoptr (i32 4763897 to i32*), align 4
  %v1_40b575 = load i32, i32* %eax.global-to-local, align 4
  %v2_40b575 = and i32 %v1_40b575, %v0_40b575
  store i32 %v2_40b575, i32* inttoptr (i32 4763897 to i32*), align 4
  %v0_40b57b = load i32, i32* %ebx.global-to-local, align 4
  %v1_40b57b = add i32 %v0_40b57b, 69
  %v1_40b57e = and i32 %v1_40b57b, -71
  store i32 %v1_40b57e, i32* %ebx.global-to-local, align 4
  %v0_40b581 = load i32, i32* %esi.global-to-local, align 4
  %v1_40b581 = and i32 %v0_40b581, -4
  store i32 %v1_40b581, i32* %esi.global-to-local, align 4
  %v0_40b584 = load i32, i32* inttoptr (i32 4763703 to i32*), align 4
  %v1_40b584 = load i32, i32* %edi.global-to-local, align 4
  %v2_40b584 = add i32 %v1_40b584, %v0_40b584
  %v7_40b584 = icmp ult i32 %v2_40b584, %v0_40b584
  store i32 %v2_40b584, i32* inttoptr (i32 4763703 to i32*), align 4
  %v1_40b58a = load i32, i32* inttoptr (i32 4763888 to i32*), align 16
  %v3_40b58a = zext i1 %v7_40b584 to i32
  %v4_40b58a = add i32 %v1_40b58a, %v1_40b584
  %v5_40b58a = add i32 %v4_40b58a, %v3_40b58a
  store i32 %v5_40b58a, i32* %edi.global-to-local, align 4
  store i1 false, i1* %cf.global-to-local, align 1
  store i16* bitcast ([13 x i8]* @global_var_48b685.2 to i16*), i16** %stack_var_-268, align 4
  %v8_40b5a2 = call i1 @SetEnvironmentVariableW(i16* bitcast ([13 x i8]* @global_var_48b685.2 to i16*), i16* bitcast ([17 x i8]* @global_var_48b692.1 to i16*))
  %v9_40b5a2 = sext i1 %v8_40b5a2 to i32
  store i32 %v9_40b5a2, i32* %eax.global-to-local, align 4
  %v0_40b5a8 = load i32, i32* %esi.global-to-local, align 4
  %v1_40b5a8 = load i32, i32* inttoptr (i32 4763815 to i32*), align 4
  %v2_40b5a8 = or i32 %v1_40b5a8, %v0_40b5a8
  store i32 %v2_40b5a8, i32* %esi.global-to-local, align 4
  %v0_40b5ae = load i32, i32* inttoptr (i32 4764058 to i32*), align 4
  %v1_40b5ae = and i32 %v0_40b5ae, 3
  store i32 %v1_40b5ae, i32* inttoptr (i32 4764058 to i32*), align 4
  store i32 1, i32* %edx.global-to-local, align 4
  %v1_40b5ba = load i32, i32* inttoptr (i32 4764152 to i32*), align 8
  %v4_40b5ba = add i32 %v1_40b5ba, 1
  store i32 %v4_40b5ba, i32* %edx.global-to-local, align 4
  %v0_40b5c0 = load i32, i32* inttoptr (i32 4763704 to i32*), align 8
  %v1_40b5c0 = or i32 %v0_40b5c0, 145
  store i32 %v1_40b5c0, i32* inttoptr (i32 4763704 to i32*), align 8
  store i32 234, i32* inttoptr (i32 4764100 to i32*), align 4
  %v1_40b5d4 = load i32, i32* inttoptr (i32 4764025 to i32*), align 4
  %v4_40b5d4 = add i32 %v1_40b5d4, %v4_40b5ba
  store i32 %v4_40b5d4, i32* %edx.global-to-local, align 4
  %v2_40b5da = load i32, i32* inttoptr (i32 4763975 to i32*), align 4
  %v3_40b5da = sub i32 %v9_40b5a2, %v2_40b5da
  store i32 %v3_40b5da, i32* %eax.global-to-local, align 4
  %v0_40b5e0 = load i32, i32* inttoptr (i32 4763991 to i32*), align 4
  %v1_40b5e0 = load i32, i32* %esi.global-to-local, align 4
  %v2_40b5e0 = xor i32 %v1_40b5e0, %v0_40b5e0
  store i32 %v2_40b5e0, i32* inttoptr (i32 4763991 to i32*), align 4
  %v0_40b5e6 = load i32, i32* %ebx.global-to-local, align 4
  %v1_40b5e6 = add i32 %v0_40b5e6, -61
  store i32 %v1_40b5e6, i32* %ebx.global-to-local, align 4
  %v0_40b5e9 = load i32, i32* inttoptr (i32 4763816 to i32*), align 8
  %v1_40b5e9 = load i32, i32* %edi.global-to-local, align 4
  %v2_40b5e9 = add i32 %v1_40b5e9, %v0_40b5e9
  %v7_40b5e9 = icmp ult i32 %v2_40b5e9, %v0_40b5e9
  store i32 %v2_40b5e9, i32* inttoptr (i32 4763816 to i32*), align 8
  %v1_40b5ef = load i32, i32* inttoptr (i32 4763738 to i32*), align 4
  %v3_40b5ef = zext i1 %v7_40b5e9 to i32
  %v4_40b5ef = add i32 %v1_40b5ef, %v1_40b5e6
  %v5_40b5ef = add i32 %v4_40b5ef, %v3_40b5ef
  store i32 %v5_40b5ef, i32* %ebx.global-to-local, align 4
  %v0_40b5f5 = load i32, i32* inttoptr (i32 4763748 to i32*), align 4
  %v1_40b5f5 = load i32, i32* %edx.global-to-local, align 4
  %v2_40b5f5 = sub i32 %v0_40b5f5, %v1_40b5f5
  store i32 %v2_40b5f5, i32* inttoptr (i32 4763748 to i32*), align 4
  %v2_40b5fb = add i32 %v1_40b5f5, %v5_40b5ef
  store i32 %v2_40b5fb, i32* %ebx.global-to-local, align 4
  %v0_40b5fd = load i32, i32* inttoptr (i32 4764071 to i32*), align 4
  %v1_40b5fd = and i32 %v0_40b5fd, 124
  store i32 %v1_40b5fd, i32* inttoptr (i32 4764071 to i32*), align 4
  %v1_40b604 = load i32, i32* inttoptr (i32 4763895 to i32*), align 4
  %v4_40b604 = add i32 %v1_40b604, %v2_40b5fb
  store i32 %v4_40b604, i32* %ebx.global-to-local, align 4
  %v0_40b60a = load i32, i32* inttoptr (i32 4763869 to i32*), align 4
  %v1_40b60a = load i32, i32* %edx.global-to-local, align 4
  %v2_40b60a = sub i32 %v0_40b60a, %v1_40b60a
  store i32 %v2_40b60a, i32* inttoptr (i32 4763869 to i32*), align 4
  %v1_40b610 = load i32, i32* inttoptr (i32 4763883 to i32*), align 4
  %v2_40b610 = or i32 %v1_40b610, %v4_40b604
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v2_40b610, i32* %ebx.global-to-local, align 4
  store i16* inttoptr (i32 4240926 to i16*), i16** %stack_var_-268, align 4
  call void @__pseudo_call(i32 4240926)
  %v0_40b61e = load i32, i32* %ebx.global-to-local, align 4
  %v1_40b61e = load i32, i32* inttoptr (i32 4763887 to i32*), align 4
  %v2_40b61e = load i1, i1* %cf.global-to-local, align 1
  %v3_40b61e = zext i1 %v2_40b61e to i32
  %v4_40b61e = add i32 %v1_40b61e, %v0_40b61e
  %v5_40b61e = add i32 %v4_40b61e, %v3_40b61e
  store i32 %v5_40b61e, i32* %ebx.global-to-local, align 4
  %v0_40b624 = load i32, i32* %esi.global-to-local, align 4
  %v1_40b624 = load i32, i32* %eax.global-to-local, align 4
  %v2_40b624 = sub i32 %v0_40b624, %v1_40b624
  store i32 %v2_40b624, i32* %esi.global-to-local, align 4
  %v0_40b626 = load i32, i32* %edi.global-to-local, align 4
  %v1_40b626 = load i32, i32* %edx.global-to-local, align 4
  %v2_40b626 = add i32 %v1_40b626, %v0_40b626
  %v7_40b626 = icmp ult i32 %v2_40b626, %v0_40b626
  store i32 %v2_40b626, i32* %edi.global-to-local, align 4
  %v0_40b628 = load i32, i32* inttoptr (i32 4763987 to i32*), align 4
  %v2_40b628 = zext i1 %v7_40b626 to i32
  %v3_40b628 = add i32 %v0_40b628, 205
  %v4_40b628 = add i32 %v3_40b628, %v2_40b628
  store i32 %v4_40b628, i32* inttoptr (i32 4763987 to i32*), align 4
  %v1_40b637 = load i32, i32* %ebx.global-to-local, align 4
  %v2_40b637 = add i32 %v1_40b637, 1
  %v7_40b637 = icmp eq i32 %v2_40b637, 0
  store i32 %v2_40b637, i32* %ecx.global-to-local, align 4
  %v0_40b639 = load i32, i32* inttoptr (i32 4764142 to i32*), align 4
  %v2_40b639 = zext i1 %v7_40b637 to i32
  %v3_40b639 = add i32 %v0_40b639, 159
  %v4_40b639 = add i32 %v3_40b639, %v2_40b639
  store i32 %v4_40b639, i32* inttoptr (i32 4764142 to i32*), align 4
  %v0_40b643 = load i32, i32* %edi.global-to-local, align 4
  %v1_40b643 = add i32 %v0_40b643, -98
  store i32 %v1_40b643, i32* %edi.global-to-local, align 4
  %v0_40b646 = load i32, i32* %esi.global-to-local, align 4
  %v1_40b646 = load i32, i32* inttoptr (i32 4763670 to i32*), align 4
  %v2_40b646 = or i32 %v1_40b646, %v0_40b646
  store i32 %v2_40b646, i32* %esi.global-to-local, align 4
  %v0_40b64c = load i32, i32* %ecx.global-to-local, align 4
  %v1_40b64c = load i32, i32* %eax.global-to-local, align 4
  %v2_40b64c = add i32 %v1_40b64c, %v0_40b64c
  %v7_40b64c = icmp ult i32 %v2_40b64c, %v0_40b64c
  store i32 %v2_40b64c, i32* %ecx.global-to-local, align 4
  store i32 141, i32* inttoptr (i32 4763975 to i32*), align 4
  %v0_40b658 = load i32, i32* %edx.global-to-local, align 4
  %v1_40b658 = load i32, i32* inttoptr (i32 4763891 to i32*), align 4
  %v3_40b658 = zext i1 %v7_40b64c to i32
  %v4_40b658 = add i32 %v1_40b658, %v0_40b658
  %v5_40b658 = add i32 %v4_40b658, %v3_40b658
  %v24_40b658 = icmp ule i32 %v5_40b658, %v0_40b658
  %v25_40b658 = icmp ult i32 %v4_40b658, %v0_40b658
  %v26_40b658 = select i1 %v7_40b64c, i1 %v24_40b658, i1 %v25_40b658
  %v1_40b65e = load i32, i32* %eax.global-to-local, align 4
  %v3_40b65e = zext i1 %v26_40b658 to i32
  %v4_40b65e = sub i32 %v5_40b658, %v1_40b65e
  %v5_40b65e = add i32 %v3_40b65e, %v4_40b65e
  %v16_40b65e = sub i32 %v4_40b65e, %v3_40b65e
  %v17_40b65e = icmp ult i32 %v5_40b658, %v16_40b65e
  %v18_40b65e = icmp ne i32 %v1_40b65e, -1
  %v19_40b65e = or i1 %v18_40b65e, %v17_40b65e
  %v20_40b65e = icmp ult i32 %v5_40b658, %v1_40b65e
  %v21_40b65e = select i1 %v26_40b658, i1 %v19_40b65e, i1 %v20_40b65e
  store i32 %v5_40b65e, i32* %edx.global-to-local, align 4
  %v0_40b660 = load i32, i32* %esi.global-to-local, align 4
  %v2_40b660 = zext i1 %v21_40b65e to i32
  %v3_40b660 = add i32 %v0_40b660, 62
  %v4_40b660 = add i32 %v3_40b660, %v2_40b660
  %v0_40b663 = load i32, i32* %edi.global-to-local, align 4
  %v1_40b663 = add i32 %v0_40b663, -55
  store i32 %v1_40b663, i32* %edi.global-to-local, align 4
  %v1_40b666 = and i32 %v4_40b660, -73
  store i32 %v1_40b666, i32* %esi.global-to-local, align 4
  %v0_40b669 = load i32, i32* %ebx.global-to-local, align 4
  %v3_40b669 = add i32 %v0_40b669, 79
  %v22_40b669 = icmp ugt i32 %v0_40b669, -80
  store i32 %v3_40b669, i32* %ebx.global-to-local, align 4
  %v1_40b66c = load i32, i32* inttoptr (i32 4764147 to i32*), align 4
  %v3_40b66c = zext i1 %v22_40b669 to i32
  %v4_40b66c = add i32 %v3_40b66c, %v1_40b66c
  %v5_40b66c = add i32 %v4_40b66c, %v1_40b666
  store i32 %v5_40b66c, i32* %esi.global-to-local, align 4
  %v1_40b672 = add i32 %v0_40b663, -16
  %v5_40b672 = icmp ult i32 %v1_40b663, -39
  store i1 %v5_40b672, i1* %cf.global-to-local, align 1
  store i32 %v1_40b672, i32* %edi.global-to-local, align 4
  %v0_40b675 = load i8, i8* inttoptr (i32 4763937 to i8*), align 1
  %v1_40b675 = load i32, i32* %ecx.global-to-local, align 4
  %v2_40b675 = udiv i32 %v1_40b675, 256
  %v3_40b675 = trunc i32 %v2_40b675 to i8
  %v4_40b675 = xor i8 %v3_40b675, %v0_40b675
  store i8 %v4_40b675, i8* inttoptr (i32 4763937 to i8*), align 1
  %v0_40b67b = load i32, i32* inttoptr (i32 4763696 to i32*), align 16
  %v1_40b67b = load i32, i32* %edx.global-to-local, align 4
  %v2_40b67b = or i32 %v1_40b67b, %v0_40b67b
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v2_40b67b, i32* inttoptr (i32 4763696 to i32*), align 16
  %v0_40b681 = load i32, i32* %eax.global-to-local, align 4
  %v1_40b681 = inttoptr i32 %v0_40b681 to i8*
  %v2_40b681 = load i8, i8* %v1_40b681, align 1
  %v4_40b681 = trunc i32 %v0_40b681 to i8
  %v5_40b681 = add i8 %v4_40b681, %v2_40b681
  %v10_40b681 = icmp ult i8 %v5_40b681, %v2_40b681
  store i1 %v10_40b681, i1* %cf.global-to-local, align 1
  store i8 %v5_40b681, i8* %v1_40b681, align 1
  %v0_40b683 = load i32, i32* %eax.global-to-local, align 4
  %v1_40b683 = inttoptr i32 %v0_40b683 to i8*
  %v2_40b683 = load i8, i8* %v1_40b683, align 1
  %v4_40b683 = trunc i32 %v0_40b683 to i8
  %v5_40b683 = add i8 %v4_40b683, %v2_40b683
  %v10_40b683 = icmp ult i8 %v5_40b683, %v2_40b683
  store i1 %v10_40b683, i1* %cf.global-to-local, align 1
  store i8 %v5_40b683, i8* %v1_40b683, align 1
  %v0_40b685 = load i32, i32* %eax.global-to-local, align 4
  %v1_40b685 = inttoptr i32 %v0_40b685 to i8*
  %v2_40b685 = load i8, i8* %v1_40b685, align 1
  %v4_40b685 = trunc i32 %v0_40b685 to i8
  %v5_40b685 = add i8 %v4_40b685, %v2_40b685
  %v10_40b685 = icmp ult i8 %v5_40b685, %v2_40b685
  store i1 %v10_40b685, i1* %cf.global-to-local, align 1
  store i8 %v5_40b685, i8* %v1_40b685, align 1
  %v0_40b687 = load i32, i32* %eax.global-to-local, align 4
  %v1_40b687 = inttoptr i32 %v0_40b687 to i8*
  %v2_40b687 = load i8, i8* %v1_40b687, align 1
  %v4_40b687 = trunc i32 %v0_40b687 to i8
  %v5_40b687 = add i8 %v4_40b687, %v2_40b687
  %v10_40b687 = icmp ult i8 %v5_40b687, %v2_40b687
  store i1 %v10_40b687, i1* %cf.global-to-local, align 1
  store i8 %v5_40b687, i8* %v1_40b687, align 1
  %v0_40b689 = load i32, i32* %eax.global-to-local, align 4
  %v1_40b689 = inttoptr i32 %v0_40b689 to i8*
  %v2_40b689 = load i8, i8* %v1_40b689, align 1
  %v4_40b689 = trunc i32 %v0_40b689 to i8
  %v5_40b689 = add i8 %v4_40b689, %v2_40b689
  %v10_40b689 = icmp ult i8 %v5_40b689, %v2_40b689
  store i1 %v10_40b689, i1* %cf.global-to-local, align 1
  store i8 %v5_40b689, i8* %v1_40b689, align 1
  %v0_40b68b = load i32, i32* %eax.global-to-local, align 4
  %v1_40b68b = inttoptr i32 %v0_40b68b to i8*
  %v2_40b68b = load i8, i8* %v1_40b68b, align 1
  %v4_40b68b = trunc i32 %v0_40b68b to i8
  %v5_40b68b = add i8 %v4_40b68b, %v2_40b68b
  %v10_40b68b = icmp ult i8 %v5_40b68b, %v2_40b68b
  store i1 %v10_40b68b, i1* %cf.global-to-local, align 1
  store i8 %v5_40b68b, i8* %v1_40b68b, align 1
  %v0_40b68d = load i32, i32* %eax.global-to-local, align 4
  %v1_40b68d = inttoptr i32 %v0_40b68d to i8*
  %v2_40b68d = load i8, i8* %v1_40b68d, align 1
  %v4_40b68d = trunc i32 %v0_40b68d to i8
  %v5_40b68d = add i8 %v4_40b68d, %v2_40b68d
  %v10_40b68d = icmp ult i8 %v5_40b68d, %v2_40b68d
  store i1 %v10_40b68d, i1* %cf.global-to-local, align 1
  store i8 %v5_40b68d, i8* %v1_40b68d, align 1
  %v0_40b68f = load i32, i32* %ebx.global-to-local, align 4
  %v1_40b68f = add i32 %v0_40b68f, 1025588688
  %v2_40b68f = inttoptr i32 %v1_40b68f to i8*
  %v3_40b68f = load i8, i8* %v2_40b68f, align 1
  %v4_40b68f = load i32, i32* %eax.global-to-local, align 4
  %v5_40b68f = trunc i32 %v4_40b68f to i8
  %v6_40b68f = add i8 %v5_40b68f, %v3_40b68f
  %v11_40b68f = icmp ult i8 %v6_40b68f, %v3_40b68f
  store i1 %v11_40b68f, i1* %cf.global-to-local, align 1
  store i8 %v6_40b68f, i8* %v2_40b68f, align 1
  %v2_40b695 = load i16*, i16** %stack_var_-268, align 4
  %v3_40b695 = ptrtoint i16* %v2_40b695 to i32
  store i32 %v3_40b695, i32* %esi.global-to-local, align 4
  %v0_40b696 = load i32, i32* %ecx.global-to-local, align 4
  %v1_40b696 = and i32 %v0_40b696, -256
  %v2_40b696 = or i32 %v1_40b696, 72
  store i32 %v2_40b696, i32* %ecx.global-to-local, align 4
  %v0_40b698 = load i32, i32* %ebx.global-to-local, align 4
  %v1_40b698 = add i32 %v0_40b698, 1219540245
  %v2_40b698 = inttoptr i32 %v1_40b698 to i8*
  %v3_40b698 = load i8, i8* %v2_40b698, align 1
  %v4_40b698 = load i32, i32* %eax.global-to-local, align 4
  %v5_40b698 = trunc i32 %v4_40b698 to i8
  %v6_40b698 = add i8 %v5_40b698, %v3_40b698
  store i8 %v6_40b698, i8* %v2_40b698, align 1
  %v4_40b69e = load i32, i32* %ebx.global-to-local, align 4
  %v0_40b6a1 = load i32, i32* %eax.global-to-local, align 4
  %v5_40b6a1 = icmp ult i32 %v0_40b6a1, 4764117
  %v0_40b6a6 = load i32, i32* inttoptr (i32 4763914 to i32*), align 4
  %v3_40b6a6 = zext i1 %v5_40b6a1 to i32
  %v4_40b6a6 = add i32 %v0_40b6a6, %v4_40b69e
  %v5_40b6a6 = add i32 %v4_40b6a6, %v3_40b6a6
  store i32 %v5_40b6a6, i32* inttoptr (i32 4763914 to i32*), align 4
  %v0_40b6ac = load i32, i32* %esi.global-to-local, align 4
  %v1_40b6ac = add i32 %v0_40b6ac, 69
  store i32 %v1_40b6ac, i32* %esi.global-to-local, align 4
  %v0_40b6af = load i32, i32* inttoptr (i32 4763965 to i32*), align 4
  %v1_40b6af = load i32, i32* %eax.global-to-local, align 4
  %v2_40b6af = add i32 %v1_40b6af, %v0_40b6af
  store i32 %v2_40b6af, i32* inttoptr (i32 4763965 to i32*), align 4
  %v0_40b6b5 = load i32, i32* inttoptr (i32 4764102 to i32*), align 4
  %v2_40b6b5 = xor i32 %v1_40b6af, %v0_40b6b5
  store i32 %v2_40b6b5, i32* inttoptr (i32 4764102 to i32*), align 4
  %v1_40b6bb = trunc i32 %v1_40b6af to i8
  %v3_40b6bb = udiv i32 %v1_40b6af, 256
  %v4_40b6bb = trunc i32 %v3_40b6bb to i8
  %v5_40b6bb = add i8 %v4_40b6bb, %v1_40b6bb
  %v10_40b6bb = icmp ult i8 %v5_40b6bb, %v1_40b6bb
  %v20_40b6bb = zext i8 %v5_40b6bb to i32
  %v22_40b6bb = and i32 %v1_40b6af, -256
  %v23_40b6bb = or i32 %v20_40b6bb, %v22_40b6bb
  store i32 %v23_40b6bb, i32* %eax.global-to-local, align 4
  %v0_40b6bd = load i32, i32* %ebx.global-to-local, align 4
  %v2_40b6bd = zext i1 %v10_40b6bb to i32
  %v3_40b6bd = add i32 %v0_40b6bd, 51
  %v4_40b6bd = add i32 %v3_40b6bd, %v2_40b6bd
  store i32 %v4_40b6bd, i32* %ebx.global-to-local, align 4
  %v0_40b6c0 = load i32, i32* inttoptr (i32 4763790 to i32*), align 4
  %v2_40b6c0 = or i32 %v23_40b6bb, %v0_40b6c0
  store i32 %v2_40b6c0, i32* inttoptr (i32 4763790 to i32*), align 4
  %v0_40b6c6 = load i32, i32* %esi.global-to-local, align 4
  %v1_40b6c6 = load i32, i32* %eax.global-to-local, align 4
  %v2_40b6c6 = add i32 %v1_40b6c6, %v0_40b6c6
  %v7_40b6c6 = icmp ult i32 %v2_40b6c6, %v0_40b6c6
  store i1 %v7_40b6c6, i1* %cf.global-to-local, align 1
  store i32 %v2_40b6c6, i32* %esi.global-to-local, align 4
  %v0_40b6c8 = load i32, i32* %ebx.global-to-local, align 4
  %v1_40b6c8 = udiv i32 %v0_40b6c8, 256
  %v2_40b6c8 = trunc i32 %v1_40b6c8 to i8
  %v3_40b6c8 = load i8, i8* inttoptr (i32 4763786 to i8*), align 2
  %v4_40b6c8 = or i8 %v2_40b6c8, %v3_40b6c8
  %v10_40b6c8 = zext i8 %v4_40b6c8 to i32
  %v12_40b6c8 = mul nuw nsw i32 %v10_40b6c8, 256
  %v13_40b6c8 = and i32 %v0_40b6c8, -65281
  %v14_40b6c8 = or i32 %v12_40b6c8, %v13_40b6c8
  store i32 %v14_40b6c8, i32* %ebx.global-to-local, align 4
  %v1_40b6ce = load i32, i32* inttoptr (i32 4763832 to i32*), align 8
  %v4_40b6ce = add i32 %v1_40b6ce, %v1_40b6c6
  %v25_40b6ce = icmp ult i32 %v4_40b6ce, %v1_40b6c6
  store i32 %v4_40b6ce, i32* %eax.global-to-local, align 4
  %v0_40b6d4 = load i32, i32* inttoptr (i32 4763745 to i32*), align 4
  %v2_40b6d4 = zext i1 %v25_40b6ce to i32
  %v3_40b6d4 = add i32 %v0_40b6d4, -96
  %v4_40b6d4 = add i32 %v3_40b6d4, %v2_40b6d4
  %v11_40b6d4 = icmp ult i32 %v0_40b6d4, 96
  %v12_40b6d4 = or i1 %v25_40b6ce, %v11_40b6d4
  store i1 %v12_40b6d4, i1* %cf.global-to-local, align 1
  store i32 %v4_40b6d4, i32* inttoptr (i32 4763745 to i32*), align 4
  %v0_40b6db = load i8, i8* inttoptr (i32 4763974 to i8*), align 2
  %v1_40b6db = load i32, i32* %eax.global-to-local, align 4
  %v2_40b6db = udiv i32 %v1_40b6db, 256
  %v3_40b6db = trunc i32 %v2_40b6db to i8
  %v4_40b6db = or i8 %v3_40b6db, %v0_40b6db
  store i1 false, i1* %cf.global-to-local, align 1
  store i8 %v4_40b6db, i8* inttoptr (i32 4763974 to i8*), align 2
  store i32 0, i32* %eax.global-to-local, align 4
  store i16* null, i16** %stack_var_-268, align 4
  %v5_40b6e9 = call i32* @EncodePointer(i32* null)
  %v6_40b6e9 = ptrtoint i32* %v5_40b6e9 to i32
  store i32 %v6_40b6e9, i32* %eax.global-to-local, align 4
  %v0_40b6ef = load i32, i32* inttoptr (i32 4764065 to i32*), align 4
  %v1_40b6ef = load i1, i1* %cf.global-to-local, align 1
  %v2_40b6ef = zext i1 %v1_40b6ef to i32
  %v3_40b6ef = add i32 %v0_40b6ef, -163
  %v4_40b6ef = add i32 %v3_40b6ef, %v2_40b6ef
  store i32 %v4_40b6ef, i32* inttoptr (i32 4764065 to i32*), align 4
  %v1_40b6fe = load i32, i32* %esi.global-to-local, align 4
  %v2_40b6fe = add i32 %v1_40b6fe, 1
  store i32 %v2_40b6fe, i32* %edx.global-to-local, align 4
  %v0_40b700 = load i32, i32* %ebx.global-to-local, align 4
  %v1_40b700 = xor i32 %v0_40b700, 45
  store i32 %v1_40b700, i32* %ebx.global-to-local, align 4
  %v0_40b703 = load i32, i32* inttoptr (i32 4764006 to i32*), align 4
  %v3_40b703 = add i32 %v0_40b703, -249
  store i32 %v3_40b703, i32* inttoptr (i32 4764006 to i32*), align 4
  %v0_40b70d = load i32, i32* inttoptr (i32 4764008 to i32*), align 8
  %v1_40b70d = load i32, i32* %edx.global-to-local, align 4
  %v2_40b70d = sub i32 %v0_40b70d, %v1_40b70d
  store i32 %v2_40b70d, i32* inttoptr (i32 4764008 to i32*), align 8
  %v0_40b713 = load i32, i32* inttoptr (i32 4763698 to i32*), align 4
  %v1_40b713 = xor i32 %v0_40b713, 35
  store i32 %v1_40b713, i32* inttoptr (i32 4763698 to i32*), align 4
  %v0_40b71a = load i32, i32* %ebx.global-to-local, align 4
  %v1_40b71a = load i32, i32* inttoptr (i32 4764135 to i32*), align 4
  %v2_40b71a = or i32 %v1_40b71a, %v0_40b71a
  store i32 %v2_40b71a, i32* %ebx.global-to-local, align 4
  %v1_40b720 = load i32, i32* inttoptr (i32 4764041 to i32*), align 4
  %v4_40b720 = add i32 %v1_40b720, %v2_40b71a
  store i32 %v4_40b720, i32* %ebx.global-to-local, align 4
  store i32 85, i32* %ecx.global-to-local, align 4
  %v0_40b72e = load i32, i32* inttoptr (i32 4763710 to i32*), align 4
  %v3_40b72e = add i32 %v0_40b72e, -115
  %v12_40b72e = icmp ult i32 %v0_40b72e, 115
  store i32 %v3_40b72e, i32* inttoptr (i32 4763710 to i32*), align 4
  %v0_40b735 = load i32, i32* inttoptr (i32 4764136 to i32*), align 8
  %v3_40b735 = zext i1 %v12_40b72e to i32
  %v4_40b735 = add i32 %v0_40b735, -85
  %v5_40b735 = add i32 %v4_40b735, %v3_40b735
  %v20_40b735 = icmp ult i32 %v0_40b735, 85
  %v21_40b735 = or i1 %v12_40b72e, %v20_40b735
  store i32 %v5_40b735, i32* inttoptr (i32 4764136 to i32*), align 8
  %v0_40b73b = load i32, i32* %ebx.global-to-local, align 4
  %v1_40b73b = load i32, i32* %ecx.global-to-local, align 4
  %v3_40b73b = zext i1 %v21_40b735 to i32
  %v4_40b73b = sub i32 %v0_40b73b, %v1_40b73b
  %v5_40b73b = add i32 %v3_40b73b, %v4_40b73b
  %v16_40b73b = sub i32 %v4_40b73b, %v3_40b73b
  %v17_40b73b = icmp ult i32 %v0_40b73b, %v16_40b73b
  %v18_40b73b = icmp ne i32 %v1_40b73b, -1
  %v19_40b73b = or i1 %v18_40b73b, %v17_40b73b
  %v20_40b73b = icmp ult i32 %v0_40b73b, %v1_40b73b
  %v21_40b73b = select i1 %v21_40b735, i1 %v19_40b73b, i1 %v20_40b73b
  store i32 %v5_40b73b, i32* %ebx.global-to-local, align 4
  %v0_40b73d = load i32, i32* inttoptr (i32 4764034 to i32*), align 4
  %v1_40b73d = load i32, i32* %edi.global-to-local, align 4
  %v3_40b73d = zext i1 %v21_40b73b to i32
  %v4_40b73d = add i32 %v1_40b73d, %v0_40b73d
  %v5_40b73d = add i32 %v4_40b73d, %v3_40b73d
  store i32 %v5_40b73d, i32* inttoptr (i32 4764034 to i32*), align 4
  %v0_40b743 = load i32, i32* inttoptr (i32 4764063 to i32*), align 4
  %v1_40b743 = load i32, i32* %ebx.global-to-local, align 4
  %v2_40b743 = add i32 %v1_40b743, %v0_40b743
  store i32 %v2_40b743, i32* inttoptr (i32 4764063 to i32*), align 4
  %v1_40b749 = load i32, i32* inttoptr (i32 4764037 to i32*), align 4
  %v2_40b749 = or i32 %v1_40b749, %v1_40b743
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v2_40b749, i32* %ebx.global-to-local, align 4
  store i16* inttoptr (i32 4204916 to i16*), i16** %stack_var_-268, align 4
  call void @__pseudo_call(i32 4241239)
  %v0_40b757 = load i8, i8* inttoptr (i32 4763818 to i8*), align 2
  %v1_40b757 = add i8 %v0_40b757, 65
  store i8 %v1_40b757, i8* inttoptr (i32 4763818 to i8*), align 2
  %v0_40b75e = load i32, i32* %ebx.global-to-local, align 4
  %v1_40b75e = and i32 %v0_40b75e, -90
  store i32 %v1_40b75e, i32* %ebx.global-to-local, align 4
  %v0_40b761 = load i32, i32* %ecx.global-to-local, align 4
  %v4_40b761 = mul i32 %v0_40b761, 2
  store i32 %v4_40b761, i32* %ecx.global-to-local, align 4
  %v0_40b763 = load i32, i32* %edx.global-to-local, align 4
  %v2_40b763 = xor i32 %v0_40b763, %v1_40b75e
  store i32 %v2_40b763, i32* %edx.global-to-local, align 4
  %v1_40b765 = load i32, i32* inttoptr (i32 4764110 to i32*), align 4
  %v2_40b765 = or i32 %v1_40b765, %v6_40b6e9
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v2_40b765, i32* %eax.global-to-local, align 4
  %v1_40b76b = udiv i32 %v0_40b75e, 256
  %v2_40b76b = trunc i32 %v1_40b76b to i8
  %v3_40b76b = load i8, i8* inttoptr (i32 4763871 to i8*), align 1
  %v6_40b76b = add i8 %v3_40b76b, %v2_40b76b
  %v26_40b76b = icmp ult i8 %v6_40b76b, %v2_40b76b
  %v28_40b76b = zext i8 %v6_40b76b to i32
  %v30_40b76b = mul nuw nsw i32 %v28_40b76b, 256
  %v31_40b76b = and i32 %v0_40b75e, -65370
  %v32_40b76b = or i32 %v30_40b76b, %v31_40b76b
  store i32 %v32_40b76b, i32* %ebx.global-to-local, align 4
  %v2_40b771 = zext i1 %v26_40b76b to i32
  %v3_40b771 = add i32 %v4_40b761, 57
  %v4_40b771 = add i32 %v3_40b771, %v2_40b771
  store i32 %v4_40b771, i32* %ecx.global-to-local, align 4
  %v0_40b774 = load i32, i32* inttoptr (i32 4763904 to i32*), align 256
  %v2_40b774 = xor i32 %v32_40b76b, %v0_40b774
  store i32 %v2_40b774, i32* inttoptr (i32 4763904 to i32*), align 256
  %v0_40b77a = load i32, i32* %esi.global-to-local, align 4
  %v3_40b77a = add i32 %v0_40b77a, 73
  store i32 %v3_40b77a, i32* %esi.global-to-local, align 4
  %v0_40b77d = load i32, i32* %edi.global-to-local, align 4
  %v1_40b77d = add i32 %v0_40b77d, -68
  store i32 %v1_40b77d, i32* %edi.global-to-local, align 4
  %v0_40b780 = load i32, i32* inttoptr (i32 4764109 to i32*), align 4
  %v2_40b780 = or i32 %v0_40b780, %v3_40b77a
  store i32 %v2_40b780, i32* inttoptr (i32 4764109 to i32*), align 4
  %v0_40b786 = load i32, i32* inttoptr (i32 4764104 to i32*), align 8
  %v1_40b786 = load i32, i32* %eax.global-to-local, align 4
  %v2_40b786 = add i32 %v1_40b786, %v0_40b786
  store i32 %v2_40b786, i32* inttoptr (i32 4764104 to i32*), align 8
  %v1_40b78c = add i32 %v1_40b786, -80
  %v2_40b78c = icmp ugt i32 %v1_40b786, 79
  store i32 %v1_40b78c, i32* %eax.global-to-local, align 4
  store i32 113, i32* inttoptr (i32 4763673 to i32*), align 4
  %v0_40b799 = load i32, i32* inttoptr (i32 4763990 to i32*), align 4
  %v3_40b799 = select i1 %v2_40b78c, i32 120, i32 119
  %v4_40b799 = add i32 %v3_40b799, %v0_40b799
  %v21_40b799 = icmp ule i32 %v4_40b799, %v0_40b799
  %v22_40b799 = icmp ugt i32 %v0_40b799, -120
  %v23_40b799 = select i1 %v2_40b78c, i1 %v21_40b799, i1 %v22_40b799
  store i1 %v23_40b799, i1* %cf.global-to-local, align 1
  store i32 %v4_40b799, i32* inttoptr (i32 4763990 to i32*), align 4
  %v0_40b7a0 = load i8, i8* inttoptr (i32 4763755 to i8*), align 1
  %v1_40b7a0 = load i32, i32* %ebx.global-to-local, align 4
  %v2_40b7a0 = trunc i32 %v1_40b7a0 to i8
  %v4_40b7a0 = zext i1 %v23_40b799 to i8
  %v5_40b7a0 = add i8 %v2_40b7a0, %v0_40b7a0
  %v6_40b7a0 = add i8 %v5_40b7a0, %v4_40b7a0
  %v24_40b7a0 = icmp ule i8 %v6_40b7a0, %v0_40b7a0
  %v25_40b7a0 = icmp ult i8 %v5_40b7a0, %v0_40b7a0
  %v26_40b7a0 = select i1 %v23_40b799, i1 %v24_40b7a0, i1 %v25_40b7a0
  store i1 %v26_40b7a0, i1* %cf.global-to-local, align 1
  store i8 %v6_40b7a0, i8* inttoptr (i32 4763755 to i8*), align 1
  %v0_40b7a6 = load i32, i32* inttoptr (i32 4764088 to i32*), align 8
  %v1_40b7a6 = load i32, i32* %ebx.global-to-local, align 4
  %v3_40b7a6 = zext i1 %v26_40b7a0 to i32
  %v4_40b7a6 = sub i32 %v0_40b7a6, %v1_40b7a6
  %v5_40b7a6 = add i32 %v3_40b7a6, %v4_40b7a6
  %v16_40b7a6 = sub i32 %v4_40b7a6, %v3_40b7a6
  %v17_40b7a6 = icmp ult i32 %v0_40b7a6, %v16_40b7a6
  %v18_40b7a6 = icmp ne i32 %v1_40b7a6, -1
  %v19_40b7a6 = or i1 %v18_40b7a6, %v17_40b7a6
  %v20_40b7a6 = icmp ult i32 %v0_40b7a6, %v1_40b7a6
  %v21_40b7a6 = select i1 %v26_40b7a0, i1 %v19_40b7a6, i1 %v20_40b7a6
  store i1 %v21_40b7a6, i1* %cf.global-to-local, align 1
  store i32 %v5_40b7a6, i32* inttoptr (i32 4764088 to i32*), align 8
  %v0_40b7ac = load i8, i8* inttoptr (i32 4764131 to i8*), align 1
  %v1_40b7ac = load i32, i32* %eax.global-to-local, align 4
  %v2_40b7ac = trunc i32 %v1_40b7ac to i8
  %v4_40b7ac = zext i1 %v21_40b7a6 to i8
  %v5_40b7ac = sub i8 %v0_40b7ac, %v2_40b7ac
  %v6_40b7ac = add i8 %v5_40b7ac, %v4_40b7ac
  %v17_40b7ac = sub i8 %v5_40b7ac, %v4_40b7ac
  %v18_40b7ac = icmp ult i8 %v0_40b7ac, %v17_40b7ac
  %v19_40b7ac = icmp ne i8 %v2_40b7ac, -1
  %v20_40b7ac = or i1 %v19_40b7ac, %v18_40b7ac
  %v21_40b7ac = icmp ult i8 %v0_40b7ac, %v2_40b7ac
  %v22_40b7ac = select i1 %v21_40b7a6, i1 %v20_40b7ac, i1 %v21_40b7ac
  store i1 %v22_40b7ac, i1* %cf.global-to-local, align 1
  store i8 %v6_40b7ac, i8* inttoptr (i32 4764131 to i8*), align 1
  %v0_40b7b2 = load i32, i32* %ecx.global-to-local, align 4
  %v1_40b7b2 = load i32, i32* %edi.global-to-local, align 4
  %v3_40b7b2 = zext i1 %v22_40b7ac to i32
  %v4_40b7b2 = sub i32 %v0_40b7b2, %v1_40b7b2
  %v5_40b7b2 = add i32 %v4_40b7b2, %v3_40b7b2
  store i32 %v5_40b7b2, i32* %ecx.global-to-local, align 4
  %v0_40b7b4 = load i32, i32* inttoptr (i32 4764108 to i32*), align 4
  %v1_40b7b4 = xor i32 %v0_40b7b4, 246
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v1_40b7b4, i32* inttoptr (i32 4764108 to i32*), align 4
  %v0_40b7be = load i32, i32* %eax.global-to-local, align 4
  %v1_40b7be = inttoptr i32 %v0_40b7be to i8*
  %v2_40b7be = load i8, i8* %v1_40b7be, align 1
  %v4_40b7be = trunc i32 %v0_40b7be to i8
  %v5_40b7be = add i8 %v4_40b7be, %v2_40b7be
  %v10_40b7be = icmp ult i8 %v5_40b7be, %v2_40b7be
  store i1 %v10_40b7be, i1* %cf.global-to-local, align 1
  store i8 %v5_40b7be, i8* %v1_40b7be, align 1
  %v0_40b7c0 = load i32, i32* %eax.global-to-local, align 4
  %v1_40b7c0 = inttoptr i32 %v0_40b7c0 to i8*
  %v2_40b7c0 = load i8, i8* %v1_40b7c0, align 1
  %v4_40b7c0 = trunc i32 %v0_40b7c0 to i8
  %v5_40b7c0 = add i8 %v4_40b7c0, %v2_40b7c0
  %v10_40b7c0 = icmp ult i8 %v5_40b7c0, %v2_40b7c0
  store i1 %v10_40b7c0, i1* %cf.global-to-local, align 1
  store i8 %v5_40b7c0, i8* %v1_40b7c0, align 1
  %v0_40b7c2 = load i32, i32* %eax.global-to-local, align 4
  %v1_40b7c2 = inttoptr i32 %v0_40b7c2 to i8*
  %v2_40b7c2 = load i8, i8* %v1_40b7c2, align 1
  %v4_40b7c2 = trunc i32 %v0_40b7c2 to i8
  %v5_40b7c2 = add i8 %v4_40b7c2, %v2_40b7c2
  %v10_40b7c2 = icmp ult i8 %v5_40b7c2, %v2_40b7c2
  store i1 %v10_40b7c2, i1* %cf.global-to-local, align 1
  store i8 %v5_40b7c2, i8* %v1_40b7c2, align 1
  %v0_40b7c4 = load i32, i32* %eax.global-to-local, align 4
  %v1_40b7c4 = inttoptr i32 %v0_40b7c4 to i8*
  %v2_40b7c4 = load i8, i8* %v1_40b7c4, align 1
  %v4_40b7c4 = trunc i32 %v0_40b7c4 to i8
  %v5_40b7c4 = add i8 %v4_40b7c4, %v2_40b7c4
  %v10_40b7c4 = icmp ult i8 %v5_40b7c4, %v2_40b7c4
  store i1 %v10_40b7c4, i1* %cf.global-to-local, align 1
  store i8 %v5_40b7c4, i8* %v1_40b7c4, align 1
  %v0_40b7c6 = load i32, i32* %eax.global-to-local, align 4
  %v1_40b7c6 = inttoptr i32 %v0_40b7c6 to i8*
  %v2_40b7c6 = load i8, i8* %v1_40b7c6, align 1
  %v4_40b7c6 = trunc i32 %v0_40b7c6 to i8
  %v5_40b7c6 = add i8 %v4_40b7c6, %v2_40b7c6
  %v10_40b7c6 = icmp ult i8 %v5_40b7c6, %v2_40b7c6
  store i1 %v10_40b7c6, i1* %cf.global-to-local, align 1
  store i8 %v5_40b7c6, i8* %v1_40b7c6, align 1
  %v0_40b7c8 = load i32, i32* %eax.global-to-local, align 4
  %v1_40b7c8 = inttoptr i32 %v0_40b7c8 to i8*
  %v2_40b7c8 = load i8, i8* %v1_40b7c8, align 1
  %v4_40b7c8 = trunc i32 %v0_40b7c8 to i8
  %v5_40b7c8 = add i8 %v4_40b7c8, %v2_40b7c8
  %v10_40b7c8 = icmp ult i8 %v5_40b7c8, %v2_40b7c8
  store i1 %v10_40b7c8, i1* %cf.global-to-local, align 1
  store i8 %v5_40b7c8, i8* %v1_40b7c8, align 1
  %v0_40b7ca = load i32, i32* %eax.global-to-local, align 4
  %v1_40b7ca = inttoptr i32 %v0_40b7ca to i8*
  %v2_40b7ca = load i8, i8* %v1_40b7ca, align 1
  %v4_40b7ca = trunc i32 %v0_40b7ca to i8
  %v5_40b7ca = add i8 %v4_40b7ca, %v2_40b7ca
  %v10_40b7ca = icmp ult i8 %v5_40b7ca, %v2_40b7ca
  store i1 %v10_40b7ca, i1* %cf.global-to-local, align 1
  store i8 %v5_40b7ca, i8* %v1_40b7ca, align 1
  %v0_40b7cc = load i32, i32* %ebx.global-to-local, align 4
  %v1_40b7cc = inttoptr i32 %v0_40b7cc to i8*
  %v2_40b7cc = load i8, i8* %v1_40b7cc, align 1
  %v3_40b7cc = load i32, i32* %edx.global-to-local, align 4
  %v4_40b7cc = trunc i32 %v3_40b7cc to i8
  %v5_40b7cc = add i8 %v4_40b7cc, %v2_40b7cc
  %v10_40b7cc = icmp ult i8 %v5_40b7cc, %v2_40b7cc
  store i1 %v10_40b7cc, i1* %cf.global-to-local, align 1
  store i8 %v5_40b7cc, i8* %v1_40b7cc, align 1
  %v0_40b7ce = load i32, i32* %eax.global-to-local, align 4
  %v1_40b7ce = load i1, i1* %cf.global-to-local, align 1
  %v2_40b7ce = zext i1 %v1_40b7ce to i32
  %v3_40b7ce = add i32 %v0_40b7ce, -4763668
  %v4_40b7ce = add i32 %v3_40b7ce, %v2_40b7ce
  store i32 %v4_40b7ce, i32* %eax.global-to-local, align 4
  %v0_40b7d3 = load i32, i32* inttoptr (i32 4763869 to i32*), align 4
  %v1_40b7d3 = load i32, i32* %edi.global-to-local, align 4
  %v2_40b7d3 = add i32 %v1_40b7d3, %v0_40b7d3
  %v7_40b7d3 = icmp ult i32 %v2_40b7d3, %v0_40b7d3
  store i32 %v2_40b7d3, i32* inttoptr (i32 4763869 to i32*), align 4
  store i32 1, i32* %ecx.global-to-local, align 4
  %v1_40b7de = load i32, i32* inttoptr (i32 4763767 to i32*), align 4
  %v3_40b7de = zext i1 %v7_40b7d3 to i32
  %v4_40b7de = add i32 %v1_40b7de, 1
  %v5_40b7de = add i32 %v4_40b7de, %v3_40b7de
  %v24_40b7de = icmp ult i32 %v5_40b7de, 2
  %v25_40b7de = icmp eq i32 %v4_40b7de, 0
  %v26_40b7de = select i1 %v7_40b7d3, i1 %v24_40b7de, i1 %v25_40b7de
  store i1 %v26_40b7de, i1* %cf.global-to-local, align 1
  store i32 %v5_40b7de, i32* %ecx.global-to-local, align 4
  %v0_40b7e4 = load i8, i8* inttoptr (i32 4763715 to i8*), align 1
  %v1_40b7e4 = load i32, i32* %eax.global-to-local, align 4
  %v2_40b7e4 = trunc i32 %v1_40b7e4 to i8
  %v4_40b7e4 = zext i1 %v26_40b7de to i8
  %v5_40b7e4 = sub i8 %v0_40b7e4, %v2_40b7e4
  %v6_40b7e4 = add i8 %v5_40b7e4, %v4_40b7e4
  store i8 %v6_40b7e4, i8* inttoptr (i32 4763715 to i8*), align 1
  %v0_40b7ea = load i32, i32* %edi.global-to-local, align 4
  %v1_40b7ea = load i32, i32* %esi.global-to-local, align 4
  %v2_40b7ea = xor i32 %v1_40b7ea, %v0_40b7ea
  store i32 %v2_40b7ea, i32* %edi.global-to-local, align 4
  %v0_40b7ec = load i32, i32* %eax.global-to-local, align 4
  %v13_40b7ec = xor i32 %v0_40b7ec, 43008
  store i32 %v13_40b7ec, i32* %eax.global-to-local, align 4
  %v0_40b7ef = load i32, i32* inttoptr (i32 4763683 to i32*), align 4
  %v1_40b7ef = load i32, i32* %ecx.global-to-local, align 4
  %v2_40b7ef = add i32 %v1_40b7ef, %v0_40b7ef
  %v7_40b7ef = icmp ult i32 %v2_40b7ef, %v0_40b7ef
  store i32 %v2_40b7ef, i32* inttoptr (i32 4763683 to i32*), align 4
  %v3_40b7f5 = zext i1 %v7_40b7ef to i32
  %v4_40b7f5 = sub i32 %v1_40b7ef, %v13_40b7ec
  %v5_40b7f5 = add i32 %v4_40b7f5, %v3_40b7f5
  %v16_40b7f5 = sub i32 %v4_40b7f5, %v3_40b7f5
  %v17_40b7f5 = icmp ult i32 %v1_40b7ef, %v16_40b7f5
  %v18_40b7f5 = icmp ne i32 %v13_40b7ec, -1
  %v19_40b7f5 = or i1 %v18_40b7f5, %v17_40b7f5
  %v20_40b7f5 = icmp ult i32 %v1_40b7ef, %v13_40b7ec
  %v21_40b7f5 = select i1 %v7_40b7ef, i1 %v19_40b7f5, i1 %v20_40b7f5
  store i1 %v21_40b7f5, i1* %cf.global-to-local, align 1
  store i32 %v5_40b7f5, i32* %ecx.global-to-local, align 4
  %v0_40b7f7 = load i8, i8* inttoptr (i32 4764154 to i8*), align 2
  %v1_40b7f7 = add i8 %v0_40b7f7, -95
  store i8 %v1_40b7f7, i8* inttoptr (i32 4764154 to i8*), align 2
  %v0_40b7fe = load i32, i32* inttoptr (i32 4764002 to i32*), align 4
  %v1_40b7fe = load i32, i32* %esi.global-to-local, align 4
  %v2_40b7fe = xor i32 %v1_40b7fe, %v0_40b7fe
  store i32 %v2_40b7fe, i32* inttoptr (i32 4764002 to i32*), align 4
  %v0_40b804 = load i32, i32* %ecx.global-to-local, align 4
  %v1_40b804 = load i32, i32* %eax.global-to-local, align 4
  %v4_40b804 = sub i32 %v0_40b804, %v1_40b804
  store i32 %v4_40b804, i32* %ecx.global-to-local, align 4
  store i32 -15, i32* %edx.global-to-local, align 4
  %v1_40b80e = trunc i32 %v1_40b804 to i8
  %v4_40b80e = add i32 %v1_40b804, 169
  %v13_40b80e = icmp ult i8 %v1_40b80e, 87
  %v26_40b80e = and i32 %v4_40b80e, 255
  %v28_40b80e = and i32 %v1_40b804, -256
  %v29_40b80e = or i32 %v26_40b80e, %v28_40b80e
  store i32 %v29_40b80e, i32* %eax.global-to-local, align 4
  %v0_40b810 = load i32, i32* inttoptr (i32 4763805 to i32*), align 4
  %v3_40b810 = zext i1 %v13_40b80e to i32
  %v4_40b810 = sub i32 %v0_40b810, %v29_40b80e
  %v5_40b810 = add i32 %v4_40b810, %v3_40b810
  %v16_40b810 = sub i32 %v4_40b810, %v3_40b810
  %v17_40b810 = icmp ult i32 %v0_40b810, %v16_40b810
  %v18_40b810 = icmp ne i32 %v29_40b80e, -1
  %v19_40b810 = or i1 %v18_40b810, %v17_40b810
  %v20_40b810 = icmp ult i32 %v0_40b810, %v29_40b80e
  %v21_40b810 = select i1 %v13_40b80e, i1 %v19_40b810, i1 %v20_40b810
  store i32 %v5_40b810, i32* inttoptr (i32 4763805 to i32*), align 4
  %v0_40b816 = load i32, i32* %ebx.global-to-local, align 4
  %v2_40b816 = zext i1 %v21_40b810 to i32
  %v3_40b816 = add i32 %v0_40b816, -63
  %v4_40b816 = add i32 %v3_40b816, %v2_40b816
  %v22_40b816 = icmp ule i32 %v4_40b816, %v0_40b816
  %v23_40b816 = icmp ugt i32 %v0_40b816, 62
  %v24_40b816 = select i1 %v21_40b810, i1 %v22_40b816, i1 %v23_40b816
  store i32 %v4_40b816, i32* %ebx.global-to-local, align 4
  %v0_40b819 = load i32, i32* %eax.global-to-local, align 4
  %v1_40b819 = load i32, i32* inttoptr (i32 4764061 to i32*), align 4
  %v3_40b819 = zext i1 %v24_40b816 to i32
  %v4_40b819 = add i32 %v1_40b819, %v0_40b819
  %v5_40b819 = add i32 %v3_40b819, %v4_40b819
  %v24_40b819 = icmp ule i32 %v5_40b819, %v0_40b819
  %v25_40b819 = icmp ult i32 %v4_40b819, %v0_40b819
  %v26_40b819 = select i1 %v24_40b816, i1 %v24_40b819, i1 %v25_40b819
  store i32 %v5_40b819, i32* %eax.global-to-local, align 4
  %v0_40b81f = load i32, i32* %ecx.global-to-local, align 4
  %v1_40b81f = load i32, i32* %edi.global-to-local, align 4
  %v3_40b81f = zext i1 %v26_40b819 to i32
  %v4_40b81f = add i32 %v1_40b81f, %v0_40b81f
  %v5_40b81f = add i32 %v4_40b81f, %v3_40b81f
  store i32 %v5_40b81f, i32* %ecx.global-to-local, align 4
  store i1 false, i1* %cf.global-to-local, align 1
  %v8_40b833 = call i1 @SetEnvironmentVariableW(i16* bitcast ([13 x i8]* @global_var_48b685.2 to i16*), i16* bitcast ([17 x i8]* @global_var_48b692.1 to i16*))
  %v9_40b833 = sext i1 %v8_40b833 to i32
  store i32 %v9_40b833, i32* %eax.global-to-local, align 4
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 0, i32* %esi.global-to-local, align 4
  %v0_40b83b = load i8, i8* inttoptr (i32 4763944 to i8*), align 8
  %v1_40b83b = load i32, i32* %ebx.global-to-local, align 4
  %v2_40b83b = udiv i32 %v1_40b83b, 256
  %v3_40b83b = trunc i32 %v2_40b83b to i8
  %v4_40b83b = or i8 %v3_40b83b, %v0_40b83b
  store i8 %v4_40b83b, i8* inttoptr (i32 4763944 to i8*), align 8
  store i32 -115, i32* %edx.global-to-local, align 4
  %v1_40b849 = load i32, i32* inttoptr (i32 4763809 to i32*), align 4
  %v4_40b849 = add i32 %v1_40b849, %v9_40b833
  %v18_40b849 = trunc i32 %v4_40b849 to i8
  %v25_40b849 = icmp ult i32 %v4_40b849, %v9_40b833
  store i1 %v25_40b849, i1* %cf.global-to-local, align 1
  store i32 %v4_40b849, i32* %eax.global-to-local, align 4
  %v2_40b84f = load i8, i8* inttoptr (i32 4763685 to i8*), align 1
  store i1 false, i1* %cf.global-to-local, align 1
  %v9_40b84f = zext i8 %v2_40b84f to i32
  %v12_40b84f = or i32 %v9_40b84f, -115
  store i32 %v12_40b84f, i32* %edx.global-to-local, align 4
  %v2_40b855 = load i8, i8* inttoptr (i32 4763718 to i8*), align 2
  %v3_40b855 = or i8 %v2_40b855, %v18_40b849
  %v9_40b855 = zext i8 %v3_40b855 to i32
  %v11_40b855 = and i32 %v4_40b849, -256
  %v12_40b855 = or i32 %v9_40b855, %v11_40b855
  store i32 %v12_40b855, i32* %eax.global-to-local, align 4
  %v0_40b85b = load i32, i32* %edi.global-to-local, align 4
  %v1_40b85b = load i32, i32* inttoptr (i32 4764150 to i32*), align 4
  %v2_40b85b = or i32 %v1_40b85b, %v0_40b85b
  store i32 %v2_40b85b, i32* %edi.global-to-local, align 4
  %v0_40b861 = load i32, i32* inttoptr (i32 4763939 to i32*), align 4
  %v1_40b861 = load i32, i32* %ebx.global-to-local, align 4
  %v2_40b861 = add i32 %v1_40b861, %v0_40b861
  %v7_40b861 = icmp ult i32 %v2_40b861, %v0_40b861
  store i1 %v7_40b861, i1* %cf.global-to-local, align 1
  store i32 %v2_40b861, i32* inttoptr (i32 4763939 to i32*), align 4
  %v0_40b867 = load i8, i8* inttoptr (i32 4764109 to i8*), align 1
  %v1_40b867 = load i32, i32* %eax.global-to-local, align 4
  %v2_40b867 = trunc i32 %v1_40b867 to i8
  %v3_40b867 = sub i8 %v0_40b867, %v2_40b867
  %v8_40b867 = icmp ult i8 %v0_40b867, %v2_40b867
  store i1 %v8_40b867, i1* %cf.global-to-local, align 1
  store i8 %v3_40b867, i8* inttoptr (i32 4764109 to i8*), align 1
  %v0_40b86d = load i8, i8* inttoptr (i32 4763812 to i8*), align 4
  %v1_40b86d = load i32, i32* %edx.global-to-local, align 4
  %v2_40b86d = trunc i32 %v1_40b86d to i8
  %v3_40b86d = xor i8 %v2_40b86d, %v0_40b86d
  store i1 false, i1* %cf.global-to-local, align 1
  store i8 %v3_40b86d, i8* inttoptr (i32 4763812 to i8*), align 4
  %v0_40b873 = load i8, i8* inttoptr (i32 4763901 to i8*), align 1
  %v1_40b873 = add i8 %v0_40b873, 61
  %v5_40b873 = icmp ult i8 %v0_40b873, -61
  store i1 %v5_40b873, i1* %cf.global-to-local, align 1
  store i8 %v1_40b873, i8* inttoptr (i32 4763901 to i8*), align 1
  %v0_40b87a = load i32, i32* %eax.global-to-local, align 4
  %v1_40b87a = load i32, i32* inttoptr (i32 4763886 to i32*), align 4
  %v3_40b87a = zext i1 %v5_40b873 to i32
  %v4_40b87a = add i32 %v1_40b87a, %v0_40b87a
  %v5_40b87a = add i32 %v4_40b87a, %v3_40b87a
  store i32 %v5_40b87a, i32* %eax.global-to-local, align 4
  %v0_40b880 = load i32, i32* %ecx.global-to-local, align 4
  %v1_40b880 = and i32 %v0_40b880, -65281
  %v4_40b88243 = add i32 %v5_40b87a, 256
  %v23_40b882 = and i32 %v4_40b88243, 65280
  %v25_40b882 = or i32 %v23_40b882, %v1_40b880
  store i32 %v25_40b882, i32* %ecx.global-to-local, align 4
  %v0_40b884 = load i32, i32* %esi.global-to-local, align 4
  %v1_40b884 = load i32, i32* inttoptr (i32 4763959 to i32*), align 4
  %v2_40b884 = or i32 %v1_40b884, %v0_40b884
  store i32 %v2_40b884, i32* %esi.global-to-local, align 4
  %v0_40b88a = load i32, i32* %edx.global-to-local, align 4
  %v1_40b88a = and i32 %v0_40b88a, 19
  store i32 %v1_40b88a, i32* %edx.global-to-local, align 4
  %v0_40b88d = load i32, i32* inttoptr (i32 4763713 to i32*), align 4
  %v3_40b88d = add i32 %v0_40b88d, 54
  %v22_40b88d = icmp ugt i32 %v0_40b88d, -55
  store i32 %v3_40b88d, i32* inttoptr (i32 4763713 to i32*), align 4
  %v0_40b894 = load i32, i32* %edi.global-to-local, align 4
  %v1_40b894 = load i32, i32* inttoptr (i32 4763704 to i32*), align 8
  %v3_40b894 = zext i1 %v22_40b88d to i32
  %v4_40b894 = add i32 %v3_40b894, %v0_40b894
  %v5_40b894 = add i32 %v4_40b894, %v1_40b894
  store i32 %v5_40b894, i32* %edi.global-to-local, align 4
  %v0_40b89a = load i32, i32* %esi.global-to-local, align 4
  %v1_40b89a = load i32, i32* inttoptr (i32 4764101 to i32*), align 4
  %v2_40b89a = sub i32 %v0_40b89a, %v1_40b89a
  store i32 %v2_40b89a, i32* %esi.global-to-local, align 4
  %v0_40b8a0 = load i32, i32* %ecx.global-to-local, align 4
  %v1_40b8a0 = add i32 %v0_40b8a0, 97
  %v5_40b8a0 = icmp ult i32 %v0_40b8a0, -97
  store i1 %v5_40b8a0, i1* %cf.global-to-local, align 1
  store i32 %v1_40b8a0, i32* %ecx.global-to-local, align 4
  %v0_40b8a3 = load i8, i8* inttoptr (i32 4763944 to i8*), align 8
  %v1_40b8a3 = load i32, i32* %edx.global-to-local, align 4
  %v2_40b8a3 = trunc i32 %v1_40b8a3 to i8
  %v3_40b8a3 = xor i8 %v2_40b8a3, %v0_40b8a3
  store i1 false, i1* %cf.global-to-local, align 1
  store i8 %v3_40b8a3, i8* inttoptr (i32 4763944 to i8*), align 8
  call void @__pseudo_call(i32 4241585)
  store i32 0, i32* %edi.global-to-local, align 4
  %v0_40b8b3 = load i32, i32* %ecx.global-to-local, align 4
  %v12_40b8b3 = or i32 %v0_40b8b3, 19968
  %v1_40b8b6 = load i32, i32* %edx.global-to-local, align 4
  %v2_40b8b6 = xor i32 %v12_40b8b3, %v1_40b8b6
  store i32 %v2_40b8b6, i32* %ecx.global-to-local, align 4
  %v0_40b8b8 = load i32, i32* inttoptr (i32 4764111 to i32*), align 4
  %v1_40b8b8 = load i32, i32* %ebx.global-to-local, align 4
  %v2_40b8b8 = and i32 %v1_40b8b8, %v0_40b8b8
  store i32 %v2_40b8b8, i32* inttoptr (i32 4764111 to i32*), align 4
  %v0_40b8be = load i32, i32* inttoptr (i32 4764127 to i32*), align 4
  %v3_40b8be = add i32 %v0_40b8be, 230
  store i32 %v3_40b8be, i32* inttoptr (i32 4764127 to i32*), align 4
  %v0_40b8c8 = load i32, i32* inttoptr (i32 4763799 to i32*), align 4
  %v1_40b8c8 = load i32, i32* %ecx.global-to-local, align 4
  %v2_40b8c8 = and i32 %v1_40b8c8, %v0_40b8c8
  store i32 %v2_40b8c8, i32* inttoptr (i32 4763799 to i32*), align 4
  %v0_40b8ce = load i32, i32* inttoptr (i32 4764034 to i32*), align 4
  %v3_40b8ce = add i32 %v0_40b8ce, 217
  store i32 %v3_40b8ce, i32* inttoptr (i32 4764034 to i32*), align 4
  %v0_40b8d8 = load i32, i32* %eax.global-to-local, align 4
  %v1_40b8d8 = add i32 %v0_40b8d8, 66
  store i32 %v1_40b8d8, i32* %eax.global-to-local, align 4
  %v0_40b8db = load i32, i32* %edi.global-to-local, align 4
  %v1_40b8db = load i32, i32* %edx.global-to-local, align 4
  %v2_40b8db = sub i32 %v0_40b8db, %v1_40b8db
  store i32 %v2_40b8db, i32* %edi.global-to-local, align 4
  %v0_40b8dd = load i32, i32* %esi.global-to-local, align 4
  %v1_40b8dd = load i32, i32* inttoptr (i32 4763999 to i32*), align 4
  %v2_40b8dd = sub i32 %v0_40b8dd, %v1_40b8dd
  store i32 %v2_40b8dd, i32* %esi.global-to-local, align 4
  %v1_40b8e3 = load i32, i32* %ecx.global-to-local, align 4
  %v2_40b8e3 = sub i32 %v2_40b8db, %v1_40b8e3
  %v7_40b8e3 = icmp ult i32 %v2_40b8db, %v1_40b8e3
  store i1 %v7_40b8e3, i1* %cf.global-to-local, align 1
  store i32 %v2_40b8e3, i32* %edi.global-to-local, align 4
  %v1_40b8e5 = udiv i32 %v1_40b8d8, 256
  %v2_40b8e5 = trunc i32 %v1_40b8e5 to i8
  %v3_40b8e5 = load i8, i8* inttoptr (i32 4763834 to i8*), align 2
  %v5_40b8e5 = zext i1 %v7_40b8e3 to i8
  %v6_40b8e5 = add i8 %v5_40b8e5, %v2_40b8e5
  %v7_40b8e5 = add i8 %v6_40b8e5, %v3_40b8e5
  %v28_40b8e5 = zext i8 %v7_40b8e5 to i32
  %v30_40b8e5 = mul nuw nsw i32 %v28_40b8e5, 256
  %v31_40b8e5 = and i32 %v1_40b8d8, -65281
  %v32_40b8e5 = or i32 %v30_40b8e5, %v31_40b8e5
  store i32 %v32_40b8e5, i32* %eax.global-to-local, align 4
  %v0_40b8eb = load i32, i32* inttoptr (i32 4764112 to i32*), align 16
  %v2_40b8eb = add i32 %v0_40b8eb, %v2_40b8dd
  %v7_40b8eb = icmp ult i32 %v2_40b8eb, %v0_40b8eb
  store i1 %v7_40b8eb, i1* %cf.global-to-local, align 1
  store i32 %v2_40b8eb, i32* inttoptr (i32 4764112 to i32*), align 16
  %v1_40b8f1 = inttoptr i32 %v32_40b8e5 to i8*
  %v2_40b8f1 = load i8, i8* %v1_40b8f1, align 1
  %v4_40b8f1 = trunc i32 %v1_40b8d8 to i8
  %v5_40b8f1 = add i8 %v4_40b8f1, %v2_40b8f1
  %v10_40b8f1 = icmp ult i8 %v5_40b8f1, %v2_40b8f1
  store i1 %v10_40b8f1, i1* %cf.global-to-local, align 1
  store i8 %v5_40b8f1, i8* %v1_40b8f1, align 1
  %v0_40b8f3 = load i32, i32* %eax.global-to-local, align 4
  %v1_40b8f3 = inttoptr i32 %v0_40b8f3 to i8*
  %v2_40b8f3 = load i8, i8* %v1_40b8f3, align 1
  %v4_40b8f3 = trunc i32 %v0_40b8f3 to i8
  %v5_40b8f3 = add i8 %v4_40b8f3, %v2_40b8f3
  %v10_40b8f3 = icmp ult i8 %v5_40b8f3, %v2_40b8f3
  store i1 %v10_40b8f3, i1* %cf.global-to-local, align 1
  store i8 %v5_40b8f3, i8* %v1_40b8f3, align 1
  %v0_40b8f5 = load i32, i32* %ecx.global-to-local, align 4
  %v1_40b8f5 = add i32 %v0_40b8f5, 1
  %v2_40b8f5 = inttoptr i32 %v1_40b8f5 to i8*
  %v3_40b8f5 = load i8, i8* %v2_40b8f5, align 1
  %v4_40b8f5 = load i32, i32* %ebx.global-to-local, align 4
  %v5_40b8f5 = udiv i32 %v4_40b8f5, 256
  %v6_40b8f5 = trunc i32 %v5_40b8f5 to i8
  %v7_40b8f5 = add i8 %v6_40b8f5, %v3_40b8f5
  store i8 %v7_40b8f5, i8* %v2_40b8f5, align 1
  %v0_40b8fb = load i32, i32* %ecx.global-to-local, align 4
  %v1_40b8fe = add i32 %v0_40b8fb, -218
  store i32 %v1_40b8fe, i32* %ecx.global-to-local, align 4
  %v0_40b901 = load i32, i32* inttoptr (i32 4763867 to i32*), align 4
  %v1_40b901 = xor i32 %v0_40b901, 79
  store i32 %v1_40b901, i32* inttoptr (i32 4763867 to i32*), align 4
  %v0_40b908 = load i32, i32* inttoptr (i32 4763668 to i32*), align 4
  %v1_40b908 = xor i32 %v0_40b908, 220
  store i32 %v1_40b908, i32* inttoptr (i32 4763668 to i32*), align 4
  %v0_40b912 = load i32, i32* %ecx.global-to-local, align 4
  %v1_40b912 = load i32, i32* inttoptr (i32 4763903 to i32*), align 4
  %v4_40b912 = add i32 %v1_40b912, %v0_40b912
  %v25_40b912 = icmp ult i32 %v4_40b912, %v0_40b912
  store i32 %v4_40b912, i32* %ecx.global-to-local, align 4
  store i32 1, i32* %edx.global-to-local, align 4
  %v1_40b91d = load i32, i32* inttoptr (i32 4764137 to i32*), align 4
  %v3_40b91d = zext i1 %v25_40b912 to i32
  %v4_40b91d = add i32 %v1_40b91d, 1
  %v5_40b91d = add i32 %v4_40b91d, %v3_40b91d
  %v24_40b91d = icmp ult i32 %v5_40b91d, 2
  %v25_40b91d = icmp eq i32 %v4_40b91d, 0
  %v26_40b91d = select i1 %v25_40b912, i1 %v24_40b91d, i1 %v25_40b91d
  store i32 %v5_40b91d, i32* %edx.global-to-local, align 4
  store i32 204, i32* inttoptr (i32 4764053 to i32*), align 4
  %v0_40b92d = load i32, i32* inttoptr (i32 4763741 to i32*), align 4
  %v3_40b92d = select i1 %v26_40b91d, i32 46, i32 45
  %v4_40b92d = add i32 %v3_40b92d, %v0_40b92d
  store i32 %v4_40b92d, i32* inttoptr (i32 4763741 to i32*), align 4
  %v0_40b934 = load i32, i32* inttoptr (i32 4763915 to i32*), align 4
  %v1_40b934 = load i32, i32* %edx.global-to-local, align 4
  %v2_40b934 = add i32 %v1_40b934, %v0_40b934
  store i32 %v2_40b934, i32* inttoptr (i32 4763915 to i32*), align 4
  %v0_40b93a = load i32, i32* inttoptr (i32 4764068 to i32*), align 4
  %v1_40b93a = load i32, i32* %edi.global-to-local, align 4
  %v2_40b93a = and i32 %v1_40b93a, %v0_40b93a
  store i32 %v2_40b93a, i32* inttoptr (i32 4764068 to i32*), align 4
  %v0_40b940 = load i32, i32* inttoptr (i32 4763892 to i32*), align 4
  %v1_40b940 = load i32, i32* %edx.global-to-local, align 4
  %v2_40b940 = or i32 %v1_40b940, %v0_40b940
  store i32 %v2_40b940, i32* inttoptr (i32 4763892 to i32*), align 4
  %v0_40b946 = load i32, i32* inttoptr (i32 4763697 to i32*), align 4
  %v1_40b946 = load i32, i32* %ecx.global-to-local, align 4
  %v2_40b946 = add i32 %v1_40b946, %v0_40b946
  store i32 %v2_40b946, i32* inttoptr (i32 4763697 to i32*), align 4
  %v1_40b94c = or i32 %v1_40b946, 68
  %v1_40b94f = add i32 %v1_40b94c, -5
  store i32 %v1_40b94f, i32* %ecx.global-to-local, align 4
  store i32 11, i32* %eax.global-to-local, align 4
  store i1 false, i1* %cf.global-to-local, align 1
  %v6_40b965 = call i1 @IsBadStringPtrA(i8* getelementptr inbounds ([12 x i8], [12 x i8]* @global_var_48b6b4.5, i32 0, i32 0), i32 11)
  %v7_40b965 = sext i1 %v6_40b965 to i32
  store i32 %v7_40b965, i32* %eax.global-to-local, align 4
  store i1 false, i1* %cf.global-to-local, align 1
  %v1_40b96b = icmp eq i1 %v6_40b965, false
  %v1_40b96d = icmp eq i1 %v1_40b96b, false
  call void @__pseudo_cond_branch(i1 %v1_40b96d, i32 ptrtoint (i16** @global_var_406dd5.3 to i32))
  %v0_40b973 = load i32, i32* inttoptr (i32 4763997 to i32*), align 4
  %v1_40b973 = load i32, i32* %ebx.global-to-local, align 4
  %v2_40b973 = sub i32 %v0_40b973, %v1_40b973
  store i32 %v2_40b973, i32* inttoptr (i32 4763997 to i32*), align 4
  %v0_40b979 = load i32, i32* inttoptr (i32 4763827 to i32*), align 4
  %v2_40b979 = xor i32 %v0_40b979, %v7_40b965
  store i32 %v2_40b979, i32* inttoptr (i32 4763827 to i32*), align 4
  store i32 1, i32* %edx.global-to-local, align 4
  %v1_40b984 = load i32, i32* inttoptr (i32 4763759 to i32*), align 4
  %v4_40b984 = add i32 %v1_40b984, 1
  %v16_40b984 = icmp eq i32 %v4_40b984, 0
  %v2_40b98a = zext i1 %v16_40b984 to i32
  %v3_40b98a = add nsw i32 %v7_40b965, 107
  %v4_40b98a = add nsw i32 %v3_40b98a, %v2_40b98a
  %v12_40b98a23 = icmp ne i1 %v6_40b965, true
  %v13_40b98a = or i1 %v12_40b98a23, %v16_40b984
  store i32 %v4_40b98a, i32* %eax.global-to-local, align 4
  %v5_40b98d = zext i1 %v13_40b98a to i32
  %v6_40b98d = mul i32 %v4_40b984, 2
  %v6_40b98d.masked = and i32 %v6_40b98d, 254
  %v30_40b98d = and i32 %v4_40b984, -256
  %v28_40b98d = or i32 %v6_40b98d.masked, %v30_40b98d
  %v31_40b98d = or i32 %v28_40b98d, %v5_40b98d
  store i32 %v31_40b98d, i32* %edx.global-to-local, align 4
  store i32 0, i32* %ebx.global-to-local, align 4
  %v0_40b991 = load i32, i32* inttoptr (i32 4763850 to i32*), align 4
  %v4_40b991 = sub i32 %v0_40b991, %v31_40b98d
  store i32 %v4_40b991, i32* inttoptr (i32 4763850 to i32*), align 4
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 56, i32* %ecx.global-to-local, align 4
  %v0_40b99f = load i32, i32* %edx.global-to-local, align 4
  %v1_40b99f = trunc i32 %v0_40b99f to i8
  %v2_40b99f = load i8, i8* inttoptr (i32 4763703 to i8*), align 1
  %v5_40b99f = add i8 %v1_40b99f, %v2_40b99f
  %v25_40b99f = icmp ult i8 %v5_40b99f, %v1_40b99f
  %v27_40b99f = zext i8 %v5_40b99f to i32
  %v29_40b99f = and i32 %v0_40b99f, -256
  %v30_40b99f = or i32 %v27_40b99f, %v29_40b99f
  store i32 %v30_40b99f, i32* %edx.global-to-local, align 4
  %v0_40b9a5 = load i32, i32* %ebx.global-to-local, align 4
  %v1_40b9a5 = load i32, i32* inttoptr (i32 4763903 to i32*), align 4
  %v3_40b9a5 = zext i1 %v25_40b99f to i32
  %v4_40b9a5 = add i32 %v1_40b9a5, %v0_40b9a5
  %v5_40b9a5 = add i32 %v4_40b9a5, %v3_40b9a5
  store i32 %v5_40b9a5, i32* %ebx.global-to-local, align 4
  %v0_40b9ab = load i32, i32* %edi.global-to-local, align 4
  %v1_40b9ab = load i32, i32* inttoptr (i32 4763953 to i32*), align 4
  %v2_40b9ab = or i32 %v1_40b9ab, %v0_40b9ab
  %v1_40b9b1 = add i32 %v2_40b9ab, -90
  store i32 %v1_40b9b1, i32* %edi.global-to-local, align 4
  %v0_40b9b4 = load i32, i32* inttoptr (i32 4764006 to i32*), align 4
  %v2_40b9b4 = add i32 %v0_40b9b4, 56
  store i32 %v2_40b9b4, i32* inttoptr (i32 4764006 to i32*), align 4
  %v0_40b9ba = load i32, i32* %edx.global-to-local, align 4
  %v1_40b9ba = load i32, i32* inttoptr (i32 4763978 to i32*), align 4
  %v2_40b9ba = sub i32 %v0_40b9ba, %v1_40b9ba
  %v7_40b9ba = icmp ult i32 %v0_40b9ba, %v1_40b9ba
  store i1 %v7_40b9ba, i1* %cf.global-to-local, align 1
  store i32 %v2_40b9ba, i32* %edx.global-to-local, align 4
  call void @__pseudo_call(i32 4241864)
  %v0_40b9c8 = load i8, i8* inttoptr (i32 4763982 to i8*), align 2
  %v1_40b9c8 = add i8 %v0_40b9c8, 103
  %v5_40b9c8 = icmp ult i8 %v0_40b9c8, -103
  store i1 %v5_40b9c8, i1* %cf.global-to-local, align 1
  store i8 %v1_40b9c8, i8* inttoptr (i32 4763982 to i8*), align 2
  %v0_40b9cf = load i32, i32* %eax.global-to-local, align 4
  %v1_40b9cf = load i32, i32* inttoptr (i32 4764009 to i32*), align 4
  %v3_40b9cf = zext i1 %v5_40b9c8 to i32
  %v4_40b9cf = add i32 %v1_40b9cf, %v0_40b9cf
  %v5_40b9cf = add i32 %v4_40b9cf, %v3_40b9cf
  store i32 %v5_40b9cf, i32* %eax.global-to-local, align 4
  %v0_40b9d5 = load i32, i32* inttoptr (i32 4763832 to i32*), align 8
  %v1_40b9d5 = load i32, i32* %edx.global-to-local, align 4
  %v2_40b9d5 = xor i32 %v1_40b9d5, %v0_40b9d5
  store i32 %v2_40b9d5, i32* inttoptr (i32 4763832 to i32*), align 8
  %v0_40b9db = load i32, i32* inttoptr (i32 4764036 to i32*), align 4
  %v3_40b9db = add i32 %v0_40b9db, -235
  store i32 %v3_40b9db, i32* inttoptr (i32 4764036 to i32*), align 4
  %v0_40b9e5 = load i32, i32* %ecx.global-to-local, align 4
  %v1_40b9e5 = add i32 %v0_40b9e5, 68
  store i32 %v1_40b9e5, i32* %ecx.global-to-local, align 4
  %v0_40b9e8 = load i32, i32* %esi.global-to-local, align 4
  %v1_40b9e8 = load i32, i32* %ebx.global-to-local, align 4
  %v2_40b9e8 = xor i32 %v1_40b9e8, %v0_40b9e8
  store i32 %v2_40b9e8, i32* %esi.global-to-local, align 4
  %v0_40b9ea = load i32, i32* inttoptr (i32 4763680 to i32*), align 32
  %v1_40b9ea = load i32, i32* %edi.global-to-local, align 4
  %v2_40b9ea = add i32 %v1_40b9ea, %v0_40b9ea
  store i32 %v2_40b9ea, i32* inttoptr (i32 4763680 to i32*), align 32
  %v0_40b9f0 = load i32, i32* %ebx.global-to-local, align 4
  %v1_40b9f0 = add i32 %v0_40b9f0, -34
  store i32 %v1_40b9f0, i32* %ebx.global-to-local, align 4
  %v0_40b9f3 = load i32, i32* inttoptr (i32 4763831 to i32*), align 4
  %v1_40b9f3 = load i32, i32* %esi.global-to-local, align 4
  %v2_40b9f3 = xor i32 %v1_40b9f3, %v0_40b9f3
  store i32 %v2_40b9f3, i32* inttoptr (i32 4763831 to i32*), align 4
  %v1_40b9f9 = load i32, i32* inttoptr (i32 4763906 to i32*), align 4
  %v4_40b9f9 = add i32 %v1_40b9f9, %v1_40b9f0
  %v25_40b9f9 = icmp ult i32 %v4_40b9f9, %v1_40b9f0
  store i1 %v25_40b9f9, i1* %cf.global-to-local, align 1
  store i32 %v4_40b9f9, i32* %ebx.global-to-local, align 4
  %v0_40b9ff = load i32, i32* %eax.global-to-local, align 4
  %v1_40b9ff = inttoptr i32 %v0_40b9ff to i8*
  %v2_40b9ff = load i8, i8* %v1_40b9ff, align 1
  %v4_40b9ff = trunc i32 %v0_40b9ff to i8
  %v5_40b9ff = add i8 %v4_40b9ff, %v2_40b9ff
  %v10_40b9ff = icmp ult i8 %v5_40b9ff, %v2_40b9ff
  store i1 %v10_40b9ff, i1* %cf.global-to-local, align 1
  store i8 %v5_40b9ff, i8* %v1_40b9ff, align 1
  %v0_40ba01 = load i32, i32* %eax.global-to-local, align 4
  %v1_40ba01 = inttoptr i32 %v0_40ba01 to i8*
  %v2_40ba01 = load i8, i8* %v1_40ba01, align 1
  %v4_40ba01 = trunc i32 %v0_40ba01 to i8
  %v5_40ba01 = add i8 %v4_40ba01, %v2_40ba01
  %v10_40ba01 = icmp ult i8 %v5_40ba01, %v2_40ba01
  store i1 %v10_40ba01, i1* %cf.global-to-local, align 1
  store i8 %v5_40ba01, i8* %v1_40ba01, align 1
  %v0_40ba03 = load i32, i32* %eax.global-to-local, align 4
  %v1_40ba03 = inttoptr i32 %v0_40ba03 to i8*
  %v2_40ba03 = load i8, i8* %v1_40ba03, align 1
  %v4_40ba03 = trunc i32 %v0_40ba03 to i8
  %v5_40ba03 = add i8 %v4_40ba03, %v2_40ba03
  %v10_40ba03 = icmp ult i8 %v5_40ba03, %v2_40ba03
  store i1 %v10_40ba03, i1* %cf.global-to-local, align 1
  store i8 %v5_40ba03, i8* %v1_40ba03, align 1
  %v0_40ba05 = load i32, i32* %eax.global-to-local, align 4
  %v1_40ba05 = inttoptr i32 %v0_40ba05 to i8*
  %v2_40ba05 = load i8, i8* %v1_40ba05, align 1
  %v4_40ba05 = trunc i32 %v0_40ba05 to i8
  %v5_40ba05 = add i8 %v4_40ba05, %v2_40ba05
  %v10_40ba05 = icmp ult i8 %v5_40ba05, %v2_40ba05
  store i1 %v10_40ba05, i1* %cf.global-to-local, align 1
  store i8 %v5_40ba05, i8* %v1_40ba05, align 1
  %v0_40ba07 = load i32, i32* %eax.global-to-local, align 4
  %v1_40ba07 = inttoptr i32 %v0_40ba07 to i8*
  %v2_40ba07 = load i8, i8* %v1_40ba07, align 1
  %v4_40ba07 = trunc i32 %v0_40ba07 to i8
  %v5_40ba07 = add i8 %v4_40ba07, %v2_40ba07
  %v10_40ba07 = icmp ult i8 %v5_40ba07, %v2_40ba07
  store i1 %v10_40ba07, i1* %cf.global-to-local, align 1
  store i8 %v5_40ba07, i8* %v1_40ba07, align 1
  %v0_40ba09 = load i32, i32* inttoptr (i32 4763730 to i32*), align 4
  %v1_40ba09 = load i1, i1* %cf.global-to-local, align 1
  %v2_40ba09 = zext i1 %v1_40ba09 to i32
  %v3_40ba09 = add i32 %v0_40ba09, -100
  %v4_40ba09 = add i32 %v3_40ba09, %v2_40ba09
  %v12_40ba09 = icmp ult i32 %v0_40ba09, 100
  %v13_40ba09 = or i1 %v12_40ba09, %v1_40ba09
  store i32 %v4_40ba09, i32* inttoptr (i32 4763730 to i32*), align 4
  %v0_40ba10 = load i32, i32* %edi.global-to-local, align 4
  %v1_40ba10 = load i32, i32* %esi.global-to-local, align 4
  %v3_40ba10 = zext i1 %v13_40ba09 to i32
  %v4_40ba10 = add i32 %v3_40ba10, %v0_40ba10
  %v5_40ba10 = add i32 %v4_40ba10, %v1_40ba10
  store i32 %v5_40ba10, i32* %edi.global-to-local, align 4
  store i32 129, i32* inttoptr (i32 4763742 to i32*), align 4
  %v0_40ba1c = load i32, i32* inttoptr (i32 4763796 to i32*), align 4
  %v1_40ba1c = and i32 %v0_40ba1c, 76
  store i32 %v1_40ba1c, i32* inttoptr (i32 4763796 to i32*), align 4
  %v0_40ba23 = load i32, i32* inttoptr (i32 4763691 to i32*), align 4
  %v1_40ba23 = or i32 %v0_40ba23, 172
  store i32 %v1_40ba23, i32* inttoptr (i32 4763691 to i32*), align 4
  %v0_40ba2d = load i32, i32* %edx.global-to-local, align 4
  %v1_40ba2d = and i32 %v0_40ba2d, -256
  %v2_40ba2f = load i32, i32* %ebx.global-to-local, align 4
  %v3_40ba2f = udiv i32 %v2_40ba2f, 256
  %v4_40ba2f = trunc i32 %v3_40ba2f to i8
  %v5_40ba2f = add i8 %v4_40ba2f, 1
  %v10_40ba2f = icmp eq i8 %v5_40ba2f, 0
  %v20_40ba2f = zext i8 %v5_40ba2f to i32
  %v23_40ba2f = or i32 %v20_40ba2f, %v1_40ba2d
  store i32 %v23_40ba2f, i32* %edx.global-to-local, align 4
  %v0_40ba31 = load i32, i32* inttoptr (i32 4763714 to i32*), align 4
  %v3_40ba31 = zext i1 %v10_40ba2f to i32
  %v4_40ba31 = add i32 %v0_40ba31, %v2_40ba2f
  %v5_40ba31 = add i32 %v4_40ba31, %v3_40ba31
  store i32 %v5_40ba31, i32* inttoptr (i32 4763714 to i32*), align 4
  %v0_40ba37 = load i32, i32* inttoptr (i32 4764018 to i32*), align 4
  %v1_40ba37 = and i32 %v0_40ba37, 84
  store i32 %v1_40ba37, i32* inttoptr (i32 4764018 to i32*), align 4
  %v0_40ba3e = load i32, i32* %esi.global-to-local, align 4
  %v4_40ba3e = mul i32 %v0_40ba3e, 2
  %v25_40ba3e = icmp ult i32 %v4_40ba3e, %v0_40ba3e
  store i32 %v4_40ba3e, i32* %esi.global-to-local, align 4
  %v0_40ba40 = load i32, i32* inttoptr (i32 4763908 to i32*), align 4
  %v3_40ba40 = select i1 %v25_40ba3e, i32 253, i32 252
  %v4_40ba40 = add i32 %v3_40ba40, %v0_40ba40
  store i32 %v4_40ba40, i32* inttoptr (i32 4763908 to i32*), align 4
  store i32 123, i32* %ecx.global-to-local, align 4
  store i32 213, i32* inttoptr (i32 4763719 to i32*), align 4
  %v0_40ba5c = load i32, i32* inttoptr (i32 4764086 to i32*), align 4
  %v1_40ba5c = load i32, i32* %edi.global-to-local, align 4
  %v2_40ba5c = or i32 %v1_40ba5c, %v0_40ba5c
  store i32 %v2_40ba5c, i32* inttoptr (i32 4764086 to i32*), align 4
  %v0_40ba62 = load i32, i32* %ebx.global-to-local, align 4
  %v1_40ba62 = and i32 %v0_40ba62, -59
  store i32 %v1_40ba62, i32* %ebx.global-to-local, align 4
  %v0_40ba65 = load i32, i32* inttoptr (i32 4764118 to i32*), align 4
  %v1_40ba65 = load i32, i32* %esi.global-to-local, align 4
  %v2_40ba65 = xor i32 %v1_40ba65, %v0_40ba65
  store i32 %v2_40ba65, i32* inttoptr (i32 4764118 to i32*), align 4
  %v0_40ba6b = load i32, i32* inttoptr (i32 4763941 to i32*), align 4
  %v3_40ba6b = add i32 %v0_40ba6b, 9
  %v22_40ba6b = icmp ugt i32 %v0_40ba6b, -10
  store i32 %v3_40ba6b, i32* inttoptr (i32 4763941 to i32*), align 4
  %v0_40ba72 = load i32, i32* %ecx.global-to-local, align 4
  %v1_40ba72 = load i32, i32* inttoptr (i32 4763764 to i32*), align 4
  %v3_40ba72 = zext i1 %v22_40ba6b to i32
  %v4_40ba72 = add i32 %v3_40ba72, %v0_40ba72
  %v5_40ba72 = add i32 %v4_40ba72, %v1_40ba72
  store i32 %v5_40ba72, i32* %ecx.global-to-local, align 4
  store i32 11, i32* %eax.global-to-local, align 4
  store i1 false, i1* %cf.global-to-local, align 1
  %v7_40ba89 = call i1 @IsBadStringPtrA(i8* getelementptr inbounds ([12 x i8], [12 x i8]* @global_var_48b6b4.5, i32 0, i32 0), i32 11)
  %v8_40ba89 = sext i1 %v7_40ba89 to i32
  store i32 %v8_40ba89, i32* %eax.global-to-local, align 4
  store i1 false, i1* %cf.global-to-local, align 1
  %v1_40ba8f = icmp eq i1 %v7_40ba89, false
  %v1_40ba92 = icmp eq i1 %v1_40ba8f, false
  call void @__pseudo_cond_branch(i1 %v1_40ba92, i32 4204629)
  %v1_40ba9d = load i32, i32* %edi.global-to-local, align 4
  %v2_40ba9d = add i32 %v1_40ba9d, 1
  store i32 %v2_40ba9d, i32* %ecx.global-to-local, align 4
  %v2_40baa7 = xor i32 %v2_40ba9d, -114
  store i32 %v2_40baa7, i32* %edx.global-to-local, align 4
  %v0_40baa9 = load i32, i32* %ebx.global-to-local, align 4
  %v1_40baa9 = load i32, i32* inttoptr (i32 4763918 to i32*), align 4
  %v4_40baa9 = add i32 %v1_40baa9, %v0_40baa9
  %v25_40baa9 = icmp ult i32 %v4_40baa9, %v0_40baa9
  store i32 %v4_40baa9, i32* %ebx.global-to-local, align 4
  %v0_40baaf = load i32, i32* inttoptr (i32 4763811 to i32*), align 4
  %v3_40baaf = zext i1 %v25_40baa9 to i32
  %v4_40baaf = add i32 %v0_40baaf, %v1_40ba9d
  %v5_40baaf = add i32 %v4_40baaf, %v3_40baaf
  %v24_40baaf = icmp ule i32 %v5_40baaf, %v0_40baaf
  %v25_40baaf = icmp ult i32 %v4_40baaf, %v0_40baaf
  %v26_40baaf = select i1 %v25_40baa9, i1 %v24_40baaf, i1 %v25_40baaf
  store i32 %v5_40baaf, i32* inttoptr (i32 4763811 to i32*), align 4
  %v1_40bab5 = load i32, i32* inttoptr (i32 4763711 to i32*), align 4
  %v3_40bab5 = zext i1 %v26_40baaf to i32
  %v4_40bab5 = add i32 %v1_40bab5, %v8_40ba89
  %v5_40bab5 = add i32 %v3_40bab5, %v4_40bab5
  %v24_40bab5 = icmp ule i32 %v5_40bab5, %v8_40ba89
  %v25_40bab5 = icmp ult i32 %v4_40bab5, %v8_40ba89
  %v26_40bab5 = select i1 %v26_40baaf, i1 %v24_40bab5, i1 %v25_40bab5
  store i32 %v5_40bab5, i32* %eax.global-to-local, align 4
  store i32 36, i32* inttoptr (i32 4763991 to i32*), align 4
  %v0_40bac5 = load i32, i32* inttoptr (i32 4763836 to i32*), align 4
  %v3_40bac5 = select i1 %v26_40bab5, i32 237, i32 236
  %v4_40bac5 = add i32 %v3_40bac5, %v0_40bac5
  store i32 %v4_40bac5, i32* inttoptr (i32 4763836 to i32*), align 4
  %v0_40bacf = load i32, i32* %edx.global-to-local, align 4
  %v1_40bacf = and i32 %v0_40bacf, 25
  store i32 %v1_40bacf, i32* %edx.global-to-local, align 4
  %v0_40bad2 = load i32, i32* %ebx.global-to-local, align 4
  %v1_40bad2 = add i32 %v0_40bad2, 112
  store i32 %v1_40bad2, i32* %ebx.global-to-local, align 4
  %v0_40bad5 = load i32, i32* %esi.global-to-local, align 4
  %v1_40bad5 = load i32, i32* inttoptr (i32 4763787 to i32*), align 4
  %v2_40bad5 = or i32 %v1_40bad5, %v0_40bad5
  store i32 %v2_40bad5, i32* %esi.global-to-local, align 4
  %v1_40badb = load i32, i32* %ecx.global-to-local, align 4
  %v2_40badb = xor i32 %v1_40badb, %v1_40bad2
  store i32 %v2_40badb, i32* %ebx.global-to-local, align 4
  %v0_40badd = load i32, i32* inttoptr (i32 4764133 to i32*), align 4
  %v4_40badd = add i32 %v0_40badd, %v1_40bacf
  %v25_40badd = icmp ult i32 %v4_40badd, %v0_40badd
  store i32 %v4_40badd, i32* inttoptr (i32 4764133 to i32*), align 4
  %v0_40bae3 = load i32, i32* %eax.global-to-local, align 4
  %v3_40bae3 = select i1 %v25_40badd, i32 108, i32 107
  %v4_40bae3 = add i32 %v3_40bae3, %v0_40bae3
  %v0_40bae6 = load i32, i32* %edx.global-to-local, align 4
  %v2_40bae6 = mul i32 %v0_40bae6, 2
  store i32 %v2_40bae6, i32* %edx.global-to-local, align 4
  %v0_40bae8 = load i32, i32* %ebx.global-to-local, align 4
  %v1_40bae8 = and i32 %v0_40bae8, -88
  store i32 %v1_40bae8, i32* %ebx.global-to-local, align 4
  %v1_40baeb = load i32, i32* %edi.global-to-local, align 4
  %v4_40baeb = add i32 %v1_40baeb, %v4_40bae3
  %v25_40baeb = icmp ult i32 %v4_40baeb, %v4_40bae3
  store i1 %v25_40baeb, i1* %cf.global-to-local, align 1
  store i32 %v4_40baeb, i32* %eax.global-to-local, align 4
  call void @__pseudo_call(i32 4242165)
  %v0_40baf5 = load i32, i32* %ecx.global-to-local, align 4
  %v1_40baf8 = xor i32 %v0_40baf5, 12
  store i32 %v1_40baf8, i32* %ecx.global-to-local, align 4
  %v0_40bafb = load i32, i32* %ebx.global-to-local, align 4
  %v1_40bafb = load i32, i32* %eax.global-to-local, align 4
  %v2_40bafb = add i32 %v1_40bafb, %v0_40bafb
  store i32 %v2_40bafb, i32* %ebx.global-to-local, align 4
  %v1_40bafd = load i32, i32* inttoptr (i32 4763655 to i32*), align 4
  %v2_40bafd = or i32 %v1_40bafd, %v2_40bafb
  store i32 %v2_40bafd, i32* %ebx.global-to-local, align 4
  %v0_40bb03 = load i32, i32* %edx.global-to-local, align 4
  %v1_40bb03 = add i32 %v0_40bb03, 67
  %v5_40bb03 = icmp ult i32 %v0_40bb03, -67
  store i32 %v1_40bb03, i32* %edx.global-to-local, align 4
  %v0_40bb06 = load i32, i32* inttoptr (i32 4763830 to i32*), align 4
  %v3_40bb06 = zext i1 %v5_40bb03 to i32
  %v4_40bb06 = add i32 %v0_40bb06, %v2_40bafd
  %v5_40bb06 = add i32 %v4_40bb06, %v3_40bb06
  store i32 %v5_40bb06, i32* inttoptr (i32 4763830 to i32*), align 4
  %v0_40bb0c = load i32, i32* inttoptr (i32 4764103 to i32*), align 4
  %v1_40bb0c = load i32, i32* %edx.global-to-local, align 4
  %v2_40bb0c = add i32 %v1_40bb0c, %v0_40bb0c
  store i32 %v2_40bb0c, i32* inttoptr (i32 4764103 to i32*), align 4
  %v0_40bb12 = load i32, i32* %ebx.global-to-local, align 4
  %v1_40bb12 = load i32, i32* %edi.global-to-local, align 4
  %v2_40bb12 = xor i32 %v1_40bb12, %v0_40bb12
  store i32 %v2_40bb12, i32* %ebx.global-to-local, align 4
  %v1_40bb14 = add i32 %v1_40bb12, -19
  store i32 %v1_40bb14, i32* %edi.global-to-local, align 4
  store i32 0, i32* %eax.global-to-local, align 4
  %v0_40bb19 = load i32, i32* %edx.global-to-local, align 4
  %v1_40bb19 = load i32, i32* inttoptr (i32 4763751 to i32*), align 4
  %v4_40bb19 = add i32 %v1_40bb19, %v0_40bb19
  store i32 %v4_40bb19, i32* %edx.global-to-local, align 4
  %v0_40bb25 = load i32, i32* %esi.global-to-local, align 4
  %v1_40bb25 = or i32 %v0_40bb25, 40
  store i32 %v1_40bb25, i32* %esi.global-to-local, align 4
  %v1_40bb28 = load i32, i32* inttoptr (i32 4764156 to i32*), align 4
  %v4_40bb28 = add i32 %v1_40bb28, %v1_40bb25
  %v25_40bb28 = icmp ult i32 %v4_40bb28, %v1_40bb25
  store i32 %v4_40bb28, i32* %esi.global-to-local, align 4
  %v1_40bb2e = load i32, i32* inttoptr (i32 4763745 to i32*), align 4
  %v3_40bb2e = zext i1 %v25_40bb28 to i32
  %v4_40bb2e = add i32 %v1_40bb2e, %v2_40bb12
  %v5_40bb2e = add i32 %v4_40bb2e, %v3_40bb2e
  store i32 %v5_40bb2e, i32* %ebx.global-to-local, align 4
  store i1 false, i1* %cf.global-to-local, align 1
  call void @llvm.trap()
  unreachable

; uselistorder directives
  uselistorder i32 %v1_40bb25, { 1, 0, 2 }
  uselistorder i32 %v1_40bb12, { 1, 0 }
  uselistorder i32 %v0_40bb03, { 1, 0 }
  uselistorder i32 %v4_40bae3, { 1, 0 }
  uselistorder i32 %v0_40badd, { 1, 0 }
  uselistorder i32 %v5_40bab5, { 1, 0 }
  uselistorder i32 %v4_40bab5, { 1, 0 }
  uselistorder i1 %v26_40baaf, { 1, 0 }
  uselistorder i32 %v5_40baaf, { 1, 0 }
  uselistorder i32 %v4_40baaf, { 1, 0 }
  uselistorder i32 %v0_40baaf, { 1, 2, 0 }
  uselistorder i32 %v0_40baa9, { 1, 0 }
  uselistorder i32 %v8_40ba89, { 2, 1, 0, 3 }
  uselistorder i32 %v4_40ba3e, { 1, 0 }
  uselistorder i32 %v0_40ba3e, { 1, 0 }
  uselistorder i8 %v5_40ba2f, { 1, 0 }
  uselistorder i32 %v2_40ba2f, { 1, 0 }
  uselistorder i32 %v0_40ba09, { 1, 0 }
  uselistorder i8 %v2_40ba07, { 1, 0 }
  uselistorder i8 %v2_40ba05, { 1, 0 }
  uselistorder i8 %v2_40ba03, { 1, 0 }
  uselistorder i8 %v2_40ba01, { 1, 0 }
  uselistorder i8 %v2_40b9ff, { 1, 0 }
  uselistorder i8 %v0_40b9c8, { 1, 0 }
  uselistorder i1 %v16_40b984, { 1, 0 }
  uselistorder i32 %v4_40b984, { 1, 0, 2 }
  uselistorder i32 %v7_40b965, { 1, 0, 2 }
  uselistorder i32 %v5_40b91d, { 1, 0 }
  uselistorder i32 %v4_40b91d, { 1, 0 }
  uselistorder i32 %v0_40b912, { 1, 0 }
  uselistorder i8 %v2_40b8f3, { 1, 0 }
  uselistorder i8 %v2_40b8f1, { 1, 0 }
  uselistorder i32 %v0_40b8eb, { 1, 0 }
  uselistorder i32 %v2_40b8db, { 1, 0, 2 }
  uselistorder i32 %v1_40b8d8, { 0, 2, 1, 3 }
  uselistorder i32 %v0_40b8a0, { 1, 0 }
  uselistorder i8 %v0_40b873, { 1, 0 }
  uselistorder i32 %v0_40b861, { 1, 0 }
  uselistorder i32 %v4_40b849, { 0, 2, 3, 1 }
  uselistorder i32 %v9_40b833, { 1, 0, 2 }
  uselistorder i32 %v5_40b819, { 1, 0 }
  uselistorder i32 %v4_40b819, { 1, 0 }
  uselistorder i32 %v0_40b819, { 1, 2, 0 }
  uselistorder i1 %v24_40b816, { 1, 0 }
  uselistorder i32 %v4_40b816, { 1, 0 }
  uselistorder i1 %v21_40b810, { 1, 0 }
  uselistorder i32 %v4_40b810, { 1, 0 }
  uselistorder i32 %v3_40b810, { 1, 0 }
  uselistorder i32 %v29_40b80e, { 1, 2, 0, 3 }
  uselistorder i1 %v13_40b80e, { 1, 0 }
  uselistorder i32 %v1_40b804, { 1, 0, 2, 3 }
  uselistorder i32 %v4_40b7f5, { 1, 0 }
  uselistorder i32 %v3_40b7f5, { 1, 0 }
  uselistorder i1 %v7_40b7ef, { 1, 0 }
  uselistorder i32 %v1_40b7ef, { 2, 1, 0, 3 }
  uselistorder i32 %v0_40b7ef, { 1, 0 }
  uselistorder i32 %v13_40b7ec, { 1, 2, 0, 3 }
  uselistorder i32 %v5_40b7de, { 1, 0 }
  uselistorder i32 %v4_40b7de, { 1, 0 }
  uselistorder i1 %v7_40b7d3, { 1, 0 }
  uselistorder i32 %v0_40b7d3, { 1, 0 }
  uselistorder i8 %v2_40b7cc, { 1, 0 }
  uselistorder i8 %v2_40b7ca, { 1, 0 }
  uselistorder i8 %v2_40b7c8, { 1, 0 }
  uselistorder i8 %v2_40b7c6, { 1, 0 }
  uselistorder i8 %v2_40b7c4, { 1, 0 }
  uselistorder i8 %v2_40b7c2, { 1, 0 }
  uselistorder i8 %v2_40b7c0, { 1, 0 }
  uselistorder i8 %v2_40b7be, { 1, 0 }
  uselistorder i8 %v2_40b7ac, { 1, 0, 2 }
  uselistorder i1 %v21_40b7a6, { 1, 0, 2 }
  uselistorder i32 %v4_40b7a6, { 1, 0 }
  uselistorder i32 %v3_40b7a6, { 1, 0 }
  uselistorder i32 %v1_40b7a6, { 1, 0, 2 }
  uselistorder i1 %v26_40b7a0, { 1, 0, 2 }
  uselistorder i8 %v6_40b7a0, { 1, 0 }
  uselistorder i8 %v5_40b7a0, { 1, 0 }
  uselistorder i8 %v0_40b7a0, { 1, 2, 0 }
  uselistorder i1 %v23_40b799, { 1, 0, 2 }
  uselistorder i32 %v4_40b799, { 1, 0 }
  uselistorder i32 %v0_40b799, { 1, 2, 0 }
  uselistorder i1 %v2_40b78c, { 1, 0 }
  uselistorder i32 %v1_40b786, { 1, 0, 2 }
  uselistorder i8 %v2_40b76b, { 1, 0 }
  uselistorder i32 %v4_40b761, { 1, 0 }
  uselistorder i32 %v0_40b75e, { 1, 0, 2 }
  uselistorder i32 %v4_40b73b, { 1, 0 }
  uselistorder i32 %v3_40b73b, { 1, 0 }
  uselistorder i32 %v1_40b73b, { 1, 0, 2 }
  uselistorder i32 %v0_40b735, { 1, 0 }
  uselistorder i32 %v0_40b72e, { 1, 0 }
  uselistorder i32 %v0_40b6d4, { 1, 0 }
  uselistorder i32 %v0_40b6c8, { 1, 0 }
  uselistorder i32 %v1_40b6c6, { 2, 0, 1 }
  uselistorder i32 %v0_40b6c6, { 1, 0 }
  uselistorder i8 %v1_40b6bb, { 1, 0 }
  uselistorder i32 %v1_40b6af, { 1, 2, 0, 3, 4 }
  uselistorder i8 %v3_40b68f, { 1, 0 }
  uselistorder i8 %v2_40b68d, { 1, 0 }
  uselistorder i8 %v2_40b68b, { 1, 0 }
  uselistorder i8 %v2_40b689, { 1, 0 }
  uselistorder i8 %v2_40b687, { 1, 0 }
  uselistorder i8 %v2_40b685, { 1, 0 }
  uselistorder i8 %v2_40b683, { 1, 0 }
  uselistorder i8 %v2_40b681, { 1, 0 }
  uselistorder i32 %v4_40b65e, { 1, 0 }
  uselistorder i32 %v3_40b65e, { 1, 0 }
  uselistorder i32 %v1_40b65e, { 1, 0, 2 }
  uselistorder i32 %v5_40b658, { 3, 2, 1, 0 }
  uselistorder i32 %v4_40b658, { 1, 0 }
  uselistorder i32 %v0_40b658, { 1, 2, 0 }
  uselistorder i1 %v7_40b64c, { 1, 0 }
  uselistorder i32 %v0_40b64c, { 1, 0 }
  uselistorder i32 %v2_40b637, { 1, 0 }
  uselistorder i32 %v0_40b626, { 1, 0 }
  uselistorder i32 %v0_40b5e9, { 1, 0 }
  uselistorder i32 %v0_40b584, { 1, 0 }
  uselistorder i8 %v2_40b550, { 1, 0 }
  uselistorder i32 %v5_40b526, { 1, 0, 2 }
  uselistorder i8 %v2_40b520, { 1, 0 }
  uselistorder i32 %v0_40b520, { 1, 0 }
  uselistorder i32 %v1_40b4f1, { 2, 0, 1 }
  uselistorder i8 %v0_40b4cc, { 1, 0 }
  uselistorder i32 %v6_40b494, { 2, 0, 1, 3, 4 }
  uselistorder i32 %v0_40b45b, { 1, 0 }
  uselistorder i32 %v2_40b453, { 0, 2, 1 }
  uselistorder i32 %v3_40b43e, { 2, 1, 0 }
  uselistorder i32 %v0_40b43e, { 1, 0 }
  uselistorder i8 %v2_40b43a, { 1, 0 }
  uselistorder i8 %v2_40b438, { 1, 0 }
  uselistorder i8 %v2_40b436, { 1, 0 }
  uselistorder i32 %v5_40b434, { 1, 0 }
  uselistorder i32 %v4_40b434, { 1, 0 }
  uselistorder i32 %v0_40b434, { 1, 2, 0 }
  uselistorder i1 %v23_40b42d, { 1, 0 }
  uselistorder i32 %v4_40b42d, { 1, 0 }
  uselistorder i32 %v0_40b42d, { 1, 2, 0 }
  uselistorder i32 %v0_40b427, { 1, 0 }
  uselistorder i32 %v0_40b3ef, { 1, 0 }
  uselistorder i32 %v5_40b3c8, { 1, 0 }
  uselistorder i32 %v4_40b3c8, { 1, 0 }
  uselistorder i32 %v0_40b3c8, { 1, 2, 0 }
  uselistorder i1 %v23_40b3be, { 1, 0 }
  uselistorder i32 %v4_40b3be, { 1, 0 }
  uselistorder i32 %v0_40b3be, { 1, 2, 0 }
  uselistorder i1 %v8_40b3ae, { 1, 0 }
  uselistorder i8 %v1_40b3a8, { 1, 0 }
  uselistorder i8 %v5_40b3a1, { 0, 1, 3, 2 }
  uselistorder i32 %v4_40b393, { 1, 0 }
  uselistorder i32 %v3_40b393, { 1, 0 }
  uselistorder i32 %v1_40b393, { 1, 0, 2 }
  uselistorder i32 %v4_40b361, { 1, 0, 2 }
  uselistorder i32 %v4_40b357, { 1, 0 }
  uselistorder i32 %v0_40b357, { 1, 2, 0 }
  uselistorder i1 %v24_40b354, { 1, 0 }
  uselistorder i32 %v4_40b354, { 1, 0 }
  uselistorder i32 %v0_40b354, { 1, 2, 0 }
  uselistorder i1 %v26_40b34e, { 1, 0 }
  uselistorder i32 %v5_40b34e, { 1, 0 }
  uselistorder i32 %v4_40b34e, { 1, 0 }
  uselistorder i32 %v0_40b34e, { 1, 2, 0 }
  uselistorder i1 %v7_40b348, { 1, 0 }
  uselistorder i32 %v0_40b348, { 1, 0 }
  uselistorder i8 %v2_40b2fc, { 1, 0 }
  uselistorder i8 %v2_40b2fa, { 1, 0 }
  uselistorder i32 %v28_40b2eb, { 1, 0, 2 }
  uselistorder i32 %v0_40b2eb, { 1, 0, 2 }
  uselistorder i32 %v0_40b2d5, { 1, 0 }
  uselistorder i32 %v0_40b2cf, { 1, 0 }
  uselistorder i32 %v0_40b2b9, { 1, 0 }
  uselistorder i32 %v0_40b29d, { 1, 0 }
  uselistorder i32 %v5_40b284, { 0, 2, 1 }
  uselistorder i32 %v4_40b284, { 1, 0 }
  uselistorder i1 %v7_40b27e, { 1, 0 }
  uselistorder i32 %v2_40b27e, { 2, 1, 0, 3 }
  uselistorder i32 %v0_40b276, { 1, 0 }
  uselistorder i32 %v5_40b26a, { 1, 0 }
  uselistorder i32 %v4_40b26a, { 1, 0 }
  uselistorder i32 %v0_40b26a, { 1, 2, 0 }
  uselistorder i1 %v7_40b264, { 1, 0 }
  uselistorder i32 %v1_40b262, { 1, 0, 2 }
  uselistorder i32 %v0_40b259, { 1, 0 }
  uselistorder i32 %sext7, { 1, 0 }
  uselistorder i32 %v5_40b1f8, { 1, 0 }
  uselistorder i32 %v4_40b1f8, { 1, 0 }
  uselistorder i32 %v0_40b1f8, { 1, 2, 0 }
  uselistorder i32 %v4_40b1f2, { 0, 2, 1 }
  uselistorder i32 %v5_40b1cc, { 1, 0, 2 }
  uselistorder i8 %v2_40b1c3, { 1, 0 }
  uselistorder i8 %v1_40b1c1, { 1, 0 }
  uselistorder i32 %v0_40b1b5, { 1, 0 }
  uselistorder i32 %sext, { 1, 0 }
  uselistorder i8 %v1_40b09f, { 1, 0 }
  uselistorder i32 %v1_40b09e, { 1, 0 }
  uselistorder i8 %v2_40b095, { 1, 0 }
  uselistorder i8 %v2_40b093, { 1, 0 }
  uselistorder i8 %v2_40b091, { 1, 0 }
  uselistorder i8 %v2_40b08f, { 1, 0 }
  uselistorder i32 %v1_40b08d, { 1, 0, 2, 3 }
  uselistorder i32 %v4_40b07d, { 1, 0 }
  uselistorder i32 %v3_40b07d, { 1, 0 }
  uselistorder i32 %v1_40b07d, { 1, 0, 2 }
  uselistorder i32 %v4_40b076, { 1, 0 }
  uselistorder i1 %v20_40b070, { 1, 0 }
  uselistorder i8 %v6_40b05d, { 1, 0 }
  uselistorder i1 %v11_40b05a, { 1, 0 }
  uselistorder i8 %v4_40b042, { 1, 2, 0, 3 }
  uselistorder i32 %v0_40b042, { 1, 2, 0 }
  uselistorder i32 %v5_40b03c, { 1, 0, 3, 2 }
  uselistorder i32 %v4_40b03c, { 1, 0 }
  uselistorder i1 %v5_40b034, { 1, 0 }
  uselistorder i32 %v0_40b034, { 1, 0 }
  uselistorder i32 %v0_40aff5, { 1, 0 }
  uselistorder i32 %v0_40afef, { 1, 0 }
  uselistorder i32 %v0_40afbe, { 1, 0 }
  uselistorder i1 %v22_40af93, { 1, 0 }
  uselistorder i32 %v1_40af8e, { 1, 0, 2 }
  uselistorder i32 %v1_40af88, { 1, 0 }
  uselistorder i32 %v0_40af88, { 1, 0 }
  uselistorder i32 %v0_40af68, { 1, 0 }
  uselistorder i8 %v2_40af66, { 1, 0 }
  uselistorder i8 %v2_40af64, { 1, 0 }
  uselistorder i8 %v2_40af62, { 1, 0 }
  uselistorder i8 %v2_40af60, { 1, 0 }
  uselistorder i8 %v2_40af5e, { 1, 0 }
  uselistorder i32 %v4_40af5b, { 1, 0 }
  uselistorder i1 %v7_40af55, { 1, 0 }
  uselistorder i32 %v0_40af55, { 1, 0 }
  uselistorder i32 %v2_40af53, { 2, 1, 0, 3 }
  uselistorder i32 %v0_40af4d, { 1, 0 }
  uselistorder i32 %v4_40af15, { 1, 0 }
  uselistorder i1 %v7_40af13, { 1, 0 }
  uselistorder i32 %v2_40af11, { 1, 0 }
  uselistorder i32 %v5_40aeff, { 1, 0 }
  uselistorder i32 %v4_40aeff, { 1, 0 }
  uselistorder i32 %v0_40aeff, { 1, 2, 0 }
  uselistorder i1 %v26_40aef9, { 1, 0 }
  uselistorder i8 %v6_40aef9, { 1, 0 }
  uselistorder i8 %v5_40aef9, { 1, 0 }
  uselistorder i1 %v26_40aef3, { 1, 0, 2 }
  uselistorder i32 %v5_40aef3, { 1, 0 }
  uselistorder i32 %v4_40aef3, { 1, 0 }
  uselistorder i32 %v0_40aef3, { 1, 2, 0 }
  uselistorder i1 %v26_40aef1, { 1, 0 }
  uselistorder i32 %v5_40aef1, { 1, 0 }
  uselistorder i32 %v4_40aef1, { 1, 0 }
  uselistorder i1 %v5_40aeee15, { 1, 0 }
  uselistorder i32 %v1_40aeee, { 2, 1, 0 }
  uselistorder i32 %v0_40ae9f, { 1, 0 }
  uselistorder i32 %v1_40ae8b, { 1, 0, 2, 3 }
  uselistorder i32 %v1_40ae88, { 1, 0 }
  uselistorder i32 %v5_40ae7b, { 1, 0 }
  uselistorder i32 %v4_40ae7b, { 1, 0 }
  uselistorder i8 %v2_40ae74, { 1, 0 }
  uselistorder i8 %v2_40ae72, { 1, 0 }
  uselistorder i8 %v2_40ae70, { 1, 0 }
  uselistorder i8 %v2_40ae6e, { 1, 0 }
  uselistorder i8 %v2_40ae6c, { 1, 0 }
  uselistorder i8 %v2_40ae6a, { 1, 0 }
  uselistorder i8 %v2_40ae68, { 1, 0 }
  uselistorder i32 %v0_40ae58, { 1, 0 }
  uselistorder i32 %v0_40ae56, { 1, 0 }
  uselistorder i32 %v2_40ae4a, { 1, 0 }
  uselistorder i32 %v4_40ae30, { 1, 0 }
  uselistorder i1 %v26_40ae2a, { 1, 0 }
  uselistorder i32 %v5_40ae2a, { 3, 2, 1, 0 }
  uselistorder i32 %v4_40ae2a, { 1, 0 }
  uselistorder i32 %v0_40ae2a, { 1, 2, 0 }
  uselistorder i32 %v5_40ae0a, { 1, 0 }
  uselistorder i32 %v4_40ae0a, { 1, 0 }
  uselistorder i32 %v0_40ae0a, { 1, 2, 0 }
  uselistorder i1 %v7_40ae08, { 1, 0 }
  uselistorder i32 %v1_40ae08, { 1, 0, 2, 3 }
  uselistorder i32 %v4_40adff, { 1, 0, 2 }
  uselistorder i32 %v2_40ade7, { 1, 0 }
  uselistorder i32 %v11_40add3, { 1, 0, 2, 4, 3 }
  uselistorder i8 %v7_40adb1, { 1, 0 }
  uselistorder i8 %v6_40adb1, { 1, 0 }
  uselistorder i8 %v4_40adb1, { 1, 0, 2 }
  uselistorder i1 %v7_40adaf, { 1, 0 }
  uselistorder i32 %v4_40ada8, { 2, 0, 1 }
  uselistorder i32 %v0_40ada5, { 1, 0 }
  uselistorder i32 %v5_40ad76, { 1, 0 }
  uselistorder i32 %v4_40ad76, { 1, 0 }
  uselistorder i8 %v3_40ad4a, { 1, 0 }
  uselistorder i8 %v2_40ad48, { 1, 0 }
  uselistorder i8 %v2_40ad46, { 1, 0 }
  uselistorder i8 %v2_40ad44, { 1, 0 }
  uselistorder i8 %v2_40ad42, { 1, 0 }
  uselistorder i8 %v2_40ad40, { 1, 0 }
  uselistorder i32 %v4_40ad3e, { 2, 1, 3, 0 }
  uselistorder i32 %v0_40ad3e, { 1, 0 }
  uselistorder i32 %v1_40ad13, { 0, 2, 1 }
  uselistorder i32 %v0_40ad0b, { 1, 0 }
  uselistorder i32 %v5_40ace8, { 1, 0, 2 }
  uselistorder i8 %v0_40ace1, { 1, 0 }
  uselistorder i32 %v1_40acde, { 1, 0 }
  uselistorder i32 %v0_40acde, { 1, 0 }
  uselistorder i1 %v5_40acdb, { 1, 0 }
  uselistorder i32 %v0_40acdb, { 1, 0 }
  uselistorder i32 %v5_40accd, { 1, 0 }
  uselistorder i32 %v4_40accd, { 1, 0 }
  uselistorder i1 %v24_40acca, { 1, 0 }
  uselistorder i32 %v4_40acca, { 3, 2, 0, 4, 1 }
  uselistorder i32 %v0_40acca, { 1, 2, 0 }
  uselistorder i32 %v0_40acc4, { 1, 0 }
  uselistorder i32 %v5_40ac87, { 1, 0 }
  uselistorder i32 %v4_40ac87, { 1, 0 }
  uselistorder i32 %v0_40ac87, { 1, 2, 0 }
  uselistorder i1 %v8_40ac81, { 1, 0 }
  uselistorder i8 %v6_40ac7e, { 1, 0 }
  uselistorder i32 %v0_40ac7e, { 1, 0 }
  uselistorder i1 %v5_40ac77, { 1, 0, 2 }
  uselistorder i8 %v0_40ac77, { 1, 0 }
  uselistorder i8 %v2_40ac55, { 1, 0 }
  uselistorder i8 %v0_40ac4e, { 1, 0 }
  uselistorder i32 %v0_40ac39, { 1, 0 }
  uselistorder i32 %v0_40ac2e, { 1, 0 }
  uselistorder i32 %v2_40ac06, { 1, 0 }
  uselistorder i32 %v4_40abda, { 1, 0 }
  uselistorder i32 %v0_40abda, { 1, 2, 0 }
  uselistorder i32 %v4_40abcf, { 1, 0 }
  uselistorder i32 %v0_40ab75, { 1, 0 }
  uselistorder i8 %v2_40ab52, { 1, 0 }
  uselistorder i8 %v2_40ab50, { 1, 0 }
  uselistorder i8 %v2_40ab4e, { 1, 0 }
  uselistorder i8 %v2_40ab4c, { 1, 0 }
  uselistorder i8 %v2_40ab4a, { 1, 0 }
  uselistorder i32 %v5_40ab44, { 1, 0 }
  uselistorder i32 %v4_40ab44, { 1, 0 }
  uselistorder i32 %v0_40ab44, { 1, 2, 0 }
  uselistorder i1 %v26_40ab3e, { 1, 0 }
  uselistorder i32 %v5_40ab3e, { 1, 0 }
  uselistorder i32 %v4_40ab3e, { 1, 0 }
  uselistorder i32 %v0_40ab3e, { 1, 2, 0 }
  uselistorder i1 %v9_40ab3c, { 1, 0 }
  uselistorder i32 %v4_40ab18, { 1, 0 }
  uselistorder i1 %v22_40ab12, { 1, 0, 2 }
  uselistorder i8 %v5_40ab12, { 1, 0 }
  uselistorder i8 %v4_40ab12, { 1, 0 }
  uselistorder i1 %v10_40ab10, { 1, 0, 2 }
  uselistorder i32 %v1_40ab10, { 1, 0 }
  uselistorder i32 %v2_40ab0e, { 1, 0 }
  uselistorder i8 %v14_40ab0c, { 1, 2, 0, 3 }
  uselistorder i32 %v4_40aaf2, { 0, 2, 1 }
  uselistorder i8 %v0_40aaaf, { 1, 0 }
  uselistorder i32 %v4_40aaac, { 1, 0 }
  uselistorder i32 %v0_40aaac, { 1, 2, 0 }
  uselistorder i1 %v23_40aaa5, { 1, 0 }
  uselistorder i32 %v4_40aaa5, { 1, 0 }
  uselistorder i1 %v13_40aa9e, { 1, 0 }
  uselistorder i32 %v0_40aa9e, { 1, 0 }
  uselistorder i32 %v5_40aa98, { 1, 0 }
  uselistorder i32 %v4_40aa98, { 1, 0 }
  uselistorder i1 %v7_40aa96, { 1, 0 }
  uselistorder i32 %v2_40aa96, { 1, 0 }
  uselistorder i32 %v1_40aa96, { 2, 1, 0, 3 }
  uselistorder i32 %v9_40aa8b, { 2, 0, 1, 3 }
  uselistorder i32 %v0_40aa6d, { 1, 0 }
  uselistorder i32 %v0_40aa5e, { 1, 0 }
  uselistorder i8 %v2_40aa2d, { 1, 0 }
  uselistorder i8 %v2_40aa2b, { 1, 0 }
  uselistorder i8 %v2_40aa29, { 1, 0 }
  uselistorder i8 %v2_40aa27, { 1, 0 }
  uselistorder i32 %v1_40aa1b, { 1, 0, 2 }
  uselistorder i32 %v0_40a9ff, { 1, 0 }
  uselistorder i32 %v2_40a9d8, { 1, 0, 2 }
  uselistorder i8 %v7_40a9cc, { 1, 0 }
  uselistorder i8 %v2_40a9cc, { 1, 2, 0 }
  uselistorder i32 %v0_40a9cc, { 1, 0 }
  uselistorder i32 %v5_40a9be, { 1, 0 }
  uselistorder i32 %v4_40a9be, { 1, 0 }
  uselistorder i32 %v0_40a9be, { 1, 2, 0 }
  uselistorder i1 %v5_40a9bb, { 1, 0 }
  uselistorder i32 %v2_40a955, { 2, 0, 1 }
  uselistorder i32 %v0_40a955, { 1, 0 }
  uselistorder i8 %v7_40a949, { 1, 0 }
  uselistorder i8 %v6_40a949, { 1, 0 }
  uselistorder i8 %v0_40a949, { 1, 2, 0 }
  uselistorder i1 %v7_40a947, { 1, 0, 2 }
  uselistorder i32 %v1_40a944, { 1, 0 }
  uselistorder i8 %v2_40a92c, { 1, 0 }
  uselistorder i8 %v2_40a92a, { 1, 0 }
  uselistorder i8 %v2_40a928, { 1, 0 }
  uselistorder i8 %v2_40a926, { 1, 0 }
  uselistorder i8 %v0_40a8e9, { 1, 0 }
  uselistorder i32 %v2_40a8e7, { 1, 0 }
  uselistorder i32 %v1_40a8c3, { 1, 0, 2 }
  uselistorder i32 %v1_40a8b3, { 1, 0, 2 }
  uselistorder i32 %v0_40a8b1, { 1, 0 }
  uselistorder i32 %v1_40a88e, { 2, 1, 0 }
  uselistorder i8 %v7_40a882, { 1, 0 }
  uselistorder i8 %v6_40a882, { 1, 0 }
  uselistorder i1 %v16_40a872, { 1, 2, 0 }
  uselistorder i32 %v4_40a872, { 1, 0 }
  uselistorder i8 %v12_40a860, { 1, 2, 0 }
  uselistorder i32 %v1_40a833, { 1, 0 }
  uselistorder i32 %v0_40a833, { 1, 0 }
  uselistorder i8 %v0_40a801, { 1, 0 }
  uselistorder i8 %v2_40a7ec, { 1, 0 }
  uselistorder i8 %v2_40a7ea, { 1, 0 }
  uselistorder i8 %v2_40a7e8, { 1, 0 }
  uselistorder i8 %v2_40a7e6, { 1, 0 }
  uselistorder i8 %v2_40a7e4, { 1, 0 }
  uselistorder i32 %v0_40a7b8, { 1, 0 }
  uselistorder i8 %v2_40a769, { 1, 0 }
  uselistorder i32 %v0_40a745, { 1, 0 }
  uselistorder i32 %v0_40a71d, { 1, 0 }
  uselistorder i32 %v0_40a70a, { 1, 0 }
  uselistorder i32 %v5_40a704, { 1, 0 }
  uselistorder i32 %v4_40a704, { 1, 0 }
  uselistorder i32 %v0_40a704, { 1, 2, 0 }
  uselistorder i1 %v5_40a701, { 1, 0 }
  uselistorder i32 %v5_40a6f9, { 1, 2, 0 }
  uselistorder i32 %v4_40a6f9, { 1, 0 }
  uselistorder i1 %v26_40a6ee, { 1, 0 }
  uselistorder i32 %v5_40a6ee, { 1, 0 }
  uselistorder i32 %v4_40a6ee, { 1, 0 }
  uselistorder i32 %v0_40a6ee, { 1, 2, 0 }
  uselistorder i32 %v0_40a6de, { 1, 0 }
  uselistorder i32 %v1_40a6be, { 1, 0, 2 }
  uselistorder i8 %v0_40a6b0, { 1, 0 }
  uselistorder i8 %v3_40a6aa, { 1, 0 }
  uselistorder i8 %v2_40a6a8, { 1, 0 }
  uselistorder i8 %v2_40a6a6, { 1, 0 }
  uselistorder i8 %v2_40a6a4, { 1, 0 }
  uselistorder i32 %v1_40a698, { 1, 0, 2 }
  uselistorder i32 %v0_40a695, { 1, 0 }
  uselistorder i32 %v5_40a674, { 0, 2, 1 }
  uselistorder i32 %v4_40a674, { 1, 0 }
  uselistorder i1 %v26_40a672, { 1, 0 }
  uselistorder i32 %v5_40a672, { 1, 0 }
  uselistorder i32 %v4_40a672, { 1, 0 }
  uselistorder i1 %v23_40a66f, { 1, 0 }
  uselistorder i32 %v4_40a66f, { 2, 1, 0, 4, 3 }
  uselistorder i32 %v32_40a669, { 2, 1, 0 }
  uselistorder i1 %v27_40a669, { 1, 0 }
  uselistorder i8 %v7_40a669, { 1, 0 }
  uselistorder i8 %v2_40a669, { 1, 2, 0 }
  uselistorder i32 %v0_40a669, { 1, 0 }
  uselistorder i1 %v21_40a667, { 1, 0, 2 }
  uselistorder i32 %v4_40a667, { 1, 0 }
  uselistorder i32 %v3_40a667, { 1, 0 }
  uselistorder i32 %v1_40a667, { 0, 1, 3, 2, 4 }
  uselistorder i32 %v0_40a642, { 1, 0 }
  uselistorder i32 %v4_40a605, { 1, 0 }
  uselistorder i32 %v0_40a605, { 1, 2, 0 }
  uselistorder i1 %v26_40a5ff, { 1, 0 }
  uselistorder i32 %v5_40a5ff, { 1, 0 }
  uselistorder i32 %v4_40a5ff, { 1, 0 }
  uselistorder i32 %v6_40a5f4, { 4, 3, 0, 1, 2, 5 }
  uselistorder i32 %v5_40a5dc, { 1, 0 }
  uselistorder i32 %v4_40a5dc, { 1, 0 }
  uselistorder i1 %v26_40a5da, { 1, 0 }
  uselistorder i32 %v5_40a5da, { 1, 0 }
  uselistorder i32 %v4_40a5da, { 1, 0 }
  uselistorder i32 %v1_40a5da, { 3, 2, 0, 1 }
  uselistorder i32 %v0_40a5da, { 1, 2, 0 }
  uselistorder i1 %v9_40a5d4, { 1, 0 }
  uselistorder i32 %v0_40a5d4, { 1, 2, 0 }
  uselistorder i8 %v5_40a5b5, { 1, 0 }
  uselistorder i32 %v0_40a588, { 1, 0 }
  uselistorder i8 %v2_40a57d, { 1, 0 }
  uselistorder i8 %v2_40a57b, { 1, 0 }
  uselistorder i8 %v2_40a579, { 1, 0 }
  uselistorder i8 %v2_40a577, { 1, 0 }
  uselistorder i8 %v2_40a575, { 1, 0 }
  uselistorder i8 %v2_40a573, { 1, 0 }
  uselistorder i8 %v6_40a535, { 1, 0 }
  uselistorder i8 %v5_40a535, { 1, 0 }
  uselistorder i1 %v7_40a52f, { 1, 0, 2 }
  uselistorder i32 %v0_40a52f, { 1, 0 }
  uselistorder i32 %v5_40a50b, { 0, 2, 1 }
  uselistorder i32 %v4_40a50b, { 1, 0 }
  uselistorder i32 %v0_40a50b, { 1, 2, 0 }
  uselistorder i32 %v0_40a4f9, { 1, 0 }
  uselistorder i32 %v0_40a4f7, { 1, 0 }
  uselistorder i8 %v6_40a4e7, { 1, 0 }
  uselistorder i8 %v5_40a4e7, { 1, 0 }
  uselistorder i8 %v0_40a4e7, { 1, 2, 0 }
  uselistorder i1 %v26_40a4e5, { 1, 0, 2 }
  uselistorder i32 %v5_40a4e5, { 1, 0 }
  uselistorder i32 %v0_40a4e5, { 1, 2, 0 }
  uselistorder i1 %v21_40a4df, { 1, 0 }
  uselistorder i32 %v4_40a4df, { 1, 0 }
  uselistorder i32 %v3_40a4df, { 1, 0 }
  uselistorder i1 %v7_40a4dd, { 1, 0 }
  uselistorder i32 %v1_40a4da, { 1, 0 }
  uselistorder i32 %v5_40a4c7, { 1, 0, 2 }
  uselistorder i32 %v3_40a4bf, { 1, 0, 2, 3, 4 }
  uselistorder i32 %v0_40a4a6, { 1, 0 }
  uselistorder i1 %v24_40a46c, { 1, 2, 0 }
  uselistorder i8 %v6_40a46c, { 1, 0 }
  uselistorder i1 %v7_40a466, { 1, 0 }
  uselistorder i32 %v2_40a466, { 1, 0 }
  uselistorder i32 %v4_40a461, { 1, 0, 2 }
  uselistorder i8 %v3_40a45e, { 1, 0 }
  uselistorder i8 %v3_40a458, { 1, 0 }
  uselistorder i32 %v0_40a452, { 1, 0 }
  uselistorder i8 %v6_40a426, { 1, 0 }
  uselistorder i8 %v5_40a426, { 1, 0 }
  uselistorder i8 %v10_40a423, { 2, 1, 0 }
  uselistorder i1 %v4_40a423, { 1, 0, 2 }
  uselistorder i32 %v2_40a416, { 1, 0 }
  uselistorder i32 %v4_40a3ef, { 1, 0 }
  uselistorder i32 %v5_40a3d6, { 1, 0 }
  uselistorder i32 %v4_40a3d6, { 1, 0 }
  uselistorder i1 %v26_40a3cb, { 1, 0 }
  uselistorder i32 %v5_40a3cb, { 1, 0 }
  uselistorder i32 %v4_40a3cb, { 1, 0 }
  uselistorder i32 %v0_40a3cb, { 1, 2, 0 }
  uselistorder i1 %v26_40a3c5, { 1, 0 }
  uselistorder i8 %v6_40a3c5, { 1, 0 }
  uselistorder i8 %v5_40a3c5, { 1, 0 }
  uselistorder i1 %v22_40a3bf, { 1, 0, 2 }
  uselistorder i32 %v5_40a3b3, { 1, 0, 2 }
  uselistorder i32 %v0_40a3a5, { 2, 0, 1 }
  uselistorder i32 %v5_40a369, { 1, 0 }
  uselistorder i32 %v4_40a369, { 1, 0 }
  uselistorder i32 %v0_40a369, { 1, 2, 0 }
  uselistorder i1 %v7_40a363, { 1, 0 }
  uselistorder i32 %v0_40a363, { 1, 0 }
  uselistorder i32 %v5_40a348, { 1, 0 }
  uselistorder i32 %v4_40a348, { 1, 0 }
  uselistorder i32 %v0_40a348, { 1, 2, 0 }
  uselistorder i8 %v2_40a346, { 1, 0 }
  uselistorder i8 %v2_40a344, { 1, 0 }
  uselistorder i8 %v2_40a342, { 1, 0 }
  uselistorder i8 %v2_40a340, { 1, 0 }
  uselistorder i32 %v0_40a33d, { 1, 0 }
  uselistorder i32 %v0_40a337, { 1, 0 }
  uselistorder i32 %v4_40a30f, { 1, 0 }
  uselistorder i32 %v0_40a30f, { 1, 2, 0 }
  uselistorder i1 %v23_40a305, { 1, 0 }
  uselistorder i32 %v4_40a305, { 1, 0 }
  uselistorder i1 %v7_40a303, { 1, 0 }
  uselistorder i32 %v0_40a303, { 1, 0 }
  uselistorder i32 %v4_40a2de, { 1, 0 }
  uselistorder i32 %v0_40a2de, { 1, 2, 0 }
  uselistorder i32 %v2_40a2ca, { 0, 2, 1 }
  uselistorder i1 %v22_40a2ba, { 1, 0 }
  uselistorder i32 %v1_40a2aa, { 2, 1, 0, 3 }
  uselistorder i8 %v1_40a264, { 1, 0 }
  uselistorder i32 %v4_40a24f, { 1, 0 }
  uselistorder i32 %v0_40a24f, { 1, 0 }
  uselistorder i32 %v4_40a248, { 1, 0 }
  uselistorder i32 %v0_40a248, { 1, 2, 0 }
  uselistorder i1 %v6_40a245, { 1, 0 }
  uselistorder i32 %v0_40a20a, { 1, 0 }
  uselistorder i32 %v1_40a201, { 1, 0 }
  uselistorder i32 %v0_40a201, { 1, 0 }
  uselistorder i32 %v2_40a1f1, { 2, 0, 1 }
  uselistorder i32 %v1_40a1ee, { 1, 0 }
  uselistorder i32 %v4_40a1e9, { 1, 0 }
  uselistorder i32 %v3_40a1e9, { 1, 0 }
  uselistorder i32 %v1_40a1e9, { 0, 2, 1, 3 }
  uselistorder i1 %v8_40a1e3, { 1, 0 }
  uselistorder i32 %v0_40a1d9, { 1, 0 }
  uselistorder i1 %v26_40a1d3, { 1, 0 }
  uselistorder i8 %v6_40a1d3, { 1, 0 }
  uselistorder i8 %v5_40a1d3, { 1, 0 }
  uselistorder i1 %v26_40a1cd, { 1, 0, 2 }
  uselistorder i8 %v6_40a1cd, { 2, 3, 0, 4, 1 }
  uselistorder i8 %v5_40a1cd, { 1, 0 }
  uselistorder i32 %v5_40a1a9, { 1, 0 }
  uselistorder i32 %v4_40a1a9, { 1, 0 }
  uselistorder i32 %v0_40a1a9, { 1, 2, 0 }
  uselistorder i1 %v7_40a1a7, { 1, 0 }
  uselistorder i32 %v0_40a1a7, { 1, 0 }
  uselistorder i8* %tmp107, { 1, 0 }
  uselistorder i32 %v5_40a179, { 3, 0, 4, 1, 2, 5, 6 }
  uselistorder i32 %v5_40a163, { 1, 0, 3, 2 }
  uselistorder i32 %v4_40a163, { 1, 0 }
  uselistorder i1 %v12_40a160, { 1, 0 }
  uselistorder i32 %v0_40a160, { 1, 0 }
  uselistorder i32 %v2_40a151, { 2, 1, 0, 3 }
  uselistorder i8 %v2_40a12c, { 1, 0 }
  uselistorder i8 %v2_40a12a, { 1, 0 }
  uselistorder i8 %v2_40a128, { 1, 0 }
  uselistorder i8 %v2_40a126, { 1, 0 }
  uselistorder i8 %v2_40a124, { 1, 0 }
  uselistorder i8 %v2_40a122, { 1, 0 }
  uselistorder i8 %v2_40a120, { 1, 0 }
  uselistorder i32 %v2_40a115, { 1, 0 }
  uselistorder i32 %v0_40a0f4, { 1, 0 }
  uselistorder i32 %v0_40a0ee, { 1, 0 }
  uselistorder i32 %v0_40a0ce, { 1, 0 }
  uselistorder i32 %v1_40a0bd, { 1, 0, 2 }
  uselistorder i32 %v5_40a09c, { 1, 0 }
  uselistorder i32 %v4_40a09c, { 1, 0 }
  uselistorder i1 %v7_40a091, { 1, 0 }
  uselistorder i32 %v5_40a081, { 1, 0 }
  uselistorder i32 %v4_40a081, { 1, 0 }
  uselistorder i32 %v0_40a081, { 1, 2, 0 }
  uselistorder i1 %v21_40a07b, { 1, 0 }
  uselistorder i32 %v4_40a07b, { 1, 0 }
  uselistorder i32 %v3_40a07b, { 1, 0 }
  uselistorder i1 %v7_40a079, { 1, 0 }
  uselistorder i32 %v1_40a079, { 1, 2, 0, 3, 4 }
  uselistorder i32 %v2_40a077, { 1, 0 }
  uselistorder i32 %v1_40a06e, { 1, 0 }
  uselistorder i32 %v0_40a06e, { 1, 0 }
  uselistorder i32 %v7_40a046, { 1, 0, 4, 3, 2, 5 }
  uselistorder i32 %v0_40a026, { 1, 0 }
  uselistorder i8 %v6_40a012, { 1, 0 }
  uselistorder i8 %v5_40a012, { 1, 0 }
  uselistorder i8 %v1_40a012, { 2, 1, 0 }
  uselistorder i1 %v7_40a00c, { 1, 0, 2 }
  uselistorder i32 %v0_40a00c, { 1, 0 }
  uselistorder i32 %v4_40a003, { 1, 0, 2 }
  uselistorder i1 %v5_40a000, { 1, 0 }
  uselistorder i32 %v1_40a000, { 1, 0 }
  uselistorder i32 %v5_409ff4, { 1, 0 }
  uselistorder i32 %v4_409ff4, { 1, 0 }
  uselistorder i1 %v5_409fe8, { 1, 0, 2 }
  uselistorder i8 %v0_409fe8, { 1, 0 }
  uselistorder i32 %v0_409fe5, { 1, 0 }
  uselistorder i32 %v0_409fce, { 1, 0 }
  uselistorder i32 %v5_409fcb, { 1, 0 }
  uselistorder i8 %v2_409fc7, { 1, 0 }
  uselistorder i32 %v2_409f99, { 1, 0 }
  uselistorder i32 %v4_409f81, { 1, 0 }
  uselistorder i32 %v3_409f81, { 1, 0 }
  uselistorder i32 %v1_409f81, { 1, 0, 2 }
  uselistorder i1 %v27_409f7f, { 1, 0 }
  uselistorder i8 %v1_409f7f, { 1, 0 }
  uselistorder i32 %v1_409f62, { 1, 0 }
  uselistorder i32 %v0_409f5f, { 1, 0 }
  uselistorder i32 %v0_409f55, { 1, 0 }
  uselistorder i32 %v4_409f41, { 1, 0, 2 }
  uselistorder i32 %v0_409efc, { 1, 0 }
  uselistorder i32 %v5_409ef6, { 0, 2, 1 }
  uselistorder i32 %v4_409ef6, { 1, 0 }
  uselistorder i32 %v0_409ef6, { 1, 2, 0 }
  uselistorder i1 %v23_409eef, { 1, 0 }
  uselistorder i32 %v4_409eef, { 1, 0 }
  uselistorder i1 %v7_409eed, { 1, 0 }
  uselistorder i32 %v2_409eed, { 1, 0 }
  uselistorder i32 %v2_409edb, { 1, 0 }
  uselistorder i32 %v0_409ebf, { 1, 0 }
  uselistorder i32 %v1_409eb0, { 0, 2, 1 }
  uselistorder i8 %v8_409ea1, { 1, 0 }
  uselistorder i8 %v7_409ea1, { 1, 0 }
  uselistorder i8 %v1_409ea1, { 1, 2, 0 }
  uselistorder i1 %v26_409e9b, { 1, 0 }
  uselistorder i32 %v5_409e9b, { 0, 2, 1 }
  uselistorder i32 %v4_409e9b, { 1, 0 }
  uselistorder i32 %v0_409e9b, { 1, 2, 0 }
  uselistorder i1 %v26_409e95, { 1, 0 }
  uselistorder i32 %v5_409e95, { 1, 0 }
  uselistorder i32 %v4_409e95, { 1, 0 }
  uselistorder i32 %v0_409e95, { 1, 2, 0 }
  uselistorder i1 %v11_409e8e, { 1, 0 }
  uselistorder i32 %v0_409e8e, { 1, 0 }
  uselistorder i32 %v5_409e4e, { 1, 0, 2 }
  uselistorder i1 %v9_409e49, { 1, 0 }
  uselistorder i8 %v4_409e49, { 1, 0 }
  uselistorder i32 %v2_409e49, { 2, 1, 0, 3 }
  uselistorder i32 %v0_409e03, { 1, 0 }
  uselistorder i32 %v0_409dd9, { 1, 0, 2 }
  uselistorder i32 %v4_409dbc, { 1, 0, 3, 2 }
  uselistorder i8 %v3_409da1, { 1, 0 }
  uselistorder i8 %v2_409d9f, { 1, 0 }
  uselistorder i8 %v2_409d9d, { 1, 0 }
  uselistorder i8 %v2_409d9b, { 1, 0 }
  uselistorder i8 %v2_409d99, { 1, 0 }
  uselistorder i8 %v2_409d97, { 1, 0 }
  uselistorder i32 %v1_409d77, { 2, 0, 1 }
  uselistorder i32 %v0_409d75, { 1, 0 }
  uselistorder i32 %v0_409d69, { 1, 0 }
  uselistorder i32 %v0_409d58, { 1, 0 }
  uselistorder i32 %v2_409d44, { 1, 0, 2 }
  uselistorder i32 %v5_409d2e, { 1, 0, 2 }
  uselistorder i1 %v26_409d28, { 1, 0 }
  uselistorder i8 %v6_409d28, { 1, 0 }
  uselistorder i8 %v5_409d28, { 1, 0 }
  uselistorder i1 %v25_409d26, { 1, 2, 0 }
  uselistorder i32 %v4_409d26, { 1, 0 }
  uselistorder i32 %v0_409d26, { 1, 0 }
  uselistorder i32 %v1_409d1b, { 2, 1, 0, 3 }
  uselistorder i32 %v10_409cee, { 1, 0, 2 }
  uselistorder i32 %v1_409ccd, { 1, 0 }
  uselistorder i8 %v6_409cbb, { 1, 0 }
  uselistorder i8 %v5_409cbb, { 1, 0 }
  uselistorder i8 %v3_409cbb, { 1, 0, 2 }
  uselistorder i1 %v12_409cb8, { 1, 0, 2 }
  uselistorder i8 %v5_409cb6, { 1, 0 }
  uselistorder i32 %v3_409ca7, { 0, 2, 1 }
  uselistorder i8 %v2_409c8a, { 1, 0 }
  uselistorder i8 %v2_409c88, { 1, 0 }
  uselistorder i8 %v2_409c86, { 1, 0 }
  uselistorder i32 %v0_409c80, { 1, 0 }
  uselistorder i32 %v5_409c52, { 1, 0 }
  uselistorder i32 %v4_409c52, { 1, 0 }
  uselistorder i32 %v0_409c52, { 1, 2, 0 }
  uselistorder i1 %v5_409c4f, { 1, 0 }
  uselistorder i32 %v0_409c1c, { 1, 0 }
  uselistorder i32 %v0_409c06, { 1, 0 }
  uselistorder i32 %v0_409bfa, { 1, 0 }
  uselistorder i32 %v5_409b96, { 1, 0 }
  uselistorder i32 %v4_409b96, { 1, 0 }
  uselistorder i1 %v13_409b8a, { 1, 0 }
  uselistorder i32 %v0_409b8a, { 1, 0 }
  uselistorder i32 %v4_409b87, { 1, 0 }
  uselistorder i1 %v7_409b85, { 1, 0 }
  uselistorder i32 %v2_409b85, { 1, 0, 2 }
  uselistorder i32 %v5_409b73, { 1, 0, 2 }
  uselistorder i16** %stack_var_-268, { 4, 3, 2, 1, 0 }
  uselistorder i32* %esi.global-to-local, { 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 71, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 214, 215, 216, 217, 218, 219 }
  uselistorder i32* %edx.global-to-local, { 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246 }
  uselistorder i32* %edi.global-to-local, { 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 65, 66, 64, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 83, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 106, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 152, 151, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232 }
  uselistorder i32* %ecx.global-to-local, { 0, 2, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 75, 73, 74, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 228, 229, 230, 231, 232, 233, 234, 235, 236 }
  uselistorder i32* %ebx.global-to-local, { 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 81, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293 }
  uselistorder i32* %eax.global-to-local, { 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 369, 367, 368, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 203, 202, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 241, 235, 236, 242, 237, 238, 239, 240, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 267, 261, 262, 263, 264, 265, 266, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 286, 285, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418 }
  uselistorder i1* %cf.global-to-local, { 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360 }
  uselistorder i32 4763908, { 1, 0 }
  uselistorder i32* inttoptr (i32 4763908 to i32*), { 1, 2, 0 }
  uselistorder i32 4763759, { 1, 0 }
  uselistorder i32* inttoptr (i32 4763759 to i32*), { 1, 0 }
  uselistorder i8 -61, { 1, 0, 2 }
  uselistorder i8 61, { 0, 2, 1 }
  uselistorder i32 4763944, { 1, 0 }
  uselistorder i32 4764154, { 1, 0 }
  uselistorder i32 -120, { 1, 2, 0 }
  uselistorder i32 113, { 2, 3, 5, 6, 4, 0, 1 }
  uselistorder i32 -39, { 1, 0 }
  uselistorder i32 -73, { 1, 2, 0, 3 }
  uselistorder i32 4764142, { 1, 0 }
  uselistorder i32* inttoptr (i32 4763987 to i32*), { 2, 3, 0, 1 }
  uselistorder i32 -61, { 2, 3, 0, 1 }
  uselistorder i32 234, { 2, 3, 1, 0 }
  uselistorder i32 3, { 1, 0 }
  uselistorder i32* inttoptr (i32 4763888 to i32*), { 1, 0, 2, 3, 4 }
  uselistorder i32 69, { 1, 2, 3, 0, 4 }
  uselistorder i32 141, { 1, 2, 3, 0 }
  uselistorder i32* inttoptr (i32 4763901 to i32*), { 1, 2, 0 }
  uselistorder i32 4763663, { 1, 0 }
  uselistorder i32 4764120, { 1, 0 }
  uselistorder i32 4763859, { 1, 0 }
  uselistorder i32* inttoptr (i32 4764041 to i32*), { 2, 3, 4, 5, 0, 1, 6, 7, 8 }
  uselistorder i8* inttoptr (i32 4763810 to i8*), { 1, 0 }
  uselistorder i32* inttoptr (i32 4763785 to i32*), { 1, 0 }
  uselistorder i32* inttoptr (i32 4763935 to i32*), { 0, 3, 4, 1, 2 }
  uselistorder i32 -5, { 3, 0, 2, 1 }
  uselistorder i32* inttoptr (i32 4763884 to i32*), { 1, 2, 3, 4, 5, 6, 0 }
  uselistorder i32* inttoptr (i32 4764121 to i32*), { 1, 2, 3, 4, 5, 6, 7, 8, 0 }
  uselistorder i32 56, { 0, 1, 3, 2, 4 }
  uselistorder i32 50, { 2, 0, 3, 1 }
  uselistorder i32 4764003, { 1, 0 }
  uselistorder i32* inttoptr (i32 4764003 to i32*), { 2, 3, 0, 1 }
  uselistorder i32 4764109, { 1, 0 }
  uselistorder i32 -41, { 0, 3, 2, 1 }
  uselistorder i32 -14, { 1, 0 }
  uselistorder i32* inttoptr (i32 4763853 to i32*), { 2, 3, 0, 1 }
  uselistorder i32 29, { 2, 3, 1, 0, 4 }
  uselistorder i32* inttoptr (i32 4763992 to i32*), { 2, 3, 6, 7, 0, 1, 4, 5 }
  uselistorder i32 247, { 1, 0 }
  uselistorder i32* inttoptr (i32 4763870 to i32*), { 2, 3, 4, 5, 6, 0, 1 }
  uselistorder i32* inttoptr (i32 4764031 to i32*), { 2, 3, 0, 1, 4, 5 }
  uselistorder i32 4764004, { 1, 0 }
  uselistorder i32 -124, { 0, 2, 1 }
  uselistorder i32* inttoptr (i32 4764068 to i32*), { 2, 3, 4, 5, 8, 9, 6, 7, 0, 1 }
  uselistorder i32 4763656, { 1, 0 }
  uselistorder i32* inttoptr (i32 4763656 to i32*), { 2, 0, 1 }
  uselistorder i32* inttoptr (i32 4763936 to i32*), { 2, 3, 0, 1 }
  uselistorder i32 4763751, { 1, 0 }
  uselistorder i8* inttoptr (i32 4763751 to i8*), { 1, 0 }
  uselistorder i32 -78, { 2, 0, 3, 1 }
  uselistorder i32 79, { 2, 0, 3, 1 }
  uselistorder i32 4763810, { 1, 0 }
  uselistorder i32* inttoptr (i32 4764052 to i32*), { 4, 5, 0, 1, 2, 3 }
  uselistorder i32 33, { 4, 2, 5, 0, 1, 3 }
  uselistorder i32 -128, { 2, 3, 0, 1, 4 }
  uselistorder i32* inttoptr (i32 4763863 to i32*), { 2, 3, 0, 1 }
  uselistorder i32 67, { 1, 3, 4, 2, 0 }
  uselistorder i32 -105, { 0, 2, 1 }
  uselistorder i32 230, { 2, 0, 1 }
  uselistorder i32 109, { 1, 0 }
  uselistorder i32* inttoptr (i32 4763940 to i32*), { 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 10 }
  uselistorder i32 -44, { 1, 0 }
  uselistorder i32 87, { 1, 2, 3, 0 }
  uselistorder i32* inttoptr (i32 4763670 to i32*), { 2, 3, 4, 5, 6, 0, 1 }
  uselistorder i32 -3, { 2, 3, 1, 4, 0 }
  uselistorder i32 -37, { 1, 0 }
  uselistorder i32 208, { 0, 2, 3, 1 }
  uselistorder i32 233, { 1, 2, 0 }
  uselistorder i32* inttoptr (i32 4763867 to i32*), { 1, 2, 3, 4, 0 }
  uselistorder i32 4764023, { 1, 0 }
  uselistorder i32 114, { 2, 5, 3, 6, 0, 4, 7, 1 }
  uselistorder i32 142, { 1, 2, 0, 3 }
  uselistorder i32 61, { 0, 1, 3, 2 }
  uselistorder i32 102, { 0, 3, 4, 5, 6, 1, 7, 2 }
  uselistorder i32 101, { 2, 3, 4, 5, 6, 0, 1 }
  uselistorder i32* inttoptr (i32 4763816 to i32*), { 2, 3, 4, 5, 0, 1 }
  uselistorder i32 78, { 1, 0, 2 }
  uselistorder i32 -84, { 1, 0 }
  uselistorder i32 47, { 0, 2, 1 }
  uselistorder i32* inttoptr (i32 4763916 to i32*), { 2, 3, 4, 5, 6, 0, 1 }
  uselistorder i32 25, { 3, 4, 0, 1, 2 }
  uselistorder i32* inttoptr (i32 4763668 to i32*), { 2, 3, 4, 5, 0, 1 }
  uselistorder i8 -108, { 1, 0 }
  uselistorder i32* inttoptr (i32 4763775 to i32*), { 2, 3, 4, 5, 6, 7, 8, 0, 1 }
  uselistorder i32 4763674, { 1, 0 }
  uselistorder i32* inttoptr (i32 4763744 to i32*), { 2, 3, 0, 1 }
  uselistorder i32 4763673, { 1, 0 }
  uselistorder i32 4763906, { 1, 0 }
  uselistorder i32 19, { 1, 2, 3, 0, 4 }
  uselistorder i32 238, { 0, 2, 1 }
  uselistorder i32 -88, { 3, 0, 4, 1, 2 }
  uselistorder i32 127, { 1, 2, 3, 0 }
  uselistorder i32* inttoptr (i32 4764014 to i32*), { 5, 6, 7, 4, 0, 1, 2, 3 }
  uselistorder i32* inttoptr (i32 4763761 to i32*), { 2, 3, 4, 5, 6, 0, 1 }
  uselistorder i32 4763758, { 1, 0 }
  uselistorder i32* inttoptr (i32 4763986 to i32*), { 1, 2, 3, 4, 5, 6, 0 }
  uselistorder i32 104, { 1, 2, 0 }
  uselistorder i32* inttoptr (i32 4763821 to i32*), { 3, 4, 5, 6, 7, 8, 0, 1, 2 }
  uselistorder i32 123, { 0, 2, 3, 1 }
  uselistorder i32* inttoptr (i32 4764123 to i32*), { 2, 3, 4, 5, 6, 7, 8, 9, 0, 1 }
  uselistorder i32* inttoptr (i32 4763835 to i32*), { 3, 4, 5, 0, 1, 2 }
  uselistorder i32 164, { 1, 2, 3, 0 }
  uselistorder i32* inttoptr (i32 4763943 to i32*), { 4, 5, 6, 7, 0, 1, 2, 3 }
  uselistorder i32 -107, { 1, 0, 2 }
  uselistorder i32 4764130, { 1, 0 }
  uselistorder i32 -42, { 1, 2, 3, 4, 0 }
  uselistorder i32* inttoptr (i32 4763697 to i32*), { 1, 2, 3, 4, 0 }
  uselistorder i32* inttoptr (i32 4764129 to i32*), { 2, 3, 0, 1 }
  uselistorder i32 -90, { 3, 4, 5, 0, 1, 2, 6 }
  uselistorder i32 -67, { 4, 1, 2, 3, 0, 5, 6 }
  uselistorder i32* inttoptr (i32 4763879 to i32*), { 0, 1, 2, 3, 5, 4 }
  uselistorder i32 77, { 2, 1, 0, 3 }
  uselistorder i32* inttoptr (i32 4764094 to i32*), { 0, 1, 2, 3, 4, 5, 6, 11, 12, 13, 14, 7, 8, 9, 10 }
  uselistorder i32 40, { 4, 0, 1, 5, 6, 2, 3, 7 }
  uselistorder i32 -98, { 1, 2, 3, 4, 0 }
  uselistorder i32 216, { 2, 1, 0 }
  uselistorder i32 -76, { 1, 0 }
  uselistorder i32 75, { 1, 2, 0, 3 }
  uselistorder i32 76, { 2, 1, 0 }
  uselistorder i32 95, { 1, 0, 3, 2 }
  uselistorder i32 245, { 1, 2, 0 }
  uselistorder i32* inttoptr (i32 4764138 to i32*), { 2, 3, 0, 1 }
  uselistorder i32 121, { 6, 7, 0, 4, 5, 1, 2, 3 }
  uselistorder i32 -103, { 1, 0, 2 }
  uselistorder i32 -35, { 3, 0, 4, 1, 2, 5 }
  uselistorder i32 35, { 1, 2, 0, 3, 4 }
  uselistorder i32 4763687, { 1, 0 }
  uselistorder i32* inttoptr (i32 4763844 to i32*), { 1, 2, 3, 0 }
  uselistorder i32* inttoptr (i32 4763692 to i32*), { 1, 2, 3, 0 }
  uselistorder i32 4763691, { 1, 0 }
  uselistorder i32 235, { 1, 0 }
  uselistorder i32* inttoptr (i32 4763949 to i32*), { 4, 5, 6, 7, 8, 0, 1, 2, 3 }
  uselistorder i32 83, { 1, 2, 0 }
  uselistorder i32 -17, { 2, 0, 1, 3 }
  uselistorder i32* inttoptr (i32 4764070 to i32*), { 0, 1, 3, 4, 2 }
  uselistorder i32 -26, { 1, 0 }
  uselistorder i32 26, { 0, 2, 1, 3 }
  uselistorder i32 -53, { 0, 2, 1, 3, 4, 5, 6, 7 }
  uselistorder i32 106, { 2, 0, 1 }
  uselistorder i32 -9, { 0, 2, 1 }
  uselistorder i32 9, { 3, 4, 0, 5, 1, 6, 2 }
  uselistorder i32 156, { 3, 2, 1, 4, 0 }
  uselistorder i32 157, { 1, 0, 2 }
  uselistorder i32* inttoptr (i32 4763989 to i32*), { 2, 3, 4, 0, 1 }
  uselistorder i32* inttoptr (i32 4764053 to i32*), { 2, 3, 4, 5, 6, 0, 1 }
  uselistorder i32 4763975, { 1, 0 }
  uselistorder i32 46, { 0, 2, 1, 3, 4 }
  uselistorder i32 -25, { 1, 0 }
  uselistorder i32* inttoptr (i32 4763714 to i32*), { 0, 1, 2, 3, 6, 7, 4, 5 }
  uselistorder i32 195, { 1, 2, 0 }
  uselistorder i32* inttoptr (i32 4763787 to i32*), { 0, 1, 2, 3, 4, 8, 5, 6, 7 }
  uselistorder i32 52, { 1, 0, 2 }
  uselistorder i32 159, { 2, 3, 0, 1 }
  uselistorder i32 4764063, { 1, 0 }
  uselistorder i32* inttoptr (i32 4764063 to i32*), { 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 0, 1 }
  uselistorder i32 17, { 1, 0, 2, 3 }
  uselistorder i32 49, { 0, 1, 2, 3, 4, 6, 5 }
  uselistorder i32* inttoptr (i32 4763799 to i32*), { 2, 3, 4, 5, 6, 7, 8, 0, 1 }
  uselistorder i32 30, { 1, 2, 0 }
  uselistorder i32 -118, { 0, 4, 5, 1, 6, 7, 3, 2 }
  uselistorder i32 112, { 0, 1, 2, 4, 3 }
  uselistorder i32 -112, { 1, 0 }
  uselistorder i32* inttoptr (i32 4763988 to i32*), { 0, 1, 4, 5, 2, 3 }
  uselistorder i32* inttoptr (i32 4764106 to i32*), { 1, 2, 3, 4, 5, 6, 7, 8, 0 }
  uselistorder i32 53, { 1, 2, 0, 3 }
  uselistorder i32 -54, { 1, 2, 0, 3, 4 }
  uselistorder i32 163, { 1, 0 }
  uselistorder i32* inttoptr (i32 4764081 to i32*), { 1, 2, 3, 4, 5, 0 }
  uselistorder i8 88, { 1, 0 }
  uselistorder i32 4763770, { 1, 0 }
  uselistorder i32* inttoptr (i32 4764030 to i32*), { 2, 0, 1 }
  uselistorder i32 41, { 1, 2, 0, 3 }
  uselistorder i32 65280, { 5, 6, 7, 2, 3, 9, 8, 11, 10, 12, 13, 38, 14, 15, 16, 17, 18, 19, 21, 20, 22, 24, 23, 25, 26, 39, 40, 27, 28, 1, 0, 29, 4, 30, 31, 32, 33, 34, 35, 41, 36, 37 }
  uselistorder i32 4763899, { 1, 0 }
  uselistorder i32* inttoptr (i32 4763827 to i32*), { 2, 3, 4, 0, 1 }
  uselistorder i32 4764126, { 1, 0 }
  uselistorder i32* inttoptr (i32 4764126 to i32*), { 1, 2, 3, 4, 5, 0 }
  uselistorder i32* inttoptr (i32 4763653 to i32*), { 1, 2, 3, 0 }
  uselistorder i32 32, { 2, 0, 4, 5, 1, 3 }
  uselistorder i32 -11, { 1, 0, 2, 3, 4 }
  uselistorder i32 -10, { 2, 1, 4, 5, 0, 3 }
  uselistorder i32 -28, { 4, 5, 6, 7, 1, 2, 0, 3 }
  uselistorder i32 4763901, { 1, 0 }
  uselistorder i32* inttoptr (i32 4763808 to i32*), { 4, 5, 6, 0, 1, 2, 3 }
  uselistorder i32* inttoptr (i32 4764013 to i32*), { 0, 1, 4, 2, 3 }
  uselistorder i32* inttoptr (i32 4763771 to i32*), { 2, 3, 0, 1 }
  uselistorder i32 4764123, { 1, 0 }
  uselistorder i32 -80, { 4, 1, 2, 3, 6, 0, 5 }
  uselistorder i32 80, { 3, 4, 1, 5, 0, 2 }
  uselistorder i32* inttoptr (i32 4763769 to i32*), { 0, 1, 2, 5, 3, 4 }
  uselistorder i32 88, { 3, 4, 0, 5, 1, 2 }
  uselistorder i32 4763797, { 2, 1, 0 }
  uselistorder i32* inttoptr (i32 4763723 to i32*), { 1, 2, 0 }
  uselistorder i32 228, { 1, 2, 0 }
  uselistorder i32 66, { 0, 1, 2, 4, 3 }
  uselistorder i32* inttoptr (i32 4763747 to i32*), { 2, 0, 1 }
  uselistorder i32* inttoptr (i32 4764128 to i32*), { 2, 3, 4, 5, 7, 6, 0, 1 }
  uselistorder i32 -46, { 0, 2, 3, 1 }
  uselistorder i32 -64, { 1, 2, 5, 0, 3, 4 }
  uselistorder i32 189, { 1, 0 }
  uselistorder i32 4763664, { 1, 0 }
  uselistorder i32* inttoptr (i32 4763828 to i32*), { 0, 1, 6, 7, 2, 3, 4, 5 }
  uselistorder i32* inttoptr (i32 4763969 to i32*), { 0, 3, 1, 2 }
  uselistorder i32 119, { 0, 2, 1 }
  uselistorder i8* inttoptr (i32 4763923 to i8*), { 2, 0, 1 }
  uselistorder i32* inttoptr (i32 4763895 to i32*), { 0, 1, 8, 2, 3, 4, 5, 6, 7 }
  uselistorder i32 108, { 0, 5, 6, 1, 2, 3, 4 }
  uselistorder i32 -109, { 1, 0, 2 }
  uselistorder i32* inttoptr (i32 4763832 to i32*), { 0, 1, 2, 4, 3 }
  uselistorder i32* inttoptr (i32 4763824 to i32*), { 1, 0 }
  uselistorder i32 118, { 4, 1, 5, 6, 0, 7, 8, 9, 2, 10, 3 }
  uselistorder i32 4764056, { 1, 0 }
  uselistorder i32* inttoptr (i32 4764049 to i32*), { 0, 5, 1, 2, 3, 4 }
  uselistorder i32 14, { 0, 2, 3, 1 }
  uselistorder i32 4763753, { 1, 2, 0 }
  uselistorder i32* @ebp, { 2, 1, 0 }
}

define i32 @function_40bd72() local_unnamed_addr {
dec_label_pc_40bd72:
  %cf.global-to-local = alloca i1, align 1
  %df.global-to-local = alloca i1, align 1
  %eax.global-to-local = alloca i32, align 4
  %ebp.global-to-local = alloca i32, align 4
  %ebx.global-to-local = alloca i32, align 4
  %ecx.global-to-local = alloca i32, align 4
  %edi.global-to-local = alloca i32, align 4
  %edx.global-to-local = alloca i32, align 4
  %es.global-to-local = alloca i16, align 2
  %esi.global-to-local = alloca i32, align 4
  %st0.global-to-local = alloca x86_fp80, align 4
  store x86_fp80 0xK00000000000000000000, x86_fp80* %st0.global-to-local, align 4
  store i16 0, i16* %es.global-to-local, align 2
  %tmp = call i32 @__decompiler_undefined_function_3()
  %tmp30 = call i16 @__decompiler_undefined_function_5()
  %tmp31 = call i8* @__decompiler_undefined_function_1()
  %stack_var_-9 = alloca i64, align 8
  %stack_var_-13 = alloca i8, align 1
  %stack_var_-45 = alloca i32, align 4
  %v0_40bd72 = load i32, i32* @eax, align 4
  %v1_40bd72 = load i32, i32* inttoptr (i32 4763878 to i32*), align 4
  %v2_40bd72 = load i1, i1* @cf, align 1
  %v3_40bd72 = zext i1 %v2_40bd72 to i32
  %v4_40bd72 = add i32 %v1_40bd72, %v0_40bd72
  %v5_40bd72 = add i32 %v4_40bd72, %v3_40bd72
  store i32 %v5_40bd72, i32* %eax.global-to-local, align 4
  %v0_40bd78 = load i32, i32* inttoptr (i32 4763700 to i32*), align 4
  %v1_40bd78 = load i32, i32* @ebx, align 4
  %v2_40bd78 = add i32 %v1_40bd78, %v0_40bd78
  store i32 %v2_40bd78, i32* inttoptr (i32 4763700 to i32*), align 4
  %v0_40bd7e = load i32, i32* @edi, align 4
  %v2_40bd7e = add i32 %v5_40bd72, %v0_40bd7e
  %v7_40bd7e = icmp ult i32 %v2_40bd7e, %v0_40bd7e
  store i32 %v2_40bd7e, i32* %edi.global-to-local, align 4
  %v0_40bd80 = load i32, i32* inttoptr (i32 4763957 to i32*), align 4
  %v2_40bd80 = zext i1 %v7_40bd7e to i32
  %v3_40bd80 = add i32 %v0_40bd80, 54
  %v4_40bd80 = add i32 %v3_40bd80, %v2_40bd80
  store i32 %v4_40bd80, i32* inttoptr (i32 4763957 to i32*), align 4
  %v0_40bd87 = load i32, i32* %eax.global-to-local, align 4
  %v1_40bd87 = and i32 %v0_40bd87, 20
  %v1_40bd8f = load i32, i32* @ebx, align 4
  %v2_40bd8f = add i32 %v1_40bd8f, 1
  store i32 %v2_40bd8f, i32* %ecx.global-to-local, align 4
  store i32 %v1_40bd87, i32* %eax.global-to-local, align 4
  %v1_40bd94 = load i32, i32* inttoptr (i32 4764065 to i32*), align 4
  %v4_40bd94 = add i32 %v1_40bd94, %v2_40bd8f
  store i32 %v4_40bd94, i32* %ecx.global-to-local, align 4
  %v0_40bd9a = load i32, i32* inttoptr (i32 4763929 to i32*), align 4
  %v1_40bd9a = xor i32 %v0_40bd9a, 63
  store i32 %v1_40bd9a, i32* inttoptr (i32 4763929 to i32*), align 4
  %v0_40bda1 = load i32, i32* %edi.global-to-local, align 4
  %v1_40bda1 = load i32, i32* @esi, align 4
  %v2_40bda1 = xor i32 %v1_40bda1, %v0_40bda1
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v2_40bda1, i32* %edi.global-to-local, align 4
  %v0_40bda3 = load i8, i8* inttoptr (i32 4764084 to i8*), align 4
  %v1_40bda3 = add i8 %v0_40bda3, 87
  %v5_40bda3 = icmp ult i8 %v0_40bda3, -87
  store i1 %v5_40bda3, i1* %cf.global-to-local, align 1
  store i8 %v1_40bda3, i8* inttoptr (i32 4764084 to i8*), align 4
  %v0_40bdaa = load i32, i32* inttoptr (i32 4764058 to i32*), align 4
  %v2_40bdaa = zext i1 %v5_40bda3 to i32
  %v3_40bdaa = add i32 %v0_40bdaa, 217
  %v4_40bdaa = add i32 %v3_40bdaa, %v2_40bdaa
  store i32 %v4_40bdaa, i32* inttoptr (i32 4764058 to i32*), align 4
  %v0_40bdb4 = load i32, i32* %edi.global-to-local, align 4
  %v1_40bdb4 = or i32 %v0_40bdb4, 72
  store i32 %v1_40bdb4, i32* %edi.global-to-local, align 4
  %v0_40bdb7 = load i32, i32* inttoptr (i32 4763685 to i32*), align 4
  %v3_40bdb7 = add i32 %v0_40bdb7, -13
  %v12_40bdb7 = icmp ult i32 %v0_40bdb7, 13
  store i1 %v12_40bdb7, i1* %cf.global-to-local, align 1
  store i32 %v3_40bdb7, i32* inttoptr (i32 4763685 to i32*), align 4
  store i32 0, i32* %eax.global-to-local, align 4
  %v4_40bdc6 = call i32* @EncodePointer(i32* null)
  %v5_40bdc6 = ptrtoint i32* %v4_40bdc6 to i32
  store i32 %v5_40bdc6, i32* %eax.global-to-local, align 4
  %v0_40bdcc = load i32, i32* inttoptr (i32 4763923 to i32*), align 4
  %v1_40bdcc = load i1, i1* %cf.global-to-local, align 1
  %v2_40bdcc = zext i1 %v1_40bdcc to i32
  %v3_40bdcc = add i32 %v0_40bdcc, -146
  %v4_40bdcc = add i32 %v3_40bdcc, %v2_40bdcc
  store i32 %v4_40bdcc, i32* inttoptr (i32 4763923 to i32*), align 4
  %v0_40bdd6 = load i32, i32* inttoptr (i32 4763836 to i32*), align 4
  %v1_40bdd6 = and i32 %v0_40bdd6, 110
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v1_40bdd6, i32* inttoptr (i32 4763836 to i32*), align 4
  %v0_40bddd = load i8, i8* inttoptr (i32 4764122 to i8*), align 2
  %v3_40bddd = udiv i32 %v5_40bdc6, 256
  %v4_40bddd = trunc i32 %v3_40bddd to i8
  %v5_40bddd = sub i8 %v0_40bddd, %v4_40bddd
  store i8 %v5_40bddd, i8* inttoptr (i32 4764122 to i8*), align 2
  %v0_40bde3 = load i32, i32* inttoptr (i32 4764018 to i32*), align 4
  %v1_40bde3 = load i32, i32* @ebx, align 4
  %v2_40bde3 = sub i32 %v0_40bde3, %v1_40bde3
  %v7_40bde3 = icmp ult i32 %v0_40bde3, %v1_40bde3
  store i32 %v2_40bde3, i32* inttoptr (i32 4764018 to i32*), align 4
  %v0_40bde9 = load i32, i32* @ebx, align 4
  %v2_40bde9 = zext i1 %v7_40bde3 to i32
  %v3_40bde9 = add i32 %v0_40bde9, -121
  %v4_40bde9 = add i32 %v3_40bde9, %v2_40bde9
  %v22_40bde9 = icmp ule i32 %v4_40bde9, %v0_40bde9
  %v23_40bde9 = icmp ugt i32 %v0_40bde9, 120
  %v24_40bde9 = select i1 %v7_40bde3, i1 %v22_40bde9, i1 %v23_40bde9
  store i32 %v4_40bde9, i32* %ebx.global-to-local, align 4
  %v0_40bdec = load i32, i32* inttoptr (i32 4763737 to i32*), align 4
  %v3_40bdec = select i1 %v24_40bde9, i32 176, i32 175
  %v4_40bdec = add i32 %v3_40bdec, %v0_40bdec
  %v21_40bdec = icmp ule i32 %v4_40bdec, %v0_40bdec
  %v22_40bdec = icmp ugt i32 %v0_40bdec, -176
  %v23_40bdec = select i1 %v24_40bde9, i1 %v21_40bdec, i1 %v22_40bdec
  store i1 %v23_40bdec, i1* %cf.global-to-local, align 1
  store i32 %v4_40bdec, i32* inttoptr (i32 4763737 to i32*), align 4
  %v0_40bdf6 = load i8, i8* inttoptr (i32 4764110 to i8*), align 2
  %v1_40bdf6 = load i32, i32* %ebx.global-to-local, align 4
  %v2_40bdf6 = udiv i32 %v1_40bdf6, 256
  %v3_40bdf6 = trunc i32 %v2_40bdf6 to i8
  %v4_40bdf6 = add i8 %v3_40bdf6, %v0_40bdf6
  store i8 %v4_40bdf6, i8* inttoptr (i32 4764110 to i8*), align 2
  store i32 -93, i32* %edx.global-to-local, align 4
  %v0_40be04 = load i32, i32* %edi.global-to-local, align 4
  %v1_40be04 = or i32 %v0_40be04, -99
  store i32 %v1_40be04, i32* %edi.global-to-local, align 4
  %v0_40be07 = load i32, i32* @esi, align 4
  %v1_40be07 = load i32, i32* inttoptr (i32 4763932 to i32*), align 4
  %v2_40be07 = sub i32 %v0_40be07, %v1_40be07
  %v7_40be07 = icmp ult i32 %v0_40be07, %v1_40be07
  store i1 %v7_40be07, i1* %cf.global-to-local, align 1
  store i32 %v2_40be07, i32* %esi.global-to-local, align 4
  call void @__pseudo_call(i32 4242965)
  %v0_40be15 = load i32, i32* inttoptr (i32 4763702 to i32*), align 4
  %v1_40be15 = xor i32 %v0_40be15, 20
  store i32 %v1_40be15, i32* inttoptr (i32 4763702 to i32*), align 4
  %v0_40be1c = load i32, i32* inttoptr (i32 4763800 to i32*), align 8
  %v1_40be1c = xor i32 %v0_40be1c, 246
  store i32 %v1_40be1c, i32* inttoptr (i32 4763800 to i32*), align 8
  %v0_40be26 = load i32, i32* inttoptr (i32 4763922 to i32*), align 4
  %v3_40be26 = add i32 %v0_40be26, -115
  store i32 %v3_40be26, i32* inttoptr (i32 4763922 to i32*), align 4
  %v0_40be2d = load i32, i32* %ebx.global-to-local, align 4
  %v1_40be2d = load i32, i32* inttoptr (i32 4764135 to i32*), align 4
  %v2_40be2d = or i32 %v1_40be2d, %v0_40be2d
  store i32 %v2_40be2d, i32* %ebx.global-to-local, align 4
  %v0_40be33 = load i32, i32* %edi.global-to-local, align 4
  %v1_40be33 = add i32 %v0_40be33, 34
  %v5_40be33 = icmp ult i32 %v0_40be33, -34
  store i32 %v1_40be33, i32* %edi.global-to-local, align 4
  %v0_40be36 = load i32, i32* inttoptr (i32 4763731 to i32*), align 4
  %v2_40be36 = zext i1 %v5_40be33 to i32
  %v3_40be36 = add i32 %v0_40be36, -127
  %v4_40be36 = add i32 %v3_40be36, %v2_40be36
  store i32 %v4_40be36, i32* inttoptr (i32 4763731 to i32*), align 4
  %v0_40be3d = load i32, i32* %ebx.global-to-local, align 4
  %v1_40be3d = load i32, i32* %edi.global-to-local, align 4
  %v2_40be3d = sub i32 %v0_40be3d, %v1_40be3d
  store i32 %v2_40be3d, i32* %ebx.global-to-local, align 4
  %v0_40be3f = load i32, i32* inttoptr (i32 4764089 to i32*), align 4
  %v2_40be3f = sub i32 %v0_40be3f, %v2_40be3d
  %v7_40be3f = icmp ult i32 %v0_40be3f, %v2_40be3d
  store i1 %v7_40be3f, i1* %cf.global-to-local, align 1
  store i32 %v2_40be3f, i32* inttoptr (i32 4764089 to i32*), align 4
  %v0_40be45 = load i8, i8* inttoptr (i32 4764092 to i8*), align 4
  %v1_40be45 = add i8 %v0_40be45, 21
  %v5_40be45 = icmp ult i8 %v0_40be45, -21
  store i1 %v5_40be45, i1* %cf.global-to-local, align 1
  store i8 %v1_40be45, i8* inttoptr (i32 4764092 to i8*), align 4
  %v0_40be4c = load i32, i32* %esi.global-to-local, align 4
  %v1_40be4c = load i32, i32* inttoptr (i32 4764033 to i32*), align 4
  %v3_40be4c = zext i1 %v5_40be45 to i32
  %v4_40be4c = add i32 %v1_40be4c, %v0_40be4c
  %v5_40be4c = add i32 %v4_40be4c, %v3_40be4c
  store i32 %v5_40be4c, i32* %esi.global-to-local, align 4
  %v0_40be52 = load i32, i32* %edx.global-to-local, align 4
  %v1_40be52 = load i32, i32* inttoptr (i32 4763925 to i32*), align 4
  %v2_40be52 = sub i32 %v0_40be52, %v1_40be52
  store i32 %v2_40be52, i32* %edx.global-to-local, align 4
  %v0_40be58 = load i32, i32* inttoptr (i32 4763959 to i32*), align 4
  %v1_40be58 = load i32, i32* %ebx.global-to-local, align 4
  %v2_40be58 = xor i32 %v1_40be58, %v0_40be58
  store i32 %v2_40be58, i32* inttoptr (i32 4763959 to i32*), align 4
  %v0_40be5e = load i32, i32* %esi.global-to-local, align 4
  %v1_40be5e = load i32, i32* inttoptr (i32 4764071 to i32*), align 4
  %v4_40be5e = add i32 %v1_40be5e, %v0_40be5e
  store i32 %v4_40be5e, i32* %esi.global-to-local, align 4
  %v0_40be64 = load i32, i32* inttoptr (i32 4763957 to i32*), align 4
  %v1_40be64 = or i32 %v0_40be64, 23
  store i32 %v1_40be64, i32* inttoptr (i32 4763957 to i32*), align 4
  %v0_40be6b = load i32, i32* %edi.global-to-local, align 4
  %v1_40be6b = load i32, i32* inttoptr (i32 4763984 to i32*), align 16
  %v4_40be6b = add i32 %v1_40be6b, %v0_40be6b
  store i32 %v4_40be6b, i32* %edi.global-to-local, align 4
  %v2_40be71 = load i32, i32* %esi.global-to-local, align 4
  %v3_40be71 = sub i32 %v5_40bdc6, %v2_40be71
  %v8_40be71 = icmp ult i32 %v5_40bdc6, %v2_40be71
  store i32 %v3_40be71, i32* %eax.global-to-local, align 4
  %v0_40be73 = load i32, i32* %edx.global-to-local, align 4
  %v1_40be73 = load i32, i32* inttoptr (i32 4763713 to i32*), align 4
  %v3_40be73 = zext i1 %v8_40be71 to i32
  %v4_40be73 = add i32 %v1_40be73, %v0_40be73
  %v5_40be73 = add i32 %v4_40be73, %v3_40be73
  %v24_40be73 = icmp ule i32 %v5_40be73, %v0_40be73
  %v25_40be73 = icmp ult i32 %v4_40be73, %v0_40be73
  %v26_40be73 = select i1 %v8_40be71, i1 %v24_40be73, i1 %v25_40be73
  store i32 %v5_40be73, i32* %edx.global-to-local, align 4
  %v0_40be79 = load i32, i32* inttoptr (i32 4763855 to i32*), align 4
  %v3_40be79 = select i1 %v26_40be73, i32 45, i32 44
  %v4_40be79 = add i32 %v3_40be79, %v0_40be79
  %v21_40be79 = icmp ule i32 %v4_40be79, %v0_40be79
  %v22_40be79 = icmp ugt i32 %v0_40be79, -45
  %v23_40be79 = select i1 %v26_40be73, i1 %v21_40be79, i1 %v22_40be79
  store i1 %v23_40be79, i1* %cf.global-to-local, align 1
  store i32 %v4_40be79, i32* inttoptr (i32 4763855 to i32*), align 4
  %v0_40be80 = load i32, i32* %eax.global-to-local, align 4
  %v1_40be80 = inttoptr i32 %v0_40be80 to i8*
  %v2_40be80 = load i8, i8* %v1_40be80, align 1
  %v4_40be80 = trunc i32 %v0_40be80 to i8
  %v5_40be80 = add i8 %v4_40be80, %v2_40be80
  %v10_40be80 = icmp ult i8 %v5_40be80, %v2_40be80
  store i1 %v10_40be80, i1* %cf.global-to-local, align 1
  store i8 %v5_40be80, i8* %v1_40be80, align 1
  %v0_40be82 = load i32, i32* %eax.global-to-local, align 4
  %v1_40be82 = inttoptr i32 %v0_40be82 to i8*
  %v2_40be82 = load i8, i8* %v1_40be82, align 1
  %v4_40be82 = trunc i32 %v0_40be82 to i8
  %v5_40be82 = add i8 %v4_40be82, %v2_40be82
  %v10_40be82 = icmp ult i8 %v5_40be82, %v2_40be82
  store i1 %v10_40be82, i1* %cf.global-to-local, align 1
  store i8 %v5_40be82, i8* %v1_40be82, align 1
  %v0_40be84 = load i32, i32* %eax.global-to-local, align 4
  %v1_40be84 = inttoptr i32 %v0_40be84 to i8*
  %v2_40be84 = load i8, i8* %v1_40be84, align 1
  %v4_40be84 = trunc i32 %v0_40be84 to i8
  %v5_40be84 = add i8 %v4_40be84, %v2_40be84
  %v10_40be84 = icmp ult i8 %v5_40be84, %v2_40be84
  store i1 %v10_40be84, i1* %cf.global-to-local, align 1
  store i8 %v5_40be84, i8* %v1_40be84, align 1
  %v0_40be86 = load i32, i32* %eax.global-to-local, align 4
  %v1_40be86 = inttoptr i32 %v0_40be86 to i8*
  %v2_40be86 = load i8, i8* %v1_40be86, align 1
  %v4_40be86 = trunc i32 %v0_40be86 to i8
  %v5_40be86 = add i8 %v4_40be86, %v2_40be86
  %v10_40be86 = icmp ult i8 %v5_40be86, %v2_40be86
  store i1 %v10_40be86, i1* %cf.global-to-local, align 1
  store i8 %v5_40be86, i8* %v1_40be86, align 1
  %v0_40be88 = load i32, i32* %eax.global-to-local, align 4
  %v1_40be88 = inttoptr i32 %v0_40be88 to i8*
  %v2_40be88 = load i8, i8* %v1_40be88, align 1
  %v4_40be88 = trunc i32 %v0_40be88 to i8
  %v5_40be88 = add i8 %v4_40be88, %v2_40be88
  %v10_40be88 = icmp ult i8 %v5_40be88, %v2_40be88
  store i1 %v10_40be88, i1* %cf.global-to-local, align 1
  store i8 %v5_40be88, i8* %v1_40be88, align 1
  %v0_40be8a = load i32, i32* %eax.global-to-local, align 4
  %v1_40be8a = inttoptr i32 %v0_40be8a to i8*
  %v2_40be8a = load i8, i8* %v1_40be8a, align 1
  %v4_40be8a = trunc i32 %v0_40be8a to i8
  %v5_40be8a = add i8 %v4_40be8a, %v2_40be8a
  %v10_40be8a = icmp ult i8 %v5_40be8a, %v2_40be8a
  store i1 %v10_40be8a, i1* %cf.global-to-local, align 1
  store i8 %v5_40be8a, i8* %v1_40be8a, align 1
  %v0_40be8c = load i32, i32* %eax.global-to-local, align 4
  %v1_40be8c = inttoptr i32 %v0_40be8c to i8*
  %v2_40be8c = load i8, i8* %v1_40be8c, align 1
  %v4_40be8c = trunc i32 %v0_40be8c to i8
  %v5_40be8c = add i8 %v4_40be8c, %v2_40be8c
  %v10_40be8c = icmp ult i8 %v5_40be8c, %v2_40be8c
  store i1 %v10_40be8c, i1* %cf.global-to-local, align 1
  store i8 %v5_40be8c, i8* %v1_40be8c, align 1
  %v0_40be8e = load i32, i32* %ecx.global-to-local, align 4
  %v1_40be8e = inttoptr i32 %v0_40be8e to i8*
  %v2_40be8e = load i8, i8* %v1_40be8e, align 1
  %v3_40be8e = load i32, i32* %edx.global-to-local, align 4
  %v4_40be8e = trunc i32 %v3_40be8e to i8
  %v5_40be8e = add i8 %v4_40be8e, %v2_40be8e
  store i8 %v5_40be8e, i8* %v1_40be8e, align 1
  %v0_40be92 = load i32, i32* %eax.global-to-local, align 4
  %v5_40be92 = icmp ult i32 %v0_40be92, 4764131
  store i1 %v5_40be92, i1* %cf.global-to-local, align 1
  %v1_40be97 = trunc i32 %v0_40be92 to i8
  %v2_40be97 = load i8, i8* inttoptr (i32 4763688 to i8*), align 8
  %v4_40be97 = zext i1 %v5_40be92 to i8
  %v5_40be97 = add i8 %v2_40be97, %v1_40be97
  %v6_40be97 = add i8 %v5_40be97, %v4_40be97
  %v27_40be97 = zext i8 %v6_40be97 to i32
  %v29_40be97 = and i32 %v0_40be92, -256
  %v30_40be97 = or i32 %v27_40be97, %v29_40be97
  store i32 %v30_40be97, i32* %eax.global-to-local, align 4
  %v0_40be9d = load i32, i32* inttoptr (i32 4764026 to i32*), align 4
  %v1_40be9d = load i32, i32* %edi.global-to-local, align 4
  %v2_40be9d = xor i32 %v1_40be9d, %v0_40be9d
  store i32 %v2_40be9d, i32* inttoptr (i32 4764026 to i32*), align 4
  store i32 51, i32* %ecx.global-to-local, align 4
  %v4_40beab = sub i32 %v1_40be9d, %v30_40be97
  store i32 %v4_40beab, i32* %edi.global-to-local, align 4
  %v0_40bead = load i32, i32* inttoptr (i32 4763979 to i32*), align 4
  %v2_40bead = add i32 %v0_40bead, %v4_40beab
  store i32 %v2_40bead, i32* inttoptr (i32 4763979 to i32*), align 4
  %v1_40beb3 = add i32 %v4_40beab, -110
  store i32 %v1_40beb3, i32* %edi.global-to-local, align 4
  %v0_40beb6 = load i32, i32* inttoptr (i32 4764104 to i32*), align 8
  %v2_40beb6 = add i32 %v0_40beb6, %v1_40beb3
  store i32 %v2_40beb6, i32* inttoptr (i32 4764104 to i32*), align 8
  %v0_40bebc = load i32, i32* inttoptr (i32 4763962 to i32*), align 4
  %v1_40bebc = and i32 %v0_40bebc, 227
  store i32 %v1_40bebc, i32* inttoptr (i32 4763962 to i32*), align 4
  %v0_40bec6 = load i32, i32* %ecx.global-to-local, align 4
  %v1_40bec6 = load i32, i32* inttoptr (i32 4764137 to i32*), align 4
  %v4_40bec6 = add i32 %v1_40bec6, %v0_40bec6
  store i32 %v4_40bec6, i32* %ecx.global-to-local, align 4
  store i32 11, i32* %eax.global-to-local, align 4
  store i1 false, i1* %cf.global-to-local, align 1
  %v6_40bedd = call i1 @IsBadStringPtrA(i8* getelementptr inbounds ([12 x i8], [12 x i8]* @global_var_48b6b4.5, i32 0, i32 0), i32 11)
  %v7_40bedd = sext i1 %v6_40bedd to i32
  store i32 %v7_40bedd, i32* %eax.global-to-local, align 4
  store i1 false, i1* %cf.global-to-local, align 1
  %v2_40bee3 = icmp eq i1 %v6_40bedd, false
  %v1_40bee6 = icmp eq i1 %v2_40bee3, false
  call void @__pseudo_cond_branch(i1 %v1_40bee6, i32 ptrtoint (i16** @global_var_406dd5.3 to i32))
  store i32 -94, i32* %edx.global-to-local, align 4
  %v0_40bef4 = load i32, i32* %ecx.global-to-local, align 4
  %v1_40bef4 = and i32 %v0_40bef4, -256
  %v5_40bef6 = add nsw i32 %v7_40bedd, 1
  %v20_40bef6 = and i32 %v5_40bef6, 255
  %v23_40bef6 = or i32 %v1_40bef4, %v20_40bef6
  store i32 %v23_40bef6, i32* %ecx.global-to-local, align 4
  %v0_40bef8 = load i32, i32* inttoptr (i32 4764144 to i32*), align 16
  %v1_40bef8 = load i32, i32* %esi.global-to-local, align 4
  %v2_40bef8 = add i32 %v1_40bef8, %v0_40bef8
  %v7_40bef8 = icmp ult i32 %v2_40bef8, %v0_40bef8
  store i32 %v2_40bef8, i32* inttoptr (i32 4764144 to i32*), align 16
  %v0_40befe = load i32, i32* inttoptr (i32 4763964 to i32*), align 4
  %v4_40befe = zext i1 %v7_40bef8 to i32
  %v5_40befe = sub i32 %v0_40befe, %v7_40bedd
  %v6_40befe = add i32 %v4_40befe, %v5_40befe
  %v17_40befe = sub i32 %v5_40befe, %v4_40befe
  %v18_40befe = icmp ult i32 %v0_40befe, %v17_40befe
  %v19_40befe = icmp ne i1 %v6_40bedd, true
  %v20_40befe = or i1 %v19_40befe, %v18_40befe
  %v21_40befe = icmp ult i32 %v0_40befe, %v7_40bedd
  %v22_40befe = select i1 %v7_40bef8, i1 %v20_40befe, i1 %v21_40befe
  store i32 %v6_40befe, i32* inttoptr (i32 4763964 to i32*), align 4
  %v0_40bf04 = load i32, i32* inttoptr (i32 4763962 to i32*), align 4
  %v2_40bf04 = zext i1 %v22_40befe to i32
  %v3_40bf04 = add i32 %v0_40bf04, -253
  %v4_40bf04 = add i32 %v3_40bf04, %v2_40bf04
  %v12_40bf04 = icmp ult i32 %v0_40bf04, 253
  %v13_40bf04 = or i1 %v12_40bf04, %v22_40befe
  store i1 %v13_40bf04, i1* %cf.global-to-local, align 1
  store i32 %v4_40bf04, i32* inttoptr (i32 4763962 to i32*), align 4
  %v0_40bf0e = load i32, i32* %ecx.global-to-local, align 4
  %v1_40bf0e = trunc i32 %v0_40bf0e to i8
  %v2_40bf0e = load i8, i8* inttoptr (i32 4763867 to i8*), align 1
  %v4_40bf0e = zext i1 %v13_40bf04 to i8
  %v5_40bf0e = add i8 %v1_40bf0e, %v2_40bf0e
  %v6_40bf0e = add i8 %v5_40bf0e, %v4_40bf0e
  %v27_40bf0e = zext i8 %v6_40bf0e to i32
  %v29_40bf0e = and i32 %v0_40bf0e, -256
  %v30_40bf0e = or i32 %v27_40bf0e, %v29_40bf0e
  store i32 %v30_40bf0e, i32* %ecx.global-to-local, align 4
  store i32 220, i32* inttoptr (i32 4764024 to i32*), align 8
  %v0_40bf1e = load i32, i32* inttoptr (i32 4764025 to i32*), align 4
  %v1_40bf1e = and i32 %v0_40bf1e, 166
  store i32 %v1_40bf1e, i32* inttoptr (i32 4764025 to i32*), align 4
  %v0_40bf28 = load i32, i32* %edi.global-to-local, align 4
  %v1_40bf28 = load i32, i32* inttoptr (i32 4763905 to i32*), align 4
  %v2_40bf28 = sub i32 %v0_40bf28, %v1_40bf28
  store i32 %v2_40bf28, i32* %edi.global-to-local, align 4
  %v0_40bf2e = load i32, i32* inttoptr (i32 4763826 to i32*), align 4
  %v1_40bf2e = load i32, i32* %edx.global-to-local, align 4
  %v2_40bf2e = add i32 %v1_40bf2e, %v0_40bf2e
  store i32 %v2_40bf2e, i32* inttoptr (i32 4763826 to i32*), align 4
  %v3_40bf34 = sub i32 %v7_40bedd, %v2_40bf28
  store i32 %v3_40bf34, i32* %eax.global-to-local, align 4
  %v0_40bf36 = load i32, i32* %esi.global-to-local, align 4
  %v1_40bf36 = load i32, i32* %ebx.global-to-local, align 4
  %v2_40bf36 = sub i32 %v0_40bf36, %v1_40bf36
  %v7_40bf36 = icmp ult i32 %v0_40bf36, %v1_40bf36
  store i1 %v7_40bf36, i1* %cf.global-to-local, align 1
  store i32 %v2_40bf36, i32* %esi.global-to-local, align 4
  call void @__pseudo_call(i32 ptrtoint (i32* @global_var_40bf40.25 to i32))
  %v0_40bf40 = load i32, i32* %eax.global-to-local, align 4
  %v2_40bf40 = load i32, i32* %ecx.global-to-local, align 4
  %v3_40bf40 = udiv i32 %v2_40bf40, 256
  %v5_40bf40 = load i1, i1* %cf.global-to-local, align 1
  %v6_40bf40 = zext i1 %v5_40bf40 to i32
  %v7_40bf40 = add i32 %v3_40bf40, %v0_40bf40
  %v8_40bf40 = add i32 %v7_40bf40, %v6_40bf40
  %v29_40bf40 = and i32 %v8_40bf40, 255
  %v31_40bf40 = and i32 %v0_40bf40, -256
  %v32_40bf40 = or i32 %v29_40bf40, %v31_40bf40
  store i32 %v32_40bf40, i32* %eax.global-to-local, align 4
  %v0_40bf42 = load i32, i32* inttoptr (i32 4764084 to i32*), align 4
  %v2_40bf42 = add i32 %v32_40bf40, %v0_40bf42
  store i32 %v2_40bf42, i32* inttoptr (i32 4764084 to i32*), align 4
  %v12_40bf48 = and i32 %v32_40bf40, -53505
  store i32 %v12_40bf48, i32* %eax.global-to-local, align 4
  %v0_40bf4b = load i32, i32* inttoptr (i32 4763974 to i32*), align 4
  %v1_40bf4b = load i32, i32* %ebx.global-to-local, align 4
  %v4_40bf4b = add i32 %v1_40bf4b, %v0_40bf4b
  store i32 %v4_40bf4b, i32* inttoptr (i32 4763974 to i32*), align 4
  %v0_40bf51 = load i32, i32* inttoptr (i32 4763730 to i32*), align 4
  %v1_40bf51 = load i32, i32* %esi.global-to-local, align 4
  %v2_40bf51 = add i32 %v1_40bf51, %v0_40bf51
  store i32 %v2_40bf51, i32* inttoptr (i32 4763730 to i32*), align 4
  %v0_40bf57 = load i32, i32* %ecx.global-to-local, align 4
  %v1_40bf57 = load i32, i32* inttoptr (i32 4764034 to i32*), align 4
  %v2_40bf57 = or i32 %v1_40bf57, %v0_40bf57
  %v1_40bf5d = load i32, i32* %eax.global-to-local, align 4
  %v2_40bf5d = xor i32 %v1_40bf5d, %v2_40bf57
  store i32 %v2_40bf5d, i32* %ecx.global-to-local, align 4
  %v0_40bf5f = load i32, i32* inttoptr (i32 4763938 to i32*), align 4
  %v3_40bf5f = add i32 %v0_40bf5f, -99
  store i32 %v3_40bf5f, i32* inttoptr (i32 4763938 to i32*), align 4
  %v1_40bf66 = load i32, i32* inttoptr (i32 4763662 to i32*), align 4
  %v2_40bf66 = sub i32 %v2_40bf5d, %v1_40bf66
  %v7_40bf66 = icmp ult i32 %v2_40bf5d, %v1_40bf66
  store i1 %v7_40bf66, i1* %cf.global-to-local, align 1
  store i32 %v2_40bf66, i32* %ecx.global-to-local, align 4
  %v0_40bf6c = load i8, i8* inttoptr (i32 4763820 to i8*), align 4
  %v1_40bf6c = add i8 %v0_40bf6c, -35
  %v5_40bf6c = icmp ult i8 %v0_40bf6c, 35
  store i1 %v5_40bf6c, i1* %cf.global-to-local, align 1
  store i8 %v1_40bf6c, i8* inttoptr (i32 4763820 to i8*), align 4
  %v0_40bf73 = load i8, i8* inttoptr (i32 4763787 to i8*), align 1
  %v1_40bf73 = add i8 %v0_40bf73, 94
  store i8 %v1_40bf73, i8* inttoptr (i32 4763787 to i8*), align 1
  %v0_40bf7a = load i32, i32* %ecx.global-to-local, align 4
  %v1_40bf7a = load i32, i32* inttoptr (i32 4763952 to i32*), align 16
  %v2_40bf7a = sub i32 %v0_40bf7a, %v1_40bf7a
  %v7_40bf7a = icmp ult i32 %v0_40bf7a, %v1_40bf7a
  store i1 %v7_40bf7a, i1* %cf.global-to-local, align 1
  store i32 %v2_40bf7a, i32* %ecx.global-to-local, align 4
  %v0_40bf80 = load i8, i8* inttoptr (i32 4763887 to i8*), align 1
  %v1_40bf80 = load i32, i32* %eax.global-to-local, align 4
  %v2_40bf80 = trunc i32 %v1_40bf80 to i8
  %v3_40bf80 = add i8 %v2_40bf80, %v0_40bf80
  %v8_40bf80 = icmp ult i8 %v3_40bf80, %v0_40bf80
  store i1 %v8_40bf80, i1* %cf.global-to-local, align 1
  store i8 %v3_40bf80, i8* inttoptr (i32 4763887 to i8*), align 1
  %v1_40bf86 = udiv i32 %v1_40bf80, 256
  %v2_40bf86 = trunc i32 %v1_40bf86 to i8
  %v3_40bf86 = load i8, i8* inttoptr (i32 4763849 to i8*), align 1
  %v5_40bf86 = zext i1 %v8_40bf80 to i8
  %v6_40bf86 = add i8 %v2_40bf86, %v3_40bf86
  %v7_40bf86 = add i8 %v6_40bf86, %v5_40bf86
  %v28_40bf86 = zext i8 %v7_40bf86 to i32
  %v30_40bf86 = mul nuw nsw i32 %v28_40bf86, 256
  %v31_40bf86 = and i32 %v1_40bf80, -65281
  %v32_40bf86 = or i32 %v30_40bf86, %v31_40bf86
  %v1_40bf8c = xor i32 %v32_40bf86, -48
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v1_40bf8c, i32* %eax.global-to-local, align 4
  %v0_40bf8f = load i8, i8* inttoptr (i32 4763973 to i8*), align 1
  %v1_40bf8f = load i32, i32* %ebx.global-to-local, align 4
  %v2_40bf8f = trunc i32 %v1_40bf8f to i8
  %v3_40bf8f = add i8 %v2_40bf8f, %v0_40bf8f
  %v8_40bf8f = icmp ult i8 %v3_40bf8f, %v0_40bf8f
  store i1 %v8_40bf8f, i1* %cf.global-to-local, align 1
  store i8 %v3_40bf8f, i8* inttoptr (i32 4763973 to i8*), align 1
  %v0_40bf95 = load i32, i32* inttoptr (i32 4764110 to i32*), align 4
  %v2_40bf95 = zext i1 %v8_40bf8f to i32
  %v3_40bf95 = add i32 %v0_40bf95, 190
  %v4_40bf95 = add i32 %v3_40bf95, %v2_40bf95
  %v21_40bf95 = icmp ule i32 %v4_40bf95, %v0_40bf95
  %v22_40bf95 = icmp ugt i32 %v0_40bf95, -191
  %v23_40bf95 = select i1 %v8_40bf8f, i1 %v21_40bf95, i1 %v22_40bf95
  store i1 %v23_40bf95, i1* %cf.global-to-local, align 1
  store i32 %v4_40bf95, i32* inttoptr (i32 4764110 to i32*), align 4
  %v0_40bf9f = load i32, i32* %ecx.global-to-local, align 4
  %v1_40bf9f = inttoptr i32 %v0_40bf9f to i8*
  %v2_40bf9f = load i8, i8* %v1_40bf9f, align 1
  %v3_40bf9f = load i32, i32* %edx.global-to-local, align 4
  %v4_40bf9f = trunc i32 %v3_40bf9f to i8
  %v5_40bf9f = add i8 %v4_40bf9f, %v2_40bf9f
  store i8 %v5_40bf9f, i8* %v1_40bf9f, align 1
  %v1_40bfa1 = load x86_fp80, x86_fp80* %st0.global-to-local, align 4
  %v2_40bfa1 = fptosi x86_fp80 %v1_40bfa1 to i32
  %v3_40bfa1 = load i32, i32* %ebx.global-to-local, align 4
  %v4_40bfa1 = inttoptr i32 %v3_40bfa1 to i32*
  store i32 %v2_40bfa1, i32* %v4_40bfa1, align 4
  %v0_40bfa3 = load i32, i32* %eax.global-to-local, align 4
  %v5_40bfa3 = icmp ult i32 %v0_40bfa3, 4764103
  %v0_40bfa8 = load i32, i32* %esi.global-to-local, align 4
  %v1_40bfa8 = load i32, i32* inttoptr (i32 4764097 to i32*), align 4
  %v3_40bfa8 = zext i1 %v5_40bfa3 to i32
  %v4_40bfa8 = add i32 %v1_40bfa8, %v0_40bfa8
  %v5_40bfa8 = add i32 %v4_40bfa8, %v3_40bfa8
  store i32 %v5_40bfa8, i32* %esi.global-to-local, align 4
  %v1_40bfae = load i32, i32* inttoptr (i32 4763953 to i32*), align 4
  %v2_40bfae = or i32 %v1_40bfae, %v5_40bfa8
  store i32 %v2_40bfae, i32* %esi.global-to-local, align 4
  %v0_40bfb4 = load i32, i32* %edi.global-to-local, align 4
  %v3_40bfb4 = add i32 %v0_40bfb4, -27
  %v12_40bfb4 = icmp ult i32 %v0_40bfb4, 27
  store i32 %v3_40bfb4, i32* %edi.global-to-local, align 4
  %v0_40bfb7 = load i32, i32* %ebx.global-to-local, align 4
  %v1_40bfb7 = load i32, i32* inttoptr (i32 4764152 to i32*), align 8
  %v3_40bfb7 = zext i1 %v12_40bfb4 to i32
  %v4_40bfb7 = add i32 %v1_40bfb7, %v0_40bfb7
  %v5_40bfb7 = add i32 %v4_40bfb7, %v3_40bfb7
  %v24_40bfb7 = icmp ule i32 %v5_40bfb7, %v0_40bfb7
  %v25_40bfb7 = icmp ult i32 %v4_40bfb7, %v0_40bfb7
  %v26_40bfb7 = select i1 %v12_40bfb4, i1 %v24_40bfb7, i1 %v25_40bfb7
  store i32 %v5_40bfb7, i32* %ebx.global-to-local, align 4
  %v0_40bfbd = load i32, i32* inttoptr (i32 4763720 to i32*), align 8
  %v2_40bfbd = zext i1 %v26_40bfb7 to i32
  %v3_40bfbd = add i32 %v0_40bfbd, -249
  %v4_40bfbd = add i32 %v3_40bfbd, %v2_40bfbd
  store i32 %v4_40bfbd, i32* inttoptr (i32 4763720 to i32*), align 8
  %v1_40bfc7 = load i32, i32* %esi.global-to-local, align 4
  %v2_40bfc7 = xor i32 %v1_40bfc7, %v5_40bfb7
  store i32 %v2_40bfc7, i32* %ebx.global-to-local, align 4
  %v0_40bfc9 = load i32, i32* %eax.global-to-local, align 4
  %v1_40bfc9 = add i32 %v0_40bfc9, -85
  %v5_40bfc9 = icmp ugt i32 %v0_40bfc9, 84
  store i1 %v5_40bfc9, i1* %cf.global-to-local, align 1
  store i32 %v1_40bfc9, i32* %eax.global-to-local, align 4
  %v0_40bfcc = load i8, i8* inttoptr (i32 4763918 to i8*), align 2
  %v2_40bfcc = udiv i32 %v1_40bfc9, 256
  %v3_40bfcc = trunc i32 %v2_40bfcc to i8
  %v4_40bfcc = sub i8 %v0_40bfcc, %v3_40bfcc
  %v9_40bfcc = icmp ult i8 %v0_40bfcc, %v3_40bfcc
  store i1 %v9_40bfcc, i1* %cf.global-to-local, align 1
  store i8 %v4_40bfcc, i8* inttoptr (i32 4763918 to i8*), align 2
  %v0_40bfd2 = load i32, i32* %eax.global-to-local, align 4
  %v1_40bfd2 = load i32, i32* inttoptr (i32 4763750 to i32*), align 4
  %v3_40bfd2 = zext i1 %v9_40bfcc to i32
  %v4_40bfd2 = add i32 %v1_40bfd2, %v0_40bfd2
  %v5_40bfd2 = add i32 %v4_40bfd2, %v3_40bfd2
  store i32 %v5_40bfd2, i32* %eax.global-to-local, align 4
  %v0_40bfd8 = load i32, i32* %esi.global-to-local, align 4
  %v1_40bfd8 = xor i32 %v0_40bfd8, 48
  %v1_40bfdb = load i32, i32* %edi.global-to-local, align 4
  %v4_40bfdb = add i32 %v1_40bfd8, -126
  %v1_40bfdd = add i32 %v4_40bfdb, %v1_40bfdb
  store i32 %v1_40bfdd, i32* %esi.global-to-local, align 4
  %v1_40bfe0 = add i32 %v1_40bfdb, -19
  %v5_40bfe0 = icmp ugt i32 %v1_40bfdb, 18
  store i32 %v1_40bfe0, i32* %edi.global-to-local, align 4
  store i32 1, i32* %ecx.global-to-local, align 4
  %v1_40bfe8 = load i32, i32* inttoptr (i32 4763806 to i32*), align 4
  %v4_40bfe8 = select i1 %v5_40bfe0, i32 2, i32 1
  %v5_40bfe8 = add i32 %v4_40bfe8, %v1_40bfe8
  store i32 %v5_40bfe8, i32* %ecx.global-to-local, align 4
  store i1 false, i1* %cf.global-to-local, align 1
  %v8_40c000 = call i1 @SetEnvironmentVariableW(i16* bitcast ([13 x i8]* @global_var_48b685.2 to i16*), i16* bitcast ([17 x i8]* @global_var_48b692.1 to i16*))
  %v9_40c000 = sext i1 %v8_40c000 to i32
  store i32 %v9_40c000, i32* %eax.global-to-local, align 4
  store i32 1, i32* %edx.global-to-local, align 4
  %v1_40c00b = load i32, i32* inttoptr (i32 4763996 to i32*), align 4
  %v2_40c00b = load i1, i1* %cf.global-to-local, align 1
  %v3_40c00b = zext i1 %v2_40c00b to i32
  %v4_40c00b = add i32 %v1_40c00b, 1
  %v5_40c00b = add i32 %v4_40c00b, %v3_40c00b
  store i32 %v5_40c00b, i32* %edx.global-to-local, align 4
  %v0_40c011 = load i32, i32* %ebx.global-to-local, align 4
  %v1_40c011 = xor i32 %v0_40c011, 125
  store i32 %v1_40c011, i32* %ebx.global-to-local, align 4
  %v0_40c014 = load i32, i32* %edi.global-to-local, align 4
  %v2_40c014 = add i32 %v0_40c014, %v9_40c000
  store i32 %v2_40c014, i32* %edi.global-to-local, align 4
  %v0_40c016 = load i32, i32* inttoptr (i32 4763815 to i32*), align 4
  %v2_40c016 = sub i32 %v0_40c016, %v1_40c011
  store i32 %v2_40c016, i32* inttoptr (i32 4763815 to i32*), align 4
  %v0_40c01c = load i32, i32* %esi.global-to-local, align 4
  %v2_40c01c = xor i32 %v2_40c014, %v0_40c01c
  store i32 %v2_40c01c, i32* %esi.global-to-local, align 4
  store i32 39, i32* inttoptr (i32 4763931 to i32*), align 4
  %v2_40c02d = add nsw i32 %v9_40c000, 1
  store i32 %v2_40c02d, i32* %ecx.global-to-local, align 4
  %v0_40c02f = load i32, i32* inttoptr (i32 4763766 to i32*), align 4
  %v1_40c02f = or i32 %v0_40c02f, 145
  store i32 %v1_40c02f, i32* inttoptr (i32 4763766 to i32*), align 4
  %v0_40c039 = load i32, i32* inttoptr (i32 4764007 to i32*), align 4
  %v3_40c039 = add i32 %v0_40c039, 96
  %v21_40c039 = icmp ugt i32 %v0_40c039, -97
  store i32 %v3_40c039, i32* inttoptr (i32 4764007 to i32*), align 4
  %v0_40c040 = load i32, i32* %ebx.global-to-local, align 4
  %v2_40c040 = zext i1 %v21_40c039 to i32
  %v3_40c040 = add i32 %v0_40c040, 93
  %v4_40c040 = add i32 %v3_40c040, %v2_40c040
  %v12_40c040 = icmp ult i32 %v0_40c040, -93
  %v13_40c040 = or i1 %v21_40c039, %v12_40c040
  store i1 %v13_40c040, i1* %cf.global-to-local, align 1
  store i32 %v4_40c040, i32* %ebx.global-to-local, align 4
  %v0_40c043 = load i8, i8* inttoptr (i32 4764129 to i8*), align 1
  %v1_40c043 = add i8 %v0_40c043, 70
  store i8 %v1_40c043, i8* inttoptr (i32 4764129 to i8*), align 1
  %v0_40c04a = load i32, i32* inttoptr (i32 4763786 to i32*), align 4
  %v1_40c04a = load i32, i32* %edi.global-to-local, align 4
  %v2_40c04a = xor i32 %v1_40c04a, %v0_40c04a
  store i32 %v2_40c04a, i32* inttoptr (i32 4763786 to i32*), align 4
  %v0_40c050 = load i32, i32* inttoptr (i32 4763886 to i32*), align 4
  %v1_40c050 = and i32 %v0_40c050, 81
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v1_40c050, i32* inttoptr (i32 4763886 to i32*), align 4
  call void @__pseudo_call(i32 4243551)
  %v0_40c05f = load i32, i32* %esi.global-to-local, align 4
  %v1_40c05f = add i32 %v0_40c05f, -104
  %v5_40c05f = icmp ugt i32 %v0_40c05f, 103
  %v0_40c062 = load i32, i32* %ecx.global-to-local, align 4
  %v2_40c062 = zext i1 %v5_40c05f to i32
  %v3_40c062 = add i32 %v0_40c062, -125
  %v4_40c062 = add i32 %v3_40c062, %v2_40c062
  store i32 %v4_40c062, i32* %ecx.global-to-local, align 4
  %v1_40c065 = or i32 %v1_40c05f, 60
  store i32 %v1_40c065, i32* %esi.global-to-local, align 4
  %v0_40c068 = load i32, i32* %edi.global-to-local, align 4
  %v1_40c068 = load i32, i32* inttoptr (i32 4763886 to i32*), align 4
  %v2_40c068 = or i32 %v1_40c068, %v0_40c068
  %v2_40c06e = add i32 %v2_40c068, %v1_40c065
  %v7_40c06e = icmp ult i32 %v2_40c06e, %v2_40c068
  store i32 %v2_40c06e, i32* %edi.global-to-local, align 4
  %v0_40c070 = load i32, i32* inttoptr (i32 4764025 to i32*), align 4
  %v3_40c070 = zext i1 %v7_40c06e to i32
  %v4_40c070 = sub i32 %v0_40c070, %v4_40c062
  %v5_40c070 = add i32 %v4_40c070, %v3_40c070
  store i32 %v5_40c070, i32* inttoptr (i32 4764025 to i32*), align 4
  %v0_40c076 = load i32, i32* %edx.global-to-local, align 4
  %v12_40c076 = and i32 %v0_40c076, -45057
  %v2_40c079 = xor i32 %v12_40c076, %v9_40c000
  store i32 %v2_40c079, i32* %edx.global-to-local, align 4
  %v0_40c07b = load i32, i32* inttoptr (i32 4763684 to i32*), align 4
  %v1_40c07b = load i32, i32* %edi.global-to-local, align 4
  %v2_40c07b = sub i32 %v0_40c07b, %v1_40c07b
  store i32 %v2_40c07b, i32* inttoptr (i32 4763684 to i32*), align 4
  store i32 0, i32* %ebx.global-to-local, align 4
  store i32 219, i32* inttoptr (i32 4763834 to i32*), align 4
  %v3_40c08d = add nsw i32 %v9_40c000, 98
  %v15_40c08d = trunc i32 %v3_40c08d to i8
  store i1 %v8_40c000, i1* %cf.global-to-local, align 1
  store i32 %v3_40c08d, i32* %eax.global-to-local, align 4
  %v3_40c090 = load i8, i8* inttoptr (i32 1219589141 to i8*), align 1
  %v6_40c090 = add i8 %v3_40c090, %v15_40c08d
  %v11_40c090 = icmp ult i8 %v6_40c090, %v3_40c090
  store i1 %v11_40c090, i1* %cf.global-to-local, align 1
  store i8 %v6_40c090, i8* inttoptr (i32 1219589141 to i8*), align 1
  %v0_40c096 = load i32, i32* %ebx.global-to-local, align 4
  %v1_40c096 = add i32 %v0_40c096, -125
  %v2_40c096 = inttoptr i32 %v1_40c096 to i8*
  %v3_40c096 = load i8, i8* %v2_40c096, align 1
  %v4_40c096 = load i32, i32* %eax.global-to-local, align 4
  %v5_40c096 = udiv i32 %v4_40c096, 256
  %v6_40c096 = trunc i32 %v5_40c096 to i8
  %v7_40c096 = add i8 %v6_40c096, %v3_40c096
  %v12_40c096 = icmp ult i8 %v7_40c096, %v3_40c096
  store i1 %v12_40c096, i1* %cf.global-to-local, align 1
  store i8 %v7_40c096, i8* %v2_40c096, align 1
  %v6_40c099 = load x86_fp80, x86_fp80* %st0.global-to-local, align 4
  %v1_40c09f = load i32, i32* %ecx.global-to-local, align 4
  %v2_40c09f = add i32 %v1_40c09f, 16515144
  %v3_40c09f = inttoptr i32 %v2_40c09f to i16*
  %v4_40c09f = load i16, i16* %v3_40c09f, align 2
  %v5_40c09f = sitofp i16 %v4_40c09f to x86_fp80
  %v7_40c09f = fdiv x86_fp80 %v6_40c099, %v5_40c09f
  store x86_fp80 %v7_40c09f, x86_fp80* %st0.global-to-local, align 4
  %v0_40c0a5 = load i32, i32* %eax.global-to-local, align 4
  %v1_40c0a5 = inttoptr i32 %v0_40c0a5 to i8*
  %v2_40c0a5 = load i8, i8* %v1_40c0a5, align 1
  %v4_40c0a5 = trunc i32 %v0_40c0a5 to i8
  %v5_40c0a5 = add i8 %v4_40c0a5, %v2_40c0a5
  store i8 %v5_40c0a5, i8* %v1_40c0a5, align 1
  %v0_40c0a7 = load i32, i32* inttoptr (i32 4764108 to i32*), align 4
  %v1_40c0a7 = and i32 %v0_40c0a7, 181
  store i32 %v1_40c0a7, i32* inttoptr (i32 4764108 to i32*), align 4
  %v0_40c0b1 = load i32, i32* %edi.global-to-local, align 4
  %v1_40c0b1 = load i32, i32* %ebx.global-to-local, align 4
  %v4_40c0b1 = add i32 %v1_40c0b1, %v0_40c0b1
  %v25_40c0b1 = icmp ult i32 %v4_40c0b1, %v0_40c0b1
  store i32 %v4_40c0b1, i32* %edi.global-to-local, align 4
  store i32 13, i32* inttoptr (i32 4763950 to i32*), align 4
  %v1_40c0bd = load i32, i32* inttoptr (i32 4763972 to i32*), align 4
  %v3_40c0bd = zext i1 %v25_40c0b1 to i32
  %v4_40c0bd = add i32 %v1_40c0bd, %v1_40c0b1
  %v5_40c0bd = add i32 %v4_40c0bd, %v3_40c0bd
  %v24_40c0bd = icmp ule i32 %v5_40c0bd, %v1_40c0b1
  %v25_40c0bd = icmp ult i32 %v4_40c0bd, %v1_40c0b1
  %v26_40c0bd = select i1 %v25_40c0b1, i1 %v24_40c0bd, i1 %v25_40c0bd
  store i32 %v5_40c0bd, i32* %ebx.global-to-local, align 4
  %v0_40c0c3 = load i32, i32* inttoptr (i32 4764026 to i32*), align 4
  %v2_40c0c3 = zext i1 %v26_40c0bd to i32
  %v3_40c0c3 = add i32 %v0_40c0c3, -223
  %v4_40c0c3 = add i32 %v3_40c0c3, %v2_40c0c3
  %v12_40c0c3 = icmp ult i32 %v0_40c0c3, 223
  %v13_40c0c3 = or i1 %v12_40c0c3, %v26_40c0bd
  store i1 %v13_40c0c3, i1* %cf.global-to-local, align 1
  store i32 %v4_40c0c3, i32* inttoptr (i32 4764026 to i32*), align 4
  %v0_40c0cd = load i8, i8* inttoptr (i32 4763919 to i8*), align 1
  %v1_40c0cd = load i32, i32* %eax.global-to-local, align 4
  %v2_40c0cd = trunc i32 %v1_40c0cd to i8
  %v3_40c0cd = sub i8 %v0_40c0cd, %v2_40c0cd
  store i8 %v3_40c0cd, i8* inttoptr (i32 4763919 to i8*), align 1
  %v1_40c0d8 = load i32, i32* %esi.global-to-local, align 4
  %v2_40c0d8 = add i32 %v1_40c0d8, 1
  %v7_40c0d8 = icmp eq i32 %v2_40c0d8, 0
  store i1 %v7_40c0d8, i1* %cf.global-to-local, align 1
  store i32 %v2_40c0d8, i32* %ecx.global-to-local, align 4
  %v0_40c0da = load i8, i8* inttoptr (i32 4763761 to i8*), align 1
  %v1_40c0da = add i8 %v0_40c0da, -24
  %v5_40c0da = icmp ult i8 %v0_40c0da, 24
  store i1 %v5_40c0da, i1* %cf.global-to-local, align 1
  store i8 %v1_40c0da, i8* inttoptr (i32 4763761 to i8*), align 1
  %v2_40c0e1 = zext i1 %v5_40c0da to i32
  %v3_40c0e1 = add i32 %v1_40c0d8, -45
  %v4_40c0e1 = add i32 %v3_40c0e1, %v2_40c0e1
  store i32 %v4_40c0e1, i32* %ecx.global-to-local, align 4
  %v0_40c0e4 = load i32, i32* inttoptr (i32 4763805 to i32*), align 4
  %v1_40c0e4 = load i32, i32* %eax.global-to-local, align 4
  %v2_40c0e4 = xor i32 %v1_40c0e4, %v0_40c0e4
  store i32 %v2_40c0e4, i32* inttoptr (i32 4763805 to i32*), align 4
  %v0_40c0ea = load i32, i32* inttoptr (i32 4763960 to i32*), align 8
  %v1_40c0ea = load i32, i32* %esi.global-to-local, align 4
  %v4_40c0ea = sub i32 %v0_40c0ea, %v1_40c0ea
  %v20_40c0ea = icmp ult i32 %v0_40c0ea, %v1_40c0ea
  store i32 %v4_40c0ea, i32* inttoptr (i32 4763960 to i32*), align 8
  %v0_40c0f0 = load i32, i32* inttoptr (i32 4763746 to i32*), align 4
  %v3_40c0f0 = zext i1 %v20_40c0ea to i32
  %v4_40c0f0 = add i32 %v3_40c0f0, %v0_40c0f0
  %v5_40c0f0 = sub i32 %v4_40c0f0, %v1_40c0ea
  store i32 %v5_40c0f0, i32* inttoptr (i32 4763746 to i32*), align 4
  %v0_40c0f6 = load i32, i32* %ecx.global-to-local, align 4
  store i1 false, i1* %cf.global-to-local, align 1
  %v9_40c0f6 = or i32 %v0_40c0f6, 248
  store i32 %v9_40c0f6, i32* %ecx.global-to-local, align 4
  %v0_40c0f9 = load i32, i32* %eax.global-to-local, align 4
  %v1_40c0f9 = trunc i32 %v0_40c0f9 to i8
  %v2_40c0f9 = load i8, i8* inttoptr (i32 4763885 to i8*), align 1
  %v5_40c0f9 = add i8 %v1_40c0f9, %v2_40c0f9
  %v27_40c0f9 = zext i8 %v5_40c0f9 to i32
  %v29_40c0f9 = and i32 %v0_40c0f9, -256
  %v30_40c0f9 = or i32 %v27_40c0f9, %v29_40c0f9
  store i32 %v30_40c0f9, i32* %eax.global-to-local, align 4
  %v0_40c0ff = load i32, i32* %edi.global-to-local, align 4
  %v2_40c0ff = add i32 %v30_40c0f9, %v0_40c0ff
  %v7_40c0ff = icmp ult i32 %v2_40c0ff, %v0_40c0ff
  store i32 %v2_40c0ff, i32* %edi.global-to-local, align 4
  %v0_40c101 = load i32, i32* %esi.global-to-local, align 4
  %v1_40c101 = load i32, i32* inttoptr (i32 4763902 to i32*), align 4
  %v3_40c101 = zext i1 %v7_40c0ff to i32
  %v4_40c101 = add i32 %v1_40c101, %v0_40c101
  %v5_40c101 = add i32 %v4_40c101, %v3_40c101
  store i32 %v5_40c101, i32* %esi.global-to-local, align 4
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 1048576, i32* %eax.global-to-local, align 4
  %v10_40c120 = call i32* @OpenJobObjectW(i32 1048576, i1 false, i16* bitcast ([13 x i8]* @global_var_48b6a3.4 to i16*))
  %v11_40c120 = ptrtoint i32* %v10_40c120 to i32
  store i32 %v11_40c120, i32* %eax.global-to-local, align 4
  store i1 false, i1* %cf.global-to-local, align 1
  %v1_40c126 = icmp eq i32* %v10_40c120, null
  %v1_40c129 = icmp eq i1 %v1_40c126, false
  call void @__pseudo_cond_branch(i1 %v1_40c129, i32 ptrtoint (i16** @global_var_406dd5.3 to i32))
  %v0_40c12f = load i32, i32* %edx.global-to-local, align 4
  %v1_40c12f = and i32 %v0_40c12f, -65281
  %v20_40c131 = or i32 %v1_40c12f, 25344
  store i32 %v20_40c131, i32* %edx.global-to-local, align 4
  %v0_40c134 = load i32, i32* inttoptr (i32 4764029 to i32*), align 4
  %v3_40c134 = add i32 %v0_40c134, -187
  store i32 %v3_40c134, i32* inttoptr (i32 4764029 to i32*), align 4
  %v1_40c143 = load i32, i32* %esi.global-to-local, align 4
  %v2_40c143 = add i32 %v1_40c143, 1
  %v7_40c143 = icmp eq i32 %v2_40c143, 0
  store i32 %v2_40c143, i32* %ecx.global-to-local, align 4
  %v2_40c145 = zext i1 %v7_40c143 to i32
  %v3_40c145 = add i32 %v1_40c143, 4
  %v4_40c145 = add i32 %v3_40c145, %v2_40c145
  store i32 %v4_40c145, i32* %esi.global-to-local, align 4
  %v1_40c148 = load i32, i32* %edi.global-to-local, align 4
  %v2_40c148 = add i32 %v1_40c148, %v11_40c120
  store i32 %v2_40c148, i32* %eax.global-to-local, align 4
  %v0_40c14a = load i32, i32* inttoptr (i32 4763732 to i32*), align 4
  %v1_40c14a = load i32, i32* %edx.global-to-local, align 4
  %v2_40c14a = and i32 %v1_40c14a, %v0_40c14a
  store i32 %v2_40c14a, i32* inttoptr (i32 4763732 to i32*), align 4
  %v0_40c150 = load i32, i32* inttoptr (i32 4763807 to i32*), align 4
  %v3_40c150 = add i32 %v0_40c150, 68
  store i32 %v3_40c150, i32* inttoptr (i32 4763807 to i32*), align 4
  %v0_40c157 = load i32, i32* %eax.global-to-local, align 4
  %v1_40c157 = load i32, i32* %edi.global-to-local, align 4
  %v2_40c157 = sub i32 %v0_40c157, %v1_40c157
  %v7_40c157 = icmp ult i32 %v0_40c157, %v1_40c157
  store i32 %v2_40c157, i32* %eax.global-to-local, align 4
  %v0_40c159 = load i32, i32* inttoptr (i32 4763868 to i32*), align 4
  %v2_40c159 = zext i1 %v7_40c157 to i32
  %v3_40c159 = add i32 %v0_40c159, -113
  %v4_40c159 = add i32 %v3_40c159, %v2_40c159
  store i32 %v4_40c159, i32* inttoptr (i32 4763868 to i32*), align 4
  %v0_40c160 = load i32, i32* %ebx.global-to-local, align 4
  %v1_40c160 = add i32 %v0_40c160, 115
  store i32 %v1_40c160, i32* %ebx.global-to-local, align 4
  %v0_40c163 = load i32, i32* %edi.global-to-local, align 4
  %v1_40c163 = load i32, i32* inttoptr (i32 4763706 to i32*), align 4
  %v2_40c163 = sub i32 %v0_40c163, %v1_40c163
  %v7_40c163 = icmp ult i32 %v0_40c163, %v1_40c163
  store i32 %v2_40c163, i32* %edi.global-to-local, align 4
  %v1_40c169 = load i32, i32* inttoptr (i32 4764009 to i32*), align 4
  %v3_40c169 = zext i1 %v7_40c163 to i32
  %v4_40c169 = add i32 %v1_40c169, %v1_40c160
  %v5_40c169 = add i32 %v4_40c169, %v3_40c169
  %v24_40c169 = icmp ule i32 %v5_40c169, %v1_40c160
  %v25_40c169 = icmp ult i32 %v4_40c169, %v1_40c160
  %v26_40c169 = select i1 %v7_40c163, i1 %v24_40c169, i1 %v25_40c169
  %v2_40c16f = zext i1 %v26_40c169 to i32
  %v3_40c16f = add i32 %v5_40c169, -13
  %v4_40c16f = add i32 %v3_40c16f, %v2_40c16f
  %v22_40c16f = icmp ule i32 %v4_40c16f, %v5_40c169
  %v23_40c16f = icmp ugt i32 %v5_40c169, 12
  %v24_40c16f = select i1 %v26_40c169, i1 %v22_40c16f, i1 %v23_40c16f
  store i1 %v24_40c16f, i1* %cf.global-to-local, align 1
  store i32 %v4_40c16f, i32* %ebx.global-to-local, align 4
  call void @__pseudo_call(i32 sext (i1 ptrtoint (i1* @global_var_40c17a.26 to i1) to i32))
  %v0_40c17a = load i32, i32* %edi.global-to-local, align 4
  %v1_40c17a = load i32, i32* %ebx.global-to-local, align 4
  %v2_40c17a = add i32 %v1_40c17a, %v0_40c17a
  %v7_40c17a = icmp ult i32 %v2_40c17a, %v0_40c17a
  store i1 %v7_40c17a, i1* %cf.global-to-local, align 1
  store i32 %v2_40c17a, i32* %edi.global-to-local, align 4
  %v0_40c17c = load i8, i8* inttoptr (i32 4764062 to i8*), align 2
  %v1_40c17c = load i32, i32* %edx.global-to-local, align 4
  %v2_40c17c = trunc i32 %v1_40c17c to i8
  %v3_40c17c = or i8 %v2_40c17c, %v0_40c17c
  store i1 false, i1* %cf.global-to-local, align 1
  store i8 %v3_40c17c, i8* inttoptr (i32 4764062 to i8*), align 2
  %v0_40c182 = load i32, i32* inttoptr (i32 4763739 to i32*), align 4
  %v1_40c182 = load i32, i32* %edi.global-to-local, align 4
  %v5_40c182 = add i32 %v1_40c182, %v0_40c182
  store i32 %v5_40c182, i32* inttoptr (i32 4763739 to i32*), align 4
  %v1_40c188 = load i32, i32* inttoptr (i32 4763681 to i32*), align 4
  %v2_40c188 = sub i32 %v1_40c182, %v1_40c188
  store i32 %v2_40c188, i32* %edi.global-to-local, align 4
  %v0_40c18e = load i32, i32* %ebx.global-to-local, align 4
  %v1_40c18e = load i32, i32* inttoptr (i32 4763913 to i32*), align 4
  %v2_40c18e = sub i32 %v0_40c18e, %v1_40c18e
  %v7_40c18e = icmp ult i32 %v0_40c18e, %v1_40c18e
  store i32 %v2_40c18e, i32* %ebx.global-to-local, align 4
  %v0_40c194 = load i32, i32* inttoptr (i32 4764021 to i32*), align 4
  %v1_40c194 = load i32, i32* %esi.global-to-local, align 4
  %v3_40c194 = zext i1 %v7_40c18e to i32
  %v4_40c194 = add i32 %v1_40c194, %v0_40c194
  %v5_40c194 = add i32 %v4_40c194, %v3_40c194
  %v24_40c194 = icmp ule i32 %v5_40c194, %v0_40c194
  %v25_40c194 = icmp ult i32 %v4_40c194, %v0_40c194
  %v26_40c194 = select i1 %v7_40c18e, i1 %v24_40c194, i1 %v25_40c194
  store i32 %v5_40c194, i32* inttoptr (i32 4764021 to i32*), align 4
  %v0_40c19a = load i32, i32* %ecx.global-to-local, align 4
  %v1_40c19a = load i32, i32* inttoptr (i32 4763778 to i32*), align 4
  %v3_40c19a = zext i1 %v26_40c194 to i32
  %v4_40c19a = add i32 %v1_40c19a, %v0_40c19a
  %v5_40c19a = add i32 %v4_40c19a, %v3_40c19a
  %v0_40c1a0 = load i32, i32* %esi.global-to-local, align 4
  %v1_40c1a0 = add i32 %v0_40c1a0, -63
  store i32 %v1_40c1a0, i32* %esi.global-to-local, align 4
  %v1_40c1a3 = load i32, i32* %edx.global-to-local, align 4
  %v2_40c1a3 = add i32 %v5_40c19a, %v1_40c1a3
  %v1_40c1a5 = add i32 %v1_40c1a3, -63
  %v5_40c1a5 = icmp ugt i32 %v1_40c1a3, 62
  store i32 %v1_40c1a5, i32* %edx.global-to-local, align 4
  %v2_40c1a8 = zext i1 %v5_40c1a5 to i32
  %v3_40c1a8 = add i32 %v2_40c1a3, -97
  %v4_40c1a8 = add i32 %v3_40c1a8, %v2_40c1a8
  %v12_40c1a8 = icmp ult i32 %v2_40c1a3, 97
  %v13_40c1a8 = or i1 %v5_40c1a5, %v12_40c1a8
  store i32 %v4_40c1a8, i32* %ecx.global-to-local, align 4
  %v1_40c1ab = load i32, i32* inttoptr (i32 4763972 to i32*), align 4
  %v3_40c1ab = zext i1 %v13_40c1a8 to i32
  %v4_40c1ab = add i32 %v1_40c1ab, %v1_40c1a0
  %v5_40c1ab = add i32 %v3_40c1ab, %v4_40c1ab
  %v24_40c1ab = icmp ule i32 %v5_40c1ab, %v1_40c1a0
  %v25_40c1ab = icmp ult i32 %v4_40c1ab, %v1_40c1a0
  %v26_40c1ab = select i1 %v13_40c1a8, i1 %v24_40c1ab, i1 %v25_40c1ab
  store i32 %v5_40c1ab, i32* %esi.global-to-local, align 4
  %v3_40c1b1 = zext i1 %v26_40c1ab to i32
  %v4_40c1b1 = add i32 %v5_40c1ab, %v4_40c1a8
  %v5_40c1b1 = add i32 %v3_40c1b1, %v4_40c1b1
  %v24_40c1b1 = icmp ule i32 %v5_40c1b1, %v4_40c1a8
  %v25_40c1b1 = icmp ult i32 %v4_40c1b1, %v4_40c1a8
  %v26_40c1b1 = select i1 %v26_40c1ab, i1 %v24_40c1b1, i1 %v25_40c1b1
  %v2_40c1b3 = zext i1 %v26_40c1b1 to i32
  %v3_40c1b3 = add i32 %v5_40c1b1, -127
  %v4_40c1b3 = add i32 %v3_40c1b3, %v2_40c1b3
  store i32 %v4_40c1b3, i32* %ecx.global-to-local, align 4
  %v0_40c1b6 = load i32, i32* inttoptr (i32 4763746 to i32*), align 4
  %v1_40c1b6 = and i32 %v0_40c1b6, 223
  store i32 %v1_40c1b6, i32* inttoptr (i32 4763746 to i32*), align 4
  %v0_40c1c0 = load i32, i32* %esi.global-to-local, align 4
  %v2_40c1c0 = sub i32 %v0_40c1c0, %v4_40c1b3
  %v7_40c1c0 = icmp ult i32 %v0_40c1c0, %v4_40c1b3
  store i32 %v2_40c1c0, i32* %esi.global-to-local, align 4
  %v0_40c1c2 = load i32, i32* %edx.global-to-local, align 4
  %v1_40c1c2 = trunc i32 %v0_40c1c2 to i8
  %v2_40c1c2 = load i32, i32* %ebx.global-to-local, align 4
  %v3_40c1c2 = trunc i32 %v2_40c1c2 to i8
  %v5_40c1c2 = zext i1 %v7_40c1c0 to i8
  %v6_40c1c2 = sub i8 %v1_40c1c2, %v3_40c1c2
  %v7_40c1c2 = add i8 %v6_40c1c2, %v5_40c1c2
  %v18_40c1c2 = sub i8 %v6_40c1c2, %v5_40c1c2
  %v19_40c1c2 = icmp ult i8 %v1_40c1c2, %v18_40c1c2
  %v20_40c1c2 = icmp ne i8 %v3_40c1c2, -1
  %v21_40c1c2 = or i1 %v20_40c1c2, %v19_40c1c2
  %v22_40c1c2 = icmp ult i8 %v1_40c1c2, %v3_40c1c2
  %v23_40c1c2 = select i1 %v7_40c1c0, i1 %v21_40c1c2, i1 %v22_40c1c2
  %v37_40c1c2 = zext i8 %v7_40c1c2 to i32
  %v39_40c1c2 = and i32 %v0_40c1c2, -256
  %v40_40c1c2 = or i32 %v37_40c1c2, %v39_40c1c2
  store i32 %v40_40c1c2, i32* %edx.global-to-local, align 4
  %v0_40c1c4 = load i32, i32* inttoptr (i32 4764107 to i32*), align 4
  %v3_40c1c4 = zext i1 %v23_40c1c2 to i32
  %v4_40c1c4 = add i32 %v0_40c1c4, %v2_40c1c0
  %v5_40c1c4 = add i32 %v3_40c1c4, %v4_40c1c4
  %v24_40c1c4 = icmp ule i32 %v5_40c1c4, %v0_40c1c4
  %v25_40c1c4 = icmp ult i32 %v4_40c1c4, %v0_40c1c4
  %v26_40c1c4 = select i1 %v23_40c1c2, i1 %v24_40c1c4, i1 %v25_40c1c4
  store i32 %v5_40c1c4, i32* inttoptr (i32 4764107 to i32*), align 4
  %v0_40c1ca = load i32, i32* inttoptr (i32 4763937 to i32*), align 4
  %v3_40c1ca = select i1 %v26_40c1c4, i32 60, i32 59
  %v4_40c1ca = add i32 %v3_40c1ca, %v0_40c1ca
  %v21_40c1ca = icmp ule i32 %v4_40c1ca, %v0_40c1ca
  %v22_40c1ca = icmp ugt i32 %v0_40c1ca, -60
  %v23_40c1ca = select i1 %v26_40c1c4, i1 %v21_40c1ca, i1 %v22_40c1ca
  store i1 %v23_40c1ca, i1* %cf.global-to-local, align 1
  store i32 %v4_40c1ca, i32* inttoptr (i32 4763937 to i32*), align 4
  %v0_40c1d1 = load i32, i32* %edx.global-to-local, align 4
  %v1_40c1d1 = inttoptr i32 %v0_40c1d1 to i8*
  %v2_40c1d1 = load i8, i8* %v1_40c1d1, align 1
  %v4_40c1d1 = trunc i32 %v0_40c1d1 to i8
  %v5_40c1d1 = add i8 %v4_40c1d1, %v2_40c1d1
  %v10_40c1d1 = icmp ult i8 %v5_40c1d1, %v2_40c1d1
  store i1 %v10_40c1d1, i1* %cf.global-to-local, align 1
  store i8 %v5_40c1d1, i8* %v1_40c1d1, align 1
  %v0_40c1d3 = load i32, i32* %eax.global-to-local, align 4
  %v1_40c1d3 = load i1, i1* %cf.global-to-local, align 1
  %v2_40c1d3 = zext i1 %v1_40c1d3 to i32
  %v3_40c1d3 = add i32 %v0_40c1d3, -4763676
  %v4_40c1d3 = add i32 %v3_40c1d3, %v2_40c1d3
  %v12_40c1d3 = icmp ult i32 %v0_40c1d3, 4763676
  %v13_40c1d3 = or i1 %v12_40c1d3, %v1_40c1d3
  store i32 %v4_40c1d3, i32* %eax.global-to-local, align 4
  %v0_40c1d8 = load i32, i32* inttoptr (i32 4763893 to i32*), align 4
  %v2_40c1d8 = zext i1 %v13_40c1d3 to i32
  %v3_40c1d8 = add i32 %v0_40c1d8, -246
  %v4_40c1d8 = add i32 %v3_40c1d8, %v2_40c1d8
  store i32 %v4_40c1d8, i32* inttoptr (i32 4763893 to i32*), align 4
  %v0_40c1e2 = load i32, i32* inttoptr (i32 4763767 to i32*), align 4
  %v1_40c1e2 = load i32, i32* %ebx.global-to-local, align 4
  %v2_40c1e2 = add i32 %v1_40c1e2, %v0_40c1e2
  store i32 %v2_40c1e2, i32* inttoptr (i32 4763767 to i32*), align 4
  %v0_40c1e8 = load i32, i32* %edi.global-to-local, align 4
  %v1_40c1e8 = load i32, i32* inttoptr (i32 4763982 to i32*), align 4
  %v2_40c1e8 = sub i32 %v0_40c1e8, %v1_40c1e8
  %v7_40c1e8 = icmp ult i32 %v0_40c1e8, %v1_40c1e8
  store i32 %v2_40c1e8, i32* %edi.global-to-local, align 4
  store i32 1, i32* %edx.global-to-local, align 4
  %v1_40c1f3 = load i32, i32* inttoptr (i32 4764058 to i32*), align 4
  %v4_40c1f3 = select i1 %v7_40c1e8, i32 2, i32 1
  %v5_40c1f3 = add i32 %v4_40c1f3, %v1_40c1f3
  store i32 %v5_40c1f3, i32* %edx.global-to-local, align 4
  %v1_40c1f9 = add i32 %v2_40c1e8, 18
  %v5_40c1f9 = icmp ugt i32 %v2_40c1e8, -19
  store i32 %v1_40c1f9, i32* %edi.global-to-local, align 4
  %v0_40c1fc = load i32, i32* %esi.global-to-local, align 4
  %v1_40c1fc = load i32, i32* inttoptr (i32 4764069 to i32*), align 4
  %v3_40c1fc = zext i1 %v5_40c1f9 to i32
  %v4_40c1fc = add i32 %v1_40c1fc, %v0_40c1fc
  %v5_40c1fc = add i32 %v4_40c1fc, %v3_40c1fc
  %v24_40c1fc = icmp ule i32 %v5_40c1fc, %v0_40c1fc
  %v25_40c1fc = icmp ult i32 %v4_40c1fc, %v0_40c1fc
  %v26_40c1fc = select i1 %v5_40c1f9, i1 %v24_40c1fc, i1 %v25_40c1fc
  store i32 %v5_40c1fc, i32* %esi.global-to-local, align 4
  store i32 1, i32* %ecx.global-to-local, align 4
  %v1_40c207 = load i32, i32* inttoptr (i32 4763840 to i32*), align 64
  %v3_40c207 = zext i1 %v26_40c1fc to i32
  %v4_40c207 = add i32 %v1_40c207, 1
  %v5_40c207 = add i32 %v3_40c207, %v4_40c207
  %v24_40c207 = icmp ult i32 %v5_40c207, 2
  %v25_40c207 = icmp eq i32 %v4_40c207, 0
  %v26_40c207 = select i1 %v26_40c1fc, i1 %v24_40c207, i1 %v25_40c207
  store i32 %v5_40c207, i32* %ecx.global-to-local, align 4
  %v2_40c20d = zext i1 %v26_40c207 to i32
  %v3_40c20d = add i32 %v5_40c1fc, -55
  %v4_40c20d = add i32 %v3_40c20d, %v2_40c20d
  %v12_40c20d = icmp ult i32 %v5_40c1fc, 55
  %v13_40c20d = or i1 %v12_40c20d, %v26_40c207
  store i32 %v4_40c20d, i32* %esi.global-to-local, align 4
  %v0_40c210 = load i32, i32* inttoptr (i32 4763755 to i32*), align 4
  %v2_40c210 = zext i1 %v13_40c20d to i32
  %v3_40c210 = add i32 %v0_40c210, 22
  %v4_40c210 = add i32 %v3_40c210, %v2_40c210
  store i32 %v4_40c210, i32* inttoptr (i32 4763755 to i32*), align 4
  %v0_40c217 = load i32, i32* %ecx.global-to-local, align 4
  %v1_40c217 = load i32, i32* inttoptr (i32 4763981 to i32*), align 4
  %v2_40c217 = or i32 %v1_40c217, %v0_40c217
  store i32 %v2_40c217, i32* %ecx.global-to-local, align 4
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 1048576, i32* %eax.global-to-local, align 4
  %v9_40c23c = call i32* @OpenJobObjectW(i32 1048576, i1 false, i16* bitcast ([13 x i8]* @global_var_48b6a3.4 to i16*))
  %v10_40c23c = ptrtoint i32* %v9_40c23c to i32
  store i32 %v10_40c23c, i32* %eax.global-to-local, align 4
  store i1 false, i1* %cf.global-to-local, align 1
  %v1_40c242 = icmp eq i32* %v9_40c23c, null
  %v1_40c245 = icmp eq i1 %v1_40c242, false
  call void @__pseudo_cond_branch(i1 %v1_40c245, i32 ptrtoint (i16** @global_var_406dd5.3 to i32))
  %v0_40c24b = load i32, i32* inttoptr (i32 4763909 to i32*), align 4
  %v2_40c24b = add i32 %v0_40c24b, %v10_40c23c
  %v7_40c24b = icmp ult i32 %v2_40c24b, %v0_40c24b
  store i1 %v7_40c24b, i1* %cf.global-to-local, align 1
  store i32 %v2_40c24b, i32* inttoptr (i32 4763909 to i32*), align 4
  %v0_40c251 = load i8, i8* inttoptr (i32 4763815 to i8*), align 1
  %v1_40c251 = add i8 %v0_40c251, -101
  store i8 %v1_40c251, i8* inttoptr (i32 4763815 to i8*), align 1
  %v0_40c258 = load i32, i32* inttoptr (i32 4764132 to i32*), align 4
  %v1_40c258 = or i32 %v0_40c258, 179
  store i32 %v1_40c258, i32* inttoptr (i32 4764132 to i32*), align 4
  %v0_40c262 = load i32, i32* %esi.global-to-local, align 4
  %v2_40c262 = mul i32 %v0_40c262, 2
  %v1_40c264 = load i32, i32* %edi.global-to-local, align 4
  %v2_40c264 = add i32 %v1_40c264, %v2_40c262
  %v7_40c264 = icmp ult i32 %v2_40c264, %v2_40c262
  store i32 %v2_40c264, i32* %esi.global-to-local, align 4
  %v0_40c266 = load i32, i32* inttoptr (i32 4763958 to i32*), align 4
  %v1_40c266 = load i32, i32* %ebx.global-to-local, align 4
  %v3_40c266 = zext i1 %v7_40c264 to i32
  %v4_40c266 = add i32 %v1_40c266, %v0_40c266
  %v5_40c266 = add i32 %v4_40c266, %v3_40c266
  store i32 %v5_40c266, i32* inttoptr (i32 4763958 to i32*), align 4
  %v0_40c26c = load i32, i32* inttoptr (i32 4764020 to i32*), align 4
  %v1_40c26c = and i32 %v0_40c26c, 201
  store i32 %v1_40c26c, i32* inttoptr (i32 4764020 to i32*), align 4
  %v0_40c276 = load i32, i32* %esi.global-to-local, align 4
  %v1_40c276 = load i32, i32* inttoptr (i32 4763788 to i32*), align 4
  %v4_40c276 = add i32 %v1_40c276, %v0_40c276
  %v25_40c276 = icmp ult i32 %v4_40c276, %v0_40c276
  store i32 %v4_40c276, i32* %esi.global-to-local, align 4
  %v0_40c27c = load i32, i32* inttoptr (i32 4764111 to i32*), align 4
  %v3_40c27c = select i1 %v25_40c276, i32 43, i32 42
  %v4_40c27c = add i32 %v3_40c27c, %v0_40c27c
  store i32 %v4_40c27c, i32* inttoptr (i32 4764111 to i32*), align 4
  %v0_40c283 = load i32, i32* inttoptr (i32 4763843 to i32*), align 4
  %v1_40c283 = load i32, i32* %edi.global-to-local, align 4
  %v2_40c283 = sub i32 %v0_40c283, %v1_40c283
  store i32 %v2_40c283, i32* inttoptr (i32 4763843 to i32*), align 4
  %v1_40c289 = or i32 %v1_40c283, -116
  store i32 %v1_40c289, i32* %edi.global-to-local, align 4
  %v0_40c28c = load i32, i32* inttoptr (i32 4763742 to i32*), align 4
  %v3_40c28c = add i32 %v0_40c28c, -94
  %v12_40c28c = icmp ult i32 %v0_40c28c, 94
  store i1 %v12_40c28c, i1* %cf.global-to-local, align 1
  store i32 %v3_40c28c, i32* inttoptr (i32 4763742 to i32*), align 4
  call void @__pseudo_call(i32 -1)
  %v0_40c29b = load i32, i32* inttoptr (i32 4763739 to i32*), align 4
  %v1_40c29b = load i1, i1* %cf.global-to-local, align 1
  %v2_40c29b = zext i1 %v1_40c29b to i32
  %v3_40c29b = add i32 %v0_40c29b, 203
  %v4_40c29b = add i32 %v3_40c29b, %v2_40c29b
  store i32 %v4_40c29b, i32* inttoptr (i32 4763739 to i32*), align 4
  %v1_40c2a5 = load i32, i32* %edi.global-to-local, align 4
  %v2_40c2a5 = xor i32 %v1_40c2a5, %v10_40c23c
  store i32 %v2_40c2a5, i32* %eax.global-to-local, align 4
  %v0_40c2a7 = load i32, i32* inttoptr (i32 4763873 to i32*), align 4
  %v3_40c2a7 = add i32 %v0_40c2a7, 173
  %v22_40c2a7 = icmp ugt i32 %v0_40c2a7, -174
  store i32 %v3_40c2a7, i32* inttoptr (i32 4763873 to i32*), align 4
  store i32 1, i32* %edx.global-to-local, align 4
  %v1_40c2b6 = load i32, i32* inttoptr (i32 4764076 to i32*), align 4
  %v4_40c2b6 = select i1 %v22_40c2a7, i32 2, i32 1
  %v5_40c2b6 = add i32 %v4_40c2b6, %v1_40c2b6
  store i32 %v5_40c2b6, i32* %edx.global-to-local, align 4
  %v1_40c2c1 = load i32, i32* %edi.global-to-local, align 4
  %v2_40c2c1 = add i32 %v1_40c2c1, 1
  store i32 %v2_40c2c1, i32* %ecx.global-to-local, align 4
  %v1_40c2c3 = or i32 %v1_40c2c1, -60
  store i32 %v1_40c2c3, i32* %edi.global-to-local, align 4
  %v0_40c2c6 = load i32, i32* %eax.global-to-local, align 4
  %v1_40c2c6 = udiv i32 %v0_40c2c6, 256
  %v2_40c2c6 = trunc i32 %v1_40c2c6 to i8
  %v4_40c2c6 = trunc i32 %v0_40c2c6 to i8
  %v5_40c2c6 = add i8 %v2_40c2c6, %v4_40c2c6
  %v10_40c2c6 = icmp ult i8 %v5_40c2c6, %v2_40c2c6
  store i1 %v10_40c2c6, i1* %cf.global-to-local, align 1
  %v20_40c2c6 = zext i8 %v5_40c2c6 to i32
  %v22_40c2c6 = mul nuw nsw i32 %v20_40c2c6, 256
  %v23_40c2c6 = and i32 %v0_40c2c6, -65281
  %v24_40c2c6 = or i32 %v22_40c2c6, %v23_40c2c6
  store i32 %v24_40c2c6, i32* %eax.global-to-local, align 4
  %v1_40c2c8 = udiv i32 %v2_40c2c1, 256
  %v2_40c2c8 = trunc i32 %v1_40c2c8 to i8
  %v3_40c2c8 = load i8, i8* inttoptr (i32 4764025 to i8*), align 1
  %v4_40c2c8 = sub i8 %v2_40c2c8, %v3_40c2c8
  %v19_40c2c8 = zext i8 %v4_40c2c8 to i32
  %v21_40c2c8 = mul nuw nsw i32 %v19_40c2c8, 256
  %v22_40c2c8 = and i32 %v2_40c2c1, -65281
  %v23_40c2c8 = or i32 %v21_40c2c8, %v22_40c2c8
  store i32 %v23_40c2c8, i32* %ecx.global-to-local, align 4
  %v1_40c2ce = xor i32 %v24_40c2c6, 86
  store i32 %v1_40c2ce, i32* %eax.global-to-local, align 4
  %v0_40c2d1 = load i32, i32* inttoptr (i32 4763746 to i32*), align 4
  %v3_40c2d1 = add i32 %v0_40c2d1, 7
  store i32 %v3_40c2d1, i32* inttoptr (i32 4763746 to i32*), align 4
  %v0_40c2d8 = load i32, i32* inttoptr (i32 4764065 to i32*), align 4
  %v1_40c2d8 = load i32, i32* %ebx.global-to-local, align 4
  %v2_40c2d8 = or i32 %v1_40c2d8, %v0_40c2d8
  store i32 %v2_40c2d8, i32* inttoptr (i32 4764065 to i32*), align 4
  %v0_40c2de = load i32, i32* %esi.global-to-local, align 4
  %v1_40c2de = add i32 %v0_40c2de, 93
  %v5_40c2de = icmp ugt i32 %v0_40c2de, -94
  store i32 %v1_40c2de, i32* %esi.global-to-local, align 4
  %v0_40c2e1 = load i32, i32* %edi.global-to-local, align 4
  %v2_40c2e1 = zext i1 %v5_40c2de to i32
  %v3_40c2e1 = add i32 %v0_40c2e1, -38
  %v4_40c2e1 = add i32 %v3_40c2e1, %v2_40c2e1
  %v22_40c2e1 = icmp ule i32 %v4_40c2e1, %v0_40c2e1
  %v23_40c2e1 = icmp ugt i32 %v0_40c2e1, 37
  %v24_40c2e1 = select i1 %v5_40c2de, i1 %v22_40c2e1, i1 %v23_40c2e1
  store i1 %v24_40c2e1, i1* %cf.global-to-local, align 1
  store i32 %v4_40c2e1, i32* %edi.global-to-local, align 4
  %v0_40c2e4 = load i8, i8* inttoptr (i32 4763794 to i8*), align 2
  %v1_40c2e4 = add i8 %v0_40c2e4, -68
  store i8 %v1_40c2e4, i8* inttoptr (i32 4763794 to i8*), align 2
  %v0_40c2eb = load i32, i32* %ebx.global-to-local, align 4
  %v1_40c2eb = add i32 %v0_40c2eb, -86
  store i32 %v1_40c2eb, i32* %ebx.global-to-local, align 4
  %v0_40c2ee = load i32, i32* inttoptr (i32 4763897 to i32*), align 4
  %v1_40c2ee = or i32 %v0_40c2ee, 133
  store i32 %v1_40c2ee, i32* inttoptr (i32 4763897 to i32*), align 4
  %v0_40c2f8 = load i32, i32* inttoptr (i32 4763907 to i32*), align 4
  %v3_40c2f8 = add i32 %v0_40c2f8, 85
  store i32 %v3_40c2f8, i32* inttoptr (i32 4763907 to i32*), align 4
  %v0_40c2ff = load i32, i32* %eax.global-to-local, align 4
  %v1_40c2ff = add i32 %v0_40c2ff, 59
  %v5_40c2ff = icmp ult i32 %v0_40c2ff, -59
  store i1 %v5_40c2ff, i1* %cf.global-to-local, align 1
  %v12_40c2ff = trunc i32 %v1_40c2ff to i8
  store i32 %v1_40c2ff, i32* %eax.global-to-local, align 4
  %v0_40c302 = load i32, i32* %edx.global-to-local, align 4
  %v1_40c302 = trunc i32 %v0_40c302 to i8
  %v2_40c302 = load i8, i8* inttoptr (i32 4763772 to i8*), align 4
  %v4_40c302 = zext i1 %v5_40c2ff to i8
  %v5_40c302 = add i8 %v1_40c302, %v2_40c302
  %v6_40c302 = add i8 %v5_40c302, %v4_40c302
  %v24_40c302 = icmp ule i8 %v6_40c302, %v1_40c302
  %v25_40c302 = icmp ult i8 %v5_40c302, %v1_40c302
  %v26_40c302 = select i1 %v5_40c2ff, i1 %v24_40c302, i1 %v25_40c302
  store i1 %v26_40c302, i1* %cf.global-to-local, align 1
  %v27_40c302 = zext i8 %v6_40c302 to i32
  %v29_40c302 = and i32 %v0_40c302, -256
  %v30_40c302 = or i32 %v27_40c302, %v29_40c302
  store i32 %v30_40c302, i32* %edx.global-to-local, align 4
  %v2_40c308 = load i8, i8* inttoptr (i32 4763685 to i8*), align 1
  %v4_40c308 = zext i1 %v26_40c302 to i8
  %v5_40c308 = add i8 %v2_40c308, %v6_40c302
  %v6_40c308 = add i8 %v4_40c308, %v5_40c308
  %v24_40c308 = icmp ule i8 %v6_40c308, %v6_40c302
  %v25_40c308 = icmp ult i8 %v5_40c308, %v6_40c302
  %v26_40c308 = select i1 %v26_40c302, i1 %v24_40c308, i1 %v25_40c308
  store i1 %v26_40c308, i1* %cf.global-to-local, align 1
  %v27_40c308 = zext i8 %v6_40c308 to i32
  %v30_40c308 = or i32 %v27_40c308, %v29_40c302
  store i32 %v30_40c308, i32* %edx.global-to-local, align 4
  %v1_40c30e = inttoptr i32 %v1_40c2ff to i8*
  %v2_40c30e = load i8, i8* %v1_40c30e, align 1
  %v5_40c30e = add i8 %v2_40c30e, %v12_40c2ff
  %v10_40c30e = icmp ult i8 %v5_40c30e, %v2_40c30e
  store i1 %v10_40c30e, i1* %cf.global-to-local, align 1
  store i8 %v5_40c30e, i8* %v1_40c30e, align 1
  %v0_40c310 = load i32, i32* %eax.global-to-local, align 4
  %v1_40c310 = inttoptr i32 %v0_40c310 to i8*
  %v2_40c310 = load i8, i8* %v1_40c310, align 1
  %v4_40c310 = trunc i32 %v0_40c310 to i8
  %v5_40c310 = add i8 %v4_40c310, %v2_40c310
  %v10_40c310 = icmp ult i8 %v5_40c310, %v2_40c310
  store i1 %v10_40c310, i1* %cf.global-to-local, align 1
  store i8 %v5_40c310, i8* %v1_40c310, align 1
  %v0_40c312 = load i32, i32* %eax.global-to-local, align 4
  %v1_40c312 = inttoptr i32 %v0_40c312 to i8*
  %v2_40c312 = load i8, i8* %v1_40c312, align 1
  %v4_40c312 = trunc i32 %v0_40c312 to i8
  %v5_40c312 = add i8 %v4_40c312, %v2_40c312
  %v10_40c312 = icmp ult i8 %v5_40c312, %v2_40c312
  store i1 %v10_40c312, i1* %cf.global-to-local, align 1
  store i8 %v5_40c312, i8* %v1_40c312, align 1
  %v0_40c314 = load i32, i32* %eax.global-to-local, align 4
  %v1_40c314 = inttoptr i32 %v0_40c314 to i8*
  %v2_40c314 = load i8, i8* %v1_40c314, align 1
  %v4_40c314 = trunc i32 %v0_40c314 to i8
  %v5_40c314 = add i8 %v4_40c314, %v2_40c314
  %v10_40c314 = icmp ult i8 %v5_40c314, %v2_40c314
  store i1 %v10_40c314, i1* %cf.global-to-local, align 1
  store i8 %v5_40c314, i8* %v1_40c314, align 1
  %v0_40c316 = load i32, i32* %eax.global-to-local, align 4
  %v1_40c316 = inttoptr i32 %v0_40c316 to i8*
  %v2_40c316 = load i8, i8* %v1_40c316, align 1
  %v4_40c316 = trunc i32 %v0_40c316 to i8
  %v5_40c316 = add i8 %v4_40c316, %v2_40c316
  %v10_40c316 = icmp ult i8 %v5_40c316, %v2_40c316
  store i1 %v10_40c316, i1* %cf.global-to-local, align 1
  store i8 %v5_40c316, i8* %v1_40c316, align 1
  %v0_40c318 = load i32, i32* %eax.global-to-local, align 4
  %v1_40c318 = inttoptr i32 %v0_40c318 to i8*
  %v2_40c318 = load i8, i8* %v1_40c318, align 1
  %v4_40c318 = trunc i32 %v0_40c318 to i8
  %v5_40c318 = add i8 %v4_40c318, %v2_40c318
  %v10_40c318 = icmp ult i8 %v5_40c318, %v2_40c318
  store i1 %v10_40c318, i1* %cf.global-to-local, align 1
  store i8 %v5_40c318, i8* %v1_40c318, align 1
  %v0_40c31a = load i32, i32* %eax.global-to-local, align 4
  %v1_40c31a = inttoptr i32 %v0_40c31a to i8*
  %v2_40c31a = load i8, i8* %v1_40c31a, align 1
  %v4_40c31a = trunc i32 %v0_40c31a to i8
  %v5_40c31a = add i8 %v4_40c31a, %v2_40c31a
  %v10_40c31a = icmp ult i8 %v5_40c31a, %v2_40c31a
  store i1 %v10_40c31a, i1* %cf.global-to-local, align 1
  store i8 %v5_40c31a, i8* %v1_40c31a, align 1
  %v0_40c31c = load i32, i32* %eax.global-to-local, align 4
  %v1_40c31c = inttoptr i32 %v0_40c31c to i8*
  %v2_40c31c = load i8, i8* %v1_40c31c, align 1
  %v4_40c31c = trunc i32 %v0_40c31c to i8
  %v5_40c31c = add i8 %v4_40c31c, %v2_40c31c
  %v10_40c31c = icmp ult i8 %v5_40c31c, %v2_40c31c
  store i1 %v10_40c31c, i1* %cf.global-to-local, align 1
  store i8 %v5_40c31c, i8* %v1_40c31c, align 1
  %v0_40c31e = load i32, i32* %eax.global-to-local, align 4
  %v1_40c31e = inttoptr i32 %v0_40c31e to i8*
  %v2_40c31e = load i8, i8* %v1_40c31e, align 1
  %v4_40c31e = trunc i32 %v0_40c31e to i8
  %v5_40c31e = add i8 %v4_40c31e, %v2_40c31e
  store i8 %v5_40c31e, i8* %v1_40c31e, align 1
  %v0_40c321 = load i32, i32* %eax.global-to-local, align 4
  %v1_40c321 = add i32 %v0_40c321, -22801
  %v5_40c321 = icmp ult i32 %v0_40c321, 22801
  store i1 %v5_40c321, i1* %cf.global-to-local, align 1
  %v11_40c321 = trunc i32 %v1_40c321 to i8
  store i32 %v1_40c321, i32* %eax.global-to-local, align 4
  %v1_40c326 = inttoptr i32 %v1_40c321 to i8*
  %v2_40c326 = load i8, i8* %v1_40c326, align 1
  %v5_40c326 = add i8 %v2_40c326, %v11_40c321
  %v10_40c326 = icmp ult i8 %v5_40c326, %v2_40c326
  store i1 %v10_40c326, i1* %cf.global-to-local, align 1
  store i8 %v5_40c326, i8* %v1_40c326, align 1
  %v0_40c328 = load i32, i32* %eax.global-to-local, align 4
  %v1_40c328 = inttoptr i32 %v0_40c328 to i8*
  %v2_40c328 = load i8, i8* %v1_40c328, align 1
  %v4_40c328 = trunc i32 %v0_40c328 to i8
  %v5_40c328 = add i8 %v4_40c328, %v2_40c328
  %v10_40c328 = icmp ult i8 %v5_40c328, %v2_40c328
  store i1 %v10_40c328, i1* %cf.global-to-local, align 1
  store i8 %v5_40c328, i8* %v1_40c328, align 1
  %v0_40c32a = load i32, i32* %eax.global-to-local, align 4
  %v1_40c32a = inttoptr i32 %v0_40c32a to i8*
  %v2_40c32a = load i8, i8* %v1_40c32a, align 1
  %v4_40c32a = trunc i32 %v0_40c32a to i8
  %v5_40c32a = add i8 %v4_40c32a, %v2_40c32a
  %v10_40c32a = icmp ult i8 %v5_40c32a, %v2_40c32a
  store i1 %v10_40c32a, i1* %cf.global-to-local, align 1
  store i8 %v5_40c32a, i8* %v1_40c32a, align 1
  %v0_40c32c = load i32, i32* %eax.global-to-local, align 4
  %v2_40c32c = inttoptr i32 %v0_40c32c to i32*
  %v3_40c32c = load i32, i32* %v2_40c32c, align 4
  %v4_40c32c = load i1, i1* %cf.global-to-local, align 1
  %v5_40c32c = zext i1 %v4_40c32c to i32
  %v6_40c32c = sub i32 %v0_40c32c, %v3_40c32c
  %v7_40c32c = add i32 %v5_40c32c, %v6_40c32c
  %v18_40c32c = sub i32 %v6_40c32c, %v5_40c32c
  %v19_40c32c = icmp ult i32 %v0_40c32c, %v18_40c32c
  %v20_40c32c = icmp ne i32 %v3_40c32c, -1
  %v21_40c32c = or i1 %v20_40c32c, %v19_40c32c
  %v22_40c32c = icmp ult i32 %v0_40c32c, %v3_40c32c
  %v23_40c32c = select i1 %v4_40c32c, i1 %v21_40c32c, i1 %v22_40c32c
  store i1 %v23_40c32c, i1* %cf.global-to-local, align 1
  %v33_40c32c = trunc i32 %v7_40c32c to i8
  store i32 %v7_40c32c, i32* %eax.global-to-local, align 4
  %v1_40c32e = inttoptr i32 %v7_40c32c to i8*
  %v2_40c32e = load i8, i8* %v1_40c32e, align 1
  %v5_40c32e = add i8 %v2_40c32e, %v33_40c32c
  %v10_40c32e = icmp ult i8 %v5_40c32e, %v2_40c32e
  store i1 %v10_40c32e, i1* %cf.global-to-local, align 1
  store i8 %v5_40c32e, i8* %v1_40c32e, align 1
  %v0_40c330 = load i32, i32* %eax.global-to-local, align 4
  %v1_40c330 = trunc i32 %v0_40c330 to i8
  %v2_40c330 = load i1, i1* %cf.global-to-local, align 1
  %v3_40c330 = zext i1 %v2_40c330 to i8
  %v4_40c330 = add i8 %v3_40c330, %v1_40c330
  %v22_40c330 = zext i8 %v4_40c330 to i32
  %v24_40c330 = and i32 %v0_40c330, -256
  %v25_40c330 = or i32 %v22_40c330, %v24_40c330
  store i32 %v25_40c330, i32* %eax.global-to-local, align 4
  %v1_40c332 = inttoptr i32 %v25_40c330 to i8*
  %v2_40c332 = load i8, i8* %v1_40c332, align 1
  %v5_40c332 = add i8 %v2_40c332, %v4_40c330
  store i8 %v5_40c332, i8* %v1_40c332, align 1
  %v0_40c33b = load i32, i32* %ebx.global-to-local, align 4
  store i32 1795163290, i32* %esi.global-to-local, align 4
  %v0_40c341 = load i16, i16* %es.global-to-local, align 2
  %v4_40c341 = sext i16 %v0_40c341 to i32
  store i32 %v4_40c341, i32* %stack_var_-45, align 4
  %v1_40c343 = udiv i32 %v0_40c33b, 256
  %v2_40c343 = trunc i32 %v1_40c343 to i8
  %v4_40c343 = trunc i32 %v0_40c33b to i8
  %v5_40c343 = add i8 %v2_40c343, %v4_40c343
  %v10_40c343 = icmp ult i8 %v5_40c343, %v2_40c343
  store i1 %v10_40c343, i1* %cf.global-to-local, align 1
  %v15_40c343 = icmp eq i8 %v5_40c343, 0
  %v20_40c343 = zext i8 %v5_40c343 to i32
  %v22_40c343 = mul nuw nsw i32 %v20_40c343, 256
  %v23_40c343 = and i32 %v0_40c33b, -65281
  %v24_40c343 = or i32 %v22_40c343, %v23_40c343
  store i32 %v24_40c343, i32* %ebx.global-to-local, align 4
  %v1_40c345 = icmp eq i1 %v15_40c343, false
  call void @__pseudo_cond_branch(i1 %v1_40c345, i32 4244296)
  %v0_40c347 = load i32, i32* %edx.global-to-local, align 4
  %v1_40c347 = trunc i32 %v0_40c347 to i8
  %v2_40c347 = load i32, i32* %eax.global-to-local, align 4
  %v3_40c347 = trunc i32 %v2_40c347 to i8
  %v4_40c347 = add i8 %v3_40c347, %v1_40c347
  %v9_40c347 = icmp ult i8 %v4_40c347, %v1_40c347
  store i1 %v9_40c347, i1* %cf.global-to-local, align 1
  store i32 65538, i32* %edx.global-to-local, align 4
  %v1_40c34e = inttoptr i32 %v2_40c347 to i8*
  %v2_40c34e = load i8, i8* %v1_40c34e, align 1
  %v5_40c34e = add i8 %v2_40c34e, %v3_40c347
  %v10_40c34e = icmp ult i8 %v5_40c34e, %v2_40c34e
  store i1 %v10_40c34e, i1* %cf.global-to-local, align 1
  store i8 %v5_40c34e, i8* %v1_40c34e, align 1
  %v3_40c350 = load i32, i32* %esi.global-to-local, align 4
  %v4_40c350 = inttoptr i32 %v3_40c350 to i8*
  %v5_40c350 = load i8, i8* %v4_40c350, align 1
  call void @__asm_outsb(i16 2, i8 %v5_40c350)
  %v9_40c351 = load i32, i32* %stack_var_-45, align 4
  %v16_40c351 = ptrtoint i8* %tmp31 to i32
  %v19_40c351 = sext i16 %tmp30 to i32
  store i32 %v9_40c351, i32* %edi.global-to-local, align 4
  store i32 %v16_40c351, i32* %ebx.global-to-local, align 4
  store i32 %v19_40c351, i32* %edx.global-to-local, align 4
  store i32 %tmp, i32* %eax.global-to-local, align 4
  %v2_40c352 = load i8, i8* %tmp31, align 1
  %v4_40c352 = udiv i32 %tmp, 256
  %v5_40c352 = trunc i32 %v4_40c352 to i8
  %v6_40c352 = add i8 %v2_40c352, %v5_40c352
  store i8 %v6_40c352, i8* %tmp31, align 1
  %v0_40c354 = load i32, i32* %eax.global-to-local, align 4
  %v1_40c354 = load i32, i32* %edi.global-to-local, align 4
  %v2_40c354 = inttoptr i32 %v1_40c354 to i32*
  %v3_40c354 = load i32, i32* %v2_40c354, align 4
  %v4_40c354 = sub i32 %v0_40c354, %v3_40c354
  %v5_40c354 = and i32 %v0_40c354, 15
  %v6_40c354 = and i32 %v3_40c354, 15
  %v7_40c354 = sub nsw i32 %v5_40c354, %v6_40c354
  %v8_40c354 = icmp ugt i32 %v7_40c354, 15
  %v9_40c354 = icmp ult i32 %v0_40c354, %v3_40c354
  %v14_40c354 = icmp eq i32 %v4_40c354, 0
  %v16_40c354 = trunc i32 %v4_40c354 to i8
  %v17_40c354 = call i8 @llvm.ctpop.i8(i8 %v16_40c354)
  %v18_40c354 = and i8 %v17_40c354, 1
  %v21_40c354 = load i1, i1* @df, align 1
  %v1_40c355 = zext i1 %v9_40c354 to i32
  %tmp58 = zext i8 %v18_40c354 to i32
  %tmp59 = shl nuw nsw i32 %tmp58, 2
  %v12_40c355 = select i1 %v8_40c354, i32 16, i32 0
  %v14_40c355 = select i1 %v14_40c354, i32 64, i32 0
  %tmp60 = ashr i32 %v4_40c354, 31
  %tmp61 = and i32 %tmp60, 128
  %v11_40c355 = or i32 %v14_40c355, %v1_40c355
  %v13_40c355 = or i32 %v11_40c355, %tmp61
  %tmp62 = or i32 %v13_40c355, %v12_40c355
  %v15_40c355 = or i32 %tmp59, %tmp62
  %v17_40c355 = xor i32 %v15_40c355, 4
  %v19_40c355 = mul nuw nsw i32 %v17_40c355, 256
  %v20_40c355 = and i32 %v0_40c354, -65281
  %v21_40c355 = or i32 %v19_40c355, %v20_40c355
  %v22_40c355 = or i32 %v21_40c355, 512
  %factor = select i1 %v21_40c354, i32 -8, i32 8
  %v23_40c35d = add i32 %factor, %v1_40c354
  store i32 %v23_40c35d, i32* %edi.global-to-local, align 4
  %v0_40c35e = load i32, i32* %edx.global-to-local, align 4
  %v1_40c35e = trunc i32 %v0_40c35e to i16
  %v3_40c35e = trunc i32 %v22_40c355 to i16
  %v4_40c35e = and i16 %v1_40c35e, 255
  %v5_40c35e = udiv i16 %v3_40c35e, %v4_40c35e
  %v6_40c35e = zext i16 %v5_40c35e to i32
  %v9_40c35e = and i32 %v21_40c355, -65536
  %v6_40c35e.masked = and i32 %v6_40c35e, 255
  %v2_40c360 = load i8, i8* %stack_var_-13, align 1
  %v3_40c360 = sext i8 %v2_40c360 to i32
  %v6_40c360 = and i32 %v3_40c360, 1
  %v7_40c360 = and i32 %v3_40c360, 4
  %v8_40c360 = and i32 %v3_40c360, 16
  %v9_40c360 = and i32 %v3_40c360, 64
  %v12_40c360 = and i32 %v3_40c360, 1024
  %v15_40c360 = icmp ne i32 %v6_40c360, 0
  %v18_40c360 = icmp ne i32 %v9_40c360, 0
  %v20_40c360 = icmp slt i8 %v2_40c360, 0
  %v23_40c360 = icmp ne i32 %v12_40c360, 0
  store i1 %v15_40c360, i1* %cf.global-to-local, align 1
  store i1 %v23_40c360, i1* %df.global-to-local, align 1
  %v1_40c368 = zext i1 %v15_40c360 to i32
  %v16_40c368 = select i1 %v20_40c360, i32 128, i32 0
  %v11_40c368 = or i32 %v1_40c368, %v16_40c368
  %v13_40c368 = or i32 %v11_40c368, %v7_40c360
  %v15_40c368 = or i32 %v13_40c368, %v8_40c360
  %v17_40c368 = or i32 %v15_40c368, %v9_40c360
  %v19_40c368 = mul nuw nsw i32 %v17_40c368, 256
  %v15_40c35e = or i32 %v6_40c35e.masked, %v9_40c35e
  %v21_40c368 = or i32 %v15_40c35e, %v19_40c368
  %v22_40c368 = or i32 %v21_40c368, 512
  store i32 %v22_40c368, i32* %eax.global-to-local, align 4
  br label %dec_label_pc_40c369

dec_label_pc_40c369:                              ; preds = %.dec_label_pc_40c369_crit_edge, %dec_label_pc_40bd72
  %v8_40c388 = phi i1 [ %v3_40c3b7, %.dec_label_pc_40c369_crit_edge ], [ %v20_40c360, %dec_label_pc_40bd72 ]
  %v6_40c388 = phi i1 [ %v2_40c3b7, %.dec_label_pc_40c369_crit_edge ], [ %v18_40c360, %dec_label_pc_40bd72 ]
  %v4_40c388 = phi i32 [ 0, %.dec_label_pc_40c369_crit_edge ], [ %v8_40c360, %dec_label_pc_40bd72 ]
  %v2_40c388 = phi i32 [ 0, %.dec_label_pc_40c369_crit_edge ], [ %v7_40c360, %dec_label_pc_40bd72 ]
  %v0_40c388 = phi i1 [ false, %.dec_label_pc_40c369_crit_edge ], [ %v15_40c360, %dec_label_pc_40bd72 ]
  %v4_40c38c = phi i1 [ %v4_40c36c.pre, %.dec_label_pc_40c369_crit_edge ], [ %v23_40c360, %dec_label_pc_40bd72 ]
  %v0_40c36c = load i32, i32* %esi.global-to-local, align 4
  %v5_40c36c = select i1 %v4_40c38c, i32 -4, i32 4
  %v6_40c36c = add i32 %v5_40c36c, %v0_40c36c
  %v5_40c36f = trunc i32 %v6_40c36c to i8
  store i8 %v5_40c36f, i8* %stack_var_-13, align 1
  %v1_40c370 = zext i1 %v0_40c388 to i32
  %v14_40c370 = select i1 %v6_40c388, i32 64, i32 0
  %v16_40c370 = select i1 %v8_40c388, i32 128, i32 0
  %v11_40c370 = or i32 %v14_40c370, %v16_40c370
  %v13_40c370 = or i32 %v11_40c370, %v4_40c388
  %v15_40c370 = or i32 %v13_40c370, %v1_40c370
  %v17_40c370 = or i32 %v15_40c370, %v2_40c388
  %v19_40c370 = mul nuw nsw i32 %v17_40c370, 256
  %v6_40c374 = add i32 %v6_40c36c, %v5_40c36c
  store i32 %v6_40c374, i32* %esi.global-to-local, align 4
  %sext = mul i32 %v6_40c36c, 16777216
  %v3_40c377 = sdiv i32 %sext, 16777216
  %v20_40c378 = and i32 %v3_40c377, -65281
  %v21_40c378 = or i32 %v19_40c370, %v20_40c378
  %v22_40c378 = or i32 %v21_40c378, 512
  store i32 %v22_40c378, i32* %eax.global-to-local, align 4
  %v1_40c37c = inttoptr i32 %v6_40c374 to i32*
  %v2_40c37c = load i32, i32* %v1_40c37c, align 4
  %v6_40c37c = add i32 %v6_40c374, %v5_40c36c
  store i32 %v6_40c37c, i32* %esi.global-to-local, align 4
  %v2_40c37f = load i64, i64* %stack_var_-9, align 8
  %v3_40c37f = trunc i64 %v2_40c37f to i32
  store i32 %v3_40c37f, i32* %edx.global-to-local, align 4
  %v2_40c37d = and i32 %v2_40c37c, -65536
  %v20_40c380 = or i32 %v19_40c370, %v2_40c37d
  %v22_40c380 = or i32 %v20_40c380, 758
  store i32 %v22_40c380, i32* %eax.global-to-local, align 4
  %v1_40c384 = inttoptr i32 %v6_40c37c to i32*
  %v2_40c384 = load i32, i32* %v1_40c384, align 4
  %v6_40c384 = add i32 %v6_40c37c, %v5_40c36c
  store i32 %v6_40c384, i32* %esi.global-to-local, align 4
  %v2_40c385 = and i32 %v2_40c384, -65536
  %v20_40c388 = or i32 %v19_40c370, %v2_40c385
  %v22_40c388 = or i32 %v20_40c388, 758
  store i32 %v22_40c388, i32* %eax.global-to-local, align 4
  %v1_40c38c = inttoptr i32 %v6_40c384 to i32*
  %v2_40c38c = load i32, i32* %v1_40c38c, align 4
  %v6_40c38c = add i32 %v6_40c384, %v5_40c36c
  store i32 %v6_40c38c, i32* %esi.global-to-local, align 4
  %v1_40c38d = and i32 %v2_40c38c, -256
  %v2_40c38d = or i32 %v1_40c38d, 246
  store i32 %v2_40c38d, i32* %eax.global-to-local, align 4
  %v0_40c38f = load i3, i3* @fpu_stat_TOP, align 1
  %storemerge15 = add i3 %v0_40c38f, 1
  store i3 %storemerge15, i3* @fpu_stat_TOP, align 1
  %v0_40c398 = load i32, i32* %ecx.global-to-local, align 4
  %v2_40c39d = zext i32 %v2_40c38d to i64
  %v4_40c39d = mul i64 %v2_40c37f, 4294967296
  %v6_40c39d = or i64 %v2_40c39d, %v4_40c39d
  %v8_40c39d = sdiv i64 %v6_40c39d, %v2_40c39d
  %v9_40c39d = trunc i64 %v8_40c39d to i32
  store i32 %v9_40c39d, i32* %eax.global-to-local, align 4
  %v10_40c39d = srem i64 %v6_40c39d, %v2_40c39d
  %v11_40c39d = trunc i64 %v10_40c39d to i32
  store i32 %v11_40c39d, i32* %edx.global-to-local, align 4
  %v2_40c39f = inttoptr i32 %v6_40c38c to i16*
  %v3_40c39f = load i16, i16* %v2_40c39f, align 2
  %v4_40c39f = sitofp i16 %v3_40c39f to x86_fp80
  %v5_40c39f = load x86_fp80, x86_fp80* %st0.global-to-local, align 4
  %v6_40c39f = fsub x86_fp80 %v5_40c39f, %v4_40c39f
  store x86_fp80 %v6_40c39f, x86_fp80* %st0.global-to-local, align 4
  %v1_40c3a1 = or i32 %v9_40c39d, 1821438196
  store i1 false, i1* %cf.global-to-local, align 1
  store i32 %v1_40c3a1, i32* %eax.global-to-local, align 4
  %v1_40c3a7 = inttoptr i32 %v11_40c39d to i32*
  %v2_40c3a7 = load i32, i32* %v1_40c3a7, align 4
  %v4_40c3a7 = and i32 %v0_40c398, 31
  %v6_40c3a7 = icmp eq i32 %v4_40c3a7, 0
  br i1 %v6_40c3a7, label %bb55, label %bb

bb:                                               ; preds = %dec_label_pc_40c369
  %v7_40c3a7 = shl i32 %v2_40c3a7, %v4_40c3a7
  store i32 %v7_40c3a7, i32* %v1_40c3a7, align 4
  %v16_40c3a7 = add nsw i32 %v4_40c3a7, -1
  %tmp57 = lshr i32 -2147483648, %v16_40c3a7
  %v18_40c3a7.mask56 = and i32 %v2_40c3a7, %tmp57
  %v19_40c3a7 = icmp ne i32 %v18_40c3a7.mask56, 0
  store i1 %v19_40c3a7, i1* %cf.global-to-local, align 1
  %v0_40c3a9.pre = load i32, i32* %eax.global-to-local, align 4
  br label %bb55

bb55:                                             ; preds = %dec_label_pc_40c369, %bb
  %v0_40c3a9 = phi i32 [ %v1_40c3a1, %dec_label_pc_40c369 ], [ %v0_40c3a9.pre, %bb ]
  %v1_40c3a9 = load i32, i32* %ebp.global-to-local, align 4
  store i32 %v1_40c3a9, i32* %eax.global-to-local, align 4
  store i32 %v0_40c3a9, i32* %ebp.global-to-local, align 4
  %v1_40c3aa = add i32 %v0_40c3a9, 1473049746
  %v2_40c3aa = inttoptr i32 %v1_40c3aa to i8*
  %v3_40c3aa = load i8, i8* %v2_40c3aa, align 1
  %v4_40c3aa = sub i8 0, %v3_40c3aa
  %v8_40c3aa = icmp ne i8 %v3_40c3aa, 0
  store i1 %v8_40c3aa, i1* %cf.global-to-local, align 1
  store i8 %v4_40c3aa, i8* %v2_40c3aa, align 1
  %v0_40c3b0 = load i32, i32* %eax.global-to-local, align 4
  %v1_40c3b0 = udiv i32 %v0_40c3b0, 256
  %v2_40c3b0 = trunc i32 %v1_40c3b0 to i8
  %v3_40c3b0 = load i32, i32* %edx.global-to-local, align 4
  %v4_40c3b0 = inttoptr i32 %v3_40c3b0 to i8*
  %v5_40c3b0 = load i8, i8* %v4_40c3b0, align 1
  %v6_40c3b0 = xor i8 %v2_40c3b0, %v5_40c3b0
  %v12_40c3b0 = zext i8 %v6_40c3b0 to i32
  %v14_40c3b0 = mul nuw nsw i32 %v12_40c3b0, 256
  %v15_40c3b0 = and i32 %v0_40c3b0, -291569440
  %v14_40c3b0.masked = and i32 %v14_40c3b0, 31488
  %v1_40c3b7 = or i32 %v14_40c3b0.masked, %v15_40c3b0
  store i1 false, i1* %cf.global-to-local, align 1
  %v4_40c3b7 = trunc i32 %v15_40c3b0 to i8
  %v5_40c3b7 = call i8 @llvm.ctpop.i8(i8 %v4_40c3b7)
  %v6_40c3b7 = and i8 %v5_40c3b7, 1
  %v7_40c3b7 = icmp eq i8 %v6_40c3b7, 0
  store i32 %v1_40c3b7, i32* %eax.global-to-local, align 4
  %v1_40c3bc = icmp eq i1 %v7_40c3b7, false
  br i1 %v1_40c3bc, label %.dec_label_pc_40c369_crit_edge, label %dec_label_pc_40c3be

.dec_label_pc_40c369_crit_edge:                   ; preds = %bb55
  %v3_40c3b7 = icmp slt i32 %v1_40c3b7, 0
  %v2_40c3b7 = icmp eq i32 %v1_40c3b7, 0
  %v4_40c36c.pre = load i1, i1* %df.global-to-local, align 1
  br label %dec_label_pc_40c369

dec_label_pc_40c3be:                              ; preds = %bb55
  %v1_40c3be = udiv i32 %v14_40c3b0.masked, 256
  %v2_40c3be = trunc i32 %v1_40c3be to i8
  %v3_40c3be = load i32, i32* %ebx.global-to-local, align 4
  %v4_40c3be = add i32 %v3_40c3be, -1042300935
  %v5_40c3be = inttoptr i32 %v4_40c3be to i8*
  %v6_40c3be = load i8, i8* %v5_40c3be, align 1
  %v7_40c3be = sub i8 %v2_40c3be, %v6_40c3be
  %v12_40c3be = icmp ult i8 %v2_40c3be, %v6_40c3be
  store i1 %v12_40c3be, i1* %cf.global-to-local, align 1
  %v22_40c3be = zext i8 %v7_40c3be to i32
  %v24_40c3be = mul nuw nsw i32 %v22_40c3be, 256
  %v26_40c3be = or i32 %v24_40c3be, %v15_40c3b0
  store i32 %v26_40c3be, i32* %eax.global-to-local, align 4
  %v0_40c3c4 = load i32, i32* @esp, align 4
  %v1_40c3c4 = inttoptr i32 %v0_40c3c4 to i32*
  %v2_40c3c4 = load i32, i32* %v1_40c3c4, align 4
  store i32 %v2_40c3c4, i32* %ebx.global-to-local, align 4
  %v1_40c3c5 = add i32 %v26_40c3be, 90
  %v2_40c3c5 = inttoptr i32 %v1_40c3c5 to i8*
  %v3_40c3c5 = load i8, i8* %v2_40c3c5, align 2
  %v4_40c3c5 = udiv i8 %v3_40c3c5, 2
  %v5_40c3c5 = shl i8 %v3_40c3c5, 7
  %v6_40c3c5 = or i8 %v4_40c3c5, %v5_40c3c5
  store i8 %v6_40c3c5, i8* %v2_40c3c5, align 2
  %v10_40c3c5 = and i8 %v3_40c3c5, 1
  %v11_40c3c5 = icmp ne i8 %v10_40c3c5, 0
  store i1 %v11_40c3c5, i1* %cf.global-to-local, align 1
  %v0_40c3c9 = load i32, i32* @esp, align 4
  %v1_40c3c9 = add i32 %v0_40c3c9, 4
  %v2_40c3c9 = add i32 %v0_40c3c9, 8
  %v3_40c3c9 = add i32 %v0_40c3c9, 16
  %v4_40c3c9 = add i32 %v0_40c3c9, 20
  %v5_40c3c9 = add i32 %v0_40c3c9, 24
  %v6_40c3c9 = add i32 %v0_40c3c9, 28
  %v8_40c3c9 = inttoptr i32 %v0_40c3c9 to i32*
  %v9_40c3c9 = load i32, i32* %v8_40c3c9, align 4
  %v10_40c3c9 = inttoptr i32 %v1_40c3c9 to i32*
  %v11_40c3c9 = load i32, i32* %v10_40c3c9, align 4
  %v12_40c3c9 = inttoptr i32 %v2_40c3c9 to i32*
  %v13_40c3c9 = load i32, i32* %v12_40c3c9, align 4
  %v14_40c3c9 = inttoptr i32 %v3_40c3c9 to i32*
  %v15_40c3c9 = load i32, i32* %v14_40c3c9, align 4
  %v16_40c3c9 = inttoptr i32 %v4_40c3c9 to i32*
  %v17_40c3c9 = load i32, i32* %v16_40c3c9, align 4
  %v18_40c3c9 = inttoptr i32 %v5_40c3c9 to i32*
  %v19_40c3c9 = load i32, i32* %v18_40c3c9, align 4
  %v20_40c3c9 = inttoptr i32 %v6_40c3c9 to i32*
  %v21_40c3c9 = load i32, i32* %v20_40c3c9, align 4
  store i32 %v9_40c3c9, i32* %edi.global-to-local, align 4
  store i32 %v11_40c3c9, i32* %esi.global-to-local, align 4
  store i32 %v13_40c3c9, i32* %ebp.global-to-local, align 4
  store i32 %v15_40c3c9, i32* %ebx.global-to-local, align 4
  store i32 %v17_40c3c9, i32* %edx.global-to-local, align 4
  store i32 %v19_40c3c9, i32* %ecx.global-to-local, align 4
  store i32 %v21_40c3c9, i32* %eax.global-to-local, align 4
  %v0_40c3cb = call i32 @unknown_4b353338()
  store i32 %v0_40c3cb, i32* %eax.global-to-local, align 4
  ret i32 %v0_40c3cb

; uselistorder directives
  uselistorder i32 %v0_40c3c9, { 5, 0, 1, 2, 3, 4, 6 }
  uselistorder i8 %v3_40c3c5, { 1, 2, 0 }
  uselistorder i32 %v15_40c3b0, { 0, 2, 1 }
  uselistorder i32 %v0_40c3b0, { 1, 0 }
  uselistorder i32 %v0_40c3a9, { 1, 0 }
  uselistorder i64 %v2_40c39d, { 2, 1, 0 }
  uselistorder i32 %v19_40c370, { 2, 1, 0 }
  uselistorder i1 %v20_40c360, { 1, 0 }
  uselistorder i8 %v2_40c34e, { 1, 0 }
  uselistorder i8 %v1_40c347, { 1, 0 }
  uselistorder i8 %v2_40c343, { 1, 0 }
  uselistorder i32 %v0_40c33b, { 1, 2, 0 }
  uselistorder i8 %v2_40c32e, { 1, 0 }
  uselistorder i32 %v6_40c32c, { 1, 0 }
  uselistorder i32 %v5_40c32c, { 1, 0 }
  uselistorder i32 %v3_40c32c, { 1, 0, 2 }
  uselistorder i32 %v0_40c32c, { 1, 2, 3, 0 }
  uselistorder i8 %v2_40c32a, { 1, 0 }
  uselistorder i8 %v2_40c328, { 1, 0 }
  uselistorder i8 %v2_40c326, { 1, 0 }
  uselistorder i32 %v1_40c321, { 0, 2, 1 }
  uselistorder i32 %v0_40c321, { 1, 0 }
  uselistorder i8 %v2_40c31c, { 1, 0 }
  uselistorder i8 %v2_40c31a, { 1, 0 }
  uselistorder i8 %v2_40c318, { 1, 0 }
  uselistorder i8 %v2_40c316, { 1, 0 }
  uselistorder i8 %v2_40c314, { 1, 0 }
  uselistorder i8 %v2_40c312, { 1, 0 }
  uselistorder i8 %v2_40c310, { 1, 0 }
  uselistorder i8 %v2_40c30e, { 1, 0 }
  uselistorder i8 %v6_40c308, { 1, 0 }
  uselistorder i8 %v5_40c308, { 1, 0 }
  uselistorder i1 %v26_40c302, { 1, 0, 2 }
  uselistorder i8 %v6_40c302, { 2, 3, 0, 4, 1 }
  uselistorder i8 %v5_40c302, { 1, 0 }
  uselistorder i1 %v5_40c2ff, { 1, 0, 2 }
  uselistorder i32 %v1_40c2ff, { 0, 2, 1 }
  uselistorder i32 %v0_40c2ff, { 1, 0 }
  uselistorder i32 %v4_40c2e1, { 1, 0 }
  uselistorder i1 %v5_40c2de, { 1, 0 }
  uselistorder i8 %v2_40c2c6, { 1, 0 }
  uselistorder i32 %v0_40c2c6, { 1, 2, 0 }
  uselistorder i32 %v2_40c2c1, { 1, 0, 2 }
  uselistorder i32 %v0_40c28c, { 1, 0 }
  uselistorder i32 %v0_40c276, { 1, 0 }
  uselistorder i32 %v0_40c24b, { 1, 0 }
  uselistorder i32 %v5_40c207, { 1, 0 }
  uselistorder i32 %v4_40c207, { 1, 0 }
  uselistorder i1 %v26_40c1fc, { 1, 0 }
  uselistorder i32 %v5_40c1fc, { 0, 1, 3, 2 }
  uselistorder i32 %v4_40c1fc, { 1, 0 }
  uselistorder i32 %v0_40c1fc, { 1, 2, 0 }
  uselistorder i1 %v5_40c1f9, { 1, 0 }
  uselistorder i32 %v2_40c1e8, { 1, 0, 2 }
  uselistorder i32 %v0_40c1d3, { 1, 0 }
  uselistorder i8 %v2_40c1d1, { 1, 0 }
  uselistorder i32 %v4_40c1ca, { 1, 0 }
  uselistorder i32 %v0_40c1ca, { 1, 2, 0 }
  uselistorder i1 %v26_40c1c4, { 1, 0 }
  uselistorder i32 %v5_40c1c4, { 1, 0 }
  uselistorder i32 %v4_40c1c4, { 1, 0 }
  uselistorder i32 %v0_40c1c4, { 1, 2, 0 }
  uselistorder i1 %v23_40c1c2, { 1, 0 }
  uselistorder i8 %v6_40c1c2, { 1, 0 }
  uselistorder i8 %v5_40c1c2, { 1, 0 }
  uselistorder i8 %v3_40c1c2, { 1, 0, 2 }
  uselistorder i1 %v7_40c1c0, { 1, 0 }
  uselistorder i32 %v4_40c1b3, { 1, 0, 2 }
  uselistorder i32 %v5_40c1b1, { 1, 0 }
  uselistorder i32 %v4_40c1b1, { 1, 0 }
  uselistorder i1 %v26_40c1ab, { 1, 0 }
  uselistorder i32 %v5_40c1ab, { 0, 2, 1 }
  uselistorder i32 %v4_40c1ab, { 1, 0 }
  uselistorder i1 %v13_40c1a8, { 1, 0 }
  uselistorder i32 %v4_40c1a8, { 2, 1, 0, 3 }
  uselistorder i32 %v1_40c1a3, { 2, 1, 0 }
  uselistorder i32 %v1_40c1a0, { 2, 1, 0, 3 }
  uselistorder i32 %v5_40c194, { 1, 0 }
  uselistorder i32 %v4_40c194, { 1, 0 }
  uselistorder i32 %v0_40c194, { 1, 2, 0 }
  uselistorder i1 %v7_40c18e, { 1, 0 }
  uselistorder i32 %v0_40c17a, { 1, 0 }
  uselistorder i32 %v4_40c16f, { 1, 0 }
  uselistorder i1 %v26_40c169, { 1, 0 }
  uselistorder i32 %v5_40c169, { 3, 2, 1, 0 }
  uselistorder i32 %v4_40c169, { 1, 0 }
  uselistorder i1 %v7_40c163, { 1, 0 }
  uselistorder i32 %v1_40c160, { 2, 1, 0, 3 }
  uselistorder i32 %v2_40c143, { 1, 0 }
  uselistorder i32 %v0_40c0ff, { 1, 0 }
  uselistorder i8 %v0_40c0da, { 1, 0 }
  uselistorder i32 %v2_40c0d8, { 1, 0 }
  uselistorder i32 %v0_40c0c3, { 1, 0 }
  uselistorder i32 %v5_40c0bd, { 1, 0 }
  uselistorder i32 %v4_40c0bd, { 1, 0 }
  uselistorder i32 %v1_40c0b1, { 1, 0, 2, 3 }
  uselistorder i32 %v0_40c0b1, { 1, 0 }
  uselistorder i8 %v3_40c096, { 1, 0 }
  uselistorder i8 %v3_40c090, { 1, 0 }
  uselistorder i32 %v3_40c08d, { 1, 0 }
  uselistorder i32 %v2_40c068, { 1, 0 }
  uselistorder i32 %v0_40c040, { 1, 0 }
  uselistorder i32 %v9_40c000, { 2, 0, 3, 1, 4 }
  uselistorder i32 %v1_40bfdb, { 2, 1, 0 }
  uselistorder i32 %v5_40bfb7, { 0, 2, 1 }
  uselistorder i32 %v4_40bfb7, { 1, 0 }
  uselistorder i32 %v0_40bfb7, { 1, 2, 0 }
  uselistorder i1 %v12_40bfb4, { 1, 0 }
  uselistorder i32 %v0_40bfb4, { 1, 0 }
  uselistorder i32 %v4_40bf95, { 1, 0 }
  uselistorder i1 %v8_40bf8f, { 1, 0, 2 }
  uselistorder i8 %v0_40bf8f, { 1, 0 }
  uselistorder i8 %v0_40bf80, { 1, 0 }
  uselistorder i8 %v0_40bf6c, { 1, 0 }
  uselistorder i32 %v2_40bf5d, { 1, 0, 2 }
  uselistorder i32 %v0_40bf40, { 1, 0 }
  uselistorder i32 %v0_40bf04, { 1, 0 }
  uselistorder i1 %v22_40befe, { 1, 0 }
  uselistorder i32 %v5_40befe, { 1, 0 }
  uselistorder i32 %v4_40befe, { 1, 0 }
  uselistorder i1 %v7_40bef8, { 1, 0 }
  uselistorder i32 %v0_40bef8, { 1, 0 }
  uselistorder i32 %v7_40bedd, { 1, 3, 2, 0, 4 }
  uselistorder i8 %v2_40be8c, { 1, 0 }
  uselistorder i8 %v2_40be8a, { 1, 0 }
  uselistorder i8 %v2_40be88, { 1, 0 }
  uselistorder i8 %v2_40be86, { 1, 0 }
  uselistorder i8 %v2_40be84, { 1, 0 }
  uselistorder i8 %v2_40be82, { 1, 0 }
  uselistorder i8 %v2_40be80, { 1, 0 }
  uselistorder i32 %v4_40be79, { 1, 0 }
  uselistorder i32 %v0_40be79, { 1, 2, 0 }
  uselistorder i1 %v26_40be73, { 1, 0 }
  uselistorder i32 %v5_40be73, { 1, 0 }
  uselistorder i32 %v4_40be73, { 1, 0 }
  uselistorder i32 %v0_40be73, { 1, 2, 0 }
  uselistorder i1 %v8_40be71, { 1, 0 }
  uselistorder i8 %v0_40be45, { 1, 0 }
  uselistorder i32 %v2_40be3d, { 1, 0, 2 }
  uselistorder i32 %v0_40be33, { 1, 0 }
  uselistorder i32 %v4_40bdec, { 1, 0 }
  uselistorder i32 %v0_40bdec, { 1, 2, 0 }
  uselistorder i1 %v24_40bde9, { 1, 0 }
  uselistorder i32 %v4_40bde9, { 1, 0 }
  uselistorder i1 %v7_40bde3, { 1, 0 }
  uselistorder i32 %v5_40bdc6, { 2, 1, 0, 3 }
  uselistorder i32 %v0_40bdb7, { 1, 0 }
  uselistorder i8 %v0_40bda3, { 1, 0 }
  uselistorder i32 %v0_40bd7e, { 1, 0 }
  uselistorder i8* %stack_var_-13, { 1, 0 }
  uselistorder i8* %tmp31, { 0, 2, 1 }
  uselistorder x86_fp80* %st0.global-to-local, { 5, 4, 3, 1, 0, 2 }
  uselistorder i32* %ebx.global-to-local, { 0, 1, 2, 3, 4, 5, 6, 9, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 30, 32, 33, 34, 35, 36, 37, 38, 39 }
  uselistorder i32* %eax.global-to-local, { 84, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83 }
  uselistorder i32 28, { 1, 5, 2, 6, 0, 7, 8, 3, 4 }
  uselistorder i32 24, { 0, 2, 1 }
  uselistorder i8 7, { 2, 0, 1 }
  uselistorder i8 2, { 0, 3, 1, 2 }
  uselistorder i32 90, { 0, 2, 3, 4, 5, 1 }
  uselistorder i32* @esp, { 1, 2, 3, 4, 5, 6, 0, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 29, 20, 21, 22, 23, 24, 25, 26, 27, 28 }
  uselistorder i32 16777216, { 1, 0, 5, 2, 6, 3, 16, 7, 4, 9, 8, 12, 10, 13, 11, 15, 14 }
  uselistorder i32 -4, { 25, 26, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27 }
  uselistorder i32 -65536, { 0, 1, 5, 2, 3, 4 }
  uselistorder i32 8, { 3, 0, 1, 5, 4, 6, 2 }
  uselistorder i32 -8, { 0, 3, 4, 1, 5, 6, 7, 2, 8 }
  uselistorder i32 512, { 3, 4, 5, 0, 1, 2 }
  uselistorder i32 128, { 0, 1, 2, 4, 3, 5 }
  uselistorder i32 31, { 1, 0, 2, 3, 4 }
  uselistorder i32 64, { 0, 5, 1, 6, 2, 7, 8, 9, 3, 4 }
  uselistorder i32 16, { 1, 3, 0, 4, 2, 5 }
  uselistorder i8 1, { 8, 9, 10, 1, 2, 0, 3, 4, 5, 11, 6, 7 }
  uselistorder i8 0, { 8, 9, 10, 11, 7, 12, 0, 1, 2, 3, 4, 13, 5, 6 }
  uselistorder i32 -59, { 3, 4, 0, 2, 1 }
  uselistorder i32 85, { 2, 0, 1, 3 }
  uselistorder i32* inttoptr (i32 4763907 to i32*), { 2, 3, 0, 1 }
  uselistorder i32 133, { 1, 2, 3, 0 }
  uselistorder i32 37, { 1, 3, 2, 5, 0, 4 }
  uselistorder i32 7, { 4, 5, 6, 7, 0, 2, 8, 3, 1 }
  uselistorder i32 86, { 1, 0 }
  uselistorder i32* inttoptr (i32 4763873 to i32*), { 0, 1, 4, 5, 2, 3 }
  uselistorder i32 -1, { 11, 12, 3, 13, 14, 15, 16, 17, 18, 4, 5, 0, 19, 20, 21, 49, 22, 23, 24, 6, 25, 26, 27, 28, 29, 7, 30, 31, 32, 33, 34, 50, 35, 36, 37, 38, 39, 40, 41, 42, 43, 2, 44, 45, 8, 46, 9, 10, 1, 47, 48 }
  uselistorder i32 94, { 2, 1, 0, 3, 4 }
  uselistorder i32* inttoptr (i32 4763742 to i32*), { 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 0, 1, 2, 3, 4, 5 }
  uselistorder i32 -116, { 2, 0, 1 }
  uselistorder i32* inttoptr (i32 4764111 to i32*), { 0, 1, 4, 5, 6, 7, 8, 2, 3, 9 }
  uselistorder i32* inttoptr (i32 4763788 to i32*), { 2, 3, 0, 1 }
  uselistorder i32 4764020, { 1, 0 }
  uselistorder i32* inttoptr (i32 4763909 to i32*), { 1, 2, 3, 4, 5, 6, 7, 8, 0 }
  uselistorder i32 22, { 2, 0, 3, 4, 1 }
  uselistorder i32* inttoptr (i32 4763767 to i32*), { 2, 3, 4, 5, 6, 7, 8, 9, 10, 0, 1 }
  uselistorder i32* inttoptr (i32 4763893 to i32*), { 0, 1, 2, 8, 9, 3, 4, 5, 6, 7 }
  uselistorder i32 -60, { 2, 0, 3, 1, 4 }
  uselistorder i32 59, { 4, 1, 6, 0, 7, 8, 3, 2, 5 }
  uselistorder i32 97, { 1, 0, 2, 3 }
  uselistorder i32 62, { 0, 1, 2, 4, 3 }
  uselistorder i32 -63, { 1, 2, 3, 4, 0, 5 }
  uselistorder i32 4763913, { 1, 0 }
  uselistorder i32 4763681, { 1, 0 }
  uselistorder i32* inttoptr (i32 4763681 to i32*), { 1, 2, 0 }
  uselistorder i32 4764062, { 1, 0 }
  uselistorder i32 12, { 1, 0, 2 }
  uselistorder i32 115, { 1, 2, 3, 0 }
  uselistorder i32 -113, { 0, 4, 1, 2, 5, 3 }
  uselistorder i32 68, { 1, 2, 3, 0, 4 }
  uselistorder i32* inttoptr (i32 4763807 to i32*), { 2, 3, 6, 7, 8, 9, 10, 11, 12, 4, 5, 13, 14, 15, 0, 1 }
  uselistorder i32 4, { 3, 4, 5, 0, 6, 7, 1, 2 }
  uselistorder i32* inttoptr (i32 4764029 to i32*), { 1, 2, 3, 4, 5, 0 }
  uselistorder i32* (i32, i1, i16*)* @OpenJobObjectW, { 13, 12, 11, 8, 10, 9, 0, 1, 7, 6, 5, 4, 3, 2, 14 }
  uselistorder [13 x i8]* @global_var_48b6a3.4, { 1, 0 }
  uselistorder i32* inttoptr (i32 4763902 to i32*), { 2, 3, 0, 1 }
  uselistorder i32 4763746, { 1, 0 }
  uselistorder i32 181, { 1, 2, 0 }
  uselistorder i8* inttoptr (i32 1219589141 to i8*), { 1, 0 }
  uselistorder i32 98, { 2, 3, 0, 4, 1 }
  uselistorder i32* inttoptr (i32 4763834 to i32*), { 2, 3, 4, 5, 6, 0, 1 }
  uselistorder i32 219, { 2, 0, 3, 1 }
  uselistorder i32 60, { 1, 6, 7, 3, 0, 4, 8, 2, 5 }
  uselistorder i32 -125, { 1, 2, 0, 3 }
  uselistorder i32 103, { 0, 1, 3, 4, 8, 5, 6, 7, 2 }
  uselistorder i32 81, { 4, 1, 2, 5, 0, 3 }
  uselistorder i32 4763886, { 1, 0 }
  uselistorder i32* inttoptr (i32 4763886 to i32*), { 2, 3, 4, 7, 8, 5, 6, 0, 1 }
  uselistorder i32 4763786, { 1, 0 }
  uselistorder i32 93, { 1, 0, 2, 3, 4 }
  uselistorder i32 -97, { 0, 1, 4, 2, 3 }
  uselistorder i32 96, { 1, 2, 3, 4, 0 }
  uselistorder i32* inttoptr (i32 4764007 to i32*), { 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 0, 1 }
  uselistorder i32* inttoptr (i32 4763766 to i32*), { 2, 3, 4, 5, 6, 7, 0, 1 }
  uselistorder i32 39, { 1, 0, 2, 3, 4 }
  uselistorder i32* inttoptr (i32 4763815 to i32*), { 0, 1, 2, 5, 6, 3, 4 }
  uselistorder i32 125, { 1, 2, 3, 0 }
  uselistorder i1 (i16*, i16*)* @SetEnvironmentVariableW, { 15, 14, 13, 6, 12, 11, 10, 9, 8, 7, 0, 1, 5, 4, 3, 2, 17, 16 }
  uselistorder [17 x i8]* @global_var_48b692.1, { 1, 0 }
  uselistorder [13 x i8]* @global_var_48b685.2, { 1, 0 }
  uselistorder i32 2, { 1, 47, 2, 61, 48, 49, 3, 4, 5, 62, 63, 6, 7, 50, 8, 64, 77, 51, 65, 9, 66, 10, 74, 11, 12, 13, 14, 67, 52, 68, 15, 16, 17, 53, 18, 69, 19, 75, 20, 70, 71, 21, 22, 23, 24, 72, 54, 25, 26, 78, 27, 28, 55, 29, 30, 31, 32, 33, 56, 60, 59, 34, 35, 57, 0, 36, 37, 38, 39, 40, 41, 42, 43, 58, 76, 44, 45, 73, 46 }
  uselistorder i32 18, { 1, 0, 2, 3 }
  uselistorder i32 -19, { 1, 4, 2, 0, 5, 3 }
  uselistorder i32 48, { 2, 1, 0, 3, 4 }
  uselistorder i32 -85, { 2, 0, 3, 1 }
  uselistorder i32* inttoptr (i32 4764152 to i32*), { 1, 2, 3, 0 }
  uselistorder i32 27, { 1, 0, 2, 3 }
  uselistorder i32 -27, { 1, 2, 3, 0 }
  uselistorder i32 -48, { 2, 3, 0, 1 }
  uselistorder i32 -65281, { 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 0, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 109, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 103, 104, 105, 106, 107, 108, 20, 79, 80, 81, 82, 83, 84, 1, 85, 86, 2, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12 }
  uselistorder i32 4763662, { 1, 0 }
  uselistorder i32 4764025, { 1, 0, 2 }
  uselistorder i32 220, { 1, 2, 0, 3, 4 }
  uselistorder i32 253, { 1, 0, 2 }
  uselistorder i1 true, { 1, 2, 3, 0, 4, 5, 6, 7 }
  uselistorder i32* inttoptr (i32 4763964 to i32*), { 2, 3, 4, 5, 0, 1 }
  uselistorder i32 255, { 24, 4, 0, 5, 25, 6, 26, 7, 8, 23, 9, 10, 1, 2, 11, 12, 13, 14, 28, 15, 16, 27, 17, 18, 19, 20, 21, 3, 22 }
  uselistorder i32 -94, { 2, 3, 1, 0 }
  uselistorder void (i1, i32)* @__pseudo_cond_branch, { 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 24, 6, 16, 17, 18, 19, 20, 21, 22, 23, 0, 1 }
  uselistorder i32 ptrtoint (i16** @global_var_406dd5.3 to i32), { 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0 }
  uselistorder i1 (i8*, i32)* @IsBadStringPtrA, { 8, 6, 5, 4, 3, 2, 7, 1, 0, 9 }
  uselistorder i32 11, { 0, 10, 1, 11, 2, 12, 3, 13, 22, 4, 14, 5, 15, 23, 24, 6, 16, 7, 17, 20, 8, 18, 21, 9, 19 }
  uselistorder i32 51, { 0, 2, 3, 1 }
  uselistorder i32 -256, { 12, 13, 14, 15, 16, 17, 18, 19, 20, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 2, 49, 50, 51, 52, 53, 1, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 3, 66, 67, 68, 106, 107, 69, 70, 71, 72, 73, 74, 75, 76, 77, 100, 101, 102, 103, 104, 105, 21, 22, 78, 79, 80, 81, 82, 0, 83, 84, 85, 4, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 5, 6, 7, 8, 9, 10, 11 }
  uselistorder i32 4763688, { 1, 0 }
  uselistorder i32 -45, { 0, 2, 3, 1, 4 }
  uselistorder i32 4764071, { 1, 0 }
  uselistorder i32* inttoptr (i32 4763959 to i32*), { 2, 3, 4, 5, 6, 7, 0, 1 }
  uselistorder i32* inttoptr (i32 4763925 to i32*), { 2, 3, 0, 1 }
  uselistorder i8 -21, { 1, 0 }
  uselistorder i8 21, { 1, 0 }
  uselistorder i32 -127, { 0, 1, 2, 4, 3 }
  uselistorder i32* inttoptr (i32 4763731 to i32*), { 2, 3, 4, 5, 6, 7, 8, 0, 1 }
  uselistorder i32 -34, { 2, 1, 3, 0 }
  uselistorder i32 34, { 2, 3, 0, 5, 4, 1 }
  uselistorder i32 -115, { 3, 0, 2, 4, 5, 6, 1 }
  uselistorder i32* inttoptr (i32 4763922 to i32*), { 0, 1, 4, 5, 2, 3 }
  uselistorder void (i32)* @__pseudo_call, { 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 54, 50, 51, 52, 53, 10, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 0, 1, 2, 3 }
  uselistorder i32 -99, { 2, 4, 3, 5, 0, 1 }
  uselistorder i32 -93, { 2, 0, 1, 3 }
  uselistorder i32 -176, { 1, 0, 2, 3 }
  uselistorder i32 175, { 1, 0, 2 }
  uselistorder i32 176, { 0, 2, 1 }
  uselistorder i32 120, { 3, 0, 5, 6, 1, 2, 4 }
  uselistorder i32 -121, { 3, 0, 1, 2 }
  uselistorder i32* inttoptr (i32 4764018 to i32*), { 2, 3, 4, 5, 6, 7, 8, 9, 10, 0, 1 }
  uselistorder i32 256, { 2, 3, 4, 5, 6, 7, 8, 13, 9, 14, 10, 15, 11, 16, 17, 18, 12, 19, 20, 21, 22, 56, 57, 23, 58, 236, 59, 24, 60, 61, 25, 62, 63, 64, 65, 26, 66, 229, 27, 67, 68, 28, 69, 70, 71, 72, 29, 30, 31, 73, 32, 74, 33, 75, 34, 76, 77, 35, 78, 36, 37, 79, 80, 81, 38, 82, 39, 83, 40, 84, 85, 41, 86, 42, 87, 88, 89, 43, 90, 91, 92, 93, 94, 230, 95, 96, 44, 97, 98, 45, 99, 46, 100, 47, 48, 101, 102, 103, 104, 105, 49, 106, 231, 107, 50, 108, 109, 232, 110, 51, 111, 112, 113, 114, 52, 115, 116, 53, 117, 118, 119, 54, 120, 121, 55, 122, 123, 126, 124, 127, 125, 128, 129, 130, 133, 131, 134, 132, 135, 136, 138, 137, 139, 140, 144, 0, 141, 145, 142, 146, 147, 143, 148, 1, 149, 151, 152, 150, 153, 154, 176, 155, 177, 156, 178, 233, 179, 180, 181, 157, 182, 237, 234, 158, 183, 159, 184, 185, 186, 160, 187, 161, 188, 162, 163, 189, 190, 164, 191, 165, 192, 193, 235, 194, 166, 195, 167, 196, 197, 198, 168, 199, 169, 200, 201, 170, 171, 202, 172, 203, 173, 204, 174, 205, 175, 206, 207, 208, 209, 216, 217, 210, 218, 219, 211, 220, 212, 221, 222, 213, 223, 224, 214, 225, 215, 226, 227, 228 }
  uselistorder i32 110, { 2, 0, 4, 3, 1 }
  uselistorder i32 4763923, { 1, 0 }
  uselistorder i32* inttoptr (i32 4763923 to i32*), { 2, 3, 4, 5, 0, 1 }
  uselistorder i32* (i32*)* @EncodePointer, { 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 0, 3, 1, 2 }
  uselistorder i32 13, { 2, 3, 0, 4, 5, 6, 1 }
  uselistorder i32 -13, { 3, 0, 1, 2 }
  uselistorder i32 72, { 3, 4, 0, 1, 5, 6, 2 }
  uselistorder i32 217, { 2, 3, 0, 1 }
  uselistorder i8 -87, { 1, 0 }
  uselistorder i32 4764084, { 1, 0 }
  uselistorder i32* @esi, { 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 13, 14, 0, 1 }
  uselistorder i32 63, { 2, 1, 0, 3 }
  uselistorder i32 20, { 2, 3, 4, 5, 1, 0, 6 }
  uselistorder i32 54, { 2, 4, 5, 0, 6, 7, 3, 1, 8 }
  uselistorder i32* @edi, { 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 13, 0, 1 }
  uselistorder i32* @ebx, { 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 19, 20, 17, 18, 0 }
  uselistorder i32* inttoptr (i32 4763700 to i32*), { 2, 3, 4, 5, 6, 7, 11, 12, 8, 9, 10, 0, 1 }
  uselistorder i1 false, { 66, 67, 68, 3, 69, 70, 37, 4, 71, 72, 73, 38, 5, 74, 75, 76, 77, 78, 79, 20, 39, 80, 81, 82, 0, 89, 21, 40, 90, 22, 91, 23, 92, 93, 94, 95, 96, 41, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 24, 110, 111, 112, 25, 113, 114, 115, 116, 117, 6, 118, 119, 120, 121, 122, 7, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 42, 8, 135, 136, 137, 138, 26, 139, 140, 141, 27, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 2, 9, 154, 155, 156, 157, 158, 159, 10, 160, 161, 162, 163, 164, 28, 165, 166, 167, 168, 169, 170, 171, 172, 29, 43, 173, 241, 44, 11, 242, 30, 243, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 240, 1, 231, 232, 233, 234, 235, 236, 237, 238, 239, 83, 84, 85, 31, 86, 87, 88, 191, 192, 45, 12, 193, 194, 195, 196, 13, 197, 198, 199, 200, 32, 201, 202, 203, 204, 205, 206, 33, 207, 208, 209, 14, 210, 211, 212, 213, 34, 214, 215, 15, 216, 217, 218, 219, 35, 46, 220, 221, 222, 16, 223, 224, 225, 226, 47, 17, 227, 48, 228, 229, 230, 49, 50, 51, 52, 53, 54, 55, 36, 56, 57, 58, 59, 60, 61, 18, 62, 63, 64, 19, 65, 244, 245 }
  uselistorder i32 1, { 151, 59, 41, 152, 60, 153, 42, 154, 61, 62, 63, 64, 155, 43, 156, 54, 65, 147, 144, 145, 32, 26, 1, 27, 31, 30, 28, 25, 33, 24, 29, 66, 67, 157, 68, 158, 159, 69, 160, 70, 71, 72, 161, 73, 74, 75, 76, 77, 162, 44, 163, 78, 0, 164, 79, 165, 80, 45, 166, 81, 82, 167, 53, 83, 84, 168, 85, 86, 87, 88, 89, 90, 169, 91, 170, 92, 171, 93, 172, 46, 173, 174, 94, 175, 95, 176, 47, 177, 96, 178, 97, 98, 179, 99, 180, 181, 100, 101, 182, 102, 183, 103, 184, 104, 105, 106, 185, 186, 107, 108, 109, 207, 110, 48, 208, 148, 146, 2, 3, 8, 5, 6, 7, 9, 4, 111, 187, 188, 112, 113, 189, 114, 205, 115, 116, 206, 55, 117, 118, 12, 13, 11, 10, 14, 15, 16, 119, 58, 57, 49, 190, 120, 121, 122, 123, 191, 50, 192, 124, 193, 194, 51, 195, 125, 126, 196, 127, 128, 129, 197, 130, 198, 131, 132, 199, 200, 133, 134, 201, 135, 202, 52, 203, 136, 137, 204, 17, 19, 21, 20, 18, 23, 22, 138, 139, 149, 56, 140, 141, 142, 150, 143, 36, 34, 37, 38, 39, 35, 40 }
  uselistorder label %bb55, { 1, 0 }
}

define i32 @function_48b000(i8* %arg1, i32 %arg2, i32 %arg3, i32 %arg4, i32 %arg5, i32 %arg6, i32 %arg7, i32 %arg8, i32 %arg9, i32 %arg10, i32 %arg11, i32 %arg12, i32 %arg13, i32 %arg14) local_unnamed_addr {
entry:
  call void @llvm.trap()
  unreachable

; uselistorder directives
  uselistorder void ()* @llvm.trap, { 2, 0, 3, 1 }
}

declare i32* @OpenJobObjectW(i32, i1, i16*) local_unnamed_addr

declare i32* @EncodePointer(i32*) local_unnamed_addr

declare i1 @SetEnvironmentVariableW(i16*, i16*) local_unnamed_addr

declare i32 @WaitForSingleObject(i32*, i32) local_unnamed_addr

declare i32 ()* @GetProcAddress(i32*, i8*) local_unnamed_addr

declare i1 @IsBadStringPtrA(i8*, i32) local_unnamed_addr

declare i32* @LoadLibraryA(i8*) local_unnamed_addr

define i32 @function_48b804() local_unnamed_addr {
entry:
  %v0_48b804 = load i32, i32* @eax, align 4
  %v1_48b804 = inttoptr i32 %v0_48b804 to i8*
  %v2_48b804 = load i8, i8* %v1_48b804, align 1
  %v4_48b804 = trunc i32 %v0_48b804 to i8
  %v5_48b804 = add i8 %v4_48b804, %v2_48b804
  store i8 %v5_48b804, i8* %v1_48b804, align 1
  %v0_48b806 = load i32, i32* @eax, align 4
  %v1_48b806 = inttoptr i32 %v0_48b806 to i8*
  %v2_48b806 = load i8, i8* %v1_48b806, align 1
  %v4_48b806 = trunc i32 %v0_48b806 to i8
  %v5_48b806 = add i8 %v4_48b806, %v2_48b806
  store i8 %v5_48b806, i8* %v1_48b806, align 1
  %v0_48b808 = load i32, i32* @eax, align 4
  %v1_48b808 = inttoptr i32 %v0_48b808 to i8*
  %v2_48b808 = load i8, i8* %v1_48b808, align 1
  %v4_48b808 = trunc i32 %v0_48b808 to i8
  %v5_48b808 = add i8 %v4_48b808, %v2_48b808
  store i8 %v5_48b808, i8* %v1_48b808, align 1
  %v0_48b80a = load i32, i32* @eax, align 4
  %v1_48b80a = inttoptr i32 %v0_48b80a to i8*
  %v2_48b80a = load i8, i8* %v1_48b80a, align 1
  %v4_48b80a = trunc i32 %v0_48b80a to i8
  %v5_48b80a = add i8 %v4_48b80a, %v2_48b80a
  store i8 %v5_48b80a, i8* %v1_48b80a, align 1
  %v22_48b80a = load i32, i32* @eax, align 4
  ret i32 %v22_48b80a

; uselistorder directives
  uselistorder i32 0, { 131, 130, 9, 132, 3, 4, 2, 1, 5, 133, 134, 135, 6, 7, 136, 25, 26, 27, 100, 28, 119, 120, 137, 31, 101, 102, 32, 33, 34, 35, 36, 18, 29, 138, 30, 121, 37, 122, 123, 124, 38, 39, 40, 41, 42, 125, 43, 44, 103, 45, 104, 46, 19, 139, 126, 47, 48, 49, 50, 105, 51, 52, 53, 54, 55, 106, 56, 57, 58, 20, 12, 140, 107, 108, 109, 59, 60, 61, 74, 62, 141, 142, 143, 144, 13, 63, 145, 64, 65, 98, 99, 66, 67, 68, 69, 151, 111, 147, 70, 71, 148, 112, 8, 149, 72, 14, 113, 73, 150, 76, 110, 77, 75, 78, 21, 79, 80, 22, 127, 81, 114, 82, 83, 10, 15, 84, 85, 146, 115, 86, 116, 117, 87, 23, 24, 118, 88, 90, 91, 128, 92, 93, 94, 11, 17, 16, 95, 89, 129, 96, 0, 97, 152, 153, 154, 155, 156, 157, 158 }
  uselistorder i32* @eax, { 0, 4, 5, 6, 7, 9, 10, 1, 11, 12, 2, 13, 3, 15, 14, 8 }
}

; Function Attrs: nounwind readnone
declare i8 @llvm.ctpop.i8(i8) #0

declare void @__asm_outsb(i16, i8) local_unnamed_addr

declare i32 @unknown_8e0048b0() local_unnamed_addr

declare i32 @unknown_48b604() local_unnamed_addr

declare i32 @unknown_4b353338() local_unnamed_addr

declare i16* @__decompiler_undefined_function_0() local_unnamed_addr

declare i8* @__decompiler_undefined_function_1() local_unnamed_addr

declare i1 @__decompiler_undefined_function_2() local_unnamed_addr

declare i32 @__decompiler_undefined_function_3() local_unnamed_addr

declare i8 @__decompiler_undefined_function_4() local_unnamed_addr

declare i16 @__decompiler_undefined_function_5() local_unnamed_addr

declare i64 @__decompiler_undefined_function_6() local_unnamed_addr

; Function Attrs: noreturn nounwind
declare void @llvm.trap() #1

attributes #0 = { nounwind readnone }
attributes #1 = { noreturn nounwind }
